[{"categories":["Tutoriais"],"content":"Uma das características mais poderosas da linguagem Go é seu modelo de concorrência nativo, centrado no conceito de goroutines. Enquanto outras linguagens dependem de bibliotecas externas ou de complexos sistemas de threads do sistema operacional, Go traz a concorrência como cidadã de primeira classe.","date":"2025-10-25","objectID":"/posts/go-routines-o-que-sao-e-como-utilizar/","tags":["Golang","Goroutines","Google"],"title":"Goroutines - O que são e como utilizar","uri":"/posts/go-routines-o-que-sao-e-como-utilizar/"},{"categories":["Tutoriais"],"content":"Uma das características mais poderosas da linguagem Go é seu modelo de concorrência nativo, centrado no conceito de goroutines. Enquanto outras linguagens dependem de bibliotecas externas ou de complexos sistemas de threads do sistema operacional, Go traz a concorrência como cidadã de primeira classe. Que tal voltar um pouco? Se você ainda não conhece muito sobre esta magnífica linguagem de programação criada pelo Google, sinta-se convidado a voltar um pouco no tempo e conferir posts que escrevi anteriormente: Go Ou Go!, Linguagem Do Google Cria Primeira Intriga Go Ou Golang: Porquê Adotei Go Como Minha Linguagem Favorita ","date":"2025-10-25","objectID":"/posts/go-routines-o-que-sao-e-como-utilizar/:0:0","tags":["Golang","Goroutines","Google"],"title":"Goroutines - O que são e como utilizar","uri":"/posts/go-routines-o-que-sao-e-como-utilizar/"},{"categories":["Tutoriais"],"content":"Introdução Goroutines são importantes porque permitem que os programas executem tarefas simultaneamente de forma eficiente, aproveitando melhor os recursos do processador. Elas são mais leves que as threads do sistema operacional, com baixo custo de criação e gerenciamento, o que possibilita a execução de milhares delas e facilita a criação de softwares concorrentes e de alta performance. ","date":"2025-10-25","objectID":"/posts/go-routines-o-que-sao-e-como-utilizar/:1:0","tags":["Golang","Goroutines","Google"],"title":"Goroutines - O que são e como utilizar","uri":"/posts/go-routines-o-que-sao-e-como-utilizar/"},{"categories":["Tutoriais"],"content":"O que são Goroutines? Goroutines são funções ou métodos que são executados concorrentemente com outras funções. Elas são threads leves gerenciadas pelo runtime do Go, não pelo sistema operacional. ","date":"2025-10-25","objectID":"/posts/go-routines-o-que-sao-e-como-utilizar/:2:0","tags":["Golang","Goroutines","Google"],"title":"Goroutines - O que são e como utilizar","uri":"/posts/go-routines-o-que-sao-e-como-utilizar/"},{"categories":["Tutoriais"],"content":"Características e Vantagens Principais: Leves: Consomem apenas 2KB de stack inicialmente (comparado com 1-2MB de threads no SO); Gerenciadas pelo Go runtime: Escalonadas pelo próprio Go, não pelo SO. O Go runtime as aloca utilizando um mecanismo chamado Go scheduler (agendador); Eficientes: Você pode criar milhares sem impactar performance, o que as torna baratas por tempo de execução; Execução concorrente: Quando você executa go minhaFuncao(), a função minhaFuncao começa a ser executada em segundo plano, enquanto o restante do programa continua; Compartilhamento de memória: Goroutines rodam no mesmo espaço de endereço, o que significa que elas podem acessar a mesma memória. Sincronização: Para evitar problemas como condições de corrida (race conditions), o Go oferece mecanismos de sincronização como channels e WaitGroups; Channels: Permitem que goroutines se comuniquem de forma segura, enviando dados de uma para outra; WaitGroups: Permitem que você espere que um conjunto de goroutines termine antes de continuar. ","date":"2025-10-25","objectID":"/posts/go-routines-o-que-sao-e-como-utilizar/:2:1","tags":["Golang","Goroutines","Google"],"title":"Goroutines - O que são e como utilizar","uri":"/posts/go-routines-o-que-sao-e-como-utilizar/"},{"categories":["Tutoriais"],"content":"Como Funcionam Go implementa um modelo M:N onde: M goroutines são multiplexadas em N threads do sistema operacional; O scheduler do Go gerencia essa distribuição automaticamente; Utiliza o conceito de channel para comunicação segura entre goroutines; O modelo M:N O modelo de threading M:N trás uma abordagem inovadora, que redefine a maneira como a simultaneidade é gerenciada em linguagens de programação. Em essência, o modelo M:N mapeia dinamicamente um conjunto de threads de nível de kernel, permitindo uma alocação flexível e adaptável de recursos. Ao contrário dos modelos de threading tradicionais, em que a relação entre threads de nível de usuário e threads de nível de kernel é fixa (N:1), o modelo M:N otimiza a utilização de recursos ajustando dinamicamente o mapeamento com base na carga de trabalho e nas condições do sistema. ","date":"2025-10-25","objectID":"/posts/go-routines-o-que-sao-e-como-utilizar/:2:2","tags":["Golang","Goroutines","Google"],"title":"Goroutines - O que são e como utilizar","uri":"/posts/go-routines-o-que-sao-e-como-utilizar/"},{"categories":["Tutoriais"],"content":"Exemplos Práticos ","date":"2025-10-25","objectID":"/posts/go-routines-o-que-sao-e-como-utilizar/:3:0","tags":["Golang","Goroutines","Google"],"title":"Goroutines - O que são e como utilizar","uri":"/posts/go-routines-o-que-sao-e-como-utilizar/"},{"categories":["Tutoriais"],"content":"Exemplo 1: Programa Síncrono vs Concorrente Repare que no exemplo a seguir, ambas as funções fazem exatamente a mesma coisa: Recebem uma string nome como argumento; Entram em um loop que executa 3 passos; Em cada passo, imprimem o nome da tarefa e o número do passo; Pausam a execução por 1 segundo (time.Sleep(1 * time.Second)) para simular uma tarefa que leva tempo; Elas são idênticas em conteúdo, mas são chamadas de maneiras diferentes na função main. package main // Importa o pacote fmt para formatação de I/O (impressão) // e o pacote time para medir o tempo e pausar a execução import ( \"fmt\" \"time\" ) // Versão síncrona func tarefaSincrona(nome string) { for i := 1; i \u003c= 3; i++ { fmt.Printf(\"%s: passo %d\\n\", nome, i) time.Sleep(1 * time.Second) } } // Versão concorrente func tarefaConcorrente(nome string) { for i := 1; i \u003c= 3; i++ { fmt.Printf(\"%s: passo %d\\n\", nome, i) time.Sleep(1 * time.Second) } } func main() { fmt.Println(\"=== Versão Síncrona ===\") inicio := time.Now() tarefaSincrona(\"Tarefa A\") tarefaSincrona(\"Tarefa B\") fmt.Printf(\"Tempo total: %v\\n\", time.Since(inicio)) fmt.Println(\"\\n=== Versão Concorrente ===\") inicio = time.Now() go tarefaConcorrente(\"Tarefa C\") // 'go' cria uma goroutine go tarefaConcorrente(\"Tarefa D\") // outra goroutine time.Sleep(4 * time.Second) // espera as goroutines terminarem fmt.Printf(\"Tempo total: %v\\n\", time.Since(inicio)) } O resultado da execução deste código será o seguinte: === Versão Síncrona === Tarefa A: passo 1 Tarefa A: passo 2 Tarefa A: passo 3 Tarefa B: passo 1 Tarefa B: passo 2 Tarefa B: passo 3 Tempo total: 6s === Versão Concorrente === Tarefa C: passo 1 Tarefa D: passo 1 Tarefa C: passo 2 Tarefa D: passo 2 Tarefa C: passo 3 Tarefa D: passo 3 Tempo total: 3s Podemos perceber que a versão Concorrente (utiilizando Goroutines) levou a metade do tempo. Execução Síncrona: O Go executa a tarefaSincrona(\"Tarefa A\") completamente antes de começar a tarefaSincrona(\"Tarefa B\"). Como cada tarefa leva 3 segundos (3 passos de 1 segundo cada), o tempo total de execução será de aproximadamente 6 segundos (3 segundos para A + 3 segundos para B). As tarefas esperam a anterior terminar antes de iniciar. Execução Concorrente: O uso da palavra-chave go antes da chamada da função transforma a execução em uma goroutine. Uma goroutine é um thread leve gerenciado pelo runtime do Go, permitindo que as tarefas rodem concorrentemente (aparentemente ao mesmo tempo). Tarefa C e Tarefa D são iniciadas quase que instantaneamente e rodam lado a lado. A linha time.Sleep(4 * time.Second) é crucial na execução concorrente aqui. A função principal (main) de um programa Go não espera que as goroutines terminem. Se o main terminasse imediatamente, as goroutines Tarefa C e Tarefa D seriam interrompidas antes de concluir. Este sleep força a função main a esperar 4 segundos, dando tempo suficiente (cada tarefa leva 3 segundos) para que ambas as tarefas concorrentes terminem. (Alerta de Spoiler: No Exemplo 3 veremos uma solução melhor para isto.) Como as tarefas rodam concorrentemente, a duração total é determinada pela tarefa mais longa. Ambas levam 3 segundos, então o tempo total de execução será de aproximadamente 3 a 4 segundos. As tarefas se intercalam e trabalham em paralelo, reduzindo o tempo total. A saída no console mostrará as mensagens de “Tarefa C” e “Tarefa D” misturadas/intercaladas. ","date":"2025-10-25","objectID":"/posts/go-routines-o-que-sao-e-como-utilizar/:3:1","tags":["Golang","Goroutines","Google"],"title":"Goroutines - O que são e como utilizar","uri":"/posts/go-routines-o-que-sao-e-como-utilizar/"},{"categories":["Tutoriais"],"content":"Exemplo 2: Usando Channels para Comunicação Este código é um exemplo clássico de Pool de Workers usando Goroutines e Channels para implementar um padrão de concorrência. Ele permite que você execute várias tarefas simultaneamente de forma eficiente. De forma resumida, temos uma fila de tarefas (jobs) e um grupo de trabalhadores (workers) que pegam e processam essas tarefas em paralelo, depositando os resultados em outra fila (results). package main import ( \"fmt\" \"time\" ) // Goroutine que envia dados para um channel func worker(id int, jobs \u003c-chan int, results chan\u003c- int) { for j := range jobs { fmt.Printf(\"Worker %d processando job %d\\n\", id, j) time.Sleep(1 * time.Second) // Simula trabalho results \u003c- j * 2 // Envia resultado } } func main() { const numJobs = 5 jobs := make(chan int, numJobs) results := make(chan int, numJobs) // Inicia 3 workers for w := 1; w \u003c= 3; w++ { go worker(w, jobs, results) } // Envia jobs for j := 1; j \u003c= numJobs; j++ { jobs \u003c- j } close(jobs) // Coleta resultados for a := 1; a \u003c= numJobs; a++ { resultado := \u003c-results fmt.Printf(\"Resultado recebido: %d\\n\", resultado) } } No código acima, Channels são o meio pelo qual as goroutines se comunicam. Eles podem ser vistos como filas ou tubos por onde os dados são enviados e recebidos. jobs := make(chan int, numJobs): Este é o canal de tarefas. É um canal de inteiros. O \u003c—chan int na função worker indica que o canal é somente para receber (jobs). results := make(chan int, numJobs): Este é o canal de resultados. O chan—\u003e int na função worker indica que o canal é somente para enviar (results). Ambos são criados com buffer (capacidade para 5 itens), o que significa que podem armazenar até 5 valores antes que o remetente precise esperar o receptor. Já os Workers ou trabalhadores… As Goroutines são os lightweight workers (trabalhadores leves) do Go. A função worker é o código que cada trabalhador executa. O bloco que inicia os workers: for w := 1; w \u003c= 3; w++ { go worker(w, jobs, results) } Isto inicia 3 goroutines independentes (Workers 1, 2 e 3) que rodarão concorrentemente. ","date":"2025-10-25","objectID":"/posts/go-routines-o-que-sao-e-como-utilizar/:3:2","tags":["Golang","Goroutines","Google"],"title":"Goroutines - O que são e como utilizar","uri":"/posts/go-routines-o-que-sao-e-como-utilizar/"},{"categories":["Tutoriais"],"content":"Exemplo 3: WaitGroup para Sincronização O código a seguir exemplifica a utilização do pacote sync, especificamente o tipo sync.WaitGroup, para gerenciar e sincronizar a execução de múltiplas goroutines. Ele resolve o problema de garantir que a função principal (main) espere que todas as tarefas concorrentes terminem antes de encerrar o programa. Se lembrarmos bem, no Exemplo 1 utilizamos time.Sleep() na função main para esperar pelas goroutines, o que é uma solução ruim e imprecisa. O sync.WaitGroup oferece a solução correta e robusta. package main import ( \"fmt\" \"sync\" \"time\" ) func download(site string, wg *sync.WaitGroup) { defer wg.Done() // Marca como concluído ao final fmt.Printf(\"Iniciando download de %s\\n\", site) time.Sleep(2 * time.Second) // Simula download fmt.Printf(\"Download de %s concluído\\n\", site) } func main() { var wg sync.WaitGroup sites := []string{\"site1.com\", \"site2.com\", \"site3.com\", \"site4.com\"} for _, site := range sites { wg.Add(1) // Incrementa o contador go download(site, \u0026wg) } fmt.Println(\"Aguardando downloads...\") wg.Wait() // Espera todas as goroutines terminarem fmt.Println(\"Todos downloads concluídos!\") } O WaitGroup é essencialmente um contador interno que você gerencia com três métodos: wg.Add(n int): Adiciona n ao contador do WaitGroup. Chamamos isso antes de iniciar uma nova goroutine para avisar que há mais uma tarefa a ser esperada. wg.Done(): Subtrai 1 do contador. É tipicamente chamado ao final da goroutine (frequentemente usando defer). wg.Wait(): Bloqueia a execução da goroutine que o chamou (neste caso, a main) até que o contador do WaitGroup chegue a zero. Em resumo, o código executa os 4 downloads concorrentemente. Em vez de levar 8 segundos (4 sites vezes 2 segundos cada, sequencialmente), o tempo total de execução será de aproximadamente 2 segundos, pois todas as tarefas de download rodam ao mesmo tempo. A saída no console mostrará as mensagens de “Iniciando download” e “Download… concluído” intercaladas. O WaitGroup é a forma idiomática e mais segura no Go para esperar por um conjunto de goroutines. ","date":"2025-10-25","objectID":"/posts/go-routines-o-que-sao-e-como-utilizar/:3:3","tags":["Golang","Goroutines","Google"],"title":"Goroutines - O que são e como utilizar","uri":"/posts/go-routines-o-que-sao-e-como-utilizar/"},{"categories":["Tutoriais"],"content":"Conclusão Goroutines tornam a concorrência acessível e eficiente em Go. Combinadas com channels para comunicação e sync primitives (como waitgroup) para coordenação, elas formam uma base sólida para construir sistemas concorrentes robustos. Principais vantagens:  Fácil de usar (apenas adicione go antes da função)  Eficiente em memória e CPU  Integração nativa com channels  Gerenciamento automático pelo runtime Até a próxima. ","date":"2025-10-25","objectID":"/posts/go-routines-o-que-sao-e-como-utilizar/:4:0","tags":["Golang","Goroutines","Google"],"title":"Goroutines - O que são e como utilizar","uri":"/posts/go-routines-o-que-sao-e-como-utilizar/"},{"categories":["Tutoriais"],"content":"Que tal criar a infraesturtura e sua função lambda de forma simples e dinâmica com poucos comandos? O Serverless é um framework que abstrai tudo isto de forma uq epossamos focar apenas em nosso código.","date":"2023-12-17","objectID":"/posts/criando-funcoes-lambda-facilmente-com/","tags":["Devops","AWS","Serverless","Python","Cloud","CloudFormation","Lambda"],"title":"Criando Funções Lambda Facilmente Com O Framework Serverless","uri":"/posts/criando-funcoes-lambda-facilmente-com/"},{"categories":["Tutoriais"],"content":"Que tal criar a infraesturtura e sua função lambda de forma simples e dinâmica com poucos comandos? O Serverless é um framework que abstrai tudo isto de forma uq epossamos focar apenas em nosso código. ","date":"2023-12-17","objectID":"/posts/criando-funcoes-lambda-facilmente-com/:0:0","tags":["Devops","AWS","Serverless","Python","Cloud","CloudFormation","Lambda"],"title":"Criando Funções Lambda Facilmente Com O Framework Serverless","uri":"/posts/criando-funcoes-lambda-facilmente-com/"},{"categories":["Tutoriais"],"content":"Serverless Framework - O que é e para que serve Entregue software com bem menos trabalho! Sim, é uma afirmação forte. Não, não sou eu quem o está dizendo. É literalmente a primeira frase que podemos encontrar na página de documentação do Framework Serverless. Embora não seja minha, concordo completamente com esta afirmação. Utilizando o framework Serverless eu realmente consigo entregas mais rápidas, passando por todo o ciclo de desenvolvimento e testes, abstraindo a parte que geralmente não nos interessa tanto: a infraestrutura. Não estou menosprezando a infraestrutura, obviamente. Sempre trabalhei com infraestrutura e entendo bem a importância de uma infraestrutura bem projetada e configurada, mas quando falamos em um mundo moderno e na nuvem, principalmente em soluções serverless como é o caso de lambda functions ou funções lambda, está claro que o nosso objetivo principal é o código da aplicação em si, e não a infraestrutura. O Serverless nos ajuda justamente neste propósito, abstraindo e automatizando toda a infraestutrura que é necessária para rodarmos nossa lambda: IAM, cloudformation, Lambda em si, etc. Desta forma podemos dedicar a maior parte do nosso tempo de fato em nosso código. E a melhor parte, isto não compromete a segurança ou estabilidade da infraestrutura, já que o framework Serverless estará sempre seguindo as melhores práticas ao abstrair esta camada. Além de facilitar o processo de desenvolvimento e entrega ou deployment de nossa função lambda, o Serverless framework possui suporte à diversas linguagens, assim como o AWS Lambda: Node.js, Python, Java, Go, C#, Ruby, Swift, Kotlin, PHP, Scala e F#. ","date":"2023-12-17","objectID":"/posts/criando-funcoes-lambda-facilmente-com/:1:0","tags":["Devops","AWS","Serverless","Python","Cloud","CloudFormation","Lambda"],"title":"Criando Funções Lambda Facilmente Com O Framework Serverless","uri":"/posts/criando-funcoes-lambda-facilmente-com/"},{"categories":["Tutoriais"],"content":"Mas o que é serverless? Aqui é preciso diferenciar um pouco o conceito de serverless e o Framework Serverless. O conceito serverless, ou sem servidor quando traduzimos ao pé da letra, indica um modelo de desenvolvimento nativo na núvem (cloud-native). Isto quer dizer que o foco do desenvolvimento é 100% na aplicação, de forma que você não gerenciará a infraestrutura necessária para rodar sua aplicação. A ideia é você não precisar se preocupar em gerenciar/criar servidores, por exemplo. Sim, ainda existirão servidores que serão responsáveis por rodar a sua aplicação, obviamente, mas você não lidará com eles diretamente. Estes serão gerenciados por serviços na nuvem de sua escolha, como AWS, GCP, Azure, etc. O provedor de nuvem (cloud) cuidará desta parte de forma que você nem sequer saberá onde fisicamente está o seu servidor assim como não precisará ter acesso ao mesmo remotamente ou preocupar-se com as configurações do mesmo. Foco 100% na sua aplicação. ","date":"2023-12-17","objectID":"/posts/criando-funcoes-lambda-facilmente-com/:2:0","tags":["Devops","AWS","Serverless","Python","Cloud","CloudFormation","Lambda"],"title":"Criando Funções Lambda Facilmente Com O Framework Serverless","uri":"/posts/criando-funcoes-lambda-facilmente-com/"},{"categories":["Tutoriais"],"content":"Instalação do Serverless Framework IMPORTANTE: O meu objetivo com este post não é explicar sobre Lambda functions, mas sim como criá-las com o framework Serverless. Caso esteja buscando informações mais focadas em Lambda Functions em si, sugiro que confira um outro post que publiquei anteriormente onde o foco era a criação de uma função Lambda utilizando a linguagem GO para interagir com S3 Buckets no AWS: Criando Uma Lambda Function Com Golang Qur Interage Com S3 Buckets. A forma mais simples de instalar o serverless framework é através do npm. Caso não possua ainda Node.js instalado em sua máquina, você precisará instalá-lo antes de instalar o serverless com o npm: Node.js. ➜ npm install -g serverless Alternativamente, caso prefira instalar o Serverless sem o npm, você poderá utilizar o binário diretamente: Binário Serverless. ","date":"2023-12-17","objectID":"/posts/criando-funcoes-lambda-facilmente-com/:3:0","tags":["Devops","AWS","Serverless","Python","Cloud","CloudFormation","Lambda"],"title":"Criando Funções Lambda Facilmente Com O Framework Serverless","uri":"/posts/criando-funcoes-lambda-facilmente-com/"},{"categories":["Tutoriais"],"content":"Uso básico do Serverless Framework Uma vez que o Serverless já esteja instalado e disponível, a primeira coisa que precisamos fazer é definir as credenciais com as quais trabalharemos em nosso projeto. No console IAM do AWS, crie um novo usuário e, apenas para facilitar seu estudo inicial, inclua Acesso de Administrador ao seu novo usário. (Não entrarei em detalhes aqui sobre como criar um usuário no IAM pois assumo que se você está criando funções lambda, provavelmente já sabe fazer isso. Caso não, siga as instruções da Amazon aqui.) Com seu usuário já criado e com permissões de administrador, copie a chave de acesso (access key) e a senha da chave de acesso (secret access key) do seu novo usuário, como na imagem a seguir: Utilizaremos estas credenciais para configurar nosso framework Serverless. Em seu terminal digite: ➜ serverless config credentials --provider aws --key \u003csua-chave-de-acesso\u003e --secret \u003csua-senha-da-chave-de-acesso\u003e --profile serverlessUser Para criarmos nosso primeiro projeto podemos utilizar duas formas distintas de interação com o Serverless. A primeira é através do menu interativo do Serverless. Desta forma, apenas responderemos as perguntas que o Serverless nos fará. Digite serverless e um menu lhe será apresentado onde definiremos o nosso projeto: ➜ serverless Creating a new serverless project ? What do you want to make? ❯ AWS - Node.js - Starter AWS - Node.js - HTTP API AWS - Node.js - Scheduled Task AWS - Node.js - SQS Worker AWS - Node.js - Express API AWS - Node.js - Express API with DynamoDB AWS - Python - Starter AWS - Python - HTTP API AWS - Python - Scheduled Task AWS - Python - SQS Worker AWS - Python - Flask API AWS - Python - Flask API with DynamoDB Other No menu acima escolheremos a opção AWS - Python - Starter para esta demonstração, já que Python é uma de minhas linguagens favoritas, mas perceba que temos muitas opções disponíveis e se escolhermos Other outras linguagens serão apresentadas também. Ao selecionarmos AWS - Python - Starter o Serverless criará o diretório de nosso projeto já com um template para Python que funcionará de imediato com AWS Lambda Functions. Mas antes de isto tudo acontecer, ele nos perguntará mais alguns detalhes, portanto vamos selecionar Python e seguir em frente. A pergunta seguinte será qual nome você deseja dar para seu projeto. Aqui utilizarei primeiro-teste-serverless: ➜ serverless Creating a new serverless project ? What do you want to make? AWS - Python - Starter ? What do you want to call this project? primeiro-teste-serverless Repare que ao pressionar enter o Serverless começará o download e criação dos templates: ➜ serverless Creating a new serverless project ? What do you want to make? AWS - Python - Starter ? What do you want to call this project? primeiro-teste-serverless ✔ Project successfully created in primeiro-teste-serverless folder ? Register or Login to Serverless Framework (Y/n) Ele lhe perguntará se você deseja se cadastrar ou logar no serviço Serverless. Por hora você não precisa fazer isso, portanto apenas selecionei n e segui em frente. A pergunta seguinte será se você deseja efetuar o deployment de seu projeto. Vamos selecionar n por enquanto para que possamos verificar nosso projeto antes de fazermos o primeiro deployment. ➜ serverless Creating a new serverless project ? What do you want to make? AWS - Python - Starter ? What do you want to call this project? primeiro-teste-serverless ✔ Project successfully created in primeiro-teste-serverless folder ? Register or Login to Serverless Framework No ? Do you want to deploy now? No What next? Run these commands in the project directory: serverless deploy Deploy changes serverless info View deployed endpoints and resources serverless invoke Invoke deployed functions serverless --help Discover more commands Perceba que ignoramos o deployment inicial mas o Serverless já nos indicou que comandos podemos utilizar para fazer o deployment, pegar informações, invocar, etc. Repare que um diretório","date":"2023-12-17","objectID":"/posts/criando-funcoes-lambda-facilmente-com/:4:0","tags":["Devops","AWS","Serverless","Python","Cloud","CloudFormation","Lambda"],"title":"Criando Funções Lambda Facilmente Com O Framework Serverless","uri":"/posts/criando-funcoes-lambda-facilmente-com/"},{"categories":["Tutoriais"],"content":"Fazendo uma pequena customização Vamos fazer uma pequena alteração no template padrão que nos foi entregue. Primeiramente vamos editar nosso arquivo serverless.yml da seguinte forma: serverless.yml service: primeiro-teste-serverless frameworkVersion: '3' provider: name: aws runtime: python3.11 functions: hello: handler: handler.hello A única alteração que fizemos aqui foi na linha 6, onde alteramos a versão do Python. Vamos utilizar uma versão mais atual do Python, 3.11, ao invés da versão 3.9 que estávamos utilizando antes. (Dependendo de quando você estiver lendo isto, a versão padrão que poderá vir em seu template poderá ser diferente). Agora vamos modificar um pouco nosso arquivo handler.py: handler.py import json def hello(event, context): cumprimento = json.dumps('Olá, diretamente da sua função Lambda!') print(\"Minha primeira função AWS Lambda com Python!\") return { 'statusCode': 200, 'body': cumprimento.encode('utf-8').decode('unicode-escape') } As linhas marcadas são nossas alterações. Basicamente recriamos todo o corpo de nossa função hello para que possamos desta vez receber uma mensagem um pouco mais customizada em caso de execução com sucesso, ou seja, com status 200. Vamos fazer um novo deployment de nosso projeto com sls deploy: ➜ sls deploy Deploying primeiro-teste-serverless to stage dev (us-east-1) ⠼ Creating CloudFormation stack (2s) ⠼ Creating CloudFormation stack (0/2) (15s) ⠋ Updating CloudFormation stack (46s) ✔ Service deployed to stack primeiro-teste-serverless-dev (90s) functions: hello: primeiro-teste-serverless-dev-hello (1.7 kB) Need a faster logging experience than CloudWatch? Try our Dev Mode in Console: run \"serverless dev\" Novamente, podemos agora testar nossa função e confirmar que nosso deployment foi realizado com sucesso executando sls invoke -f hello –log: ➜ sls invoke -f hello --log { \"statusCode\": 200, \"body\": \"\\\"Olá, diretamente da sua função Lambda!\\\"\" } -------------------------------------------------------------------- START Minha primeira função AWS Lambda com Python! END Duration: 1.24 ms Memory Used: 41 MB Podemos ver claramente que nosso cumprimento foi impresso no body e também nossa frase Minha primeira função AWS Lambda com Python! foi retornada ao final. O céu é o limite quanto ao que você pode fazer com isto. Como qualquer código Python, você pode utilizar lambdas para múltiplas tarefas e automações, interações. Realmente as possibilidades são infinitas. ","date":"2023-12-17","objectID":"/posts/criando-funcoes-lambda-facilmente-com/:5:0","tags":["Devops","AWS","Serverless","Python","Cloud","CloudFormation","Lambda"],"title":"Criando Funções Lambda Facilmente Com O Framework Serverless","uri":"/posts/criando-funcoes-lambda-facilmente-com/"},{"categories":["Tutoriais"],"content":"O que é o Sceptre e como utilizar esta tecnologia para melhor gerenciamento de infraestruturas na nuvem AWS com CloudFormation.","date":"2022-03-12","objectID":"/posts/criando-infraestrutura-no-aws-com/","tags":["Devops","AWS","Sceptre","Python","Cloud","CloudFormation"],"title":"Criando Infraestrutura No Aws Com Sceptre","uri":"/posts/criando-infraestrutura-no-aws-com/"},{"categories":["Tutoriais"],"content":"O que é o Sceptre e como utilizar esta tecnologia para melhor gerenciamento de infraestruturas na nuvem AWS com CloudFormation. ","date":"2022-03-12","objectID":"/posts/criando-infraestrutura-no-aws-com/:0:0","tags":["Devops","AWS","Sceptre","Python","Cloud","CloudFormation"],"title":"Criando Infraestrutura No Aws Com Sceptre","uri":"/posts/criando-infraestrutura-no-aws-com/"},{"categories":["Tutoriais"],"content":"Sceptre? O que é isso? Sceptre é uma ferramenta de IaC ou Infraestrutura como Código (Infrastructure as Code). Se este termo ainda é novidade para você, sugiro uma lida em um post no qual explico o que é e quais as vantagens de se utilizar Infraestrutura como Código: Infraestrutura como Código com Terraform. Assim como o Terraform, o Sceptre nos ajuda a gerenciar infraestruturas no AWS de forma mais eficiente. Criado pela empresa CloudReach, o Sceptre possui algumas diferenças marcantes quando comparado ao Terraform. A primeira delas é que não se trata de uma ferramenta para gerenciamento de infraestrutura como código de forma generalista, ou seja, não pode ser utilizado para qualquer provedor de nuvem por exemplo. O Sceptre foi criado especificamente com o intuito de gerenciar infraestrutura no AWS. Além disso, o Sceptre não funciona de forma 100% autônoma, como no caso do Terraform que gerencia e manipula recursos na nuvem mantendo um arquivo (ou vários) para seu status. O Sceptre na verdade utiliza-se do já existente CloudFormation do AWS. Se você não conhece o CloudFormation, trata-se da solução nativa da Amazon para gerenciamento de infraestrutura na nuvem AWS utilizando-se de infraestrutura como código. Mas.. espera aí… algo está esquisito… Se o AWS já possui sua própria ferramenta nativa de infraestrutura como código, que é o CloudFormation… É compreensível o uso de Terraform como uma alternativa por ser um padrão mais genérico e que pode ser utilizado para todas as nuvens, não apenas o AWS. Mas o que justificaria utilizar o Sceptre ao invés do CloudFormation se por baixo ele acabará utilizando o CloudFormation? O Sceptre foi criado para gerenciar o CloudFormation, sim. Ninguém criaria algo apenas por criar, portanto o Sceptre veio com a proposta de lidar com algumas carências já existentes no CloudFormation. O Sceptre é capaz de criar, atualizar e deletar stacks ou conjuntos de recursos no AWS, além de fornecer informações mais detalhadas, metadata bem como recuperar facilmente tais dados. Criado em Python, o Sceptre pode ser utilizado como um comando CLI ou como um módulo Python, pronto para ser utilizado em ambientes de produção e enterprise e desenhado para ser executado como parte de pipelines de CI/CD. A principal motivação para a criação do Sceptre foi o fato de o CloudFormation não possuir recursos mais robustos para gerenciamento de stacks ou conjuntos de recursos, enquanto que a CLI padrão do AWS bem como a biblioteca Boto3 para Python oferecem alguns destes recursos, mas ainda assim nenhuma delas disponibiliza: Links entre a saída de uma stack com parâmetros de outra stack; Facilidade para se trabalhar com roles ou mesmo com múltiplas contas do AWS; Sem mais lenga lenga, vamos ao que interessa. ","date":"2022-03-12","objectID":"/posts/criando-infraestrutura-no-aws-com/:1:0","tags":["Devops","AWS","Sceptre","Python","Cloud","CloudFormation"],"title":"Criando Infraestrutura No Aws Com Sceptre","uri":"/posts/criando-infraestrutura-no-aws-com/"},{"categories":["Tutoriais"],"content":"Instalação As duas formas mais simples de se utilizar o Sceptre são via docker ou instalando via Pip. Sinta-se livre para utilizar a forma que mais lhe agradar. Ao longo do post estarei utilizando o sceptre instalado localmente através do pip, mas os passos deverão funcionar via docker também caso prefira este método. ","date":"2022-03-12","objectID":"/posts/criando-infraestrutura-no-aws-com/:2:0","tags":["Devops","AWS","Sceptre","Python","Cloud","CloudFormation"],"title":"Criando Infraestrutura No Aws Com Sceptre","uri":"/posts/criando-infraestrutura-no-aws-com/"},{"categories":["Tutoriais"],"content":"Utilizando Docker Esta opção assume que você já possua o Docker instalado. Baixe a imagem Docker do Sceptre da seguinte forma: ➜ docker pull cloudreach/sceptre Caso queira baixar alguma versão em específico, inclua a versão desejada ao seu comando: ➜ docker pull cloudreach/sceptre:2.1.3 Deixando em branco ele buscará a última versão disponível (latest). Podemos testar o Sceptre via Docker utilizando o comando a seguir para vermos a versão do Sceptre utilizada. ➜ docker run cloudreach/sceptre:latest --version Sceptre, version 3.0.0 Sim, o container Docker é iniciado, executa o que pedimos e se encerra em seguida. Oi, simples assim. Vale lembrar que será necessário sempre montar o seu diretório local em seu container docker para que o sceptre executado no container tenha acesso ao seu código, portanto para cada comando que executaremos a seguir você utilizaria algo similar a isto: docker run -v $(pwd):/project -v ~/.aws/:/root/.aws/:ro cloudreach/sceptre:latest ","date":"2022-03-12","objectID":"/posts/criando-infraestrutura-no-aws-com/:2:1","tags":["Devops","AWS","Sceptre","Python","Cloud","CloudFormation"],"title":"Criando Infraestrutura No Aws Com Sceptre","uri":"/posts/criando-infraestrutura-no-aws-com/"},{"categories":["Tutoriais"],"content":"Utilizando Pip Esta opção assume que você já possua o Python e o Pip instalados. Sendo uma ferramenta Python, podemos intalar o sceptre com o pip: ➜ pip install sceptre Em seguida podemos confirmar a versão do sceptre instalada: ➜ sceptre --version ","date":"2022-03-12","objectID":"/posts/criando-infraestrutura-no-aws-com/:2:2","tags":["Devops","AWS","Sceptre","Python","Cloud","CloudFormation"],"title":"Criando Infraestrutura No Aws Com Sceptre","uri":"/posts/criando-infraestrutura-no-aws-com/"},{"categories":["Tutoriais"],"content":"Utilizando o Sceptre ","date":"2022-03-12","objectID":"/posts/criando-infraestrutura-no-aws-com/:3:0","tags":["Devops","AWS","Sceptre","Python","Cloud","CloudFormation"],"title":"Criando Infraestrutura No Aws Com Sceptre","uri":"/posts/criando-infraestrutura-no-aws-com/"},{"categories":["Tutoriais"],"content":"Autenticação com o AWS O Sceptre utilizará os mesmos arquivos de configuração utilizados pela CLI do AWS para autenticar-se, portanto este post assume que você já possui também o AWS CLI instalado e configurado em sua máquina. Caso você ainda não possua, siga os passos descritos aqui para instalar e configurar o seu AWS CLI: Instalação do AWS CLI Configuração do AWS CLI Você pode testar seu AWS CLI através do seguinte comando: ➜ aws sts get-caller-identity { \"UserId\": \"ABLABLABLABLABLABLADH\", \"Account\": \"6777777777775\", \"Arn\": \"arn:aws:iam::6777777777775:user/marcelo\" } Se você recebeu um retorno similar a este, informando o ID do seu usuário AWS, o ID de sua conta AWS e o ARN de seu uruário, significa que seu AWS CLI está devidamente configurado e conseguindo autenticar e se comunicar com o AWS. ","date":"2022-03-12","objectID":"/posts/criando-infraestrutura-no-aws-com/:3:1","tags":["Devops","AWS","Sceptre","Python","Cloud","CloudFormation"],"title":"Criando Infraestrutura No Aws Com Sceptre","uri":"/posts/criando-infraestrutura-no-aws-com/"},{"categories":["Tutoriais"],"content":"Iniciando com o Sceptre Agora que sabemos que o Sceptre já conseguirá autenticar-se com o AWS vamos iniciar a configuração básica de nossa infraestrutura. O Sceptre utiliza uma árvore ou estrutura de diretórios seguindo o padrão a seguir: meu-projeto-sceptre ├── config │ └── config.yaml └── templates Basicamente a estrutura mais simples é com o diretório principal de seu projeto e dentro dele dois diretórios, sendo um deles para as configurações e o outro para os templates. O Sceptre pode criar esta árvore de diretórios automaticamente ao criarmos um novo projeto. Para isto utilizaremos o comando sceptre new project. Perceba que ele lhe pedirá que indique a região na qual deseja o seu projeto. Esta seria a região a ser utilizada no AWS para a sua infraestrutura. No meu caso estou utilizando ca-central-1, pois é onde moro. Sinta-se livre para usar a região de sua preferência, como por exemplo sa-east-1 (para São Paulo, Brasil). A lista de regiões pode ser encontrada aqui: Lista de Regiões AWS. Em seguida o Sceptre lhe pedirá um código para o projeto, pode deixar em branco: ➜ sceptre new project meu-projeto-sceptre Please enter a region []: ca-central-1 Please enter a project_code [meu-projeto-sceptre]: Podemos confirmar a criação do diretório de nosso projeto, bem como os dois sub-diretórios: ➜ ls meu-projeto-sceptre config templates Agora que temos nosso projeto criado, podemos começar a inserir nosso código de fato. Verifcando o que foi criado pelo Sceptre automaticamente veremos que o diretório de templates está vazio, mas o diretório de config possui um arquivo padrão config.yaml com o seguinte conteúdo: project_code: meu-projeto-sceptre region: ca-central-1 O diretório config é onde manteremos as configurações de nossas stacks e o diretório templates é onde manteremos os arquivos de template do CloudFormation. Vamos iniciar criando um stack chamado test e iniciaremos criando uma VPC nesta stack, visto que VPCs são geralmente o nosso ponto de partida em uma nuvem já que todo e qualquer recurso deve ser criado em uma VPC. Criaremos um diretório chamado test dentro do diretório config. Sinta-se livre para criá-lo da forma que preferir. Em Linux ou OS X(mac) podemos fazer isto através do comando mkdir executado dentro do diretório de nosso projeto, meu-projeto-sceptre: ➜ mkdir config/test ➜ ls config config.yaml test Em seguida vamos criar o arquivo de configuração de nossa stack test, o arquivo de configuração de nossa VPC e também o template de nossa vpc: ➜ touch config/test/config.yaml config/test/vpc.yaml templates/vpc.yaml A nossa árvore de diretórios e arquivos deverá estar da seguinte forma: ➜ tree . . ├── config │ ├── config.yaml │ └── test │ ├── config.yaml │ └── vpc.yaml └── templates └── vpc.yaml 3 directories, 4 files Nestes arquivos teremos: templates/vpc.yaml: o template CloudFormation de nossa VPC config/test/vpc.yaml: as configurações referentes a este template de VPC config/test/config.yaml: a configuração do ambiente Vamos iniciar pela configuração do nosso ambiente. Para isto daremos um código de projeto e a região na qual desejamos nossa infraestrutura. Vamos inserir o seguinte conteúdo no arquivo config/test/config.yaml: project_code: projeto-sceptre region: ca-central-1 Novamente, lembre-se de usar a região que melhor lhe sirva, não precisa utilizar a região canadense como estou utilizando aqui. Em seguida vamos inserir a configuração do template de nossa VPC no arquivo config/test/vpc.yaml: template: path: vpc.yaml type: file parameters: CidrBlock: 10.0.0.0/16 Repare que aqui temos dois blocos de código: template: definimos que template será usado com esta configuração. Indicamos que o path é vpc.yaml, pois este é o caminho referente ao nosso template de vpc que fica dentro do diretório de templates. parameters: aqui listamos parâmetros, que podem ser utilizados como variáveis para nosso template. Neste caso estamos utilizando apenas um parâmetro, que é o bloco de endereços IP de nossa VPC, o CidrBlock. ","date":"2022-03-12","objectID":"/posts/criando-infraestrutura-no-aws-com/:3:2","tags":["Devops","AWS","Sceptre","Python","Cloud","CloudFormation"],"title":"Criando Infraestrutura No Aws Com Sceptre","uri":"/posts/criando-infraestrutura-no-aws-com/"},{"categories":["Tutoriais"],"content":"Criando uma lambda function com golang que interage com s3 buckets do AWS","date":"2021-06-27","objectID":"/posts/criando-uma-lambda-function-com/","tags":["Devops","AWS","Lambda","Golang","Go","Microservices","Cloud"],"title":"Criando Uma Lambda Function Com Golang Que Interage Com S3 Buckets","uri":"/posts/criando-uma-lambda-function-com/"},{"categories":["Tutoriais"],"content":"Criando uma lambda function com golang que interage com s3 buckets do AWS ","date":"2021-06-27","objectID":"/posts/criando-uma-lambda-function-com/:0:0","tags":["Devops","AWS","Lambda","Golang","Go","Microservices","Cloud"],"title":"Criando Uma Lambda Function Com Golang Que Interage Com S3 Buckets","uri":"/posts/criando-uma-lambda-function-com/"},{"categories":["Tutoriais"],"content":"Go ou Golang Go, ou Golang, é uma linguagem de programação estaticamente tipificada, estrutural e com suporte nativo à concorrência. É uma linguagem compilada e desenvolvida pelo Google, mais especificamente por Robert Griesemer, Rob Pike e Ken Thompson. Go é uma linguagem sintaticamente similar ao C, com recursos de segurança para a memória, coleta de lixo, etc. Existem diversas razões pelas quais considero Golang a minha linguagem favorita, mas este não é o foco deste post. Caso tenha interesse, escrevi um outro post sobre o assunto: Go Ou Golang: Porquê Adotei Go Como Minha Linguagem Favorita Este post também não visa ensinar o básico sobre a linguagem Go, portanto assumo que você já possua familiaridade com a linguagem. A ideia é apenas apresentar um simples caso de uso no qual Go pode ser uma excelente escolha. Implementação de microserviços (microservices) ou soluções serverless, como no caso de Lambda Functions, no AWS. ","date":"2021-06-27","objectID":"/posts/criando-uma-lambda-function-com/:1:0","tags":["Devops","AWS","Lambda","Golang","Go","Microservices","Cloud"],"title":"Criando Uma Lambda Function Com Golang Que Interage Com S3 Buckets","uri":"/posts/criando-uma-lambda-function-com/"},{"categories":["Tutoriais"],"content":"Lambda Functions Aws Lambda é uma plataforma movida a eventos e serverless oferecida pelo AWS. É um serviço de computação em nuvem que executa códigos em resposta a eventos específicos e automaticamente gerencia o uso de recursos computacionais necessários para aquele código. Embora eu vá utilizar AWS Lambda neste exemplo, uma plataforma similar existe em quase todos os provedores de computação em nuvem (Cloud). No GCP (Google Cloud Platform), por exemplo, o serviço se chama Google Functions. No Microsoft Azure, se chama Microsoft Azure Functions, etc. Todos estes serviços possuem algo em comum: Suportam múltiplas linguagens de programação. No caso do AWS as linguagens hoje (Junho, 2021) suportadas são: Golang, Node.js, Python, Ruby, Java e .NET Core. A plataforma, por se tratar de uma solução serverless, não possui qualquer servidor ou sistema operacional que precise ser gerenciado por você. Toda a infraestrutura e camadas de SO são administradas e gerenciadas pelo seu provedor de Cloud. É a solução perfeita para desenvolvimento rápido quando se quer focar apenas em seu código e deixar que a plataforma de Cloud cuide das demais camadas. ","date":"2021-06-27","objectID":"/posts/criando-uma-lambda-function-com/:2:0","tags":["Devops","AWS","Lambda","Golang","Go","Microservices","Cloud"],"title":"Criando Uma Lambda Function Com Golang Que Interage Com S3 Buckets","uri":"/posts/criando-uma-lambda-function-com/"},{"categories":["Tutoriais"],"content":"Criando a nossa função O primeiro passo é criarmos a nossa função no AWS e para isso devemos ir ao menu de serviços do AWS e buscar por Lambda: Ao clicar em Lambda você será levado a uma janela similar à seguinte. Clique em Criar função (Create function). Na janela de criação, daremos um nome à nossa função e selecionaremos o Runtime ou executor de linguagem que queremos utilizar. Utilizarei o nome minhafuncaogolang e escolherei o Runtime Golang 1.x. No topo da janela você também terá opções de criação de sua função, mas como vamos criar o nosso código completamente do zero, vamos utilizar a primeira opção, Criar do Zero (Author from scratch). Caso você esteja utilizando o AWS em português, o título poderá ser um pouco diferente, mas a ideia será a mesma. Outro aspecto que gosto de selecionar é a região. Repare que no canto superior direito estou utilizando a região Canada Central 1 (Central). Por residir no Canada, esta é a região mais próxima de mim, portanto possuirá melhor performance. Embora para o exercício não vá fazer muita diferença, sinta-se livre para escolher qualquer região ou a que seja mais próxima de você. Nas configurações abaixo podemos optar por uma Role caso já saibamos que Role utilizaremos, mas podemos ignorar isto e deixar o padrão, para que o AWS crie uma automaticamente para nós. Agora nos resta apenas clicar em Criar função (Create function), no botão laranja no canto inferior direito. Após alguns segundos veremos a tela de configuração e administração de nossa função (function). Agora que já possuímos nossa função criada, chegou a hora divertida. Vamos escrever o código de nossa função. Já criei meu diretório minhafuncaogolang e agora criarei meu arquivo main.go. Como em qualquer código em Go, criaremos o nosso pacote com uma função main básica. package main func main() { } Até aqui temos apenas o início básico de nosso pacote. Por padrão, o AWS lambda espera que nosso pacote possua um handler, o qual será um método no código de nossa função que processará eventos. Quando nossa função é invocada ou executada, o Lambda rodará o método handler. Quando o handler finaliza sua execução ou retorna uma resposta, a função volta a ficar disponível para atender a outro evento ou requisição. Uma função lambda em Go requer o pacote github.com/aws/aws-lambda-go/lambda, portanto teremos de importá-lo também. A função main também é necessária, e será utilizada para chamar o nosso handler. Vamos incrementar um pouco mais nosso código: package main import ( \"github.com/aws/aws-lambda-go/lambda\" ) func main() { lambda.Start(handler) } func handler(bucket MeuBucket) (*s3.CreateBucketOutput, error) { } Agora que importamos github.com/aws/aws-lambda-go/lambda e criamos nosso handler que recebe um bucket e retorna um Output e um error, chamamos este handler a partir de nossa função main utilizando o pacote lambda fornecido pelo AWS. Indicamos que nosso handler retorna um CreateBucketOutput, o qual é padrão fornecido pela sdk Go do AWS. Mais detalhes podem ser encontrados aqui. Já que pretendemos utilizar o pacote S3 fornecido pelo AWS, devemos também importá-lo em nosso código. Além disso, para trabalharmos com o AWS devemos iniciar uma sessão, portanto criaremos uma variável para nossa sessão também. package main import ( \"github.com/aws/aws-lambda-go/lambda\" \"github.com/aws/aws-sdk-go/aws\" \"github.com/aws/aws-sdk-go/aws/session\" \"github.com/aws/aws-sdk-go/service/s3\" ) var ( sessaos3 *s3.S3 ) func main() { lambda.Start(handler) } func handler(bucket MeuBucket) (*s3.CreateBucketOutput, error) { } Como pretendemos criar um bucket no s3, criaremos um struct para nosso bucket, no qual passaremos um nome para o bucket que desejamos criar e uma região. package main import ( \"github.com/aws/aws-lambda-go/lambda\" \"github.com/aws/aws-sdk-go/aws\" \"github.com/aws/aws-sdk-go/aws/session\" \"github.com/aws/aws-sdk-go/service/s3\" ) var ( sessaos3 *s3.S3 ) type MeuBucket struct { NOME_BUCKET string `json:\"bucket\"` REGIAO string `json:\"r","date":"2021-06-27","objectID":"/posts/criando-uma-lambda-function-com/:3:0","tags":["Devops","AWS","Lambda","Golang","Go","Microservices","Cloud"],"title":"Criando Uma Lambda Function Com Golang Que Interage Com S3 Buckets","uri":"/posts/criando-uma-lambda-function-com/"},{"categories":["Tutoriais"],"content":"O GKE é a plataforma Kubernetes do GCP. Um ambiente simplificado que nos possibilita criar clusters rapidamente bem como o deployment de nossas aplicações sem a necessidade de lidarmos com a instalação do Kubernetes e seus serviços. Neste post faremos um simples deployment de cluster GKE utilizando o Terraform.","date":"2021-05-15","objectID":"/posts/criando-um-cluster-kubernetes-no/","tags":["Devops","Containers","Kubernetes","Docker","GCP","Cloud","Terraform"],"title":"Criando Um Cluster Kubernetes No Gcp Com Terraform","uri":"/posts/criando-um-cluster-kubernetes-no/"},{"categories":["Tutoriais"],"content":"O GKE é a plataforma Kubernetes do GCP. Um ambiente simplificado que nos possibilita criar clusters rapidamente bem como o deployment de nossas aplicações sem a necessidade de lidarmos com a instalação do Kubernetes e seus serviços. Neste post faremos um simples deployment de cluster GKE utilizando o Terraform. ","date":"2021-05-15","objectID":"/posts/criando-um-cluster-kubernetes-no/:0:0","tags":["Devops","Containers","Kubernetes","Docker","GCP","Cloud","Terraform"],"title":"Criando Um Cluster Kubernetes No Gcp Com Terraform","uri":"/posts/criando-um-cluster-kubernetes-no/"},{"categories":["Tutoriais"],"content":"GKE - Google Kubernetes Engine O GKE, ou Google Kubernetes Engine, é a plataforma gerenciada do Kubernetes no Google Cloud Platform, ou GCP. Embora o Kubernetes funcione de forma muito parecida em qualquer provedor ou mesmo em instalações locais, cada plataforma possui suas próprias customizações ou capacidades. A solução de Kubernetes oferecida no GCP é segura e completamente gerenciada pelo Google, oferendo a você a opção de preocupar-se em gerenciar apenas seus nodes, assim como acontece em todos os demais provedores de Cloud tais como AWS, IBM e Azure. Além disto, você também possui a opção de gerenciar unicamente as suas aplicações, de forma que o Google passe a cuidar e gerenciar também os seus nodes, o que torna a vida de desenvolvedores e engenheiros ainda mais fácil. Esta opção se chama Auto Pilot e foi disponibilizada recentemente no GCP. A proposta do Google com este GKE Auto Pilot é dar-lhe maior agilidade e simplicidade, visto que o Google gerencia agora todas as camadas do seu cluster e você passa agora a ser cobrado por Pods, ao invés de VMs que utiliza como Nodes. Bom, mas isto já é um outro assunto… O foco do post de hoje é a criação de um cluster utilizando o Terraform. Para isto não utilizaremos o Auto Pilot, pois queremos ter o controle sobre os nossos nodes, escolher a capacidade do nosso node, etc. ","date":"2021-05-15","objectID":"/posts/criando-um-cluster-kubernetes-no/:1:0","tags":["Devops","Containers","Kubernetes","Docker","GCP","Cloud","Terraform"],"title":"Criando Um Cluster Kubernetes No Gcp Com Terraform","uri":"/posts/criando-um-cluster-kubernetes-no/"},{"categories":["Tutoriais"],"content":"Leitura Recomendada Caso você tenha pouca familiaridade com Google Cloud e ainda não possua uma conta criada e já preparada em seu ambiente, recomendo que primeiro leia o post Terraform: Criando uma infraestrutura no Google Cloud. No post citado acima explico um pouco melhor os passos necessários para quem deseja utilizar GCP pela primeira vez, bem como a preparação do ambiente, criação da conta, instalação e configuração de credenciais básicas e preparo do ambiente para o Terraform com GCP. Caso não tenha ainda familiaridade com o Terraform, sugiro que leia os seguintes posts também, visto que aqui não explicarei a parte do terraform com tantos detalhes: Infraestrutura como Código (IAC - Infrastructure as Code) Introdução ao Terraform Terraform: Variáveis e Outputs Terraform Modules: Porquê E Como Trabalhar Com Módulos No Terraform - PARTE 1 Terraform Modules: Porquê E Como Trabalhar Com Módulos No Terraform - PARTE 2 ","date":"2021-05-15","objectID":"/posts/criando-um-cluster-kubernetes-no/:2:0","tags":["Devops","Containers","Kubernetes","Docker","GCP","Cloud","Terraform"],"title":"Criando Um Cluster Kubernetes No Gcp Com Terraform","uri":"/posts/criando-um-cluster-kubernetes-no/"},{"categories":["Tutoriais"],"content":"Criando nosso cluster Agora que você já possui um domínio básico de Terraform vamos começar a criar o código para a criação de nosso cluster. O Google possui 2 providers disponíveis para Terraform, sendo eles o google e o google-beta. Ambos são muito parecidos, porém o google-beta, conforme o nome indica, se diferencia do provider google pelo fato de suportar os recursos beta do GCP, os quais não são suportados pelo provider google. Vamos começar criando um arquivo chamado versions.tf. Embora este arquivo não seja uma exigência, gosto de utilizar e recomendo como uma boa prática, já que é nele que definimos alguns fatores importantes de nossa configuração, tais como versão do terraform que esperamos que seja utilizada, versão dos provedores ou providers, etc. Este será o conteúdo do nosso arquivo versions.tf: terraform { required_providers { google = { source = \"hashicorp/google\" version = \"3.52.0\" } } required_version = \"~\u003e 0.14\" } Aqui estamos definindo a versão que queremos para o provider google e também a versão que desejamos para o nosso Terraform. Embora eu esteja utilizando a versão 0.15 em meu sistema no momento, utilizei 0.14 no exemplo de código para facilitar a vida de quem possa não estar ainda rodando a última versão disponível. Em seguida criaremos um arquivo simples de variáveis chamado terraform.tfvars: project_id = \"seu-projeto-aqui\" region = \"us-central1\" Atente para a primeira linha, na qual você deverá inserir o nome do seu projeto existente no GCP. Em seguida, utilizei a região us-central1 por ser a região mais próxima de onde moro, mas sinta-se livre para utilizar qualquer outra região. Em seguida vamos criar as definições do nosso cluster. Utilizaremos o arquivo gke.tf: # Algumas variáveis extras variable \"gke_username\" { default = \"\" description = \"user do gke\" } variable \"gke_password\" { default = \"\" description = \"password do gke\" } variable \"gke_num_nodes\" { default = 2 description = \"numero de nodes para o cluster\" } # Cluster GKE resource \"google_container_cluster\" \"marcelo_cluster\" { name = sensitive(\"${var.project_id}-gke\") location = var.region remove_default_node_pool = true initial_node_count = 1 network = google_compute_network.vpc.name subnetwork = google_compute_subnetwork.subnet.name master_auth { username = var.gke_username password = var.gke_password client_certificate_config { issue_client_certificate = false } } } # Node Pool Gerenciado Separadamente resource \"google_container_node_pool\" \"nodes_primarios\" { name = \"${google_container_cluster.marcelo_cluster.name}-node-pool\" location = var.region cluster = google_container_cluster.marcelo_cluster.name node_count = var.gke_num_nodes node_config { oauth_scopes = [ \"https://www.googleapis.com/auth/logging.write\", \"https://www.googleapis.com/auth/monitoring\", ] labels = { env = sensitive(var.project_id) } machine_type = \"e2-standard-2\" tags = [\"gke-node\", sensitive(\"${var.project_id}-gke\")] metadata = { disable-legacy-endpoints = \"true\" } } } Neste arquivo temos todas as definições necessárias para criarmos o cluster, incluindo a quantidade de nodes que desejamos em nosso pool (2), as configurações de rede (vpc e subrede), as quais serão criadas em outro arquivo, o tamanho ou tipo de instância que utilizaremos para os nodes, etc. Neste arquivo utilizei o parâmetro sensitive para proteger algumas informações. Falaremos sobre ele adiante, mas basicamente ele nos ajuda a ocultar informações em nosso plan/apply. Agora que temos nossa definicão de cluster, o próximo passo é criarmos as definições de vpc. Utilizaremos um arquivo chamado vpc.tf: variable \"project_id\" { description = \"project id\" } variable \"region\" { description = \"region\" } provider \"google\" { project = var.project_id region = var.region } # VPC resource \"google_compute_network\" \"vpc\" { name = sensitive(\"${var.project_id}-vpc\") auto_create_subnetworks = \"false\" } # Subnet resource \"google_compute_subnetwork\" \"subnet\" { name = sensitive(\"${var.project_id}-subnet\") region = var.re","date":"2021-05-15","objectID":"/posts/criando-um-cluster-kubernetes-no/:3:0","tags":["Devops","Containers","Kubernetes","Docker","GCP","Cloud","Terraform"],"title":"Criando Um Cluster Kubernetes No Gcp Com Terraform","uri":"/posts/criando-um-cluster-kubernetes-no/"},{"categories":["Tutoriais"],"content":"Cansado de digitar tantos comandos com o kubectl para saber como anda o status do seu cluster? Cansado de alternar seu contexto o tempo todo para gerenciar múltiplos clusters Kubernetes? Cansado de não ter uma forma simples e interativa de gerenciar e manipular os diversos recursos em seu cluster? Apresento-lhe o Lens, uma magnífica IDE para o Kubernetes.","date":"2021-04-17","objectID":"/posts/lens-uma-ide-para-o/","tags":["Devops","Containers","Kubernetes","Docker","Prometheus","Lens"],"title":"Lens - Uma IDE para o Kubernetes","uri":"/posts/lens-uma-ide-para-o/"},{"categories":["Tutoriais"],"content":"Cansado de digitar tantos comandos com o kubectl para saber como anda o status do seu cluster? Cansado de alternar seu contexto o tempo todo para gerenciar múltiplos clusters Kubernetes? Cansado de não ter uma forma simples e interativa de gerenciar e manipular os diversos recursos em seu cluster? Apresento-lhe o Lens, uma magnífica IDE para o Kubernetes. ","date":"2021-04-17","objectID":"/posts/lens-uma-ide-para-o/:0:0","tags":["Devops","Containers","Kubernetes","Docker","Prometheus","Lens"],"title":"Lens - Uma IDE para o Kubernetes","uri":"/posts/lens-uma-ide-para-o/"},{"categories":["Tutoriais"],"content":"O problema Em meu dia a dia gerencio múltiplos clusters, seja no trabalho onde temos diversos clusters para distintos projetos ou mesmo em casa onde costumo criar clusters para estudos ou pequenos projetos pessoais, e por vezes sinto que a linha de comando, embora muito eficiente, simples e robusta, acaba me limitando ou ao menos tomando muito tempo em alguns aspectos. Se você também gerencia múltiplos clusters certamente deve ter passado pelos mesmos problemas… Executo um kubectl get pods e de repente percebo que executei no cluster errado pois esqueci de trocar meu contexto. Preciso verificar como anda o uso de recursos de meu cluster e preciso abrir uma outra aplicação, seja uma suíte completa de monitoramente, como o Datadog, Prometheus, entre outros, ou simplesmente utilizando outras ferramentas de linha de comando tais como o top. E se eu pudesse ter tudo isto em uma única interface, que reunisse todas as informações sobre o meu cluster, monitoramento e gráficos que me indiquem a performance, além de total controle sobre cada recurso rodando em meu cluster, seja um simples pod, um deployment, um replicaset ou mesmo um chart Helm? Mas sabe o que seria legal mesmo além de tudo isso? Se eu pudesse a partir desta mesma interface me conectar diretamente dentro de um container rodando em meus pods e executar comandos, checar logs, ou mesmo buscar e instalar novos charts Helm em meu cluster. Eu sei, eu sei.. estou querendo demais… ou será que não? ","date":"2021-04-17","objectID":"/posts/lens-uma-ide-para-o/:1:0","tags":["Devops","Containers","Kubernetes","Docker","Prometheus","Lens"],"title":"Lens - Uma IDE para o Kubernetes","uri":"/posts/lens-uma-ide-para-o/"},{"categories":["Tutoriais"],"content":"Lens - A magnífica IDE para Kubernetes Quer uma solução open source e gratuita que entrega tudo o que mencionei acima e muito mais? Lhes apresento o Lens, uma IDE para Kubernetes originalmente desenvolvida pela Mirantis e disponibilizada como um projeto Open Source. O Lens é hoje a IDE mais robusta para quem precisa gerenciar clusters Kubernetes diariamente. É uma aplicação única, disponível para Linux, MacOS e Windows, e não possui quaisquer requisitos específicos quanto ao cluster, podendo funcionar perfeitamente bem em qualquer cluster que você possua, seja em um provedor de cloud como o Google Cloud ou AWS, clusters locais ou mesmo soluções simples e de desenvolvimento como o kind, minikube ou o Docker para Desktop. O gerenciamento multi cluster é simples e apenas precisamos identificar o contexto de cada cluster, o que nos permitirá gerenciar clusters no Google Cloud, no AWS, locais em sua máquina com o kind, etc.. Todos em uma única interface, de forma que você apenas precisará clicar no cluster que deseja gerenciar e tudo o que verá em sua frente será referente ao cluster escolhido. Como forma de melhorar a organização de seus clusters você pode também agrupá-los de forma que você tenha clusters de produção em um grupo, clusters de desenvolvimento em outro, e até mesmo clusters de estudos em um terceiro grupo. O Lens chama estes grupos de workspaces. Para simplificar o monitoramento o Lens nos entrega uma integração com o Prometheus que lhe permite habilitar e realizar o deployment do Prometheus em seu cluster com um único clique, e assim passará a ter gráficos e métricas de seu cluster. ","date":"2021-04-17","objectID":"/posts/lens-uma-ide-para-o/:2:0","tags":["Devops","Containers","Kubernetes","Docker","Prometheus","Lens"],"title":"Lens - Uma IDE para o Kubernetes","uri":"/posts/lens-uma-ide-para-o/"},{"categories":["Tutoriais"],"content":"Instalação O processo de instalação será um pouco diferente em cada plataforma. ","date":"2021-04-17","objectID":"/posts/lens-uma-ide-para-o/:3:0","tags":["Devops","Containers","Kubernetes","Docker","Prometheus","Lens"],"title":"Lens - Uma IDE para o Kubernetes","uri":"/posts/lens-uma-ide-para-o/"},{"categories":["Tutoriais"],"content":"OS X Por sorte temos o pacote disponível via homebrew: $ brew cask install lens ","date":"2021-04-17","objectID":"/posts/lens-uma-ide-para-o/:3:1","tags":["Devops","Containers","Kubernetes","Docker","Prometheus","Lens"],"title":"Lens - Uma IDE para o Kubernetes","uri":"/posts/lens-uma-ide-para-o/"},{"categories":["Tutoriais"],"content":"Linux e Windows Os instaladores específicos para cada sistema operacional podem ser baixados diretamente aqui: https://github.com/lensapp/lens/releases/tag/v4.2.2 ","date":"2021-04-17","objectID":"/posts/lens-uma-ide-para-o/:3:2","tags":["Devops","Containers","Kubernetes","Docker","Prometheus","Lens"],"title":"Lens - Uma IDE para o Kubernetes","uri":"/posts/lens-uma-ide-para-o/"},{"categories":["Tutoriais"],"content":"Configuração Agora que temos o Lens instalado o próximo passo é sabermos que cluster desejamos administrar com ele. Para este exemplo estarei criando um cluster de testes com o kind rapidamente. Você poderá utilizar qualquer cluster Kubernetes que deseje, seja em algum provedor cloud, com docker, minikube, etc. Caso queira seguir exatamente o mesmo exemplo que farei aqui com o kind, aqui vai o arquivo yaml de configuração que estarei utilizando para criar o meu cluster: kind: Cluster apiVersion: kind.x-k8s.io/v1alpha4 nodes: - role: control-plane - role: worker - role: worker A propósito, caso nunca tenha utilizado o kind ou não entenda bem como ele funciona, sugiro a leitura de meu post anterior: Criando um cluster kubernetes local com o Kind Com meu arquivo yaml criado criarei o cluster utilizando o seguinte comando: kind create cluster --name kalibk8s --config cluster-teste.yml ➜ kind create cluster --name kalibk8s --config cluster-teste.yml Creating cluster \"kalibk8s\" ... ✓ Ensuring node image (kindest/node:v1.19.1) 🖼 ✓ Preparing nodes 📦 📦 📦 ✓ Writing configuration 📜 ✓ Starting control-plane 🕹️ ✓ Installing CNI 🔌 ✓ Installing StorageClass 💾 ✓ Joining worker nodes 🚜 Set kubectl context to \"kind-kalibk8s\" You can now use your cluster with: kubectl cluster-info --context kind-kalibk8s Com o meu cluster pronto, é hora de configurar o Lens. Repare que ao finalizar a criação do cluster o Kind me informa o nome do contexto para o meu novo cluster: kind-kalibk8s. Precisarei desta informação para configurar o Lens. Ao iniciar o Lens recebo uma tela similar a esta: O primeiro passo é clicar no botão de novo cluster ou +, conforme apresentado no imagem acima. Em seguida clique no botão Select Contexts (Selecionar Contextos). Um menu em drop down será apresentado com todos os contextos existentes para você neste momento. Ele levará em conta as configurações existentes no seu arquivo de configuração do Kubernetes. Aqui eu selecionarei o contexto do meu cluster criado com o kind: kind-kalibk8s Com o contexto selecionado, basta clicar em Add Cluster (Adicionar Cluster). Cada um destes ícones no lado esquerdo representa um dos clusters que eu tenho configurado neste momento no Lens. No seu caso, caso tenha acabado de instalar, só deverá listar um. No menu lateral esquerdo podemos ver que temos as opções de Cluster, Nodes, Workloads, Configuration, Network, etc. Estes são os recursos do meu cluster. Já na janela central, temos a parte de monitoramento ou métricas. Por padrão repare que nada aparece, pois não tenho Prometheus instalado ou configurado para este cluster. Para vermos o que acontecerá, posso executar em meu terminal o seguinte comando: kubectl get all -A ➜ kubectl get all -A NAMESPACE NAME READY STATUS RESTARTS AGE kube-system pod/coredns-f9fd979d6-5nf47 1/1 Running 0 39m kube-system pod/coredns-f9fd979d6-5v6gc 1/1 Running 0 39m kube-system pod/etcd-kalibk8s-control-plane 1/1 Running 0 39m kube-system pod/kindnet-4s9pl 1/1 Running 1 39m kube-system pod/kindnet-d4qfp 1/1 Running 0 39m kube-system pod/kindnet-ppwm7 1/1 Running 0 39m kube-system pod/kube-apiserver-kalibk8s-control-plane 1/1 Running 0 39m kube-system pod/kube-controller-manager-kalibk8s-control-plane 1/1 Running 0 39m kube-system pod/kube-proxy-c2j8p 1/1 Running 0 39m kube-system pod/kube-proxy-r2574 1/1 Running 0 39m kube-system pod/kube-proxy-s7ssz 1/1 Running 0 39m kube-system pod/kube-scheduler-kalibk8s-control-plane 1/1 Running 0 39m local-path-storage pod/local-path-provisioner-78776bfc44-69b2l 1/1 Running 0 39m NAMESPACE NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE default service/kubernetes ClusterIP 10.96.0.1 \u003cnone\u003e 443/TCP 40m kube-system service/kube-dns ClusterIP 10.96.0.10 \u003cnone\u003e 53/UDP,53/TCP,9153/TCP 40m NAMESPACE NAME DESIRED CURRENT READY UP-TO-DATE AVAILABLE NODE SELECTOR AGE kube-system daemonset.apps/kindnet 3 3 3 3 3 \u003cnone\u003e 40m kube-system daemonset.apps/kube-proxy 3 3 3 3 3 kubernetes.io/os=linux 40m NAMESPACE NAME READY UP-TO-DATE AVAILABLE A","date":"2021-04-17","objectID":"/posts/lens-uma-ide-para-o/:4:0","tags":["Devops","Containers","Kubernetes","Docker","Prometheus","Lens"],"title":"Lens - Uma IDE para o Kubernetes","uri":"/posts/lens-uma-ide-para-o/"},{"categories":["Tutoriais"],"content":"Rodar um cluster kubernetes local muitas vezes facilita e acelera o desenvolvimento de aplicações, testes ou mesmo criação de pipelines de CI/CD. Dentre as várias opções disponívels para tal, abordarei o Kind, que roda clusters kubernetes locais utilizando-se do Docker.","date":"2021-01-03","objectID":"/posts/criando-um-cluster-kubernetes-local/","tags":["Devops","Containers","Kubernetes","Docker","Kind"],"title":"Criando Um Cluster Kubernetes Local Com O Kind","uri":"/posts/criando-um-cluster-kubernetes-local/"},{"categories":["Tutoriais"],"content":"Rodar um cluster kubernetes local muitas vezes facilita e acelera o desenvolvimento de aplicações, testes ou mesmo criação de pipelines de CI/CD. Dentre as várias opções disponívels para tal, abordarei o Kind, que roda clusters kubernetes locais utilizando-se do Docker. ","date":"2021-01-03","objectID":"/posts/criando-um-cluster-kubernetes-local/:0:0","tags":["Devops","Containers","Kubernetes","Docker","Kind"],"title":"Criando Um Cluster Kubernetes Local Com O Kind","uri":"/posts/criando-um-cluster-kubernetes-local/"},{"categories":["Tutoriais"],"content":"O que é o Kind - Seja gentil Desenvolver uma aplicação para rodar em um cluster Kubernetes, embora não seja uma tarefa tão difícil, requer muitos testes e deployments, como em qualquer outro tipo de desenvolvimento mas o desafio se torna um pouco maior e caro quando falamos de Kubernetes. Nem sempre podemos ter uma série de máquinas disponíveis para criarmos um ou mais clusters para testes de forma simples e rápida, certo?! É claro, hoje temos diversos provedores na nuvem (cloud) que podem nos permitir criar um novo cluster Kubernetes em alguns minutos, mas nem sempre esta opção é viável, pois caso você mantenha o cluster rodando por algumas horas o custo começa a pesar. Além disso, dificilmente você irá precisar de apenas algumas horas, certo?! Sua aplicação vai receber atualizações, melhorias, correções de bugs, etc. Tudo isto requer mais desenvolvimento, mais testes, mais deployments, o que significa novamente clusters disponíveis para tais tarefas. Uma forma de reduzir os custos na nuvem para este tipo de rotina é você criar e destruir seus clusters cada vez que for parar de desenvolver/testar. Mas se você faz isso diariamente ou algumas vezes por semana, este trabalho se torna complicado e demandará muito de seu tempo, além de ainda assim lhe custar alguns dólares por cada hora que mantém seu cluster funcionando. Diversas alternativas foram criadas com foco nesta necessidade, visando justamente uma forma eficiente, prática e barata para que possamos rodar clusters Kubernetes localmente sem a necessidade de termos múltiplas máquinas, múltiplas VMs ou mesmo clusters na nuvem, como por exemplo no Google Cloud ou AWS. Dentre estas alternativas, algumas das mais comuns são o Docker em si, que agora trás uma versão simplificada do Kubernetes com apenas um node (master), o kubeadm, minikube, kind, etc. Neste post falaremos um pouco mais sobre o Kind. Kind, que na verdade é uma palavra em inglês que significa gentil, também é uma abreviação para Kubernetes in Docker (Kubernetes em Docker). De acordo com sua página oficial, o Kind é uma ferramenta que lhe permite rodar clusters Kubernetes utilizando-se de Docker containers como nodes. Isso mesmo, cada node do seu cluster, será na verdade um container Docker em sua máquina, o que resultará na verdade em um cluster de containers rodando dentro de outros containers. Parece engraçado e estranho, rodar containers dentro de outros containers, mas lembre-se, o objetivo aqui não é um cluster de produção, e sim uma forma simples e eficiente para testes, desenvolvimento, CI, etc. De fato, o Kind é uma ferramenta tão eficiente neste sentido que é utilizada oficialmente no desenvolvimento do Kubernetes em si, como plataforma de testes. Não seria fantástico poder subir ou deletar um novo cluster em segundos? Todos sabemos o quão rápido é criar um novo container no Docker, certo?! Muito mais rápido que criar uma nova máquina virtual. Da mesma forma, se cada node de nosso cluster será um container, podemos apenas esperar que a criação de um novo cluster seja também rápida. O kind utiliza o Containerd como seu Container Runtime ao invés do Dockershim. Apenas estou citando isto devido a todo o barulho criado com a notícia de o Kubernetes estar abandonando o uso do Docker como seu container runtime. Ou seja, o kind não será afetado em nada com isto. Diferentemente do Kubernetes que vem em sua instalação Docker, o Kind lhe permitirá facilmente criar múltiplos clusters, com imagens diferentes para os nodes bem como com múltiplos nodes, o que tornará seus testes ainda mais realistas. ","date":"2021-01-03","objectID":"/posts/criando-um-cluster-kubernetes-local/:1:0","tags":["Devops","Containers","Kubernetes","Docker","Kind"],"title":"Criando Um Cluster Kubernetes Local Com O Kind","uri":"/posts/criando-um-cluster-kubernetes-local/"},{"categories":["Tutoriais"],"content":"Instalação Aqui assumirei que você já possui o Docker instalado e funcionando, afinal o Kind criará seus nodes com containers Docker. Além do Docker, assumo que você já possua alguma familiaridade com o Kubernetes e que já possua o kubectl instalado. ","date":"2021-01-03","objectID":"/posts/criando-um-cluster-kubernetes-local/:2:0","tags":["Devops","Containers","Kubernetes","Docker","Kind"],"title":"Criando Um Cluster Kubernetes Local Com O Kind","uri":"/posts/criando-um-cluster-kubernetes-local/"},{"categories":["Tutoriais"],"content":"OS X No mac podemos utilizar o gerenciador de pacotes homebrew que cuidará de todas as dependências e configurações de ambiente: $ brew install kind ","date":"2021-01-03","objectID":"/posts/criando-um-cluster-kubernetes-local/:2:1","tags":["Devops","Containers","Kubernetes","Docker","Kind"],"title":"Criando Um Cluster Kubernetes Local Com O Kind","uri":"/posts/criando-um-cluster-kubernetes-local/"},{"categories":["Tutoriais"],"content":"Linux Para diferentes distribuições Linux o pacote poderá ter um nome diferente em seus repositórios ou mesmo não estar presente nos repositórios, portanto utilizaremos o binário oficial para a instalação aqui: $ curl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.9.0/kind-linux-amd64 $ chmod +x ./kind $ mv ./kind /algum-diretório-no-seu-PATH/kind ","date":"2021-01-03","objectID":"/posts/criando-um-cluster-kubernetes-local/:2:2","tags":["Devops","Containers","Kubernetes","Docker","Kind"],"title":"Criando Um Cluster Kubernetes Local Com O Kind","uri":"/posts/criando-um-cluster-kubernetes-local/"},{"categories":["Tutoriais"],"content":"Windows Caso você possua o choco ou chocolatey como gerenciador de pacotes, pode instalar o kind apenas utilizando o seguinte comando: $ choco install kind Caso não possua este gerenciador de pacotes, pode fazer o download manualmente através do seguinte link: https://kind.sigs.k8s.io/dl/v0.9.0/kind-windows-amd64 Salve o arquivo e lembre-se de renomeá-lo para kind.exe. É importante que ele seja salvo em um diretório que faça parte de seu Path, do contrário você precisará incluir o diretório no seu PATH em suas variáveis de ambiente. ","date":"2021-01-03","objectID":"/posts/criando-um-cluster-kubernetes-local/:2:3","tags":["Devops","Containers","Kubernetes","Docker","Kind"],"title":"Criando Um Cluster Kubernetes Local Com O Kind","uri":"/posts/criando-um-cluster-kubernetes-local/"},{"categories":["Tutoriais"],"content":"Como utilizar Antes de mais nada, vejamos se temos algum container rodando em nosso Docker. (Embora isto não seja necessário, queremos ver o que realmente será criado pelo Kind). Para isto utilizaremos o comando docker ps que listará os containers rodando no momento: $ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES Ótimo, nenhum container foi listado. Não temos nada rodando em nosso Docker. Para criarmos um novo cluster Kubernetes precisamos apenas utilizar o comando kind create cluster –name : (Aqui criarei um cluster chamado teste) $ kind create cluster --name teste Creating cluster \"teste\" ... ✓ Ensuring node image (kindest/node:v1.19.1) 🖼 ✓ Preparing nodes 📦 ✓ Writing configuration 📜 ✓ Starting control-plane 🕹️ ✓ Installing CNI 🔌 ✓ Installing StorageClass 💾 Set kubectl context to \"kind-teste\" You can now use your cluster with: kubectl cluster-info --context kind-teste Have a nice day! 👋 O kind nos informou que tudo ocorreu bem e que nosso cluster foi criado com sucesso. Além disso, ele nos informou que o nome do contexto criado foi kind-teste. Repare que ele aparentemente criou apenas o Master node (control-plane), conforme podemos ver na linha ✓ Preparing nodes 📦. (Apenas uma caixa). Vamos novmaente rodar docker ps para ver o que foi criado: $ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 0c468b4d1574 kindest/node:v1.19.1 \"/usr/local/bin/entr…\" 3 minutes ago Up 3 minutes 127.0.0.1:65165-\u003e6443/tcp teste-control-plane Podemos ver que de fato apenas um container foi criado, e que se trata de nosso master node ou control-plane. Como podemos ver se nosso cluster está funcional? Se você está utilizando o Docker para Desktop que possui Kubernetes nativo e, caso o mesmo esteja com o Kubernetes inicializado, o seu novo cluster provavelmente estará visível na lista de contextos disponíveis em seu docker: Ao selecionar este contexto kind-teste poderemos a seguir utilizar o kubectl para gerenciar nosso cluster. Opcionalmente, você também pode exportar o contexto manualmente com o comando export KUBECONFIG=\"$(kind get kubeconfig-path –name=“teste”)\". Com o cluster criado, podemos listar os clusters existentes no kind com o comando kind get clusters: $ kind get clusters teste E também podemos pegar informações importante sobre o nosso cluster com o comando kubectl cluster-info –context kind-teste: $ kubectl cluster-info --context kind-teste Kubernetes master is running at https://127.0.0.1:51908 KubeDNS is running at https://127.0.0.1:51908/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'. Podemos listar nossos nodes com kubectl get nodes e listar todos os pods (inclusive os padrões do sistema kubernetes) com kubectl get pods –all-namespaces: $ kubectl get nodes NAME STATUS ROLES AGE VERSION teste-control-plane Ready master 12m v1.19.1 $ kubectl get pods --all-namespaces NAMESPACE NAME READY STATUS RESTARTS AGE kube-system coredns-f9fd979d6-254xj 1/1 Running 0 11m kube-system coredns-f9fd979d6-s6jlc 1/1 Running 0 11m kube-system etcd-teste-control-plane 1/1 Running 0 12m kube-system kindnet-6qnl5 1/1 Running 0 11m kube-system kube-apiserver-teste-control-plane 1/1 Running 0 12m kube-system kube-controller-manager-teste-control-plane 1/1 Running 0 12m kube-system kube-proxy-fbhnf 1/1 Running 0 11m kube-system kube-scheduler-teste-control-plane 1/1 Running 0 12m local-path-storage local-path-provisioner-78776bfc44-dfcc8 1/1 Running 0 11m Como podemos ver, temos todos os pods padrões do Kubernetes, mas nenhum que nós mesmos tenhamos criado. Para deletar o cluster podemos utilizar o comando kind delete cluster –name teste*: $ kind delete cluster --name teste Deleting cluster \"teste\" ... Simples assim o seu cluster foi deletado. O kind permite diversas configurações e cenários, como por exemplo a utilização de arquivos de configuração para as definições do seu cluster. No exemplo a seguir criaremos um arquivo chamado c","date":"2021-01-03","objectID":"/posts/criando-um-cluster-kubernetes-local/:3:0","tags":["Devops","Containers","Kubernetes","Docker","Kind"],"title":"Criando Um Cluster Kubernetes Local Com O Kind","uri":"/posts/criando-um-cluster-kubernetes-local/"},{"categories":["Tutoriais"],"content":"Um breve compartivo entre duas formas de gerenciar seus recursos no Kuberntes: Declarativo vs Imperativo. O kubectl é mais poderoso do que você imagina.","date":"2020-12-24","objectID":"/posts/kubernetes-imperativo-vs-declarativo/","tags":["Devops","Containers","Kubernetes"],"title":"Kubernetes: Imperativo vs Declarativo","uri":"/posts/kubernetes-imperativo-vs-declarativo/"},{"categories":["Tutoriais"],"content":"Um breve compartivo entre duas formas de gerenciar seus recursos no Kuberntes: Declarativo vs Imperativo. O kubectl é mais poderoso do que você imagina. ","date":"2020-12-24","objectID":"/posts/kubernetes-imperativo-vs-declarativo/:0:0","tags":["Devops","Containers","Kubernetes"],"title":"Kubernetes: Imperativo vs Declarativo","uri":"/posts/kubernetes-imperativo-vs-declarativo/"},{"categories":["Tutoriais"],"content":"O que é o que Uma abordagem muito comum é a de que a capacidade de reproduzirmos coisas de forma simples e rápida é fundamental no sentido de agilidade e estabilidade. Se a ideia é termos uma infraestrutura cada vez mais descartável, a utilização de scripts ou códigos sempre que possível, preferivelmente armazenados em algum local seguro e gerenciável, como por exemplo um repositório no github, bitbucket, gitlab ou afins, é a forma correta de fazer as coisas. Um ótimo exemplo disto é a criação de recursos de infraestrutura com o Terraform, utilizando-se o princípio de Infraestrutura como Código. Ao codificarmos toda a nossa infraestrutura, torna-se fácil a restauração da mesma em casos de incidentes, indisponibilidade ou até mesmo escalonamento quando necessário. Uma vez que tenhamos tudo em código e devidamente armazenado em um repositório, fica fácil também o repasse de informações e continuidade de trabalho por outros membros da equipe em caso de você tirar férias ou deixar a empresa. Neste tipo de cenário costuma-se dizer que o código é a própria documentação da infraestrutura, sempre fiel e atualizada automagicamente. Com o Kubernetes não seria diferente, certo?! Caso não tenha um entendimento básico sobre o que é e como funciona o Kubernetes, sugiro a leitura deste outro post Conhecendo O Kubernetes antes de dar continuidade neste. O Kubernetes faz utilização da linguagem yaml para a criação e gerenciamento de seus recursos em formato de código. Desta forma, um simples exemplo para a criação de um pod rodando um servidor web nginx poderia ser um único arquivo chamado nginx-pod.yaml, da seguinte forma: apiVersion: v1 kind: Pod metadata: name: nginx spec: containers: - image: nginx name: nginx ports: - containerPort: 80 name: http Este é um típico exemplo de manifesto ou arquivo de configuração para recursos do Kubernetes. Neste caso, temos toda a definição do pod nginx em um arquivo yaml. Isto é o que chamamos de forma Declarativa, onde declaramos tudo o que esperamos para nosso pod e, ao aplicarmos este código, o Kubernetes apenas irá ler nossas definições e criar exatamente como apresentado ou declarado. A outra forma de se criar/gerenciar recursos no Kubernetes seria a Imperativa, na qual ao invés de criarmos um arquivo declarando o que queremos, simplesmente damos uma ordem (imperativa) ao Kubernetes, informando o que ele deve fazer. Algo como: Kubernetes, crie um pod rodando uma imagem nginx com a porta 80 disponível. ","date":"2020-12-24","objectID":"/posts/kubernetes-imperativo-vs-declarativo/:1:0","tags":["Devops","Containers","Kubernetes"],"title":"Kubernetes: Imperativo vs Declarativo","uri":"/posts/kubernetes-imperativo-vs-declarativo/"},{"categories":["Tutoriais"],"content":"Kubernetes de forma Declarativa Como apresentado mais acima, a forma declarativa nada mais é do que uma forma instruída com declarações ou passos que devem ser seguidos, através de um arquivo yaml, no caso do Kubernetes. Se pegarmos um cluster Kubernetes limpo, podemos ver que nenhum pod está rodando utilizando o comando kubectl get pods: ➜ kubectl get pods No resources found in default namespace. Em seguida, criaremos um arquivo chamado nginx-pod.yaml com o seguinte conteúdo: apiVersion: v1 kind: Pod metadata: name: nginx spec: containers: - image: nginx name: nginx ports: - containerPort: 80 name: http Agora podemos de fato criar o nosso pod através da declaração que incluímos no arquivo nginx-pod.yaml. Para isto utilizaremos o comando kubectl apply -f nginx-pod.yaml: ➜ kubectl apply -f nginx-pod.yaml pod/nginx created Aparentemente tudo ocorreu bem e podemos agora confirmar que nosso pod foi criado através do comando kubectl get pods novamente: ➜ kubectl get pods NAME READY STATUS RESTARTS AGE nginx 1/1 Running 0 44s Desta mesma forma podemos interagir e criar todos os recursos necessários para nosso cluster, sejam deployments, replicasets, volumes, etc. Por hora, vamos deletar o pod criado anteriormente utilizando o comando kubectl delete pod nginx e em seguida vamos confirmar o sucesso do delete com kubectl get pods: ➜ kubectl delete pod nginx pod \"nginx\" deleted ➜ kubectl get pods No resources found in default namespace. ","date":"2020-12-24","objectID":"/posts/kubernetes-imperativo-vs-declarativo/:2:0","tags":["Devops","Containers","Kubernetes"],"title":"Kubernetes: Imperativo vs Declarativo","uri":"/posts/kubernetes-imperativo-vs-declarativo/"},{"categories":["Tutoriais"],"content":"Kubernetes de forma Imperativa Da mesma forma que fizemos de forma declarativa, as APIs do Kubernetes nos permitem uma abordagem mais direta e imperativa sem a necessidade de arquivos de configuração ou manifestos em formato yaml. Neste tipo de abordagem tudo o que precisamos fazer é dizer o que queremos que seja feito, e o Kubernetes assumirá a responsabilidade de definir o que deverá ser feito para atingir o resultado esperado. Seguindo o mesmo exemplo de um simples pod rodando nginx, poderíamos simplesmente utilizar o comando kubectl run –image=nginx nginx e em seguida confirmarmos a criação do pod com kubectl get pods: ➜ kubectl run --image=nginx nginx pod/nginx created ➜ kubectl get pods NAME READY STATUS RESTARTS AGE nginx 1/1 Running 0 15s O resultado foi exatamente o mesmo, porém não utilizamos nenhum arquivo yaml para tal, o que faz com que esta abordagem acabe sendo, em muitos casos, mais simples e rápida, certo?! Além da criação do recurso em si, a abordagem imperativa lhe permite também criar uma forma híbrida de se trabalhar, onde você utilizará a abordagem imperativa como uma forma de facilitar a sua vida com a abordagem declarativa. Sim, é isso mesmo que você acabou de ler, eu não estou louco. A maior desvantagem da abordagem declarativa, em meu ver, é justamente a necessidade de digitar todas aquelas linhas de código yaml. Nem sempre conseguimos memorizar cada linha e sempre temos de ir à documentação para definir o que precisamos em nosso arquivo. Com a abordagem imperativa, temos a capacidade de criar arquivos yaml declarativos de forma rápida e automatizada. Assim, ao invés de precisarmos memorizar todas as linhas, precisamos apenas alterar as linhas que nos interessam. É basicamente uma forma simples de gerar templates rapidamente. Por exemplo, no caso de nosso pod nginx, vamos iniciar deletando o pod criado com kubectl delete pod nginx novamente: ➜ kubectl delete pod nginx pod \"nginx\" deleted Agora vamos criar um novo arquivo yaml, chamado nginx-pod2.yaml. Porém, desta vez, não criaremos o código manualmente. Utilizaremos a forma imperativa para gerar este código, através do comando kubectl run nginx –image=nginx –dry-run=client -o yaml: ➜ kubectl run nginx --image=nginx --dry-run=client -o yaml apiVersion: v1 kind: Pod metadata: creationTimestamp: null labels: run: nginx name: nginx spec: containers: - image: nginx name: nginx resources: {} dnsPolicy: ClusterFirst restartPolicy: Always status: {} Podemos ver que o comando nos jogou toda a declaração para um pod nginx, porém não era isso que queríamos, certo?! Queríamos que um novo arquivo fosse criado. Mas é importante notar que o comando nos apresentou toda a declaração necessária, o que pode nos servir de referência apenas para validação ou em caso de dúvida sobre algo. Agoras podemos incluir \u003e nginx-pod2.yaml ao final do nosso comando anterior e o mesmo irá de fato jogar este conteúdo para um novo arquivo, assim como desejamos: ➜ kubectl run nginx --image=nginx --dry-run=client -o yaml \u003e nginx-pod2.yaml Agora, com nosso novo arquivo criado, podemos criar nosso pod exatamente como fizemos anteriormente com o método declarativo, porém apontando para o novo arquivo nginx-pod2.yaml: ➜ kubectl apply -f nginx-pod2.yaml pod/nginx created ➜ kubectl get pods NAME READY STATUS RESTARTS AGE nginx 1/1 Running 0 6s Nosso pod foi novamente criado, exatamente da mesma forma. Sim, o arquivo yaml que foi criado automaticamente possui algumas linhas a mais, pois foi criado utilizando o template padrão do kubernetes, mas nenhuma delas afetará o funcionamento do seu pod. São linhas não obrigatórios, por isso conseguíamos criar o pod mesmo sem elas. Da mesma forma podemos fazer muitas outras coisas de forma imperativa: # (Para criar um deployment) kubectl create deployment --image=nginx nginx # (para criar um service para expôr um deployment) kubectl expose deployment nginx --port 80 # (para escalonar um deployment existente) kubectl scale deployment nginx --replicas=10 # ","date":"2020-12-24","objectID":"/posts/kubernetes-imperativo-vs-declarativo/:3:0","tags":["Devops","Containers","Kubernetes"],"title":"Kubernetes: Imperativo vs Declarativo","uri":"/posts/kubernetes-imperativo-vs-declarativo/"},{"categories":["Tutoriais"],"content":"Imperativo vs Declarativo Sendo assim, qual das duas é melhor? Qual devo utilizar? A resposta mais simplista seria que ambas são boas e que você deveria aprender e se sentir confortável com ambas as alternativas, visto que elas se complementam. Tudo dependerá da situação e do que se deseja fazer. Como sempre costumo dizer, um código em um repositório git é sempre a melhor prática para continuidade de negócio, no entanto existem situações em que um simples comando imperativo lhe trará resultados mais rápidos como em testes simples, automação em pipelines, validação de comandos, geração de templates ou mesmo durante exames de certificação, como o da certificação CKA (Certified Kubernetes Administrator), no qual você possui uma série de questões para resolver e um tempo limitado para tal. Comandos imperativos vão economizar segundos preciosos durante o exame. (Sim, já vi muita gente falhando no exame e dizendo que não teve tempo o suficiente para todas as questões.) No mais, espero que a diferença entre ambas as abordagens tenha ficado clara. Este post não possui o intuito de ensinar a fundo nenhum dos comandos citados acima, mas sim a diferença entre ambas as abordagens no Kubernetes portanto não entrei em detalhes para cada comando. ","date":"2020-12-24","objectID":"/posts/kubernetes-imperativo-vs-declarativo/:4:0","tags":["Devops","Containers","Kubernetes"],"title":"Kubernetes: Imperativo vs Declarativo","uri":"/posts/kubernetes-imperativo-vs-declarativo/"},{"categories":["Tutoriais"],"content":"Integração contínua (CI) e entrega contínua (CD) são termos bastante utilizados em equipes ágeis e de alta performance. São termos fundamentais na cultura e no dia a dia de uma equipe DevOps. Demonstrarei como podemos criar uma eficiente pipeline para Terraform com o Gitlab.","date":"2020-02-17","objectID":"/posts/criando-uma-pipeline-para-terraform/","tags":["Devops","Gitlab","Terraform","Cloud","AWS","CI","CD","Pipeline"],"title":"Criando Uma Pipeline Para Terraform Com o Gitlab","uri":"/posts/criando-uma-pipeline-para-terraform/"},{"categories":["Tutoriais"],"content":"Integração contínua (CI) e entrega contínua (CD) são termos bastante utilizados em equipes ágeis e de alta performance. São termos fundamentais na cultura e no dia a dia de uma equipe DevOps. Demonstrarei como podemos criar uma eficiente pipeline para Terraform com o Gitlab. ","date":"2020-02-17","objectID":"/posts/criando-uma-pipeline-para-terraform/:0:0","tags":["Devops","Gitlab","Terraform","Cloud","AWS","CI","CD","Pipeline"],"title":"Criando Uma Pipeline Para Terraform Com o Gitlab","uri":"/posts/criando-uma-pipeline-para-terraform/"},{"categories":["Tutoriais"],"content":"Integração Contínua (CI) e Entrega Contínua (CD) Muito se fala em Integração Contínua (Continuous Integration - CI) e Entrega Contínua (Continuous Delivery - CD) em equipes ágeis e de alta performance e que seguem uma filosofia ágil ou DevOps. Resumidamente, são metodologias que buscam a utilização de processos e ferramentas específicas com o intuito de realizar uma entrega rápida de novas versões de software ou mesmo infraestrutura, porque não? Supondo que sua equipe de desenvolvimento de software segue alguns passos em seu ciclo diário de desenvolvimento de código até a entrega final da aplicação ou deployment, você poderia ter um ciclo similar ao seguinte: Submeter o código atualizado para um repositório Git; Compilação ou build do código; Rodar alguns testes neste código em um ambiente qualquer para validação das alterações realizadas; Execução de alguns testes de segurança com uma ferramenta terceira em cima de seu código; Realizar a entrega ou deployment do código em si. A ideia de se ter um ciclo de Integração contínua e entrega contínua surge justamente para automatizar e acelerar este processo. As chamadas pipelines são justamente uma forma de automatizar estes passos através de uma ou mais ferramentas de forma que um processo antes demorado e executado manualmente por uma ou mais pessoas agora passa a ser executado automaticamente e de forma contínua, preferivelmente diversas vezes ao dia ou conforme a equipe for disponibilizando novas versões do código. ","date":"2020-02-17","objectID":"/posts/criando-uma-pipeline-para-terraform/:1:0","tags":["Devops","Gitlab","Terraform","Cloud","AWS","CI","CD","Pipeline"],"title":"Criando Uma Pipeline Para Terraform Com o Gitlab","uri":"/posts/criando-uma-pipeline-para-terraform/"},{"categories":["Tutoriais"],"content":"Gitlab GitLab é uma ferramenta que busca ser uma espécie de “tudo em um” quando o assunto são ciclos de desenvolvimento ágeis. Basicamente é uma ferramenta web para o ciclo de vida de projetos DevOps que, embora originalmente fosse bem mais limitada, atuando apenas como uma opcão para repositórios Git, hoje é uma ferramenta robusta e engloba diversas soluções como repositórios, tarefas/tickets, wiki, pipelines CI/CD, etc. Embora tenha sido originalmente desenvolvida em Ruby, alguns de seus componentes foram re-escritos em Go. Permitindo o controle e gerenciamento de todo o seu ciclo de desenvolvimento de forma colaborativa, GitLab é considerado o primeiro Unicórnio da Ucrânia, ou seja, uma startup avaliada em mais de 1 bilhão de dólares. Além de grandes empresas e organizações como Alibaba, Trivago, Ticketmaster, Cloud Native Foundation, AVG, Siemens, Avast, BlackBerry, Broadcom, Capgemini, Citrix, EA Sports, Ericsoon, Expedia, Nasa, Nasdaq, Governo do Canadá, Interpol, Telus, Nutanix, RedHat, SanDisk, Sony, Trend Micro, Uber, Verizon e muitas outras, o GitLab também é muito popular entre projetos de software livre ou mesmo profissionais independentes e estudantes. Sim, existem diversas outras soluções para criação de pipelines CI/CD, como Jenkins, Circle CI, Bitbucket, etc. Mas, como mencionei mais acima, o GitLab trás muito mais do que apenas a ferramenta de pipelines. Outro fator que me faz adorar este projeto é a possibilidade de utilizá-lo gratuitamente sem qualquer necessidade de instalação ou configuração. Ao contrário do Jenkins, eu não preciso instalar uma VM para ser meu servidor Jenkins para as pipelines. GitLab está disponível online e de forma gratuita para pequenos projetos, incluindo a utilização gratuita de workers que são os “trabalhadores”, digamos assim. São containers criados e destruidos automaticamente durante as execuções de suas pipelines. Sem mais enrolação… vamos ao que interessa. ","date":"2020-02-17","objectID":"/posts/criando-uma-pipeline-para-terraform/:2:0","tags":["Devops","Gitlab","Terraform","Cloud","AWS","CI","CD","Pipeline"],"title":"Criando Uma Pipeline Para Terraform Com o Gitlab","uri":"/posts/criando-uma-pipeline-para-terraform/"},{"categories":["Tutoriais"],"content":"Terraform? O objetivo deste post não é ensinar Terraform, portanto não adentraremos a fundo nisto. Caso você não possua alguma familiaridade com Terraform, sugiro que pause esta leitura e volte um pouco. Recomendo a leitura de meus posts anteriores antes de seguir com este: Infraestrutura como Código com Terraform Introdução ao Terraform Terraform: Variáveis e Outputs Terraform: Criando uma infraestrutura no Google Cloud Terraform Modules: Porquê E Como Trabalhar Com Módulos No Terraform - PARTE 1 Terraform Modules: Porquê E Como Trabalhar Com Módulos No Terraform - PARTE 2 ","date":"2020-02-17","objectID":"/posts/criando-uma-pipeline-para-terraform/:3:0","tags":["Devops","Gitlab","Terraform","Cloud","AWS","CI","CD","Pipeline"],"title":"Criando Uma Pipeline Para Terraform Com o Gitlab","uri":"/posts/criando-uma-pipeline-para-terraform/"},{"categories":["Tutoriais"],"content":"Nosso projeto ","date":"2020-02-17","objectID":"/posts/criando-uma-pipeline-para-terraform/:4:0","tags":["Devops","Gitlab","Terraform","Cloud","AWS","CI","CD","Pipeline"],"title":"Criando Uma Pipeline Para Terraform Com o Gitlab","uri":"/posts/criando-uma-pipeline-para-terraform/"},{"categories":["Tutoriais"],"content":"Assumindo que… Para este post estou assumindo que você já atende aos seguintes pré-requisitos: Já possui alguma familiaridade com o Terraform (conforme citei acima); Já possui o git instalado e também possui alguma familiaridade com o mesmo; Já possui uma conta AWS caso queira utilizar exatamente este código que utilizarei ou que possua familiaridade suficiente com o Terraform para criar seu próprio código sem utilizar o AWS como provider; Além de possuir uma conta AWS, estou assumindo que você já configurou seu ambiente exportando as variáveis de ambiente de sua chave e senha do AWS para que seu Terraform consiga se comunicar com sua conta AWS (Se também não faz ideia de o que é ou como isto é feito, volte um pouco: Terraform Modules: Porquê E Como Trabalhar Com Módulos No Terraform - PARTE 1) ","date":"2020-02-17","objectID":"/posts/criando-uma-pipeline-para-terraform/:4:1","tags":["Devops","Gitlab","Terraform","Cloud","AWS","CI","CD","Pipeline"],"title":"Criando Uma Pipeline Para Terraform Com o Gitlab","uri":"/posts/criando-uma-pipeline-para-terraform/"},{"categories":["Tutoriais"],"content":"Criando um repositório para nosso código O primeiro passo é criar uma conta gratuita em Gitlab.com. Ao criar sua conta, um email lhe será enviado para confirmação de endereço. Valide seu email clicando no link que lhe será enviado. Quando logamos pela primeira vez em nossa conta do GitLab, veremos algo similar à seguinte tela. Clique em Create a project ou Criar um projeto. Na tela seguinte, crie o seu projeto com o nome e descrição que preferir, similar ao exemplo a seguir: Embora você possa escolher entre privado ou público, sugiro que defina seu repositório como privado inicialmente, apenas para evitar algum erro. Se você ainda não possui familiaridade com o Terraform e com o GitLab, não queremos correr o risco de deixar senhas ou dados confidenciais (como chaves do AWS) em seu código publicamente acessível, certo?! Ao preencher tudo e clicar em Create project ou Criar projeto você será levado para a seguinte tela: O alerta que o GitLab nos dá acima é justamente nos informando que ainda não possuímos uma chave ssh cadastrada em nossa conta. A chave é utilizada para que possamos interagir com nosso repositório de forma segura, via ssh. Começaremos então resolvendo esta “pendência”. Você pode fazê-lo de duas formas: 1- Clicando diretamente no alerta, em *add an SSH key (adicionar uma chave ssh); 2.1- Clicando no menu principal de sua conta, no canto superior direito, conforme imagem abaixo; 2.2- No menu lateral esquerdo, clique em SSH Keys (Chaves SSH); Seguindo qualquer um dos módulos acima, você cairá na página de chaves ssh. Cole a sua chave ssh e dê um nome ou apelido para ela, conforme exemplo abaixo (Utilize sua chave pública, não a privada): Após preencher, clique em Add key (Adicionar chave). Com sua chave devidamente adicionada, podemos testar se está tudo funcionando de forma simples, clonando nosso repositório. Em um terminal qualquer, navegue até um diretório de sua preferência e clone o seu repositório: (Estou assumindo que você já possua o git instalado) Clique no botão Clone no canto superior direito da página principal de seu projeto e copie o comando SSH que lhe será apresentado. Em seguida utilize este comando para clonar seu repositório: Clone com: (Substituindo o endereço pelo que lhe foi informado no Gitlab, conforme imagem acima) $ git clone git@gitlab.com:marcelokalibtest/terraform-gitlab-kalib.git Se tudo funcionou como o esperado, você deverá agora ter um diretório com o nome do seu repositório e poderá ver que o único arquivo nele até então é o arquivo de documentação padrão README.md. Agora que temos nossa conta no Gitlab funcionando com nossa chave SSH e nosso repositório clonado localmente, nosso próximo passo será criar de fato algum código em nosso repositorio local para que possamos em seguida enviá-lo para o Gitlab. Conforme dito anteriormente, o foco deste post não é, em hipótese alguma, ensinar Terraform. Para isto citei no início deste post alguns links para posts anteriores. Utilizaremos aqui um código extremamente simplista visto que nosso objetivo aqui é apenas conhecer melhor como podemos utilizar pipelines para nossa infraestrutura. Mas, uma vez que você entenda o conceito e a técnica, o procedimento seria o mesmo, independente de quão complexo seja o código de sua infraestrutura. Em seu repositório local, crie o arquivo main.tf com o seguinte conteúdo: # Criando uma instância EC2 provider \"aws\" { region = \"ca-central-1\" } data \"aws_ami\" \"ubuntu\" { most_recent = true filter { name = \"name\" values = [\"ubuntu/images/hvm-ssd/ubuntu-trusty-14.04-amd64-server-*\"] } filter { name = \"virtualization-type\" values = [\"hvm\"] } owners = [\"099720109477\"] # Canonical } resource \"aws_instance\" \"web\" { ami = data.aws_ami.ubuntu.id instance_type = \"t2.micro\" tags = { Name = \"HelloWorld\" } } Em seguida, criaremos o arquivo .gitignore para que possamos fazer com que nossos arquivos de configuração e estado do Terraform não sejam enviados para o Gitlab. O arquivo deverá conter uma única linha: (Sim, preci","date":"2020-02-17","objectID":"/posts/criando-uma-pipeline-para-terraform/:4:2","tags":["Devops","Gitlab","Terraform","Cloud","AWS","CI","CD","Pipeline"],"title":"Criando Uma Pipeline Para Terraform Com o Gitlab","uri":"/posts/criando-uma-pipeline-para-terraform/"},{"categories":null,"content":"Quem Sou","date":"2019-08-02","objectID":"/sobre/","tags":null,"title":"Quem Sou","uri":"/sobre/"},{"categories":null,"content":"  Este é o espaço de Marcelo Cavalcante Rocha, onde ideias e experiências se encontram. Atualmente como Principal Site Reliability Engineer (SRE) na Dragos, aqui compartilho reflexões e conhecimentos, na modesta esperança de que possam ressoar com você. Marcelo e Débora ","date":"2019-08-02","objectID":"/sobre/:0:0","tags":null,"title":"Quem Sou","uri":"/sobre/"},{"categories":null,"content":"Quem Sou ","date":"2019-08-02","objectID":"/sobre/:1:0","tags":null,"title":"Quem Sou","uri":"/sobre/"},{"categories":null,"content":"Profissional  Me chamo Marcelo Cavalcante Rocha, também conhecido como Kalib. Dinâmico, escrupulosamente curioso, reservadamente convencional, multitarefa, command line heavy-user, estudante e pesquisador, (ex-)surfista por prazer, leitor inquieto e aspirante a ser humano. Sempre acreditei na ideia de que bons profissionais de tecnologia são preguiçosos, no sentido de que se algo pode ser automatizado com o fim de evitar tarefas repetitivas, automatizado será. Atualmente trabalho como Principal Site Reliability Engineer (SRE) na empresa Dragos, sediada em Hanover, Estados Unidos. A Dragos é uma empresa líder em segurança cibernética industrial (ICS/OT), focada em proteger os sistemas de tecnologia operacional (OT) que controlam infraestruturas críticas, como energia, manufatura e serviços públicos. Sua principal missão é defender o mundo contra ameaças cibernéticas que visam sistemas industriais, que são vitais para a economia e a vida cotidiana. A Dragos fornece uma plataforma de tecnologia e serviços de inteligência de ameaças que permite às organizações ter visibilidade, identificar vulnerabilidades e responder a incidentes em seus ambientes industriais. Sou formado em Sistemas de Informação e pós-graduado em Governança de Tecnologia da Informação, com MBA em Governança de TI. Embora trabalhe para uma empresa de Hanover, atualmente resido em Barrie, uma pequena e pacata cidade em Ontario, no Canada, que fica a cerca de 90km de Toronto. Trabalho em regime de home office, o que me permite desfrutar de uma vida mais calma em uma cidade menor, mais próximo da natureza e dos esportes que gosto de praticar. Apaixonado por bons vinhos e cervejas mas, acima de tudo, por minha linda companheira que insiste em transformar meu mundo em algo mais alegre e atrativo. ","date":"2019-08-02","objectID":"/sobre/:1:1","tags":null,"title":"Quem Sou","uri":"/sobre/"},{"categories":null,"content":"Tecnologias Programação Python Golang Ruby Bash Cloud AWS Google Cloud Microsoft Azure IBM Cloud SRE/DevOps Kubernetes Docker Hashicorp Terraform Hashicorp Packer Hashicorp Vault Ansible Grafana Prometheus ElasticSearch Jenkins Grafana ","date":"2019-08-02","objectID":"/sobre/:1:2","tags":null,"title":"Quem Sou","uri":"/sobre/"},{"categories":["Tutoriais"],"content":"Todos sabem que o Terraform é uma solucão fantástica para criar infraestrutura através de código, porém nem todos utilizam as diversas possibilidades do mesmo, como por exemplos módulos. Com módulos podemos fazer a reutilização de código para nossa infraestrutura.","date":"2019-05-20","objectID":"/posts/terraform-modules-porque-e-como/","tags":["Devops","Terraform","Cloud","AWS"],"title":"Terraform Modules: Porquê E Como Trabalhar Com Módulos No Terraform - PARTE 2","uri":"/posts/terraform-modules-porque-e-como/"},{"categories":["Tutoriais"],"content":"Todos sabem que o Terraform é uma solucão fantástica para criar infraestrutura através de código, porém nem todos utilizam as diversas possibilidades do mesmo, como por exemplos módulos. Com módulos podemos fazer a reutilização de código para nossa infraestrutura. OBS: Este post é a continuação do post anterior e utilizará a mesma base de código, portanto se você não leu o anterior, comece por lá clicando aqui: Terraform Modules: Porquê E Como Trabalhar Com Módulos No Terraform - PARTE 1 Continuando de onde paramos… ","date":"2019-05-20","objectID":"/posts/terraform-modules-porque-e-como/:0:0","tags":["Devops","Terraform","Cloud","AWS"],"title":"Terraform Modules: Porquê E Como Trabalhar Com Módulos No Terraform - PARTE 2","uri":"/posts/terraform-modules-porque-e-como/"},{"categories":["Tutoriais"],"content":"User Data O AWS possui um recurso chamado User Data, o qual nos permite passar um script (bash) que deverá ser executado no momento de criação de uma instância. Utilizaremos este recurso do AWS também através de nosso código Terraform para: Atualizar nossa base de repositórios do APT; Instalar e iniciar os serviços necessários; Liberar os serviços necessários no firewall do Ubuntu. Caso suas instâncias ainda estejam rodando, você perceberá que o Terraform tentará destruir a instância e criá-la novamente após fazermos esta alteração. Isto se dá porque uma das alterações que faremos de fato exigirá que uma nova instância seja criada, pois incluiremos um script que deve rodar durante a criação da instância e, obviamente, a única forma de este script ser executado é justamente criando a instância novamente. Mas isso não é problema, certo? Somos engenheiros devops e em um mundo devops o objetivo é ter uma infraestrutura automatizada e extremamente descartável, certo? É por isso que codificamos tudo. Começaremos com nosso servidor webserver. Vamos incluir uma nova tag (Projeto) bem como um bash script que será utilizado como user_data. Este bash script atualizará nossa base de repositórios e instalará o servidor web apache2, bem como habilitará o webserver no firewall padrão do Ubuntu. Este recurso user_data não é exatamente do Terraform, mas sim um mecanismo que o AWS nos provê para que possamos ter um script executado no momento de criação de uma instância ou VM. Nosso arquivo variables.tf do projeto webserver agora deverá estar assim: variable \"region\" { type = \"string\" description = \"Região no AWS onde nossos recursos estarão.\" default = \"us-east-1\" } variable \"ami\" { type = \"string\" description = \"Id da imagem EC2 que desejamos utilizar para nossa instância.\" default = \"ami-0a313d6098716f372\" } variable \"instance_type\" { type = \"string\" description = \"Tipo de instância a ser utilizado\" default = \"t2.micro\" } variable \"tags\" { type = \"map\" description = \"Tags a serem aplicadas à nossa instância.\" default = { \"Name\" = \"Ubuntu-webserver\" \"Ambiente\" = \"Desenvolvimento\" \"Projeto\" = \"Webserver\" } } variable \"user_data\" { type = \"string\" description = \"Script a ser executado durante a criação da instância.\" default = \u003c\u003c-EOF #!/bin/bash sudo apt update sudo apt install apache2 -y sudo systemctl enable apache2 sudo systemctl start apache2 sudo ufw allow 'Apache' EOF } Agora que temos nossa variável user_data criada, devemos inserir isto em nosso arquivo main.tf para que nossa instância possa utilizar este script de inicialização. Nosso main.tf do projeto webserver agora ficará assim: provider \"aws\" { region = \"${var.region}\" } resource \"aws_instance\" \"server1\" { ami = \"${var.ami}\" instance_type = \"${var.instance_type}\" user_data = \"${var.user_data}\" tags = \"${var.tags}\" } Com estas alterações já conseguiríamos criar um servidor web com Apache2, no entanto por padrão o AWS mantém as portas de novas instâncias fechadas para o mundo externo, portanto precisamos também criar alguns resources para que nossa instância seja de fato utilizável: VPC: Virtual Private Cloud é o recurso utilizado pelo AWS para definições de redes dentro de sua conta AWS; Subnet: Definiremos uma subnet ou sub-rede para nossa infraestrutura; Internet Gateway: Um gateway do aws que permitirá que nossa instância s ecomunique com a internet; Route Table: Um atabela de roteamento que permitirá que nossa vpc encaminhe pacotes devidamente; Security Groups: Security Groups ou Grupos de Segurança é como o AWS chama suas definições e regras de firewall; Adicionar um ip público ao servidor. Vamos começar criando todas as novas variáveis que precisaremos. Nosso arquivo variables.tf do projeto webserver receberá várias alterações. As variáveis que devemos criar são: Uma porta de origem para a regra de entrada ou ingress: i_from_port; Uma porta de destino para a regra de entrada ou ingress: i_to_port; Um IP ou range de ips para a regra de entrada ou ingress: i_ip_range; Uma porta","date":"2019-05-20","objectID":"/posts/terraform-modules-porque-e-como/:1:0","tags":["Devops","Terraform","Cloud","AWS"],"title":"Terraform Modules: Porquê E Como Trabalhar Com Módulos No Terraform - PARTE 2","uri":"/posts/terraform-modules-porque-e-como/"},{"categories":["Tutoriais"],"content":"Todos sabem que o Terraform é uma solucão fantástica para criar infraestrutura através de código, porém nem todos utilizam as diversas possibilidades do mesmo, como por exemplos módulos. Com módulos podemos fazer a reutilização de código para nossa infraestrutura.","date":"2019-05-17","objectID":"/posts/terraform-modules-porque-e-comop1/","tags":["Devops","Terraform","Cloud","AWS"],"title":"Terraform Modules: Porquê E Como Trabalhar Com Módulos No Terraform - PARTE 1","uri":"/posts/terraform-modules-porque-e-comop1/"},{"categories":["Tutoriais"],"content":"Todos sabem o quão fantástico o Terraform é quando o assunto é criar infraestrutura de forma automática e através de código, a chamada IaC ou Infraestrutura como Código (Infrastructure as Code). No entanto, nem todos se utilizam de todos os recursos ou funcionalidades que o Terraform nos disponibiliza para tornar nossa vida ainda mais fácil e nosso código mais organizado. A possibilidade de utilizar módulos em nosso código Terraform faz com que possamos ter a reutilização de código, não apenas nosso mas também de terceiros, evitando a repetição de código bem como nos dando flexibilidade para criarmos dezenas de recursos similares porém com suas respectivas particularidades utilizando-se da mesma base de código. O objetivo deste post não é ensinar o básico de Terraform, portanto se você ainda não possui uma certa familiaridade com o Terraform, sugiro que volte um pouco e leia estes posts antes de seguir com esta leitura: Infraestrutura como Código com Terraform Introdução ao Terraform Terraform: Variáveis e Outputs Terraform: Criando uma infraestrutura no Google Cloud ","date":"2019-05-17","objectID":"/posts/terraform-modules-porque-e-comop1/:0:0","tags":["Devops","Terraform","Cloud","AWS"],"title":"Terraform Modules: Porquê E Como Trabalhar Com Módulos No Terraform - PARTE 1","uri":"/posts/terraform-modules-porque-e-comop1/"},{"categories":["Tutoriais"],"content":"Multi Plataforma - AWS Já que o Terraform é multi plataforma, desta vez utilizarei o AWS como cloud para criar minha infraestrutura, ao contrário dos posts anteriores nos quais utilizei Google Cloud. Como costumo deixar claro, gosto muito de ambas as opções, GCP (Google Cloud Plataform) e AWS (Amazon Web Services), e não gosto de julgar uma como melhor que a outra. GCP se sai melhor em alguns aspectos, enquanto que AWS se sai melhor em outros, mas isto não é tema para este post. Caso queira acompanhar o passo a passo deste post e praticar os mesmos códigos, você precisará atender a alguns pré-requisitos: Já possuir uma conta no AWS. O AWS lhe permite criar uma conta para que você utilize alguns recursos gratuitamente durante os primeiros 12 meses para fins de estudos e serão estes os recursos nos quais focarei aqui; Possuir um usuário não root com sua devida chave. Por padrão, ao criar uma conta no AWS, você sempre logará inicialmente com a conta root ou master. Embora muitas pessoas utilizem esta conta para tudo, é extremamente importante, por questões de segurança, que esta conta seja utilizada única e exclusivamente para criar novos usuários. Portanto, sugiro que você crie um novo usuário qualquer bem como uma chave para o mesmo, de forma que você possa interagir com o AWS programaticamente, via APIs, aws cli ou mesmo via Terraform. Você deverá possuir o AWS_ACCESS_KEY_ID deste usuário, bem como sua AWS_SECRET_ACCESS_KEY. Estas informações serão utilizadas para que você consiga se comunicar com o AWS através do Terraform; ","date":"2019-05-17","objectID":"/posts/terraform-modules-porque-e-comop1/:1:0","tags":["Devops","Terraform","Cloud","AWS"],"title":"Terraform Modules: Porquê E Como Trabalhar Com Módulos No Terraform - PARTE 1","uri":"/posts/terraform-modules-porque-e-comop1/"},{"categories":["Tutoriais"],"content":"Criando uma conta e usuário no AWS Caso você já possua uma conta e um usuário pronto para utilização, siga para a próxima sessão: Criando VMs no AWS com Terraform Para criar sua conta no AWS preencha o formulário de cadastro através do seguinte link: Cadastro AWS. Após ter sua conta criada, efetue login com seu email para que possamos criar um usuário para nosso exemplo: No canto superior esquerdo clique em Serviços (Services). Busque e clique no serviço IAM. No menu da lateral esquerda clique em Usuários (Users) e em seguida clique no botão azul Adicionar Usuário (Add User). Insira um nome para seu usuário e, em Tipo de Acesso (Access Type), selecione a opcão Acesso programático (Programmatic Access). Clique no botão azul do canto inferior direito Próximo: Permissões (Next: Permissions). Na tela seguinte clique em Anexar políticas existentes de forma direta (Attach existing policies directly) e em seguida, no campo de busca, digite AmazonEC2FullAccess. Selecione a caixa para atribuir esta policy ao seu novo usuário. Agora que demos permissão para criar instâncias EC2 (VMs) ao nosso usuário, clique no botão azul Próximo: Tags (Next: Tags). Embora Tags não sejam obrigatórias, por questões de organização e para seguirmos melhores práticas, definiremos uma Tag para este usuário: Uso: Terraform Clique no botão azul do canto inferior direito, Próximo: Revisar (Next: Review). Certifique-se de que está tudo certo quanto ao seu novo usuário e em seguida clique no botão azul Criar Usuário (Create user). ATENÇÃO! Tenha cuidado nesta tela seguinte, pois esta será a única vez em que a senha de sua chave será apresentada. Clique no botão Fazer download .csv (Download .csv) para realizar o download de um arquivo .csv com sua chave e senha, ou apenas copie o conteúdo exibido na tela para sua chave e senha após clicar em Exibir (Show) no campo de senha da chave e salve estes dados em algum local seguro, pois você precisará destes dois valores para controlar sua conta AWS programaticamente com este usuário. Com seu usuário criado, clique no botão do canto inferior direito Fechar (Close). ","date":"2019-05-17","objectID":"/posts/terraform-modules-porque-e-comop1/:2:0","tags":["Devops","Terraform","Cloud","AWS"],"title":"Terraform Modules: Porquê E Como Trabalhar Com Módulos No Terraform - PARTE 1","uri":"/posts/terraform-modules-porque-e-comop1/"},{"categories":["Tutoriais"],"content":"Criando VMs no AWS com Terraform Assumindo que você já possui uma conta no AWS e um usuário com chave para acesso, vamos exportar nossa chave de acesso e nossa senha para esta chave. No Linux ou OS X, execute: $ export AWS_ACCESS_KEY_ID=\u003cSUA_CHAVE_AUI\u003e $ export AWS_SECRET_ACCESS_KEY=\u003cSUA_SENHA_PARA_A_CHAVE_AQUI\u003e Você poderá confirmar que seus comandos deram certo digitando: $ echo $AWS_ACCESS_KEY_ID \u0026\u0026 echo $AWS_SECRET_ACCESS_KEY Caso sua chave e senha tenham sido exibidas, podemos partir para o Terraform. Novamente, estou assumindo que você já possui um conhecimento básico de Terraform, visto que o foco deste post não é explicar detalhadamente o funcionamento do mesmo, mas sim explicar como e porque utilizar módulos no Terraform. Comecemos criando uma instância ou VM Ubuntu Linux simples. Iniciemos criando um diretório para nosso projeto e em seguida indo para dentro do mesmo com algum terminal ou console: $ mkdir terraform $ cd terraform A forma mais simplificada de iniciar nosso projeto e criar uma simples instância Ubuntu seria criando um arquivo main.tf e inserindo o seguinte conteúdo no mesmo: # Criando uma Instância Ubuntu no AWS provider \"aws\" { region = \"us-east-1\" } resource \"aws_instance\" \"server1\" { ami = \"ami-0a313d6098716f372\" instance_type = \"t2.micro\" tags = { Name = \"Ubuntu-1\" Ambiente = \"Desenvolvimento\" } } Obviamente este código é extremamente simplista. Sequer estamos definindo variáveis, mas chegaremos lá. O que fizemos: Indicamos que o nosso provider será o AWS; Criamos um resource do tipo aws_instance; Indicamos qual o ID exato da imagem que queremos utilizar para nossa instância. A lista completa de AMI ou imagens disponibilizadas pelo AWS pode ser encontrada aqui; Indiquei o tipo de instância como sendo t2.micro. Cada tipo de instância representa uma configuração diferente em termos de CPU, memória, etc. Uma lista completa com todos os tipos disponíveis pode ser encontrada aqui Inseri algumas tags para seguir melhores práticas e deixar nossa infraestrutura organizada e catalogada; Primeiramente, vamos testar nosso código e ver se estamos com acesso ao AWS via Terraform. Vamos validar que não temos esta instância já criada no AWS clicando em Serviços (Services) e em seguida buscando o serviço EC2: Em seguida clique em Instâncias (Instances) no menu esquerdo para listar suas instâncias: De volta ao nosso terminal, no diretório onde criamos nosso arquivo main.tf, vamos iniciar o terraform com terraform init . : $ terraform init . Initializing provider plugins... The following providers do not have any version constraints in configuration, so the latest version was installed. To prevent automatic upgrades to new major versions that may contain breaking changes, it is recommended to add version = \"...\" constraints to the corresponding provider blocks in configuration, with the constraint strings suggested below. * provider.aws: version = \"~\u003e 2.11\" Terraform has been successfully initialized! You may now begin working with Terraform. Try running \"terraform plan\" to see any changes that are required for your infrastructure. All Terraform commands should now work. If you ever set or change modules or backend configuration for Terraform, rerun this command to reinitialize your working directory. If you forget, other commands will detect it and remind you to do so if necessary. Caso você não tenha recebido um erro com o init, podemos executar o nosso plano ou plan: $ terraform plan Refreshing Terraform state in-memory prior to plan... The refreshed state will be used to calculate this plan, but will not be persisted to local or remote state storage. ------------------------------------------------------------------------ An execution plan has been generated and is shown below. Resource actions are indicated with the following symbols: + create Terraform will perform the following actions: + aws_instance.server1 id: \u003ccomputed\u003e ami: \"ami-0a313d6098716f372\" arn: \u003ccomputed\u003e associate_public_ip_address: \u003ccomputed\u003e a","date":"2019-05-17","objectID":"/posts/terraform-modules-porque-e-comop1/:3:0","tags":["Devops","Terraform","Cloud","AWS"],"title":"Terraform Modules: Porquê E Como Trabalhar Com Módulos No Terraform - PARTE 1","uri":"/posts/terraform-modules-porque-e-comop1/"},{"categories":["Impressões"],"content":"Go ou Golang, a linguagem de programação desenvolvida no Google com o intuito de ser uma linguagem que realmente fosse eficiente. Neste post explico um pouco das características do Go que me levaram a adotá-la como minha linguagem favorita.","date":"2019-04-14","objectID":"/posts/go-ou-golang-porque-adotei/","tags":["Golang","Impressões"],"title":"Go Ou Golang: Porquê Adotei Go Como Minha Linguagem Favorita","uri":"/posts/go-ou-golang-porque-adotei/"},{"categories":["Impressões"],"content":"Go ou Golang, a linguagem de programação desenvolvida no Google com o intuito de ser uma linguagem que realmente fosse eficiente. Neste post explico um pouco das características do Go que me levaram a adotá-la como minha linguagem favorita. ","date":"2019-04-14","objectID":"/posts/go-ou-golang-porque-adotei/:0:0","tags":["Golang","Impressões"],"title":"Go Ou Golang: Porquê Adotei Go Como Minha Linguagem Favorita","uri":"/posts/go-ou-golang-porque-adotei/"},{"categories":["Impressões"],"content":"Introdução Quem me conhece sabe que sempre tive uma certa queda pelo Python, e existem diversas razões óbvias para isso, visto que o Python possui uma sintaxe relativamente simples, elegante e é bastante eficiente, embora não possua a melhor performance. Apesar de todos os pontos positivos que me levaram a utilizar bastante Python, recentemente decidi me aventurar com Go ou Golang, como prefira chamar. Go foi desenvolvida para uso interno no Google em meados de 2007 com um único propósito: Melhorar a produtividade da programação em uma era de processadores e computadores com múltiplos cores, máquinas em rede e bases de dados gigantescas. Basicamente a ideia era criar uma linguagem de programação diferente, eficiente e que pudesse suprir as necessidades do Google de forma a eliminar uma série de pontos considerados negativos nas demais linguagens de programação existentes mas ao mesmo tempo mantendo pontos fortes já encontrados nas mesmas. Se isso soa familiar aos amantes do Software Livre, é porque de certa forma foi um episódio relativamente similar a quando Linus Torvalds, criador do Linux, criou o Git, onde ele alegou que nenhum gerenciador de código fonte na ocasião era bom o suficiente, portanto ele mesmo criaria um que funcionasse de forma decente. Não preciso dizer que hoje o Git é o gerenciador de códigos mais utilizado no mundo, certo?! Outro fator marcante foi o desprazer que seus criadores compartilhavam para com o C++, embora reconheçam qualidades e tenham tentado manter algumas características desta linguagem, bem como de algumas outras, resultando nas principais características do Go: ","date":"2019-04-14","objectID":"/posts/go-ou-golang-porque-adotei/:1:0","tags":["Golang","Impressões"],"title":"Go Ou Golang: Porquê Adotei Go Como Minha Linguagem Favorita","uri":"/posts/go-ou-golang-porque-adotei/"},{"categories":["Impressões"],"content":"Principais Características do Go Tipagem estática, significando que tipos são essenciais e importantes para o Go, sendo também nominal e estrutural, embora não haja hierarquia de tipos; Eficiência em tempo de execução; Sintaxe simples e sucinta, aumentando a usabilidade; Alta performance para redes e multi processamento; Imperativa e modular, com encapsulamento e polimorfismo; Excelente coletor de lixo, diminuindo a necessidade de preocupação com o gerenciamento de memória. ","date":"2019-04-14","objectID":"/posts/go-ou-golang-porque-adotei/:1:1","tags":["Golang","Impressões"],"title":"Go Ou Golang: Porquê Adotei Go Como Minha Linguagem Favorita","uri":"/posts/go-ou-golang-porque-adotei/"},{"categories":["Impressões"],"content":"Tipagem Estática vs Tipagem Dinâmica** Acredito que esta seja a dúvida mais comum, portanto vale a pena explicar ou lembrar a diferença básica entre ambas. Basicamente, com linguagens que utilizam tipagem estática, o tipo é verificado antes da execução, enquanto que com tipagem dinâmica o tipo é verificado durante a execução, ou em tempo de execução. Um exemplo simples seria: “3” + 5 Em linguagens fortemente tipadas, como Go, isto irá gerar um erro, pois estas linguagens não permitem “coerção de tipos”, que seria justamente a habilidade para um valor mudar de tipo implicitamente em certos contextos. Linguagens de tipagem fraca, tais como o JavaScript, não apresentarão um erro neste cenário, pois terão um resultado “35”. Tipagem estática permite que a linguagem garanta a segurança dos tipos, de forma que os mesmos não possam ser alterados uma vez que sejam definidos. Exemplo: // Criando uma variável do tipo inteiro var minhaVariavel = 1 minhaVariavel = \"Marcelo\" Em uma linguagem de tipagem estática, isto resultaria em um erro, pois uma variável que uma vez foi criada com o tipo int ou inteiro, não pode ser alterada para um tipo string posteriormente. No entanto, em uma linguagem de tipagem dinâmica, este código não resultaria em um erro, e a variável minhaVariavel mudaria de int para string, recebendo o novo valor Marcelo. De volta ao Go ","date":"2019-04-14","objectID":"/posts/go-ou-golang-porque-adotei/:1:2","tags":["Golang","Impressões"],"title":"Go Ou Golang: Porquê Adotei Go Como Minha Linguagem Favorita","uri":"/posts/go-ou-golang-porque-adotei/"},{"categories":["Impressões"],"content":"Criação A linguagem foi originalmente criada por três nomes já conhecidos da comunidade tecnológica: Robert Griesemer (um dos criadores da engine V8 JavaScript), Rob Pike (um dos co-criadores do Unix) e Ken Thompson (outro co-criador do Unix bem como do UTF-8). Criada internamente no Google em meados de 2007, Go foi anunciada publicamente em Novembro de 2009 e sua versão 1.0 foi disponibilizada em Março de 2012. Obviamente, Go é bastante utilizada em produção pelo Google e em diversas outras empresas. Go também é utilizada em diversos projetos de Software Livre e/ou Código Aberto. Certamente você conhece ou mesmo já utilizou aplicações escritas em Go, tais como: Docker Kubernetes Dropbox Hugo Etcd InfluxDB Istio Ethereum OpenShift Terraform Deu para entender, certo?! Quando o assunto é performance e estabilidade, Go é uma excelente escolha. Além do fato de ela ter sido criada justamente por nenhuma outra linguagem ser capaz de atender as necessidades do Google, Go também busca reduzir seu trabalho de digitação. Por design, Go tenta diminuir a desordem e complexidade em termos de declarações e cabeçalhos desnecessários; tudo é declarado exatamente uma vez. A inicialização é expressiva, automática e fácil de utilizar. Sua sintaxe é limpa e fácil de compreender, de forma que o Go consegue ser expressivo e ao mesmo tempo compreensível sem sacrificar a sofisticação. Um complexo (foo.Foo* myFoo = new(foo.Foo)) pode ser reduzido em algo simples como :=, que é um construtor de declaração e inicialização. ","date":"2019-04-14","objectID":"/posts/go-ou-golang-porque-adotei/:2:0","tags":["Golang","Impressões"],"title":"Go Ou Golang: Porquê Adotei Go Como Minha Linguagem Favorita","uri":"/posts/go-ou-golang-porque-adotei/"},{"categories":["Impressões"],"content":"Para que serve Go pode ser utilizado para praticamente tudo o que você precisar desenvolver: Aplicações Web Servidores de Redes Aplicações Móveis/Mobile Aprendizado de Máquina/Machine Learning Processamento de Imagens Load Balancers Administração de Sistemas Hardware Scripts Criptografia Go foi criado com o intuito de ser eficiente em termos de múltiplos cores, sendo a primeira linguagem a suportar múltiplos cores nativamente, de forma que trabalhar com concorrência é uma tarefa extremamente simples. Sua portabilidade é excelente, visto que pode ser compilado em diversas plataformas ou sistemas operacionais distintos, inclusive compilação cruzada, de forma que você pode compilar um código Go no OS X da Apple e rodar este binário em uma máquina Linux. Além de ter sido criada pelo Google, Go é uma linguagem de código aberto, o que facilita a evolução da linguagem por ser mantida por uma enorme comunidade de programadores espalhados pelo mundo. Como podemos ver no gráfico acima, Go possui uma sintaxe bonita e sucinta, enquanto mantém uma excelente performance para aplicações e concorrência de execuções. Manter e dar manutenção em código Go é fácil. Go não possui uma sintaxe complexa e cheia de rodeios como outras linguagens. Uma vez que o Google possui bases de códigos gigantescas, com milhões e milhões de linhas, esta característica era fundamental durante a criação do Go, visto que uma base de código deveria ser simples e legível para demais programadores. Intencionalmente, Go não trás uma série de recursos de linguagens modernas orientadas a objetos: Nada de classes: Tudo é dividido em pacotes. Go utiliza apenas structs ao invés de classes; Não suporta herança: Isto fará com que o código seja simples de se modificar. Em outras linguagens como Java/Python, se uma classe XYZ herda de uma classe 123 e você alterar algo na classe 123, isto poderá causar efeitos inesperados em outras classes que herdem dela. Ao remover heranças, Go torna fácil o entendimento do código, visto que não haverá uma super classe que deverá sempre ser checada; Sem construtores; Sem anotações; Sem genéricos; Sem exceções. Características como essas fazem com que Go seja quase tão eficiente e performático quanto C/C++, enquanto possui uma sintaxe super simples, como Ruby ou Python, conforme podemos ver no gráfico abaixo: Se nada disso lhe convenceu, que tal o fato de que de acordo com as pesquisas públicas do Slashdot Go está entre as linguagens cujos profissionais recebem os melhores salários? Ok, você não liga para dinheiro e quer apenas o suficiente para pagar suas contas, certo… Pense no seguinte.. em breve não teremos muita escolha. Com o hardware evoluindo sempre mais rapidamente que o software, já existe uma pressão muito grande para uma mudança de paradigma e de qualidade de software. De que adianta ter processadores cada vez mais modernos e com múltiplos núcleos/cores se o seu software não consegue fazer uso daquilo adequadamente? A cada ano a pressão será maior neste sentido, para que possamos escrever código que justifique o custo e as qualidades dos processadores modernos. Se ainda assim você não está convencido, só me resta apelar para o simpático mascote do Go. Se ele não lhe conquistar, nada mais o fará. Happy Hacking! ","date":"2019-04-14","objectID":"/posts/go-ou-golang-porque-adotei/:3:0","tags":["Golang","Impressões"],"title":"Go Ou Golang: Porquê Adotei Go Como Minha Linguagem Favorita","uri":"/posts/go-ou-golang-porque-adotei/"},{"categories":["Aleatórios"],"content":"Após alguns meses o blog está de volta, com diversas mudanças que facilitarão as coisas em termos de manutenção. Cara nova, estrutura nova... tudo novo.","date":"2019-04-03","objectID":"/posts/de-volta-com-novo-visual/","tags":["Golang","Impressões","Segurança"],"title":"De Volta à Ativa e Com Novo Visual","uri":"/posts/de-volta-com-novo-visual/"},{"categories":["Aleatórios"],"content":"Após alguns meses o blog está de volta, com diversas mudanças que facilitarão as coisas em termos de manutenção. Cara nova, estrutura nova… tudo novo. Sei que passei alguns meses sem publicar conteúdo por aqui mas, assim como tudo na vida, existe uma explicação para isso. (Não prometo ser uma boa explicação… :p) As coisas foram um pouco corridas no fim do ano e mais corridas ainda no início do ano. Comecei a estudar algumas tecnologias novas e, neste embalo, resolvi que era hora de fazer uma manutenção grande no blog. A manutenção foi relativamente grande, visto que o blog foi praticamente criado novamente, utilizando-se de tecnologias diferentes para o backend, novo design, mais limpo e prático. E para não ficar apenas na memória, aqui vão duas imagens de como ele era até ontem… Como no já manjado dizer: Foi bom enquanto durou. Esta antiga versão do blog foi desenvolvida com o framework Octopress. Para quem não conhece, Octopress é um framework baseado no Jekyll, a popular engine para blogs estáticos responsável pelo Github Pages. Este, por sua vez, é baseado na linguagem de programação Ruby. Embora prático, sua performance por vezes deixa a desejar bem como a pouca flexibilidade que temos neste framework. Este simpático polvo é o mascote/logo do projeto Octopress. Embora ele tenha me dado alegria por alguns anos, também me trouxe algumas frustrações e dores de cabeça, portanto achei que poderia ser a hora de buscar algo diferente. Uma das coisas que comecei a estudar nos últimos meses é a linguagem de programação criada pelo Google, o Golang ou simplesmente Go, como muitos preferem chamar. Go é uma linguagem fantástica e de excelente performance, no entanto o objetivo deste post não é falar sobre Go. Uma vez que comecei a estudar a linguagem e imediatamente gostei muito de sua sintaxe limpa, lógica e também sua performance, pensei que poderia ser uma boa linguagem para o backend principal do novo blog. Logo me deparei com o Hugo. Hugo é considerado o framework mais rápido do mundo para construção de sites e blogs. Um framework baseado em Go que trás uma série de benefícios e flexibilidade em termos de módulos e customização de código. Para se ter uma ideia, o build de meu blog anterior levava aproximadamente 35 segundos após qualquer modificação que eu fizesse no código. Com o Hugo, o build está levando cerca de 1,6 segundos. Uma diferença absurda em termos de performance, certo? O Hugo promete leva menos de 1ms para realizar o build de cada página, portanto a maioria dos blogs/sites com algumas centenas de páginas levará poucos segundos para ter um build completo, enquanto que sites mais simples geralmente levarão menos de 1 segundo para um build completo. A aparência ficou exatamente da forma que você está vendo agora. ;] Além da mudança completa no blog passei por outra grande mudança em minha vida. Mudei de emprego e isso, obviamente, também me tomou algum tempo, impactando no tempo para término desta migração para o novo blog. Águas passadas. Agora, de casa nova, tentarei voltar a ter posts com uma maior frequência com foco maior em DevOps e tecnologias em geral. Abraços. ","date":"2019-04-03","objectID":"/posts/de-volta-com-novo-visual/:0:0","tags":["Golang","Impressões","Segurança"],"title":"De Volta à Ativa e Com Novo Visual","uri":"/posts/de-volta-com-novo-visual/"},{"categories":["Tutoriais"],"content":"Uma introdução ao Terraform, da Hashicorp, como robusta e eficiente ferramenta para infraestrutura como código. Criando infraestrutura na nuvem GCP, do Google.","date":"2018-11-24","objectID":"/posts/terraform-criando-uma-infraestrutura-no/","tags":["Devops","Terraform","Cloud","GCP","Docker","Kubernetes"],"title":"Terraform: Criando uma infraestrutura no Google Cloud","uri":"/posts/terraform-criando-uma-infraestrutura-no/"},{"categories":["Tutoriais"],"content":"Quando se fala em infraestrutura como código imagina-se algo mais complexo do que simplesmente um container docker rodando uma aplicação, certo?! O propósito deste post é justamente criar uma infraestrutura um pouco mais complexa e completa no GCP, Google Cloud Platform. Embora o Terraform possua integração com diversos provedores de computação em nuvem, utilizarei o Google Cloud para este post por estar trabalhando mais com GCP atualmente e estar gostando da experiência. ","date":"2018-11-24","objectID":"/posts/terraform-criando-uma-infraestrutura-no/:0:0","tags":["Devops","Terraform","Cloud","GCP","Docker","Kubernetes"],"title":"Terraform: Criando uma infraestrutura no Google Cloud","uri":"/posts/terraform-criando-uma-infraestrutura-no/"},{"categories":["Tutoriais"],"content":"1 Introdução Uma vez que não entrarei em tantos detalhes básicos do Terraform neste post, espero que você já possua algum conhecimento básico sobre o mesmo bem como entenda como funcionam seus resources, variables, etc. Do contrário, recomendo fortemente que você volte um pouco e leia meus posts anteriores nesta respectiva ordem: Infraestrutura como Código com Terraform Introdução ao Terraform Terraform: Variáveis e Outputs Assumindo que você já possui algum conhecimento básico sobre Terraform, chegou a hora de inciarmos o nosso pequeno projeto de infraestrutura como código. ","date":"2018-11-24","objectID":"/posts/terraform-criando-uma-infraestrutura-no/:1:0","tags":["Devops","Terraform","Cloud","GCP","Docker","Kubernetes"],"title":"Terraform: Criando uma infraestrutura no Google Cloud","uri":"/posts/terraform-criando-uma-infraestrutura-no/"},{"categories":["Tutoriais"],"content":"2 GCP - Google Cloud Platform Google Cloud Platform Google Cloud Platform, ou GCP, é uma suíte de computação em nuvem oferecida pelo Google, funcionando na mesma infraestrutura que a empresa utiliza para seus produtos dirigidos aos usuários, dentre eles o buscador Google e o Youtube. Juntamente com um conjunto de ferramentas de gerenciamento modulares, o GCP fornece uma série de serviços incluindo computação, armazenamento de dados, análise de dados, machine learning, containers, etc. Novamente, o motivo pelo qual optei por utilizar GCP para este pequeno projeto foi simplesmente o fato de eu estar trabalhando mais com GCP em meu dia a dia atual, mas nada impede que você utilize AWS ou Microsoft Azure, por exemplo. Embora a sintaxe e o código Terraform deverá ser ajustado para tais plataformas caso decida utilizá-las. Outro motivo interessante é o plano gratuito oferecido pelo Google, o que facilita nossos estudos e experimentos. O GCP nos oferece 1 ano de utilização grátis OU $300 dólares em créditos, o que ocorrer primeiro. De uma forma ou de outra, isto será muito mais que o suficiente para a execução deste nosso projeto. Além das duas razões já citadas, a integração e facilidade de criação de uma nova conta no GCP foi levada em conta para esta escolha. O fato de o gmail e demais serviços do Google serem amplamente utilizados, é bem provável que você possua um email do Google (gmail, por exemplo), certo!? Se este é o caso, você já possui uma “pré-conta” no GCP sem ao menos saber. ","date":"2018-11-24","objectID":"/posts/terraform-criando-uma-infraestrutura-no/:2:0","tags":["Devops","Terraform","Cloud","GCP","Docker","Kubernetes"],"title":"Terraform: Criando uma infraestrutura no Google Cloud","uri":"/posts/terraform-criando-uma-infraestrutura-no/"},{"categories":["Tutoriais"],"content":"2.1 Cadastro Se você possui uma conta do Google, autentique-se com a mesma. Caso não possua uma, você poderá criar uma através do Gmail, por exemplo, ou criar diretamente na interface do Google Cloud durante o cadastro. 1- Uma vez logado com sua conta do Google, acesse em seu navegador o seguinte endereço: Google Cloud Console 2- Caso esteja logado com sua conta do Google, verá sua foto ou imagem de conta no canto superior direito da página conforme na imagem a seguir. Clique em Try free ou Experimente Gratuitamente; 3- Você cairá na primeira página do cadastro. Informe seu País, leia e concorde com os termos de uso caso deseje seguir e em seguida clique em Concordar e Continuar; 4- Após confirmar e validar todas as informações que eles pedem na etapa 2, clique em Iniciar minha avaliação gratuita; Em poucos segundos você deverá cair no painel ou dashboard principal do GCP, com um popup de boas vindas com alguma mensagem de boas vindas: “Olá, Marcelo, Agradecemos por você se inscrever na avaliação gratuita de 12 meses. Demos US$ 300 de crédito grátis para você gastar. Não se preocupe se o crédito acabar, você só receberá cobranças se tivermos sua permissão.” Este é outro fator interessante do GCP. Durante este período de avaliação, você não corre o risco de ser cobrado caso utilize mais do que deveria por descuido. Uma vez que o período de 12 meses, ou o crédito de $300 tenha se esgotado, você será notificado e deverá encerrar sua conta ou confirmar que deseja continuar utilizando os serviços, autorizando assim o Google a lhe efetuar cobranças a partir deste momento. O painel principal se parecerá com este: Conforme a imagem abaixo, através do Menu principal que se encontra na lateral esquerda, clique em IAM e Admin, e em seguida em Gerenciar recursos. Você receberá uma listagem inicial de seus recursos. Por padrão, quando se cria uma nova conta no GCP, apenas um projeto inicial é criado, chamado My First Project, sem qualquer recurso vinculado ou inserido no mesmo. ","date":"2018-11-24","objectID":"/posts/terraform-criando-uma-infraestrutura-no/:2:1","tags":["Devops","Terraform","Cloud","GCP","Docker","Kubernetes"],"title":"Terraform: Criando uma infraestrutura no Google Cloud","uri":"/posts/terraform-criando-uma-infraestrutura-no/"},{"categories":["Tutoriais"],"content":"2.2 Criando uma conta de serviço ou service account Embora seja possível e permitido utilizar-se de uma conta pessoal para este tipo de tarefa, não é o mais indicado. O ideal é deixar serviços utilizarem contas específicas, as chamadas service accounts. Uma vez que utilizaremos o Terraform para criar nossos recursos na nuvem, ele não deixa de funcionar como um serviço, não sendo uma pessoa XYZ de um departamento qualquer de uma empresa. 1- No menu principal da lateral esquerda, clique em IAM e Admin, em seguida em Contas de serviço, conforme na imagem abaixo: 2- Na tela de Contas de serviço, clique em Criar conta de serviço; 3- Indique o nome terraform para esta conta, conforme imagem abaixo, e clique em CRIAR; 4- No passo 2, daremos um papel para esta conta de serviço. Aqui indicaremos quais permissões ela terá. Para facilitar nosso exercício, utilizaremos Projeto \u003e Proprietário, significando que nossa conta de serviço terá todas as permissões em nosso projeto, podendo criar ou destruir qualquer tipo de recurso. 5- Em seguida, clicaremos em Continuar para seguir com a criação de nossa conta de serviço; 6- Na tela seguinte lhe será dada a opção de dar permissões para algum usuário que possa precisar utilizar-se desta conta de serviço para criar recursos. Você pode inserir neste campo o seu usuário principal do google cloud, o qual será o seu email que foi utilizado para criar esta conta no GCP. Insira-o em Papel de usuários da conta de serviço. Em seguida, clique no botão de Criar Chave que se encontra logo abaixo. Esta será a chave criptografada que utilizaremos para comunicação segura com o GCP; 7- Lhe será perguntado em que formato você deseja slavar a chave. Escolha o formato JSON e clique em CRIAR; 8- Escolha com atenção o local onde salvará esta chave, pois você não poderá baixá-la novamente e precisaremos da mesma posteriormente; OBS: Para facilitar este exemplo, estarei salvando a chave no mesmo diretório no qual criaremos o código de nosso projeto. Caso você decida fazer o mesmo, e decida hospedar este código em alguma espécie de repositório git, por exemplo, lembre-se de sempre incluir esta e outras chaves ou dados sigilosos em seu .gitignore, para que este tipo de arquivo com informações confidenciais não seja enviado para o repositório juntamente com o código. =) (Sim, já vi pessoas hospedando chaves em repositórios git e tendo sérios problemas. Sim, é você mesmo. :p) ","date":"2018-11-24","objectID":"/posts/terraform-criando-uma-infraestrutura-no/:2:2","tags":["Devops","Terraform","Cloud","GCP","Docker","Kubernetes"],"title":"Terraform: Criando uma infraestrutura no Google Cloud","uri":"/posts/terraform-criando-uma-infraestrutura-no/"},{"categories":["Tutoriais"],"content":"2.3 Google Cloud SDK Um dos nossos pré-requisitos será o Google Cloud SDK, que possui um conjunto de ferramentas via linha de comando que nos permitem interagir com o Google Cloud remotamente através de APIs. O Terraform também fará uso desta ferramenta. Para o funcionamento do gcloud SDK precisaremos também possuir o Python instalado, na versão 2.7. Você poderá confirmar a sua versão do python executando python -V em algum console ou terminal. Informações detalhadas sobre como instalar o Gcloud SDK encontram-se com excelentes detalhes nas páginas oficiais do Google, listadas abaixo: Para Linux (genérico): Aqui Para Linux (Debian e Ubuntu): Aqui Para Linux (Red Hat e CentOS): Aqui Para Mac OS X: Aqui Para Windows: Aqui É importante lembrar de reiniciar o seu terminal ou console após a instalação. Para certificar-se de que a instalação foi realizada com sucesso, execute: $ gcloud --version Google Cloud SDK 225.0.0 bq 2.0.37 core 2018.11.09 gsutil 4.34 Se você recebeu informações referentes à versão do Google Cloud SDK, significa que a instalação foi bem sucedida. O próximo passo é autenticar-se com sua conta do google através do SDK. Execute gcloud init. O seu navegador deverá abrir automaticamente lhe pedindo a autenticação de sua conta do Google após você confirmar com um Y a solicitação no console ou terminal. $ gcloud init Welcome! This command will take you through the configuration of gcloud. Your current configuration has been set to: [default] You can skip diagnostics next time by using the following flag: gcloud init --skip-diagnostics Network diagnostic detects and fixes local network connection issues. Checking network connection...done. Reachability Check passed. Network diagnostic passed (1/1 checks passed). You must log in to continue. Would you like to log in (Y/n)? Caso ao inserir um Y, o seu navegador não lhe solicite a autenticação do Google, copie e cole a longa URL que lhe será apresentada. A solicitação de autenticação será similar à esta: Ao finalizar sua autenticação no navegador, você receberá mais uma pergunta em seu terminal ou console. O SDK lhe indicará o seu projeto e lhe perguntará se você quer utilizá-lo ou criar um novo. Vamos escolher a opção 1, para utilizar o projeto que foi criado automaticamente e em seguida confirmar com um Enter: Your browser has been opened to visit: https://accounts.google.com/o/oauth2/auth?reblablabalblablaba=http%3A%2F%2Flocalhost%3A8085%2F\u0026prompt=select_account\u0026response_typereblablabalblablabauid.apps.googleusercontent.com\u0026scope=https%3A%2F%2Fwww.googleapis.com%reblablabalblablabaemreblablabalblablabaw.gooreblablabalblablaba%2Fauth%2Fclreblablabalblablaba%2Fwwwreblablabalblablabacomreblablabalblablabaappenreblablabalblablabattpsreblablabalblablabaww.reblablabalblablabaleapis.com%2Fauthreblablabalblablabattps%3A%2F%2Fwww.googleapis.com%2Fauthreblablabalblablaba\u0026access_type=offline You are logged in as: [marcelo@marceloemail.net]. Pick cloud project to use: [1] possible-sun-meuid [2] Create a new project Please enter numeric choice or text value (must exactly match list item): O SDK finalizará o setup e lhe informará que o projeto está pronto para ser utilizado. ","date":"2018-11-24","objectID":"/posts/terraform-criando-uma-infraestrutura-no/:2:3","tags":["Devops","Terraform","Cloud","GCP","Docker","Kubernetes"],"title":"Terraform: Criando uma infraestrutura no Google Cloud","uri":"/posts/terraform-criando-uma-infraestrutura-no/"},{"categories":["Tutoriais"],"content":"3 Terraform Vamos ao que interessa agora. Antes de iniciarmos nosso código, crie um diretório chamado terraform-gcp, ou algo de sua preferência. Dentro deste diretório apenas teremos por enquanto o arquivo JSON que baixamos do GCP com as credenciais de nossa conta de serviço. Criaremos agora nosso primeiro arquivo terraform. Comecemos criando nosso arquivo de variáveis, o qual por enquanto conterá apenas 2 variáveis para começarmos nosso código. Crie o arquivo variables.tf com o seguinte conteúdo: variable \"project_id\" { type = \"string\" default = \"possible-sun-83482736\" } variable \"regiao\" { type = \"string\" default = \"northamerica-northeast1\" } OBS: Lembre-se de alterar o valor default da variável project_id. Eu inseri aqui o id do projeto que foi criado para mim pelo GCP automaticamente. O id do seu projeto deverá ser o mesmo fornecido a você pelo GCP. Outra coisa importante é lembrar que estou assumindo que você já possui algum conhecimento básico sobre como o Terraform funciona, ou que leu meus posts anteriores sobre o assunto, de forma que não estarei aqui entrando em tantos detalhes explicativos sobre cada arquivo, conforme fiz nos anteriores. Em nosso arquivo variables.tf, por enquanto, criamos apenas duas variáveis: project_id e regiao. Para quem já utilizou algum serviço de computação em nuvem, seja GCP, AWS, Azure, etc., isto pode soar familiar. Sempre que se deseja criar recursos na nuvem, devemos optar por alguma região disponível no provedor de escolha. Estou optando por utilizar northamerica-northeast1 pelo fato de eu morar em Toronto, e esta ser a região mais próxima, mas sinta-se livre para optar por qualquer região disponível no GCP conforme lista fornecida aqui. Em seguida criaremos nosso arquivo main.tf que, inicialmente, possuirá apenas o seguinte: # Configura o projeto GCP provider \"google\" { credentials = \"${file(\"possible-sun-83482736-sabh45jhb2345ghv.json\")}\" project = \"${var.project_id}\" region = \"${var.regiao}\" } Aqui estamos apenas informando ao Terraform que utilizaremos o google como provedor ou provider. Para nos conectarmos com o provider precisamos passar nossas credenciais e para tal estamos apontando o arquivo ou file que baixamos do GCP com as informações de nossa conta de serviço. Aqui estou passando apenas o nome do arquivo, pois o mesmo se encontra no mesmo diretório onde se encontra meu código. Além da credencial, estamos também informando qual o nome do projeto que utilizaremos no GCP bem como a região na qual estaremos trabalhando. Ambos os valores estão sendo trazidos do arquivo variables.tf. Aqui apenas invocamos as variáveis. (Novamente: Se esta invocação das variáveis lhe parece confusa, significa que não leu o post anterior, onde expliquei o básico sobre uso de variáveis no Terraform. Volte uma casa!) Com ambos os arquivos criados, podemos iniciar a execução de nosso projeto. Neste momento, nosso código não fará nada além de permitir que o Terraform consiga se conectar ao GCP e validar que nossa conta e projeto de fato existem. Executemos terraform init para ver se está tudo certo: $ terraform init Initializing provider plugins... - Checking for available provider plugins on https://releases.hashicorp.com... - Downloading plugin for provider \"google\" (1.19.1)... The following providers do not have any version constraints in configuration, so the latest version was installed. To prevent automatic upgrades to new major versions that may contain breaking changes, it is recommended to add version = \"...\" constraints to the corresponding provider blocks in configuration, with the constraint strings suggested below. * provider.google: version = \"~\u003e 1.19\" Terraform has been successfully initialized! You may now begin working with Terraform. Try running \"terraform plan\" to see any changes that are required for your infrastructure. All Terraform commands should now work. If you ever set or change modules or backend configuration for Terraform, rerun this command to reinitialize your working ","date":"2018-11-24","objectID":"/posts/terraform-criando-uma-infraestrutura-no/:3:0","tags":["Devops","Terraform","Cloud","GCP","Docker","Kubernetes"],"title":"Terraform: Criando uma infraestrutura no Google Cloud","uri":"/posts/terraform-criando-uma-infraestrutura-no/"},{"categories":["Tutoriais"],"content":"Uma introdução ao Terraform, da Hashicorp, como robusta e eficiente ferramenta para infraestrutura como código. Separando variáveis e Outputs.","date":"2018-11-06","objectID":"/posts/terraform-variaveis-e-outputs/","tags":["Devops","Terraform","Cloud","GCP","Docker"],"title":"Terraform: Variáveis e Outputs","uri":"/posts/terraform-variaveis-e-outputs/"},{"categories":["Tutoriais"],"content":"Uma introdução ao Terraform, da Hashicorp, como robusta e eficiente ferramenta para infraestrutura como código. Separando variáveis e Outputs. ","date":"2018-11-06","objectID":"/posts/terraform-variaveis-e-outputs/:0:0","tags":["Devops","Terraform","Cloud","GCP","Docker"],"title":"Terraform: Variáveis e Outputs","uri":"/posts/terraform-variaveis-e-outputs/"},{"categories":["Tutoriais"],"content":"Onde paramos Antes de seguir em frente com esta leitura gostaria de dizer que este post é continuação do anterior, onde dei uma breve introdução ao Terraform, com um exemplo prático em que fizemos o deployment de um jogo web do Mario em um container Docker. Este post na verdade utilizará o mesmo código que escrevemos no post anterior, portanto se você não o leu, recomendo fortemente que o faça clicando aqui. ","date":"2018-11-06","objectID":"/posts/terraform-variaveis-e-outputs/:1:0","tags":["Devops","Terraform","Cloud","GCP","Docker"],"title":"Terraform: Variáveis e Outputs","uri":"/posts/terraform-variaveis-e-outputs/"},{"categories":["Tutoriais"],"content":"Variáveis Embora nosso código tenha funcionado corretamente, ele não estava limpo. Existem algumas boas práticas que devemos sempre tentar seguir, Não apenas para deixar o código limpo, mas também para facilitar a manutenção do mesmo. Imagine o seguinte código em Ruby: puts \"Meu nome é Marcelo.\" puts \"O Marcelo gosta de escrever códigos.\" puts \"Mas o Marcelo também gosta de surfar.\" puts \"Não sendo bom o suficiente a ponto de se tornar um profissional do surf, Marcelo decidiu seguir com a carreira de TI.\" puts \"Este é o Marcelo.\" Um código extremamente simples que apenas imprime diversas strings na tela. Imagine que você precisa fazer manutenção deste código pois sua empresa agora decidiu que o personagem da história seria Pedro e não mais Marcelo. Claro, você pode ir lendo linha a linha e alterando em cada linha, mas isso leva muito mais tempo do que deveria. Imagine agora que este sistema possua algumas centenas de linhas de código. Ou múltiplos arquivos. Começa a ficar mais complexo e demorado alterar tudo, sem falar que fica fácil cometer o erro de esquecer algum. Por outro lado, se o nosso código utilizasse variáveis, apenas trocaríamos o valor em um local, tendo assim certeza absoluta de que o mesmo estaria correto em todo o código. Por exemplo: nome = \"Marcelo\" puts (\"Meu nome é \" + nome + \".\") puts (\"O \" + nome + \" gosta de escrever códigos.\") puts (\"Mas o \" + nome + \" também gosta de surfar.\") puts (\"Não sendo bom o suficiente a ponto de se tornar um profissional do surf, \" + nome + \" decidiu seguir com a carreira de TI.\") puts (\"Este é o \" + nome + \".\") Neste código, quando precisarmos trocar o nome da pessoa e utilizar Pedro ao invés de Marcelo, precisaríamos alterar apenas o valor da variável na linha 1. muito mais simples, certo?! Da mesma forma que em programação básica utilizamos variáveis, quando pensamos em infraestrutura como código deveríamos pensar da mesma forma, afinal estamos programando, certo?! Nao é um sistema, mas ainda assim estamos programando nossa infraestrutura. Este é o nosso arquivo main.tf completo do post anterior: # Baixar a imagem do Projeto Docker-SuperMario resource \"docker_image\" \"image_id\" { name = \"pengbai/docker-supermario:latest\" } # Inicia o Container resource \"docker_container\" \"container_id\" { name = \"supermario\" image = \"${docker_image.image_id.latest}\" ports { internal = \"8080\" external = \"80\" } } # Nos informa o ip e nome do container criado output \"Endereco IP\" { value = \"${docker_container.container_id.ip_address}\" } output \"Nome do Container\" { value = \"${docker_container.container_id.name}\" } Neste código não estamos utilizando variáveis, embora tenhamos um pouco de interpolação de valores. Vamos então começar a criar algumas variáveis, mas, seguindo as boas práticas do Terraform, criaremos um arquivo separado para nossas variáveis. Crie um arquivo chamado variables.tf. O motivo pelo qual utilizaremos o nome em inglês aqui é por ser este o padrão adotado pelo Terraform. Ao chamarmos uma variável em nosso código, o Terraform saberá onde buscar o valor daquela variável. Para cada variável daremos um nome, uma descrição e um valor default. Nosso arquivo variables.tf ficará assim: variable \"nome_container\" { description = \"Nome do container\" default = \"supermario\" } variable \"imagem\" { description = \"Imagem do container\" default = \"pengbai/docker-supermario:latest\" } variable \"porta_interna\" { description = \"Porta interna do container\" default = \"8080\" } variable \"porta_externa\" { description = \"Porta externa do container\" default = \"80\" } O que definimos: Criamos 4 variáveis aqui: nome_container, imagem, porta_interna e porta_externa; Para cada variável nós demos 2 atributos: description (descrição) e default (Valor padrão); Variáveis não precisam ser sempre declaradas. Existem ocasiões em que podemos criar uma variável sem qualquer valor atribuído à mesma, de forma que o valor será passado durante a execução do código, por exemplo. Por padrão, quando queremos que a variável ","date":"2018-11-06","objectID":"/posts/terraform-variaveis-e-outputs/:2:0","tags":["Devops","Terraform","Cloud","GCP","Docker"],"title":"Terraform: Variáveis e Outputs","uri":"/posts/terraform-variaveis-e-outputs/"},{"categories":["Tutoriais"],"content":"Outputs Comecemos criando um arquivo chamado outputs.tf com o seguinte conteúdo: # Nos informa o ip e nome do container criado output \"Endereco IP\" { value = \"${docker_container.container_id.ip_address}\" } output \"Nome do Container\" { value = \"${docker_container.container_id.name}\" } Este foi fácil, certo?! Se prestarmos atenção, não alteramos praticamente nada. Apenas copiamos os dois blocos outputs do arquivo main.tf sem qualquer alteração. Após salvar nosso arquivo outputs.tf, removeremos estes dois outputs do arquivo main.tf. Nosso main.tf ficará assim: # Baixar a imagem do Projeto Docker-SuperMario resource \"docker_image\" \"image_id\" { name = \"${var.imagem}\" } # Inicia o Container resource \"docker_container\" \"container_id\" { name = \"${var.nome_container}\" image = \"${docker_image.image_id.latest}\" ports { internal = \"${var.porta_interna}\" external = \"${var.porta_externa}\" } } Simples, não? Nosso código está mais limpo e organizado. Vamos destuir novamente nosso projeto com terraform destroy para que possamos testar estas últimas alterações: $ terraform destroy docker_image.image_id: Refreshing state... (ID: sha256:49beaba1c5cc49d2fa424ac03a15b0e7...9c3d62pengbai/docker-supermario:latest) docker_container.container_id: Refreshing state... (ID: bbe9e8e7b5428532b882e7fbd304fc2b3d71e0bcb29fa099e15162397731e15e) An execution plan has been generated and is shown below. Resource actions are indicated with the following symbols: - destroy Terraform will perform the following actions: - docker_container.container_id - docker_image.image_id Plan: 0 to add, 0 to change, 2 to destroy. Do you really want to destroy all resources? Terraform will destroy all your managed infrastructure, as shown above. There is no undo. Only 'yes' will be accepted to confirm. Enter a value: yes docker_container.container_id: Destroying... (ID: bbe9e8e7b5428532b882e7fbd304fc2b3d71e0bcb29fa099e15162397731e15e) docker_container.container_id: Destruction complete after 1s docker_image.image_id: Destroying... (ID: sha256:49beaba1c5cc49d2fa424ac03a15b0e7...9c3d62pengbai/docker-supermario:latest) docker_image.image_id: Destruction complete after 1s Destroy complete! Resources: 2 destroyed. Agora vamos aplicar nosso plan e em seguida, caso tudo esteja correto, vamos executar terraform plan: $ terraform plan Refreshing Terraform state in-memory prior to plan... The refreshed state will be used to calculate this plan, but will not be persisted to local or remote state storage. ------------------------------------------------------------------------ An execution plan has been generated and is shown below. Resource actions are indicated with the following symbols: + create Terraform will perform the following actions: + docker_container.container_id id: \u003ccomputed\u003e attach: \"false\" bridge: \u003ccomputed\u003e container_logs: \u003ccomputed\u003e exit_code: \u003ccomputed\u003e gateway: \u003ccomputed\u003e image: \"${docker_image.image_id.latest}\" ip_address: \u003ccomputed\u003e ip_prefix_length: \u003ccomputed\u003e log_driver: \"json-file\" logs: \"false\" must_run: \"true\" name: \"supermario\" network_data.#: \u003ccomputed\u003e ports.#: \"1\" ports.0.external: \"80\" ports.0.internal: \"8080\" ports.0.ip: \"0.0.0.0\" ports.0.protocol: \"tcp\" restart: \"no\" rm: \"false\" start: \"true\" + docker_image.image_id id: \u003ccomputed\u003e latest: \u003ccomputed\u003e name: \"pengbai/docker-supermario:latest\" Plan: 2 to add, 0 to change, 0 to destroy. ------------------------------------------------------------------------ Note: You didn't specify an \"-out\" parameter to save this plan, so Terraform can't guarantee that exactly these actions will be performed if \"terraform apply\" is subsequently run. $ terraform apply An execution plan has been generated and is shown below. Resource actions are indicated with the following symbols: + create Terraform will perform the following actions: + docker_container.container_id id: \u003ccomputed\u003e attach: \"false\" bridge: \u003ccomputed\u003e container_logs: \u003ccomputed\u003e exit_code: \u003ccomputed\u003e gateway: \u003ccomputed\u003e image: \"${docker_image.image_id.latest}\" ip_ad","date":"2018-11-06","objectID":"/posts/terraform-variaveis-e-outputs/:3:0","tags":["Devops","Terraform","Cloud","GCP","Docker"],"title":"Terraform: Variáveis e Outputs","uri":"/posts/terraform-variaveis-e-outputs/"},{"categories":["Tutoriais"],"content":"Atenção: Outputs como variáveis de saída Da mesma forma que eu citei que existem outras formas de se declarar e utilizar variáveis, existem outras funções também para os outputs. Não, o Terraform não utiliza outputs apenas para apresentar informações na tela. A principal função dos outputs é na verdade a de variáveis de saída. Ou seja, pegar valores que poderão ser utilizados posteriormente. Este recurso é muito utilizado em projetos maiores com infraestruturas mais complexas mas, novamente, não é o foco deste post abordar isto. Se você é um pouco atencioso e curioso, deve ter notado que não definimos os valores dos outputs em nenhum momento, certo? Por exemplo: value = “${docker_container.container_id.ip_address}” Ou seja, estamos criando um output cujo valor será na verdade uma saída após o processamento de nosso código Terraform. Desta forma, nossos outputs são na verdade variáveis de saída.. mas isso já é uma outra história. A propósito, se você além de curioso é também meticuloso, deve ter ficado confuso e questionado: Se outputs são na verdade uma espécie de variáveis, como podemos ter espaços em seus nomes? Como por exemplo “Nome do Container”? A resposta é: Você me pegou. As melhores práticas pregam que não devemos criar outputs com espaços. Porque? Porque variáveis não podem conter espaços. Mas, como desde o início nosso objetivo era utilizar os outputs aqui apenas para nos retornar algum valor na tela, resolvi utilizar palavras em portugês e com espaços para facilitar a compreensão. O ideal seria termos utilizado nome_do_container ao invés de Nome do Container, ou endereco_ip ao invés de Endereco IP mas, novamente.. isto é uma outra história. Lembre-se de destuir o seu projeto para não deixar um container rodando desnecessariamente: $ terraform destroy Em meu próximo post pretendo elevar um pouco o nível e utilizar o Terraform para criarmos uma infraestrutura básica na nuvem. Happy Hacking! ","date":"2018-11-06","objectID":"/posts/terraform-variaveis-e-outputs/:4:0","tags":["Devops","Terraform","Cloud","GCP","Docker"],"title":"Terraform: Variáveis e Outputs","uri":"/posts/terraform-variaveis-e-outputs/"},{"categories":["Tutoriais"],"content":"Uma introdução ao Terraform, da Hashicorp, como robusta e eficiente ferramenta para infraestrutura como código.","date":"2018-10-29","objectID":"/posts/introducao-ao-terraform/","tags":["Devops","Terraform","Cloud","GCP","Docker"],"title":"Introdução ao Terraform","uri":"/posts/introducao-ao-terraform/"},{"categories":["Tutoriais"],"content":"Uma introdução ao Terraform, da Hashicorp, como robusta e eficiente ferramenta para infraestrutura como código. ","date":"2018-10-29","objectID":"/posts/introducao-ao-terraform/:0:0","tags":["Devops","Terraform","Cloud","GCP","Docker"],"title":"Introdução ao Terraform","uri":"/posts/introducao-ao-terraform/"},{"categories":["Tutoriais"],"content":"Terraform - Uma robusta opção para Infraestrutura como Código A Hashicorp é uma empresa de bastante destaque no meio DevOps por ter criado várias soluções de automação, que englobam uma série de funcionalidades, como o Packer para criação de imagens de forma automatizada, conforme apresentado nestes dois posts do blog 1, 2, Vagrant, para provisionamento simples e rápido de máquinas, Vault, para gerenciamento de senhas/segredos (secrets), Consul, para descoberta de serviços, Nomad, para agendamento e automação de deployments, e o [Terraform](https://terraform.io, foco principal deste post, uma robusta ferramenta para criação de infraestrutura como código, ou infrastructure as cdode. Caso você não possua uma ideia muito clara de qual a idea por trás do conceito de infraestrutura como código, ou mesmo quais as vantagens de se utilizar esta metodologia de gerenciamento/criação de infraestrutura, sugiro que leia meu post anterior, no qual explico alguns dos principais benefícios desta prática, bem como uma breve apresentação do Terraform. De forma resumida, o Terraform é uma ferramenta disponível em formatos Open Source ou Enterprise, cujo intuito é permitir a criação de infraestrutura como código, possibilitando o controle de versões. Suporta diversos provedores tais como AWS, OpenStack, Azure, GCP, etc. Uma de suas principais características é a idempotência, termo muito utilizado na matemática ou em ciência da computação para indicar a propriedade que algumas operações têm de poderem ser aplicadas várias vezes sem que o valor do resultado se altere após a aplicação inicial. Ou seja, uma vez aplicado o seu código terraform, você poderá aplicá-lo quantas vezes desejar e nenhuma alteração será feita em sua infraestrutura, a menos que você tenha de fato alterado algo em seu código. O Terraform utiliza uma linguagem de alto nível e fácil de se reutilizar, uma vez que podemos criar módulos e utilizar estes módulos em diversos projetos distintos, mesmo que tenhamos módulos em repositórios também distintos. A ideia de possuir um “plano” de execução nos ajuda a identificar falhas em nosso código mais rapidamente, bem como prevenir problemas em nossa infraestrutura, visto que podemos ter uma visão geral de tudo o que será aplicado em nossa infra antes mesmo da execução real de nosso código, nos permitindo ter a certeza de que todas as alterações serão de fato intencionais. Sempre digo que a melhor forma de se aprender uma nova tecnologia é colocando a mão na massa, portanto vamos escrever algumas linhas de código para entendermos as funcionalidades básicas bem como a sintaxe de código utilizada pelo Terraform. Antes de pensarmos em cenários mais complexos devemos entender o básico, no entanto eu sempre gostei de ver algum resultado como forma de ter uma motivação real para meus estudos. Nunca gostei de apenas ler e escrever códigos que não resultam em nada, e acredito que todos devam sentir a mesma insatisfação ao não ter um uso real e prático para o que quer que esteja estudando. Seguindo esta ideia, antes de pensarmos em cenários mais complexos, vamos iniciar pelo básico, porém com algum resultado prático. A ideia para este post é termos um jogo clássico do Mario rodando em um container Docker que seja acessível através de nosso browser. ","date":"2018-10-29","objectID":"/posts/introducao-ao-terraform/:1:0","tags":["Devops","Terraform","Cloud","GCP","Docker"],"title":"Introdução ao Terraform","uri":"/posts/introducao-ao-terraform/"},{"categories":["Tutoriais"],"content":"Instalação Para este post precisaremos ter três aplicativos instalados: Um navegador ou browser qualquer; (Imagino que você já tenha algum…) Docker; Terraform ","date":"2018-10-29","objectID":"/posts/introducao-ao-terraform/:2:0","tags":["Devops","Terraform","Cloud","GCP","Docker"],"title":"Introdução ao Terraform","uri":"/posts/introducao-ao-terraform/"},{"categories":["Tutoriais"],"content":"Docker O processo de instalação do Docker varia de acordo com o seu sistema operacional. Caso queira maiores detalhes sobre sua instalação, bem como uma explicação introdutória de como ele funciona, você pode visitar este outro post, embora você não precise ter nenhum conhecimento sobre Docker para seguir as instruções deste tutorial, visto que utilizaremos o Terraform para criar nosso container. No Archlinux a instalação pode ser feita através do pacman: # pacman install docker No Windows a instalação pode ser feita através do binário disponível no site oficial: Binário Windows. No OS X, você também pode baixar o binário diretamente no site oficial, Binário OS X ou através do brew: brew install docker ","date":"2018-10-29","objectID":"/posts/introducao-ao-terraform/:2:1","tags":["Devops","Terraform","Cloud","GCP","Docker"],"title":"Introdução ao Terraform","uri":"/posts/introducao-ao-terraform/"},{"categories":["Tutoriais"],"content":"Terraform A instalação do Terraform é tão simples quanto a do Docker. No Archlinux a instalação pode ser feita através do pacman: # pacman -S terraform No Windows e no OS X a instalação pode ser feita através do binário disponível no site oficial do Terraform: Binários Terraform. Outra opção para OS X é através do brew: brew install terraform ","date":"2018-10-29","objectID":"/posts/introducao-ao-terraform/:2:2","tags":["Devops","Terraform","Cloud","GCP","Docker"],"title":"Introdução ao Terraform","uri":"/posts/introducao-ao-terraform/"},{"categories":["Tutoriais"],"content":"Verificando a instalação Uma vez que você tenha instalado ambos, certifique-se de que a instalação foi bem sucedida e de que o serviço Docker esteja rodando em seu sistema. Para isto, abra algum terminal, console ou prompt do CMD (para usuários Windows) e digite o seguinte: 1- Para termos certeza de que o Terraform está instalado e funcionando: terraform -version Você deverá receber algum resultado com a versão do seu Terraform, similar a este: Terraform v0.11.10 2- Para termos certeza de que o Docker está devidamente instalado e rodando, digite: docker ps Você deverá receber algum resultado parecido com o seguinte: CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES Não se assuste ou dê importância para este resultado do comando Docker, ele apenas indica o status atual de seu Docker, informando se você possui algum container rodando ou não. Caso você tenha acabado de instalar o mesmo ou iniciado o serviço do Docker, você provavelmente não terá nenhum container rodando. Caso o retorno de seu Docker ou Terraform não seja similar aos que apresentei acima, verifique se a instalação foi realmente bem sucedida ou, no caso do Docker, verifique se o mesmo está rodando, afinal ele não apenas precisa ser instalado, mas precisa estar rodando, diferentemente do Terraform que apenas precisa ser instalado. ","date":"2018-10-29","objectID":"/posts/introducao-ao-terraform/:3:0","tags":["Devops","Terraform","Cloud","GCP","Docker"],"title":"Introdução ao Terraform","uri":"/posts/introducao-ao-terraform/"},{"categories":["Tutoriais"],"content":"Iniciando nosso projeto ","date":"2018-10-29","objectID":"/posts/introducao-ao-terraform/:4:0","tags":["Devops","Terraform","Cloud","GCP","Docker"],"title":"Introdução ao Terraform","uri":"/posts/introducao-ao-terraform/"},{"categories":["Tutoriais"],"content":"Escopo O primeiro passo de qualquer projeto é identificar alguma espécie de esboço ou escopo para o mesmo. O que queremos para o nosso projeto é: Ter um jogo web do Mario; Queremos que ele rode em um container, pois queremos uma aplicação em uma infraestrutura moderna e que possa ser capaz de rodar em qualquer local, seja em um servidor físico local, uma VM ou mesmo um provedor na nuvem, como AWS, GCP, Azure, etc.; Como não sabemos onde ou como iremos fazer o deployment deste container, queremos fazer com que seja algo automatizado e portável para facilitar futuros planos, portanto queremos criar este container com o Terraform, para que possamos gerenciar nosso código, versionar, etc. Não escreveremos a aplicação em si. O jogo do Mario já existe e uma imagem para Docker já está disponível para o mesmo através do seguinte link: Imagem Mario (Mas nós não precisamos nos precoupar com isto agora, pois o Terraform vai cuidar de baixar a imagem para nós. ;]) A aplicação deverá estar acessível via browser local para que possamos ao menos garantir que o jogo está de fato funcionando. Este será o nosso escopo básico, portanto vamos começar nosso código. ","date":"2018-10-29","objectID":"/posts/introducao-ao-terraform/:4:1","tags":["Devops","Terraform","Cloud","GCP","Docker"],"title":"Introdução ao Terraform","uri":"/posts/introducao-ao-terraform/"},{"categories":["Tutoriais"],"content":"Projeto O recurso mais básico em um código ou módulo Terraform é o resource, ou recurso. O Terraform suporta centenas de recursos diferentes, dentre eles o docker_image, que será o recurso de que precisaremos inicialmente. A partir deste momento não mais utilizarei a palavra recurso. Uma vez que o Terraform chama os recursos de resources, devemos nos acostumar com sua nomenclatura. Antes de mais nada, vamos criar um diretório para nosso projeto. Chamaremos nosso projeto de Marioweb, visto que se trata de uma versao open source do jogo Mario. Aqui estarei criando o diretório via linha de comando, mas sinta-se livre para criar um diretório da forma que você preferir. Após criar o diretório, com algum terminal ou console aberto (ou prompt do CMD para usuários do Windows), navegue até este diretório recém criado: $ mkdir marioweb $ cd marioweb Dentro do diretório marioweb crie um novo arquivo chamado main.tf. Para manter um padrão, os arquivos de código do Terraform costumam utilizar o sufixo/extensão .tf e o principal arquivo em módulos ou projetos Terraform costuma se chamar main.tf, por se tratar do arquivo principal do módulo ou projeto. Para criar este arquivo você poderá utilizar qualquer editor de textos de sua escolha: vim, emacs, vi, notepad, notepad++, sublime, atom, etc. Em nosso arquivo main.tf insira o seguinte conteúdo por enquanto: main.tf # Baixar a imagem do Projeto Docker-SuperMario resource \"docker_image\" \"image_id\" { name = \"pengbai/docker-supermario:latest\" } O que temos no bloco de código acima: A primeira linha é apenas um comentário. Como boa prática, é importante termos comentários ao longo de nosso código para descrever o que pretendemos com aquele determinado trecho de código. E por hora, o que pretendemos é exatamente apenas isso: Baixar a imagem do Projeto Docker-SuperMario para nosso ambiente. Na linha 2 estamos especificando que queremos utilizar um resource. Cada resource no Terraform leva dois parâmetros, sendo um deles o tipo de resource e o outro um nome qualquer para este resource. Como dito antes, este trecho de código pretende baixar a imagem do projeto SuperMario, portanto precisamos do tipo de resource chamado docker_image. Este é apenas um dos milhares de resources existentes para o Terraform. Em seguida estamos dando o nome image_id para nosso resource de tipo docker_image. O nome poderia ser qualquer um, até mesmo minha_imagem_do_coracao, mas para ficar mais descritiva e mantendo boas práticas, utilizarei image_id. Uma vez que identificamos o tipo de resource e o nome que queremos dar para ele, devemos encerrar a linha abrindo o bloco de código no qual listaremos os atributos deste resource. Para isto, utilizaremos um { para abrir este bloco. Na linha 3 começamos a definir os atributos do nosso resource. A documentação do Terraform é excelente e lista todos os resources suportados, bem como todos os atributos suportados por cada resource. Neste caso, o único atributo que precisamos no momento é o name, ou nome da imagem que desejamos baixar. Em seguida, indicamos qual o nome da imagem desejada. Por padrão, o Docker adota a nomenclatura \u003cREPOSITÓRIO/IMAGEM:TAG\u003e para indicar a imagem desejada. Em nosso caso, o repositório onde a imagem se encontra se chama pengbai e a imagem em si é chamada de docker-supermario, portanto teremos: name = “pengbai/super-mario”. A tag não é obrigatória. Mas como desejo garantir que utilizaremos sempre a imagem mais recente, utilizarei a tag latest (última). Uma vez que concluímos a definição de nosso resource, podemos fechar o nosso bloco de código para o mesmo utilizando um } na linha 4. Agora que temos o início de nosso código, já podemos começar a testá-lo. De volta ao nosso terminal/console, vamos iniciar o nosso ambiente Terraform para este projeto utilizando o comando terraform init. Este comando inicia nosso ambiente e baixa os plugins necessários para nosso projeto. No nosso caso, o Terraform baixará os plugins necessários para que nosso código possa l","date":"2018-10-29","objectID":"/posts/introducao-ao-terraform/:4:2","tags":["Devops","Terraform","Cloud","GCP","Docker"],"title":"Introdução ao Terraform","uri":"/posts/introducao-ao-terraform/"},{"categories":["Impressões"],"content":"Uma introdução aos conceitos e benefícios de IAC, ou Infraestrutura como Código bem como uma breve apresentação da ferramenta Terraform, da Hashicorp.","date":"2018-10-22","objectID":"/posts/infraestrutura-como-codigo-com-terraform/","tags":["Devops","Terraform","Cloud","GCP","AWS"],"title":"Infraestrutura como Código com Terraform","uri":"/posts/infraestrutura-como-codigo-com-terraform/"},{"categories":["Impressões"],"content":"Uma introdução aos conceitos e benefícios de IAC, ou Infraestrutura como Código bem como uma breve apresentação da ferramenta Terraform, da Hashicorp. ","date":"2018-10-22","objectID":"/posts/infraestrutura-como-codigo-com-terraform/:0:0","tags":["Devops","Terraform","Cloud","GCP","AWS"],"title":"Infraestrutura como Código com Terraform","uri":"/posts/infraestrutura-como-codigo-com-terraform/"},{"categories":["Impressões"],"content":"Infraestrutura como Código (IAC - Infrastructure as Code) Infraestrutura como código - IaC (ou infrastructure as code em inglês) - é o processo de gerenciamento e provisionamento de recursos de infraestrutura através de códigos ou arquivos de configuração que descrevem o estado desejado para tal infraestrutura ou recursos de infraestrutura. A principal característica de IaC é o uso de scripts ou definições declarativas ao invés de processos manuais, mas o termo é utilizado com mais frequência para promover abordagens declarativas. Como se tratam de arquivos de código, as definições podem ser armazenadas em um sistema de controle de versões, tal como o Git. Abordagens IaC são comumente promovidas para computação em nuvem e, às vezes, são comercializadas como infraestrutura como serviço (infrastructure as a service, IaaS). IaC suporta IaaS, mas os dois conceitos não devem ser confundidos. ","date":"2018-10-22","objectID":"/posts/infraestrutura-como-codigo-com-terraform/:1:0","tags":["Devops","Terraform","Cloud","GCP","AWS"],"title":"Infraestrutura como Código com Terraform","uri":"/posts/infraestrutura-como-codigo-com-terraform/"},{"categories":["Impressões"],"content":"IaC e DevOps IaC, ou Infraestrutura como Código, é um conceito bastante ligado à filosofia DevOps, visto que com práticas de implementação de uma infraestrutura baseada em códigos declarativos podemos aproximar as equipes de Operações e Desenvolvimento, fazendo com que os desenvolvedores tornem-se mais envolvidos nas configurações de máquinas ou recursos de infraestrutura como um todo, enquanto que os profissionais de Operações se envolvem mais cedo no processo de desenvolvimento. Além disso, agora ambas as equipes podem armazenar seu código em um mesmo ambiente, como por exemplo repositórios Git. Infraestrutura como código mostrou-se uma excelente solução para livrar equipes de tarefas enfadonhas do cotidiano realizadas manualmente. Além de tomarem muito tempo e serem tarefas extremamente repetitivas, os corriqueiros processos manuais estão sujeitos a erros e podem colocar as operações em risco. Algumas vantagens da utilização de IaC Elimina tarefas repetitivas - Se você precisa criar 3 clusters Kubernetes em seu provedor de cloud (GCP ou AWS, por exemplo), você não precisa repetir os mesmos passos 3 vezes. Escreve um bloco de código que define a criação de um cluster e poderá aplicar este mesmo código quantas vezes forem necessárias; Documentação simplificada - Não há necessidade de logar-se em um servidor ou provedor de cloud para tentar vasculhar tudo o que foi configurado (está tudo no código); Reaproveitamento - Uma vez que tudo está codificado e separado em módulos, fica fácil reaproveitar módulos e código para futuras implementações; Simples manutenção - Mudanças na configuração, versões, regras e demais definições podem ser implementadas e aplicadas rapidamente com pequenas alterações no código; Versionamento - Ao abordar nossa infraestrutura como código passamos a ter diversos benefícios já rotineiros para desenvolvedores, como por exemplo a possibilidade de gerenciar nosso código em sistemas de versionamento como o Git, de forma a facilitar o trabalho em equipes, controle de versões, mudanças, etc; Agilidade - Se preciso trocar a faixa de endereços IP de uma VPC ou subnet, alterar uma linha de código é muito mais rápido do que logar em uma dashboard, procurar tal recurso e alterar manualmente os valores desejados; Possibilidade de soluções agnósticas - Em um mundo tecnológico que muda constantemente não são raras as ocasiões em que temos de mudar completamente nossa infraestrutura, seja deixando de usar servidores físicos para passar a utilizar VMs, ou migrando de VMs locais para a nuvem, ou de VMs na nuvem para containers, etc. Independente de qual seja o cenário de mudança, uma vez que sua infraestrutura está definida em código, dependendo das ferramentas escolhidas para codificar sua infra, o mesmo código poderia ser utilizado para um ambiente VMWare, AWS, Azure, GCP, etc, com poucas modificações. (Já citei agilidade e Simples manutenção, certo?!); Fácil replicar - Em um ambiente não codificado ou automatizado, geralmente repetimos as mesmas configurações para criarmos ambientes distintos como Produção, Teste, Desenvolvimento, etc. Uma vez que sua infra está codificada, você aplica o mesmo código para criar quantos ambientes desejar; Recuperação de Desastres ou Disaster Recovery - Desastres acontecem. Imagine um problema grande em sua infraestrutura. Em um cenário de virtualização, imagine que seu host VMWare simplesmente parou de funcionar pois seu disco queimou. Ou que o storage onde se encontravam as suas VMs simplesmente foi destruído. Ou, em um ambiente de cloud, imagine que sua senha de administrador da nuvem vazou e seu ambiente foi completamente excluído. Ou mesmo que o próprio data center ou região na qual se encontra a sua infra estrutura teve algum problema sério e toda a sua infra caiu. Claro, as boas práticas já pregam há muito tempo que sempre devemos ter backups de todos os servidores e sistemas, mas backups nada mais são do que arquivos. E a infraestrutura de fato? Você precisa ter uma infraestrut","date":"2018-10-22","objectID":"/posts/infraestrutura-como-codigo-com-terraform/:2:0","tags":["Devops","Terraform","Cloud","GCP","AWS"],"title":"Infraestrutura como Código com Terraform","uri":"/posts/infraestrutura-como-codigo-com-terraform/"},{"categories":["Impressões"],"content":"Escolha da ferramenta ideal para IAC Com uma simples busca no Google pelo termo “ïnfraestrutura como código” ou “IAC”, será extremamente fácil encontrar diversas ferramentas, dentre as mais populares estão Chef, Puppet, Ansible, SaltStack, Terraform, CloudFormation, etc. Um problema comum para quem inicia no mundo DevOps ou simplesmente deseja começar a utilizar infraestrutura como código é justamente a escolha. Qual a melhor ferramenta? Qual devo utilizar? Esta é uma dificuldade comum e inerante ao fato de se ter muitas opções. Se em uma sorveteria você só possui os sabores chocolate e baunilha, é extremamente simples optar por um, outro ou nenhum dos dois. No entanto, em uma sorveteria com 50 sabores, você provavelmente perderá alguns minutos apenas lendo todas as opções, do contrário irá apostar na sorte e escolher o primeiro que lhe parecer apetitoso, correndo o risco de descartar algum que não chegou a ver, mas que poderia ser muito melhor e refrescante para um dia quente como os do nordeste cearense. O mais importante é sempre realizar uma pesquisa sobre pontos fortes e fracos de cada uma delas antes de tomar uma decisão, tendo em mente alguns aspectos: A escolha não deve (ou não deveria) ser puramente pessoal. A melhor ferramenta dificilmente será a que você gostou mais de utilizar. A melhor ferramenta será a que melhor atende as necessidades do seu projeto ou negócio; A análise deve ser feita em diversos aspectos, e não apenas em um ou dois. Supondo que você pesquise por exemplo quais possuem mais módulos gratuitos e quais delas possuem uma comunidade mais ativa na internet para dúvidas, mas esqueceu de ponderar o preço para ter acesso a suporte corporativo, você pode ter feito uma boa ou uma má escolha. Em caso de ser uma pequena empresa, com prazos relativamente longos para entregas de projetos e maior flexibilidade em termos de tempo fora do ar (downtime), o suporte corporativo pode não ser um fator decisivo. No entanto, em uma empresa de ambiente mais crítico, como um banco, demais sistemas financeiros, governamentais, etc., o suporte corporativo se torna um fator mais importante, portanto escolher uma ferramenta sem ponderar o valor de seu suporte corporativo acaba sendo um tiro no pé, o que reforça a ideia de que sempre devemos avaliar o máximo de aspectos possíveis e relevantes ao nosso projeto ou ambiente; Outro fator fundamental e, em meu ver o mais importante, é entender que não necessariamente a escolha será exclusiva. Imagine que você precisa montar uma mesa que veio toda desmontada: tábuas, parafusos, gavetas, etc. Você tem algumas ferramentas a disposição, como chave de fendas, martelo, régua, serra, furadeira, etc. Você pode ser uma espécie de rambo e gostar de resolver as coisas com uma ferramenta só e, sinceramente, você pode até ser capaz de conseguir montar a mesa inteira apenas utilizando o martelo, parabéns por isso. Mas será que essa é a forma mais eficiente de resolver o problema? Será que não seria mais rápido e organizado utilizando um martelo e uma chave de fendas? Afinal, temos parafusos também, certo?! Conforme descrito acima, o ideal é sempre avaliar o projeto ou ambiente no qual se irá trabalhar, sem a necessidade de escolher apenas uma ferramenta. Sim, Chef, Puppet e Ansible são ferramentas de Infraestrutura como Código, no entanto elas possuem tarefas mais específicas, nas quais possuem mais desempenho, como por exemplo o gerenciamento de configurações, para não listar todas as suas funções. E, claro, o CloudFormation é uma excelente ferramenta da Amazon para criação de infraestrutura como código, no entanto ela fica restrita ao ambiente de cloud da Amazon, o AWS. E se meu projeto estiver utilizando VMs em um ambiente VMWare? Ou se eu utilizar Google Cloud? Ou mesmo um ambiente mais heterogênio, com VMWare, Google Cloud e Amazon AWS? O CloudCloudFormation não seria a melhor opção, por ser restrito ao ambiente AWS. Sempre fui a favor de utilizar as ferramentas corretas para cada tarefa em","date":"2018-10-22","objectID":"/posts/infraestrutura-como-codigo-com-terraform/:3:0","tags":["Devops","Terraform","Cloud","GCP","AWS"],"title":"Infraestrutura como Código com Terraform","uri":"/posts/infraestrutura-como-codigo-com-terraform/"},{"categories":["Impressões"],"content":"Terraform O Terraform, da Hashicorp, lhe permite criar, alterar e melhorar sua infraestrutura de forma segura e previsível. É uma ferramenta Open Source que codifica APIs em arquivos de configuração declarativos que podem ser compartilhados entre membros de um time, tratados como código, editados, revisados e versionados. A imagem acima descreve bem o fluxo básico da utilização de Terraform para codificar sua infraestrutura, na qual o fluxo mais simplista é: Escrever o código de sua infraestrutura; Planejar a execução do seu código, de forma que você receba informações antecipadamente de tudo o que acontecerá quando você aplicar o seu código; Crie uma infraestrutura reproduzível ao aplicar seu código. Apesar de este ser o fluxo mais simplista, com a utilização de infraestrutura como código você pode melhorar seu fluxo inserindo colaboração e compartilhamento, armazenando e gereciando seu código em um repositório git, por exemplo, além de ter assim um registro completo das mudanças e evoluções de sua infraestrutura, facilitando a automação em fluxos mais complexos, como por exemplo em pipelines de Integração Contínua. O Terraform funciona basicamente através de recursos, ou resources, que definem o tipo de infraestrutura você estará criando bem como seus atributos. Além disso, conforme dito anteriormente, o Terraform também pode ser utilizado em paralelo com diversas outras ferramentas de automação em forma de provedores, ou providers, como Puppet, Chef, Ansible, etc. Por estarmos tentando aplicar para a infraestrutura um conceito que seja mais próximo do que já era utilizado por desenvolvedores há muito tempo, o Terraform possui também uma abordagem que lhe permite reaproveitamento de código, através de módulos. Existem diversos módulos criados e disponibilizados gratuitamente, mas você pode também criar seus próprios módulos de forma a melhor organizar e reaproveitar seu próprio código em diversos projetos. Arquivos de configuração descrevem ao Terraform os componentes necessários para rodar uma única aplicação que representa todo o seu datacenter. O Terraform gera um plano de execução descrevendo o que fará para alcançar o estado desejado, e em seguida, caso aprovado, o executará para criar a infraestrutura desejada. Conforme a configuração muda, o Terraform será capaz de determinar o que mudou e criará planos de execução incrementais que podem ser aplicados. Vejamos o seguinte diagrama que descreve uma simples infraesturura. Imaginemos que esta é a infraestrutura que queremos rodar em nossa conta no Google Cloud para termos um site de e-commerce: O diagrama acima possui diversos elementos: Uma organização no Google Cloud chamada Kalib Avante; Um diretório ou Folder (como chamado no Google Cloud) chamado Projetos; Um projeto chamado E-Commerce; Um projeto chamado Zebra Feliz; Dentro do projeto E-Commerce temos dois ambientes: Produção e Teste Repare que o projeto Zebra Feliz está incompleto e sem ambientes distintos, como Produção, teste, etc. Bom, trata-se de um projeto piloto ainda em desenvolvimento e planejamento, portanto os recursos não foram ainda criados por completo. Mas o Terraform nos permite incrementar recursos quando necessário, certo? Portanto, sem problemas com isto por enquanto. Esta é a estrutura básica, já em termos de recursos temos Firewalls, clusters kubernetes com Nodes, buckets de storage para conservar o status ou state do Terraform e por consequência de sua infraestrutura, Discos persistentes, Container Registry (repositório de imagens Docker), VPCs, Load Balancer, VMs, etc. Caso esteja se perguntando, sim o Terraform lhe permite criar esta infraestrutura inteira, bem como outras bem mais complexas, com mais projetos, mais ambientes, mais recursos, etc. Desta forma podemos ter um código terraform dividido em alguns módulos, armazenado em um repositório Git, por exemplo, e criar toda essa infraestrutura, desde a Organização vazia, ao diretório de projetos, aos 2 projetos em si, buckets, clusters kube","date":"2018-10-22","objectID":"/posts/infraestrutura-como-codigo-com-terraform/:4:0","tags":["Devops","Terraform","Cloud","GCP","AWS"],"title":"Infraestrutura como Código com Terraform","uri":"/posts/infraestrutura-como-codigo-com-terraform/"},{"categories":["Tutoriais"],"content":"Um exemplo de como utilizar a ferramenta Open Source Packer para criar uma imagem de forma automatizada para AWS EC2 com Puppet e Bash script para provisionar as configurações da imagem/vm.","date":"2018-08-04","objectID":"/posts/criando-uma-imagem-aws-ec2/","tags":["Devops","Packer","Cloud","Puppet","AWS"],"title":"Criando Uma Imagem Aws Ec2 Com Packer E Puppet","uri":"/posts/criando-uma-imagem-aws-ec2/"},{"categories":["Tutoriais"],"content":"Um exemplo de como utilizar a ferramenta Open Source Packer para criar uma imagem de forma automatizada para AWS EC2 com Puppet e Bash script para provisionar as configurações da imagem/vm. ","date":"2018-08-04","objectID":"/posts/criando-uma-imagem-aws-ec2/:0:0","tags":["Devops","Packer","Cloud","Puppet","AWS"],"title":"Criando Uma Imagem Aws Ec2 Com Packer E Puppet","uri":"/posts/criando-uma-imagem-aws-ec2/"},{"categories":["Tutoriais"],"content":"Packer, Puppet, Bash e AWS A plataforma AWS da Amazon é atualmente uma das maiores e mais populares quando o assunto é Cloud e automação em nuvem, permitindo o uso de soluções de infra estrutura completamente na nuvem, sem a necessidade de termos Hardware físico, otimizando custos e nos dando mais flexibilidade. A própria plataforma nos disponibiliza diversos recursos para facilitar a implementação de nossas soluções e tornar nossas tarefas rotineiras mais simples. Por exemplo, para a criação de VMs, ou instâncias, no AWS de forma mais rápida, podemos utilizar uma imagem previamente criada, de forma que possamos evitar alguns passos e configurações repetitivas. Uma vez que eu identifico uma necessidade para minha aplicação e sei que preciso de uma máquina virtual com configurações e aplicações específicas para poder rodar minha aplicação, eu posso criar uma imagem com todos estes pré-requisitos de forma que ao resolver criar uma nova VM, eu não precise realizar todos estes passos manualmente. Além de evitar trabalho repetitivo, nos garante uma maior flexibilidade ao ter nossa infraestrutura como código, de forma que podemos literalmente ter as instruções que compõem nossa infraestrutura em um repositório Git, por exemplo, além de nos permitir realizar alterações nesta imagem também de forma simples e rápida para a geração de novas imagens de instâncias com as nossas alterações em poucos segundos ou minutos, dependendo da quantidade de alterações envolvdidas. Se você ainda não faz ideia de o que seja o Packer ou o que ele é capaz de fazer, sugiro que volte uma casa e leia meu post anterior, onde explico o que é o Packer e apresento um simples exemplo de seu uso para a criação de imagens para o Docker. O intuito deste post é mostrar como podemos estruturar um simples código para que possamos criar uma imagem no AWS que poderá ser utilizada posteriormente para a criação de instâncias. Esta imagem será criada através do Packer e, para incrementar ainda mais nossa imagem, utilizaremos o recurso de provisioners (ou provisionadores/provedores) disponível no Packer. Utilizaremos dois provisioners como recursos externos para o provisionamento e configuração de nossa imagem, sendo eles bash script e Puppet. ","date":"2018-08-04","objectID":"/posts/criando-uma-imagem-aws-ec2/:1:0","tags":["Devops","Packer","Cloud","Puppet","AWS"],"title":"Criando Uma Imagem Aws Ec2 Com Packer E Puppet","uri":"/posts/criando-uma-imagem-aws-ec2/"},{"categories":["Tutoriais"],"content":"AWS Uma vez que estou assumindo que você já possui o Packer instalado, bem como que você já possui uma ideia de como ele funciona, vamos iniciar pelo AWS. (Ainda não possui o Packer e não sabe o que ele faz? Novamente, Automatizando a Criacao De Imagens Com Packer.) O primeiro pré-requisito para este post/tutorial é uma conta no AWS. Caso você não possua uma e queira repetir os passos aqui descritos, siga e crie uma. Lembrando que o AWS lhe dá uma série de recursos que podem ser utilizados gratuitamente no que eles chamam de “Free Tier”. Uma vez que utilizaremos apenas recursos simples aqui, você não deverá ser cobrado por nada ao seguir os exemplos deste post. O ideal é que você exclua os recursos ou encerre sua conta após o término deste exercício para evitar ser cobrado por algo. Caso não o faça e resolva continuar testando algumas coisas no AWS, você pode ser cobrado em alguns centavos ou reais, dependendo de o que resolva testar e por quanto. (Sua responsabilidade, claro.) A conta no AWS pode ser criada aqui: AWS Conta Gratuita. Uma vez que a conta no AWS esteja criada e pronta para uso, o primeiro passo será de fato conseguir uma chave para que possamos nos comunicar com o AWS via CLI através de uma API. Durante a criação de nosso código com o Packer precisaremos utilizar esta chave de acesso, portanto vá em frente e crie uma através deste link: [IAM](https://console.aws.amazon.com/iam/home?#security_credential. Clique na opção Access Keys, ou Chaves de Acesso, e crie uma nova. É extremamente importante que você esteja atento neste momento, pois ele apenas lhe mostrará o ID e senha para a chave uma única vez, portanto esteja pronto para copiar e salvar ambos os valores. Será algo similar a isto: É claro que eu já excluí essa chave… :p Não perca seu tempo… \u003e] Uma vez que você tenha salvo ambos os valores, vamos tratar da identificação/autenticação com o AWS. O mecanismo padrão do Packer de autenticação neste caso seria através de duas variáveis em nosso arquivo json: { \"builders\": [{ \"type\": \"amazon-ebs\", \"access_key\": \"SUA ACCESS KEY AQUI\", \"secret_key\": \"SUA SECRET ACCESS KEY AQUI\", ... ... ... Embora seja a forma mais simples, não a utilizaremos. Fica claro que não é uma forma muito segura, certo?! Quando se pensa em infraestrutura como código, um dos principais objetivos é podermos versionar e hospedar nosso código em um repositório Git, por exemplo. Ter nossa chave como parte do código não é nada seguro, especialmente se vamos compartilhar este código em um repositório Git. A forma mais simples de lidarmos com isso é salvando nossa chave e senha como variáveis de ambiente e, em nosso arquivo json, importarmos estas variáveis de ambiente diretamente. Em Linux ou OS X, digite o seguinte em um terminal ou console: $ export AWS_ACCESS_KEY_ID=SUA ACCESS KEY AQUI $ export AWS_SECRET_ACCESS_KEY=SUA SECRET ACCESS KEY AQUI Certifique-se de que os valores foram definidos corretamente: $ echo $AWS_ACCESS_KEY_ID $ echo $AWS_SECRET_ACCESS_KEY Por hora isso é tudo de que precisaremos para o AWS. ","date":"2018-08-04","objectID":"/posts/criando-uma-imagem-aws-ec2/:2:0","tags":["Devops","Packer","Cloud","Puppet","AWS"],"title":"Criando Uma Imagem Aws Ec2 Com Packer E Puppet","uri":"/posts/criando-uma-imagem-aws-ec2/"},{"categories":["Tutoriais"],"content":"Packer Hora de começarmos a escrever nosso código que será utilizado pelo Packer para a criação de nossa imagem. Desta vez estaremos criando uma imagem EC2 para o AWS, portanto alguns provisioners e parâmetros serão diferentes dos utilizados no post anterior, onde criamos uma imagem para o Docker. Comecemos criando um arquivo json vazio. Chamarei meu arquivo de ubuntuaws.json. A primeira coisa que faremos é incluir as credenciais de nossa conta no AWS. Como criamos duas variáveis de ambiente em nosso host, chamadas AWS_ACCESS_KEY_ID e AWS_SECRET_ACCESS_KEY, invocaremos estas duas variáveis da seguinte forma no início de nosso arquivo: env `AWS_ACCESS_KEY_ID`, etc… Vamos ao código. { \"variables\": { \"aws_access_key\": \"{% raw %}{{env `AWS_ACCESS_KEY_ID`}}{% endraw %}\", \"aws_secret_key\": \"{% raw %}{{env `AWS_SECRET_ACCESS_KEY`}}{% endraw %}\", \"region\": \"us-east-1\" }, } Normalmente uma varíavel poderia ser declarada apenas com “aws_access_key”: “sua_chave”, conforme fizemos com a variável region acima, no entanto, por questões de segurança, não queremos ter nossa chave exposta no código, certo?! Portanto, estamos trazendo os valores diretamente das variáveis de ambiente que criamos. A utilização do parâmetro env é o que indica ao Packer que ele deverá buscar estas variáveis em nosso env (environment). É importante lembrar que o aws possui datacenters e recursos em diversas regiões do mundo. Você não precisa obrigatoriamente utilizar a região us-east-1. Optei por utilizar esta região em meu código pelo fato de eu morar em Toronto, o que faz desta região uma boa escolha para meus recursos de nuvem por conta da proximidade (menor delay). Se você está no Brasil, provavelmente a melhor opção seja sa-east-1, a qual se encontra em São Paulo. De qualquer forma, você pode verificar a lista de regiões disponíveis no AWS através deste link. Até então nosso código está simples e não faz basicamente nada além de definir as duas variáves para nossa autenticação, mas ainda assim é importante termos certeza de que não cometemos nenhum erro de sintaxe: $ packer validate ubuntuaws.json Error initializing core: 1 error(s) occurred: * at least one builder must be defined Por enquanto ignore este erro, nossa sintaxe esta correta. O Packer apenas está nos dizendo que não conseguiu iniciar o projeto pois ao menos um builder deve ser definido e, até então, nós não definimos nenhum. Este será o nosso próximo passo. Desta vez, ao invés de utilizarmos um builder do tipo Docker, utilizaremos um do tipo amazon-ebs. Começaremos inserindo uma vírgula ao fim do bloco de variáveis e nosso código agora ficará da seguinte forma: { \"variables\": { \"aws_access_key\": \"{% raw %}{{env `AWS_ACCESS_KEY_ID`}}{% endraw %}\", \"aws_secret_key\": \"{% raw %}{{env `AWS_SECRET_ACCESS_KEY`}}{% endraw %}\", \"region\": \"us-east-1\" }, \"builders\": [{ \"type\": \"amazon-ebs\", \"access_key\": \"{% raw %}{{user `aws_access_key`}}{% endraw %}\", \"secret_key\": \"{% raw %}{{user `aws_secret_key`}}{% endraw %}\", \"region\": \"{% raw %}{{user `region`}}{% endraw %}, \"source_ami_filter\": { \"filters\": { \"virtualization-type\": \"hvm\", \"name\": \"ubuntu/images/*ubuntu-xenial-16.04-amd64-server-*\", \"root-device-type\": \"ebs\" }, \"owners\": [\"099720109477\"], \"most_recent\": true }, \"instance_type\": \"t2.micro\", \"ssh_username\": \"ubuntu\", \"ami_name\": \"packer-example {% raw %}{{timestamp}}{% endraw %}\" }] } O que temos agora: builders: Inciamos nosso bloco de builders com as intruções ou parâmetros que definirão as especificações mais básicas para a criação de nossa imagem no AWS. type: Aqui indicamos o tipo de builders que utilizaremos. No caso do EC2 do AWS, o tipo se chama amazon-ebs. Basicamente este builder irá utilizar uma imagem previamente existente, como as fornecidas por padrão pela Amazon, para criar uma nova imagem que poderá ser futuramente utilizada para provisionar suas instâncias EC2 com EBS (Elastic Block Storage). access_key: e secret_key: Aqui apenas indicamos que queremos utilizar o valor das variáveis que","date":"2018-08-04","objectID":"/posts/criando-uma-imagem-aws-ec2/:3:0","tags":["Devops","Packer","Cloud","Puppet","AWS"],"title":"Criando Uma Imagem Aws Ec2 Com Packer E Puppet","uri":"/posts/criando-uma-imagem-aws-ec2/"},{"categories":["Tutoriais"],"content":"Testando sua imagem 1- Efetue login em sua conta do AWS; 2- Vá ao menu de Serviços/Services -\u003e Imagens/Images -\u003e AMIs; 3- Na lista de imagens disponíveis, selecione a sua mais recente, para ter certeza de que está escolhendo a que foi criada por último, pois ela será a imagem que contém o deployment via puppet por completo (Repare a data de criação para ter certeza); 4- Ao selecionar a imagem, clique em Lançar/Launch, conforme imagem abaixo: 5- Selecione o tipo de instância padrão que pode ser utilizada gratuitamente para este exemplo, t2.micro, em seguida clique em Próximo/Next, conforme imagem abaixo: 6- Na tela seguinte, deixe tudo como está exceto a opção de Atribuir Ip Público/Auto-Assign Public IP. Ative esta opção, em seguida clique em Próximo, conforme imagem abaixo: 7- Na tela seguinte, pode manter o padrão de 8GB de disco/storage e clicar em Próximo; 8- Na parte de Tags, pode novamente manter tudo vazio para este exemplo e clicar em Próximo; 9- Nas configurações de Grupo de Segurança/Security Group, pode manter o padrão, mas certifique-se de inserir mais uma regra de firewall para que possamos testar o servidor web. Por padrão o AWS já apresentará a porta 22 (SSH) aberta, portanto vamos abrir também a porta 80, conforme imagem abaixo. Em seguida, clique em Revisar e Lançar/Review and Launch; 10- Em seguida, confirme novamente e clique em Lançar/Launch; 11- Uma janela popup será apresentada lhe perguntando se você deseja criar um par de chaves. Fica a seu critério. Caso deseje se conectar a esta instância via ssh, crie uma chave, do contrário, pode prosseguir sem criar uma chave. Como eu apenas quero testar se o servidor web estará rodando, e já abrimos a porta 80 no firewall, poderemos confirmar isto através de nosso navegador, portanto ignorarei a chave e clicarei em Lançar Instância/Launch Instance; 12- O AWS lhe informará que sua instância está sendo criada. Como se trata de uma instância Linux, costuma ser um processo rápido, geralmente leva algo entre 1 e 2 minutos. Você pode ir para a página principal de instâncias e aguardar sua instância estar com status running; 13- Copie o IP público ou externo que o AWS atribuiu à sua instância conforme imagem abaixo: 14- Agora cole o ip em qualquer browser e você deverá ver uma página default do apache que está rodando em seu novo servidor web: Finalizado. Lembre-se de excluir os recursos no AWS para evitar ser cobrado: Instâncias Volumes Imagens Security Groups … ou o que mais você tiver criado em seus testes caso não os vá mais utilizar. ","date":"2018-08-04","objectID":"/posts/criando-uma-imagem-aws-ec2/:4:0","tags":["Devops","Packer","Cloud","Puppet","AWS"],"title":"Criando Uma Imagem Aws Ec2 Com Packer E Puppet","uri":"/posts/criando-uma-imagem-aws-ec2/"},{"categories":["Tutoriais"],"content":"Packer é uma ferramenta Open Source, criada e mantida pela HashiCorp, para a criação de imagens de máquinas idênticas para múltiplas plataformas a partir de uma única fonte ou código de configuração. O Packer é leve, roda em praticamente todos os principais Sistemas Operacionais e possui alta performance, permitindo a criação de imagens para múltiplas plataformas em paralelo.","date":"2018-07-30","objectID":"/posts/automatizando-a-criacao-de-imagens/","tags":["Devops","Packer","Docker","Cloud"],"title":"Automatizando a Criacao De Imagens Com Packer","uri":"/posts/automatizando-a-criacao-de-imagens/"},{"categories":["Tutoriais"],"content":"Já utilizou Packer para automatizar e facilitar sua criação de recursos e imagens de máquinas? Caso não, está na hora de você conhecer e experimentar esta excelente ferramenta. ","date":"2018-07-30","objectID":"/posts/automatizando-a-criacao-de-imagens/:0:0","tags":["Devops","Packer","Docker","Cloud"],"title":"Automatizando a Criacao De Imagens Com Packer","uri":"/posts/automatizando-a-criacao-de-imagens/"},{"categories":["Tutoriais"],"content":"O que é Packer e qual sua importância Packer é uma ferramenta Open Source, criada e mantida pela HashiCorp, para a criação de imagens de máquinas idênticas para múltiplas plataformas a partir de uma única fonte ou código de configuração. O Packer é leve, roda em praticamente todos os principais Sistemas Operacionais e possui alta performance, permitindo a criação de imagens para múltiplas plataformas em paralelo. Uma imagem de máquina, nada mais é que um arquivo estático que contém um sistema operacional pré-configurado, com determinados softwares instalados e que pode ser utilizada para criar novas máquinas ou servidores de forma mais rápida, evitando o trabalho repetitivo de instalar o sistema operacional e configurar aplicações padrões. Existem diversos formatos diferentes de imagens que podem ser criadas através do Packer, como por exemplo Amazon EC2, VirtualBox, VMware, Google Cloud Platform, Microsoft Azure, Docker, QEMU, CloudStack, DigitalOcean, etc. O Packer suporta e é compatível com diversas ferramentas de provisionamento e automação, como shell script, Ansible, Puppet, Chef, etc., fazendo com que a criação de imagens seja ainda mais simples, dinâmica e robusta. A ideia de criar imagens não é nova, visto que Sysadmins já o fazem há muitos anos, porém esta sempre foi uma tarefa tediosa, demorada e muito pouco produtiva. Basicamente a ideia de se construir uma imagem partia de, antes de mais nada, realizar de fato uma instalação completa de um Sistema Operacional e em seguida utilizar algum aplicativo para “salvar” aquele estado em uma imagem, que poderia ser posteriormente aplicada em outras máquinas. Isto por si só já facilitava muito a vida de Sysadmins em geral, visto que eles apenas realizavam a instalação completa do SO uma vez. Caso, além do SO, fossem necessárias outras aplicações, o processo seria basicamente o mesmo, instalando-se uma vez o SO completo e em seguida instalando todas as aplicações desejadas para a imagem. Até então a criação da imagem parecia ser um sucesso, no entanto isto era algo improdutivo por ser absolutamente estático e imutável. Sempre que fosse necessário fazer uma mudança na imagem, atualizar versão de sistema operacional, aplicar patches, atualizar demais aplicações ou mudar configurações, novamente o processo deveria se repetir do início. Não é necessário sequer mencionar que não era nada simples gerenciar e versionar isto. Eis que surge o Packer para deixar a criação de imagens menos entediante, flexível e mais gerenciável. ","date":"2018-07-30","objectID":"/posts/automatizando-a-criacao-de-imagens/:1:0","tags":["Devops","Packer","Docker","Cloud"],"title":"Automatizando a Criacao De Imagens Com Packer","uri":"/posts/automatizando-a-criacao-de-imagens/"},{"categories":["Tutoriais"],"content":"Instalação A instalação não é complexa e pode ser feita através do binário disponível na página de downloads do Packer: Download Packer Ubuntu - Caso não queira instalar através do binário fornecido no link acima, pode instalar via: $ sudo apt-get install packer -y Arch linux - Caso não queira instalar através do binário fornecido no link acima, pode instalar através do pacote disponível no AUR. OS X - Caso não queira instalar através do binário fornecido no link acima, pode instalar através do homebrew: $ brew install packer Independente de sua forma de instalação, confirme que a instalação foi concluída com sucesso: $ packer Usage: packer [--version] [--help] \u003ccommand\u003e [\u003cargs\u003e] Available commands are: build build image(s) from template fix fixes templates from old versions of packer inspect see components of a template push push a template and supporting files to a Packer build service validate check that a template is valid version Prints the Packer version Se você recebeu algo similar, significa que você já pode começar a criar suas imagens. Caso tenha recebido um erro informando que o Packer não foi encontrado, significa que o mesmo não foi inserido corretamente na variável de ambiente de seu PATH. Certifique-se de inserir o diretório no qual o Packer foi instalado em seu PATH. ","date":"2018-07-30","objectID":"/posts/automatizando-a-criacao-de-imagens/:2:0","tags":["Devops","Packer","Docker","Cloud"],"title":"Automatizando a Criacao De Imagens Com Packer","uri":"/posts/automatizando-a-criacao-de-imagens/"},{"categories":["Tutoriais"],"content":"Criando Imagens com o Packer Conforme dito anteriormente, o Packer pode criar imagens para diversas extensões e plataformas, portanto o primeiro passo é saber para qual plataforma você deseja criar sua imagem. Para este tutorial introdutório, utilizaremos o Docker como destino para nossa imagem, ou seja, criaremos uma imagem de container que poderá rodar com o Docker. OBS: A partir deste ponto estou assumindo que você já possui o Docker instalado em seu sistema. Para confirmar, digite: $ docker --version Docker version 18.06.0-ce, build 0ffa825 Vamos ao Packer. Primeiramente mostrarei como não tenho nenhuma imagem Docker neste momento em meu sistema: $ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 1- Escolha um editor de textos de sua preferência e inicie um arquivo chamado template.json; 2- Digite o seguinte em seu arquivo template.json. { \"builders\": [{ \"type\": \"docker\", \"image\": \"ubuntu\", \"commit\": true }] } O que temos… builders: Abre o bloco builders (construtores), onde iniciamos as instruções que definirão como a nossa imagem será criada; type: Especifica o tipo de construtor que será utilizado. Neste exemplo escolhemos Docker. Aqui poderíamos utilizar AWS EC2, Google Cloud Instance, etc. image: Parâmetro no qual indicaremos qual imagem será utilizada como origem para a nossa imagem final. commit: Indica que queremos realizar o commit da imagem gerada no final. *OBS: É importante lembrar que o Packer possui uma infinidade de parâmetros ou propriedades diferentes que podem ser específicos para cada tipo de builder. Lista de parâmetros e opções para o builder Docker. Primeiramente, o indicado é validarmos a sintaxe de nosso código json: ($ packer validate template.json) $ packer validate template.json Template validated successfully. O código parece estar correto do ponto de vista do Packer. Caso houvesse algo errado com o código, a mensagem daria alguma pista de onde está o erro. Removerei o último } do arquivo template.json para forçar um erro: ($ packer validate template.json) $ packer validate template.json Failed to parse template: Error parsing JSON: unexpected end of JSON input At line 7, column 1 (offset 88): 6: }] 7: Com o arquivo de volta à sua versão correta, o próximo passo seria de fato o build, onde criaremos a imgem desejado de acordo com as intruções que demos: ($ packer build template.json) $ packer build template.json docker output will be in this color. ==\u003e docker: Creating a temporary directory for sharing data... ==\u003e docker: Pulling Docker image: ubuntu docker: Using default tag: latest docker: latest: Pulling from library/ubuntu docker: c64513b74145: Pulling fs layer docker: 01b8b12bad90: Pulling fs layer docker: c5d85cf7a05f: Pulling fs layer docker: b6b268720157: Pulling fs layer docker: e12192999ff1: Pulling fs layer docker: b6b268720157: Waiting docker: e12192999ff1: Waiting docker: c5d85cf7a05f: Verifying Checksum docker: c5d85cf7a05f: Download complete docker: 01b8b12bad90: Verifying Checksum docker: 01b8b12bad90: Download complete docker: e12192999ff1: Verifying Checksum docker: e12192999ff1: Download complete docker: b6b268720157: Verifying Checksum docker: b6b268720157: Download complete docker: c64513b74145: Verifying Checksum docker: c64513b74145: Download complete docker: c64513b74145: Pull complete docker: 01b8b12bad90: Pull complete docker: c5d85cf7a05f: Pull complete docker: b6b268720157: Pull complete docker: e12192999ff1: Pull complete docker: Digest: sha256:3f119dc0737f57f704ebecac8a6d8477b0f6ca1ca0332c7ee1395ed2c6a82be7 docker: Status: Downloaded newer image for ubuntu:latest ==\u003e docker: Starting docker container... docker: Run command: docker run -v /Users/kalib/.packer.d/tmp/packer-docker835877235:/packer-files -d -i -t ubuntu /bin/bash docker: Container ID: 50211726119aa045b0bc5eb9da8c9af243bc179fef0aad3cd94156d0f2a7a45a ==\u003e docker: Committing the container docker: Image ID: sha256:3a6a21aab4706e2b512f0c1fcbe8265e2527d4794f7c6fbdc5e4faf907d10622 ==\u003e docker: Kil","date":"2018-07-30","objectID":"/posts/automatizando-a-criacao-de-imagens/:3:0","tags":["Devops","Packer","Docker","Cloud"],"title":"Automatizando a Criacao De Imagens Com Packer","uri":"/posts/automatizando-a-criacao-de-imagens/"},{"categories":["Aleatórios"],"content":"10 anos de blog! Parece que foi ontem que comecei a postas algumas dicas simples sobre Linux... Jamais imaginei manter este blog por tanto tempo.","date":"2018-04-16","objectID":"/posts/10-anos/","tags":["Aleatório"],"title":"10 Anos de Blog!","uri":"/posts/10-anos/"},{"categories":["Aleatórios"],"content":"10 anos de blog! Parece que foi ontem que comecei a postas algumas dicas simples sobre Linux… Jamais imaginei manter este blog por tanto tempo. ","date":"2018-04-16","objectID":"/posts/10-anos/:0:0","tags":["Aleatório"],"title":"10 Anos de Blog!","uri":"/posts/10-anos/"},{"categories":["Tutoriais"],"content":"Chef é uma popular ferramenta de Gerenciamento de Configurações criado pela empresa de mesmo nome, Chef. Neste post veremos a utilização de condicionais em recipes com only_if e not_if.","date":"2018-04-14","objectID":"/posts/chef-uso-de-condicionais-not/","tags":["Devops","Chef"],"title":"Chef: Uso De Condicionais not_if E only_if","uri":"/posts/chef-uso-de-condicionais-not/"},{"categories":["Tutoriais"],"content":"Chef é uma popular ferramenta de Gerenciamento de Configurações criado pela empresa de mesmo nome, Chef. Neste post veremos a utilização de condicionais em recipes com only_if e not_if. ","date":"2018-04-14","objectID":"/posts/chef-uso-de-condicionais-not/:0:0","tags":["Devops","Chef"],"title":"Chef: Uso De Condicionais not_if E only_if","uri":"/posts/chef-uso-de-condicionais-not/"},{"categories":["Tutoriais"],"content":"Pare e volte uma casa Se você nunca utilizou ou sabe pouco sobre o Chef é importante que você pare aqui mesmo e volte uma casa. Sugiro que leia o post Chef: Automação e Gerenciamento de Configuração antes de seguir este, uma vez que através dele você entenderá o que é, e como funciona o Chef, bem como sua instalação básica. ","date":"2018-04-14","objectID":"/posts/chef-uso-de-condicionais-not/:1:0","tags":["Devops","Chef"],"title":"Chef: Uso De Condicionais not_if E only_if","uri":"/posts/chef-uso-de-condicionais-not/"},{"categories":["Tutoriais"],"content":"Resources Conforme dito no post anterior, resource é uma descrição de estado que: Descreve o estado desejado para um item de configuração Declara os passos necessários para levar o item especificado ao estado desejado Especifica o tipo de resource - por exemplo, package, template ou service Lita detalhes adicionais (também conhecidos como propriedades de resources), conforme necessário São agrupados em recipes, que descrevem configurações em geral ","date":"2018-04-14","objectID":"/posts/chef-uso-de-condicionais-not/:2:0","tags":["Devops","Chef"],"title":"Chef: Uso De Condicionais not_if E only_if","uri":"/posts/chef-uso-de-condicionais-not/"},{"categories":["Tutoriais"],"content":"Utilizando (Guardas) not_if e only_if Todos os resources (incluindo os personalizados) no Chef compartilham um conjunto de opções comuns: ações, propriedades, condicionais, notificações e paths relativos. Guards Propriedades de guarda, ou guards, como são chamadas no Chef, podem ser utilizadas para avaliar o estado de um node durante a fase de execução do chef-client. Esta avaliação funciona como uma condicional e, baseando-se nos resultados da mesma, a propriedade guard é então utilizada para indicar ao chef-client se ele deve ou não continuar a execução de um resource. Uma propriedade guard aceita tanto um valor string quanto um bloco de código Ruby. A string é executada como um comando shell. Caso o comando retorne 0 (true), a propriedade guard é aplicada. Caso o comando retorne qualquer outro valor a propriedade guard não será aplicada. Um bloco é executado como um código Ruby que deve retornar true ou false. Da mesma forma, caso o comando retorne true, a propriedade guard é aplicada. Caso o comando retorne false a propriedade guard não será aplicada. Uma guard é importante para garantir que um resource seja idempotente ao permitir um teste no próprio resource certificando-se de que o mesmo se encontra no estado desejado de forma que o chef-client não faça nada. Atributos Os seguintes atributos podem ser utilizados para definir uma guard que é avaliada durante a fase de execução do chef-client: not_if - Impede a execução de um resource quando a condição retornar true. only_if - Permite a execução de um resource apenas quando a condição retornar true. ","date":"2018-04-14","objectID":"/posts/chef-uso-de-condicionais-not/:3:0","tags":["Devops","Chef"],"title":"Chef: Uso De Condicionais not_if E only_if","uri":"/posts/chef-uso-de-condicionais-not/"},{"categories":["Tutoriais"],"content":"Mãos à obra Para simplificar seguirei utilizando a recipe utilizada no post anterior. Não sabe o que é uma recipe? -\u003e Novamente, caso não entenda o que estou dizendo, volte uma casa e leia o post anterior no qual explico o que é uma recipe, bem como cada elemento da mesma, visto que a utilizaremos aqui. Nossa recipe era a seguinte: package 'apache' do package_name 'httpd' action :install end service 'httpd' do action [:enable, :start] end file '/var/www/html/index.html' do content 'Hello World!' mode '0755' owner 'root' group 'apache' end Como primeira alteração vamos editar o arquivo /etc/motd. Este arquivo nada mais é do que a definição de um baner que será apresentado sempre que alguém se logar em seu servidor. Por padrão, este arquivo costuma vir vazio. Este é o caso da máquina utilizada para este exemplo: # cat /etc/motd Começaremos definindo o conteúdo que deverá existir em nosso arquivo /etc/motd incluindo um resource do tipo file no final de nossa recipe exemplo.rb: package 'apache' do package_name 'httpd' action :install end service 'httpd' do action [:enable, :start] end file '/var/www/html/index.html' do content 'Hello World!' mode '0755' owner 'root' group 'apache' end file '/etc/motd' do content 'Bem Vindo!' end Até aqui nenhuma novidade (caso você tenha lido de fato o post anterior ou já tenha utilizado Chef anteriormente), apenas incluímos mais um resource em nossa recipe exemplo.rb informando que o arquivo /etc/motd deve existir e que seu conteúdo deverá ser Bem Vindo!. Validando e executando localmente nossa recipe conforme feito anteriormente veremos que todos os demais passos ou resources serão ignorados por já estarem estarem no estado desejado (idempotência), restando apenas a inclusão do conteúdo no /etc/motd: Validando # ruby -c exemplo.rb \u0026\u0026 foodcritic exemplo.rb Syntax OK Checking 1 files x FC011: Missing README in markdown format: ../README.md:1 FC031: Cookbook without metadata.rb file: ../metadata.rb:1 FC071: Missing LICENSE file: ../LICENSE:1 Executando [root@kalib6 ~]# chef-client --local-mode exemplo.rb [2018-04-15T22:03:26+00:00] WARN: No config file found or specified on command line, using command line options. [2018-04-15T22:03:26+00:00] WARN: No cookbooks directory found at or above current directory. Assuming /root. Starting Chef Client, version 13.8.5 resolving cookbooks for run list: [] Synchronizing Cookbooks: Installing Cookbook Gems: Compiling Cookbooks... [2018-04-15T22:03:29+00:00] WARN: Node kalib6.test.com has an empty run list. Converging 4 resources Recipe: @recipe_files::/root/exemplo.rb * yum_package[apache] action install (up to date) * service[httpd] action enable (up to date) * service[httpd] action start (up to date) * file[/var/www/html/index.html] action create (up to date) * file[/etc/motd] action create - update content in file /etc/motd from e3b0c4 to f13843 --- /etc/motd 2018-04-15 20:51:00.411479476 +0000 +++ /etc/.chef-motd20180415-1681-1p1fm7m 2018-04-15 22:03:42.142091791 +0000 @@ -1 +1,2 @@ +Bem Vindo! - restore selinux security context Running handlers: Running handlers complete Chef Client finished, 1/5 resources updated in 15 seconds Para termos certeza de que o nosso arquivo foi corretamente alterado… [root@kalib6 ~]# cat /etc/motd Bem Vindo! Novamente, nenhuma novidade até aqui. Vamos agora utilizar o tipo de resource execute, o qual nos permite executar um comando a cada execução do chef-client. Vale lembrar que uma das características do Chef é a idempotência, portanto o execute pode ser considerado uma exceção, já que o comando será executado sempre, mesmo que já tenha sido executado anteriormente. E é neste tipo de situação que os guards se mostram importantes. Comecemos inserindo um resource do tipo execute em nossa recipe: package 'apache' do package_name 'httpd' action :install end https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet service 'httpd' do action [:enable, :start] end file '/var/www/html/index.html' do content 'Hello World!' mo","date":"2018-04-14","objectID":"/posts/chef-uso-de-condicionais-not/:4:0","tags":["Devops","Chef"],"title":"Chef: Uso De Condicionais not_if E only_if","uri":"/posts/chef-uso-de-condicionais-not/"},{"categories":["Tutoriais"],"content":"Chef é uma popular ferramenta de Gerenciamento de Configurações criado pela empresa de mesmo nome, Chef. O Chef é desenvolvido em Ruby e Erlang, utiliza uma linguagem DSL em Ruby puro para escrever arquivos de configuração de sistemas chamados recipes.","date":"2018-04-01","objectID":"/posts/chef-aautomacao-e-gerenciamento-de/","tags":["Devops","Chef"],"title":"Chef: Automação E Gerenciamento De Configuração","uri":"/posts/chef-aautomacao-e-gerenciamento-de/"},{"categories":["Tutoriais"],"content":"Chef é uma popular ferramenta de Gerenciamento de Configurações criado pela empresa de mesmo nome, Chef. O Chef é desenvolvido em Ruby e Erlang, e utiliza uma linguagem DSL (domain-specific language) em Ruby puro para escrever arquivos de configuração de sistemas chamados “recipes” (receitas). Antes de falarmos sobre o Chef é importante entender primeiramente o conceito e a utilidade de ferramentas de Gerenciamento de Configuração. ","date":"2018-04-01","objectID":"/posts/chef-aautomacao-e-gerenciamento-de/:0:0","tags":["Devops","Chef"],"title":"Chef: Automação E Gerenciamento De Configuração","uri":"/posts/chef-aautomacao-e-gerenciamento-de/"},{"categories":["Tutoriais"],"content":"Gerenciamento de Configuração Gerenciamento de Configuração, ou CM (Configuration Management), é um processo de engenharia de sistemas que visa garantir a consistência entre ativos físicos e lógicos em um ambiente operacional. O processo de gerenciamento de configuração busca identificar e rastrear itens individuais de configuração, documentando capacidades funcionais e interdependências. Administradores, técnicos e desenvolvedores de sistemas podem utilizar ferramentas de Gerenciamento de Configuração para verificar o efeito que uma mudança em um item de configuração terá em outros sistemas. Em palavras simples, o objetivo de uma ferramenta de gerenciamento de configuração é simplificar a vida de quem administra serviços e sistemas garantindo uma uniformidade no quesito configuração. Como exemplo prático e simplista, imagine um servidor web que será responsável por hospedar um pequeno site em php. Este servidor possuirá alguns atributos/aplicativos/configurações, tais como: Apache instalado; Alterações específicas nos arquivos de configuração do Apache; Serviço do Apache ativo e iniciado; Arquivos referentes ao site em si em um diretório específico; Permissões específicas atribuídas ao diretório específico do site; etc… Configurar tudo isso manualmente em um único servidor é simples. Você poderia conectar-se via SSH no servidor, instalar o apache com o gerenciador de pacotes da distribuição utilizada, configurar o que for necessário no apache, iniciar o serviço, etc, etc, etc. Mas o que fazer quando sua infraestrutura cresce? Quando se quer maior disponibilidade do site, quando agora você roda este site em um cluster com 5 servidores? Basicamente a mesma coisa, certo? Você pode se conectar em cada um dos servidores e repetir os mesmos passos. O problema se dá justamente nessa repetição de passos, onde você pode cometer erros, perder tempo, etc. Além disso, o que acontece se um colega seu modificar algo em um dos servidores e não lhe avisar? E se ele esquecer de replicar esta mudança nos demais? É fácil achar diversas razões pelas quais torna-se difícil administrar e gerenciar configurações em ambientes mais complexos. A ideia por trás de uma ferramenta de Gerenciamento de Configuração é justamente reduzir esta complexidade, eliminando a necessidade de conectar-se manualmente à diversos servidores para aplicar as mesmas rotinas, passos e configurações. Através de arquivos de texto podemos literalmente descrever o estado e as ações desejadas para nossos serviços e sistemas. Por exemplo: Posso dizer que possuo um grupo de servidores chamado WebServer, o qual contém 10 servidores com o Sistema Operacional CentOS 7. Posso incluir a informação de que preciso que todos eles estejam com a versão X do Apache instalada e que o serviço esteja ativo e rodando. Além disso, posso dizer que desejo que exista no diretório /var/www/meusite/ todo o conteúdo que está em um mapeamento de rede específico, ou mesmo em um repositório que possuo no github. Ao invés de me conectar em cada um dos 10 servidores para fazer tudo isso, um simples comando será o suficiente. O comando em específico dependerá da solução adotada, visto que existem diversas ferramentas de CM (Gerenciamento de Configuração). Mas, basicamente, ele irá ler o(s) arquivo(s) de “instruções” que nós definimos e saberá em quais servidores ele deverá instalar o Apache e configurar de acordo com o especificado, nos dando apenas o resultado final em forma de relatório simples. E se alguém da equipe alterar um arquivo de configuração diretamente em um dos servidores? A ferramenta, em sua próxima execucação, irá identificar que o estado desejado para aquele meu grupo de servidores está diferente em um dos servidores. Ela então modificará aquele arquivo específico naquele servidor para que ele volte ao seu estado desejado. Além desta segurança, nós agora passamos a ter um ponto único de modificação. Ao desejarmos mudar algo, o faremos apenas no nosso “código”, ao invés de o fazer nos 10 ser","date":"2018-04-01","objectID":"/posts/chef-aautomacao-e-gerenciamento-de/:1:0","tags":["Devops","Chef"],"title":"Chef: Automação E Gerenciamento De Configuração","uri":"/posts/chef-aautomacao-e-gerenciamento-de/"},{"categories":["Tutoriais"],"content":"O que é Chef? Conforme dito mais acima, Chef é uma das mais populares ferramentas de Gerenciamento de Configuração disponíveis atualmente. É compatível e facilmente integrado à plataformas de computação em nuvem, tais como Internap, Amazon EC2, Google Cloud Platform, OpenStack, SoftLayer, Microsoft Azure e Rackspace, provendo e configurando servidores automaticamente. O usuário escreve “recipes” (receitas) que descrevem como o Chef deve gerenciar aplicações, servidores e utilitários. Estas “recipes”, as quais podem ser agrupadas em “cookbooks” (livros de receitas) descrevem uma série de recursos que devem estar em um determinado estado. Este recursos podem ser pacotes, serviços ou mesmo arquivos. Chef pode rodar em um modo cliente/servidor ou standalone, com o chamado “chef-solo”. No modo cliente/servidor, o cliente Chef envia uma série de atributos sobre o node ou cliente/host para o Chef server. O Chef server utiliza-se da ferramenta Solr para indexar estes atributos e provê uma API na qual os clientes podem fazer consultas. As recipes podem fazer requisições à esta base de atributos e utilizar os dados resultantes para configurar o cliente ou node. Embora inicialmente o Chef fosse utilizado para gerenciar exclusivamente máquinas Linux, as versões mais atuais também suportam máquinas Windows. A ideia para este post é dar uma breve introdução ao Chef, portanto não vou entrar em maiores detalhes do funcionamento por hora. ","date":"2018-04-01","objectID":"/posts/chef-aautomacao-e-gerenciamento-de/:2:0","tags":["Devops","Chef"],"title":"Chef: Automação E Gerenciamento De Configuração","uri":"/posts/chef-aautomacao-e-gerenciamento-de/"},{"categories":["Tutoriais"],"content":"Resources Como dito antes, um Resource é uma descrição de estado desejado para um determinado item. Estes resources são gerenciados através de recipes. Um resource possui basicamente 4 componentes fundamentais que são definidos em um bloco de código Ruby: Resource Type - Tipo de resource (Pode ser um pacote, serviço, arquivo…) Resource Name - Nome do resource Resource Properties - Propriedades do resource Actions - Ações a serem aplicadas ao resource Um exemplo de recipe para instalar o Apache em um servidor Ubuntu, por exemplo, seria o seguinte: package 'httpd' do action :install end No exemplo acima temos o tipo de resource como sendo “package”, o nome do resource como sendo “httpd” e a ação “install”. O que vai acontecer aqui? Simples de entender, certo? O pacote httpd (Apache) será instalado. Mas o que acontece caso o pacote httpd já esteja instalado? Nada. Uma das características do Chef é a idempotência. Na matemática e ciência da computação, a idempotência é a propriedade que algumas operações têm de poderem ser aplicadas várias vezes sem que o valor do resultado se altere após a aplicação inicial. Ou seja, O Chef primeiramente confere se o estado desejado já está aplicado e, caso sim, ignora aquela instrução. Novamente… A ideia para este post é dar uma breve introdução ao Chef, portanto não vou entrar em maiores detalhes sobre os tipos de resources e suas possíveis ações. Vamos ao que interessa… ","date":"2018-04-01","objectID":"/posts/chef-aautomacao-e-gerenciamento-de/:3:0","tags":["Devops","Chef"],"title":"Chef: Automação E Gerenciamento De Configuração","uri":"/posts/chef-aautomacao-e-gerenciamento-de/"},{"categories":["Tutoriais"],"content":"Instalando o Chef Conforme explicado acima, o Chef pode ser utilizado em modo cliente/servidor ou standalone. Para esta introdução utilizaremos o modo standalone ou local para simplificar as coisas. Para instalar podemos utilizar o gerenciador de pacotes da distribuição Linux que utilizamos ou baixando o chefdk (Development Kit) através da página de downloads do chef. ","date":"2018-04-01","objectID":"/posts/chef-aautomacao-e-gerenciamento-de/:4:0","tags":["Devops","Chef"],"title":"Chef: Automação E Gerenciamento De Configuração","uri":"/posts/chef-aautomacao-e-gerenciamento-de/"},{"categories":["Tutoriais"],"content":"Arch Linux No meu caso, utilizarei o pacote chef-dk existente para o Arch Linux, mas sinta-se livre para baixar diretamente no site e executar o pacote de acordo com sua distribuição. 1- Baixar o pacote do AUR: $ wget https://aur.archlinux.org/cgit/aur.git/snapshot/chef-dk.tar.gz 2- Descompactar e Compilar: $ tar -xvzf chef-dk.tar.gz $ cd chef-dk $ makepkg 3- Instalar o pacote: $ sudo pacman -U chef-dk-2.5.3-1-x86_64.pkg.tar.xz 4- Confirmar que deu tudo certo:* $ chef --version Chef Development Kit Version: 2.5.3 chef-client version: 13.8.5 delivery version: master (73ebb72a6c42b3d2ff5370c476be800fee7e5427) berks version: 6.3.1 kitchen version: 1.20.0 inspec version: 1.51.21 ","date":"2018-04-01","objectID":"/posts/chef-aautomacao-e-gerenciamento-de/:4:1","tags":["Devops","Chef"],"title":"Chef: Automação E Gerenciamento De Configuração","uri":"/posts/chef-aautomacao-e-gerenciamento-de/"},{"categories":["Tutoriais"],"content":"Centos, Debian, Ubuntu… No CentOS, Ubuntu, Debian ou outras distribuições, o procedimento será relativamente parecido, portanto vejamos como seria no caso do CentOS baixando o arquivo diretamente do site de downloads: 1- Baixar o arquivo .rpm para Red Hat: Aqui $ wget https://packages.chef.io/files/stable/chefdk/2.5.3/el/7/chefdk-2.5.3-1.el7.x86_64.rpm 2- Instalar via RPM: $ sudo rpm -ivh chefdk-2.5.3-1.el7.x86_64.rpm 3- Confirmar que deu tudo certo: $ chef --version Chef Development Kit Version: 2.5.3 chef-client version: 13.8.5 delivery version: master (73ebb72a6c42b3d2ff5370c476be800fee7e5427) berks version: 6.3.1 kitchen version: 1.20.0 inspec version: 1.51.21 ","date":"2018-04-01","objectID":"/posts/chef-aautomacao-e-gerenciamento-de/:4:2","tags":["Devops","Chef"],"title":"Chef: Automação E Gerenciamento De Configuração","uri":"/posts/chef-aautomacao-e-gerenciamento-de/"},{"categories":["Tutoriais"],"content":"Testando o Chef Localmente Para facilitar o entendimento, vamos criar uma recipe simples para aplicarmos localmente. Vamos começar criando um arquivo chamado exemplo.rb com o seguinte conteúdo: package 'apache' do package_name 'httpd' action :install end O que temos aqui? Resource Type: package (Pois queremos instalar o pacote httpd) Resource Name: apache (Embora o nome do pacote no CentOS seja httpd, o nome do nosso resource aqui é apache, mas poderia ser qualquer coisa que desejarmos) Resource Properties: Aqui temos apenas package_name como propriedade, no qual damos o nome do pacote desejado. OBS: Caso não utilizemos a propriedade package_name, ele buscará por um pacote com mesmo nome do resource. No nosso caso, demos o nome apache para nosso resource, portanto ele buscaria por um pacote chamado apache e falharia, pois no CentOS este pacote não existe. Actions: install (Temos apenas uma ação para esta recipe, que é justamente a de instalar o pacote, caso já não esteja instalado (idempotência)) Salve o arquivo e verifique o mesmo com os dois passos a seguir: 1- Verifique se a sintaxe ruby está correta: # ruby -c exemplo.rb Syntax OK 2- Utilize uma ferramenta do chef para verificar se a recipe está de acordo com o esperado pelo Chef: # foodcritic exemplo.rb Checking 1 files x FC011: Missing README in markdown format: ../README.md:1 FC031: Cookbook without metadata.rb file: ../metadata.rb:1 FC071: Missing LICENSE file: ../LICENSE:1 PS: Não se espante por enquanto com estes Warnings. Ele apenas está indicando que não possuímos um metadata, um readme e uma licença, pois não os criamos para este exemplo. Verificado o código e aprovado, vamos executar esta recipe localmente. (Repare no retorno que será apresentado, onde ele verifica o tipo de resource e identifica que estamos rodando em uma máquina CentoOS, portanto utiliza por padrão o yum para instalar o pacote desejado.) # chef-client --local-mode exemplo.rb [2018-04-01T19:18:00+00:00] WARN: No config file found or specified on command line, using command line options. [2018-04-01T19:18:00+00:00] WARN: No cookbooks directory found at or above current directory. Assuming /root. Starting Chef Client, version 13.8.5 resolving cookbooks for run list: [] Synchronizing Cookbooks: Installing Cookbook Gems: Compiling Cookbooks... [2018-04-01T19:18:03+00:00] WARN: Node kalib6.test.com has an empty run list. Converging 1 resources Recipe: @recipe_files::/root/exemplo.rb * yum_package[apache] action install - install version 2.4.6-67.el7.centos.6 of package httpd Running handlers: Running handlers complete Chef Client finished, 1/1 resources updated in 16 seconds [2018-04-01T19:18:17+00:00] WARN: No config file found or specified on command line, using command line options. Simples, certo? O pacote httpd (Apache) foi instalado em nosso CentOS. Verificando o status do serviço httpd, veremos que o serviço não está rodando e também não está ativo. # systemctl status httpd ● httpd.service - The Apache HTTP Server Loaded: loaded (/usr/lib/systemd/system/httpd.service; disabled; vendor preset: disabled) Active: inactive (dead) Docs: man:httpd(8) man:apachectl(8) Isto está correto, afinal o Chef vai deixar a máquina no estado que determinamos. O determinado foi apenas instalar o pacote httpd. Mas de nada ele serve sem estar rodando como serviço, portanto vamos editar nossa recipe exemplo.rb e incluir nela um novo resource, desta vez um resource do tipo service, ou serviço. Sim, podemos ter diversos resources em uma mesma recipe. ;] Edite sua recipe para que ela possua o seguinte conteúdo: package 'apache' do package_name 'httpd' action :installchef_httpd_default.png end service 'httpd' do action [:enable, :start] end O que adicionamos aqui? Resource Type: service (Pois queremos gerenciar o serviço httpd) Resource Name: httpd (Poderíamos ter utilizado qualquer nome, mas para simplificar e não precisarmos utilizar uma propriedade de nome, deixaremos o resource com o nome do serviço, httpd) Actions","date":"2018-04-01","objectID":"/posts/chef-aautomacao-e-gerenciamento-de/:5:0","tags":["Devops","Chef"],"title":"Chef: Automação E Gerenciamento De Configuração","uri":"/posts/chef-aautomacao-e-gerenciamento-de/"},{"categories":["Tutoriais"],"content":"Vale a pena? Realizar este processo manualmente na mesma máquina CentoOS seria mais rápido do que utilizando o Chef. Vamos rever: O que precisamos? Instalar o pacote httpd Habilitar e Iniciar o serviço httpd Criar o arquivo index.html com o conteúdo “Hello World!” Fazendo manualmente seria apenas uma questão de executarmos 4 comandos: # yum install httpd # systemctl enable httpd \u0026\u0026 systemctl start httpd # echo \"Hello World!\" \u003e /var/www/html/index.html # chmod 0755 /var/www/html/index.html \u0026\u0026 chown root:apache /var/www/html/index.html Sim, é verdade que fazendo manualmente neste caso seria MUITO mais rápido. O importante é lembrar do que falamos anteriormente: E se não for apenas 1 servidor? E se for um grupo? E se ao invés de apenas 3 resources, tiver 15? ou 40? E se alguém modificar algo em algum dos resources? Como você saberá qual foi? Vai verificar todos um a um para identificar o que precisa ser corrigido? Vantagens: Imagine que algum membro de sua equipe alterou a permissão do arquivo index.html sem lhe avisar, por exemplo ele foi lá e… # chmod 0666 /var/www/html/index.html Lembrando que em nossa recipe exemplo.rb, definimos a permissão 0755. Neste caso, sempre que executarmos a recipe, o Chef irá verificar todos os resources e corrigir o que quer que tenha sido alterado. # chef-client --local-mode exemplo.rb [2018-04-01T20:04:08+00:00] WARN: No config file found or specified on command line, using command line options. [2018-04-01T20:04:08+00:00] WARN: No cookbooks directory found at or above current directory. Assuming /root. Starting Chef Client, version 13.8.5 resolving cookbooks for run list: [] Synchronizing Cookbooks: Installing Cookbook Gems: Compiling Cookbooks... [2018-04-01T20:04:10+00:00] WARN: Node kalib6.test.com has an empty run list. Converging 3 resources Recipe: @recipe_files::/root/exemplo.rb * yum_package[apache] action install (up to date) * service[httpd] action enable (up to date) * service[httpd] action start (up to date) * file[/var/www/html/index.html] action create - change mode from '0666' to '0755' - restore selinux security context Running handlers: Running handlers complete Chef Client finished, 1/4 resources updated in 06 seconds [2018-04-01T20:04:14+00:00] WARN: No config file found or specified on command line, using command line options. Repare na linha - change mode from ‘0666’ to ‘0755’. O Chef acabou de corrigir automaticamente sem que nós tenhamos de vasculhar cada componente e arquivo em nosso servidor para saber o que foi alterado ou o que está diferente do estado desejado. Novamente, aqui tratamos de um servidor único, com apenas um arquivo. Imagine ter que varrer manualmente diversos servidores e diversos arquivos e diretórios? Neste exemplo, provavelmente o site poderia continuar funcionando, pois foi alterada apenas a permissão de um único arquivo, certo? Mas imagine que sem querer ele acabou parando o serviço httpd, ou até desinstalou o mesmo? Em uma instalação padrão com Chef Server, existem agendamentos que fazem com que o Chef execute as recipes a cada X minutos, portanto o serviço seria inicializado novamente automaticamente, ou mesmo instalado caso necessário. É fácil imaginar diversos cenários nos quais seria útil ter a sua infraestrutura em formato de código. Imagine uma catástrofe em que seu servidor simplesmente parou de funcionar e você precisará criar outro. Novamente você teria que executar aqueles comandos. Se desde o início tivesse utilizado Chef, ou outra ferramenta de Gerenciamento de Configuração, você poderia ter a sua recipe armazenada em um repositório Git, por exemplo, conforme mencionado no início deste post, e bastaria apenas executar o seu chef-client para instalar os pacotes necessários, habilitar e inicializar serviços, criar arquivos, etc. A imaginação é o seu limite. ;] Em posts futuros pretendo explorar mais a fundo o Chef, bem como outras ferramentas. Happy Hacking! ","date":"2018-04-01","objectID":"/posts/chef-aautomacao-e-gerenciamento-de/:6:0","tags":["Devops","Chef"],"title":"Chef: Automação E Gerenciamento De Configuração","uri":"/posts/chef-aautomacao-e-gerenciamento-de/"},{"categories":["Tutoriais"],"content":"Sistema Open Source desenvolvido pelo Google para o gerenciamento de cluster de containers tendo como características auto-scaling de serviços e containers, auto-monitoração de containers, permite o deploy de containers e serviços, load balancer, orquestração de containers, e orquestração de volumes de armazenamento.","date":"2017-06-24","objectID":"/posts/conhecendo-o-kubernetes-clusters-de/","tags":["Devops","Docker","Kubernetes"],"title":"Conhecendo O Kubernetes - Clusters De Containers","uri":"/posts/conhecendo-o-kubernetes-clusters-de/"},{"categories":["Tutoriais"],"content":"Sistema Open Source desenvolvido pelo Google para o gerenciamento de cluster de containers tendo como características auto-scaling de serviços e containers, auto-monitoração de containers, permite o deploy de containers e serviços, load balancer, orquestração de containers, e orquestração de volumes de armazenamento. ","date":"2017-06-24","objectID":"/posts/conhecendo-o-kubernetes-clusters-de/:0:0","tags":["Devops","Docker","Kubernetes"],"title":"Conhecendo O Kubernetes - Clusters De Containers","uri":"/posts/conhecendo-o-kubernetes-clusters-de/"},{"categories":["Tutoriais"],"content":"O que é Kubernetes Kubernetes é uma solução Open Source desenvolvida pelo Google, originalmente chamada de K8s, como uma ferramenta para gerenciar clusters de containers (ou containeres, como prefira). Em 2005, quando a ferramenta foi desenvolvida, originalmente para uso interno, o Google doou o código à recém fundada Cloud Native Computing Foundation, em parceria com a The Linux Foundation. O motivo do leme em sua logomarca é devido à origem grega da palavra, que vem de Kuvernetes, que representa a pessoa que pilota o navio, timoneiro. Como objetivo primário o Kubernetes provê uma plataforma de automação para deployments, escalonamento e operações de containers de aplicações em um cluster de hosts ou nodes. Antes de seguir com a explicação, instalação e configuração do Kubernetes, estou supondo que você já possui algum conhecimento básico sobre o que sejam containers e tenha alguma familiaridade com o Docker. Caso não possua um entendimento básico sobre containers e Docker, sugiro que leia algo antes de seguir com este artigo. Possuo um post introdutório sobre containers com um exemplo básico e prático sobre como criar containers com Docker, bem como iniciar uma simples aplicação web - aqui. O Kubernetes é formado por uma série de componentes ou blocos que, quando utilizados coletivamente, fornecem um método de deployment, manutenção e escalonamento de clusters de aplicações baseadas em containers. Estes componentes, ou primitives como o Kubernetes os chama, foram desenvolvidos com o intuito de serem independentes, de forma que quase não se faz necessário ter conhecimento entre si para que possam funcionar e trabalhar juntos, visto que todos se comunicam e interligam através de uma API, sejam componentes internos do Kubernetes ou mesmo extensões e containers. Embora tenha sido inicialmente desenvolvido para o deployment e utilização de bilhões de containers internamente no Google, desde que seu código passou a ser distribuído abertamente com a licença Apache Commons o Kubernetes tem sido adotado formalmente por praticamente todos os grandes provedores de serviços em nuvem. ","date":"2017-06-24","objectID":"/posts/conhecendo-o-kubernetes-clusters-de/:1:0","tags":["Devops","Docker","Kubernetes"],"title":"Conhecendo O Kubernetes - Clusters De Containers","uri":"/posts/conhecendo-o-kubernetes-clusters-de/"},{"categories":["Tutoriais"],"content":"Arquitetura do Kubernetes Dentre os principais componentes do Kubernetes, vamos destacar os seguintes: Master ou Master Controller - Host que será o gerenciador principal do Kubernetes, responsável por gerenciar os Minions ou Nodes do Cluster; Nodes ou Minions - Embora normalmente a nomenclatura em diversos serviços de tecnolocia seja Node, o Kubernetes prefere chamar de Minions os hosts que fazem parte de um Cluster gerenciado pelo próprio Kubernetes. Este minion pode ser um servidor físico ou virtual, necessitando possuir um serviço de gerenciamento de containers, como o Docker, por exemplo; ETCD - Embora este seja um serviço independente, estou listando-o aqui pois este será fundamental em seu ciclo de desenvolvimento com o Kubernetes. Cada Minion deverá rodar o ETCD (serviço de comunicação e gerenciamento de configurações no formato par de Chave/Valor). O ETCD é utilizado para troca e armazenamento de informações sobre os containers, pods, minions, etc. Pods - São grupos de containers (um ou mais) rodando em um único minion do cluster. Cada Pod receberá um endereço IP único no Cluster como forma de possibilitar a utilização de portas sem a necessidade de se preocupar com conflitos; Labels - São informações de identificação na configuração e gerenciamento dos objetos (como Pods ou Minions) formados de pares “chave:valor”; Controllers - Além do Master Controller, dependendo do tamanho de sua infraestrutura e quantidade de Pods e Minions, você pode optar por ter mais de um Controller para dividir a carga e tarefas de gerenciamento. Os Controllers gerenciam um grupo de pods e, dependendo do estado de configuração desejada, podem acionar outros Controllers para lidar com as replicações e escalonamento. Os Controllers também são responsáveis pela substituiçao de Pods, caso um entre em estado de falha. ","date":"2017-06-24","objectID":"/posts/conhecendo-o-kubernetes-clusters-de/:2:0","tags":["Devops","Docker","Kubernetes"],"title":"Conhecendo O Kubernetes - Clusters De Containers","uri":"/posts/conhecendo-o-kubernetes-clusters-de/"},{"categories":["Tutoriais"],"content":"Instalação Vamos ao que interessa… Novamente estou supondo que você já possui alguma familiaridade com Containers, Docker e, por consequência, com GNU/Linux. Eestarei utilizando 4 servidores virtuais rodando CentOS 7 nos exemplos a seguir, mas fica a seu critério decidir quantos utilizar. Certamente você optar por utilizar outra distribuição, seja Debian, Ubuntu, etc.. Uma vez que optei pelo CentOS 7, estarei utilizando comandos voltados para esta distro, mas sinta-se livre para adaptar seus comandos, como substituir o “yum” pelo “apt-get”, “pacman”, etc.. Em minha configuração chamarei os servidores da seguinte forma: centos-master centos-minion1 centos-minion2 centos-minion3 A primeira coisa que se deve fazer sempre que se pensa em trabalhar com clusters, independente de ser um cluster de containers ou não, é ter a certeza de que os servidores terão uma correta sincronização de relógios entre si. A forma mais simples e eficiente no nosso contexto é com a utilização do NTP, portanto comece instalando o NTP nos 4 servidores, bem como habilitando o serviço e iniciando-o: # yum install -y ntp # systemctl enable ntpd \u0026\u0026 systemctl start ntpd Caso queira certificar-se de que o serviço está realmente rodando: # systemctl status ntpd ● ntpd.service - Network Time Service Loaded: loaded (/usr/lib/systemd/system/ntpd.service; enabled; vendor preset: disabled) Active: active (running) since Sat 2017-06-24 17:46:02 UTC; 3s ago Process: 1586 ExecStart=/usr/sbin/ntpd -u ntp:ntp $OPTIONS (code=exited, status=0/SUCCESS) Main PID: 1587 (ntpd) Memory: 2.1M CGroup: /system.slice/ntpd.service └─1587 /usr/sbin/ntpd -u ntp:ntp -g Pinga? É importante nos certificarmos de que os servidores conseguem se comunicar e de que conseguem resolver nomes corretamente. Neste exemplo, conforme informado mais acima, estamos utilizando 4 servidores com os seguintes nomes: centos-master, centos-minion1, centos-minion2 e centos-minion3, portanto vamos editar o arquivo /etc/hosts de cada um deles para que possam se comunicar pelos nomes que desejamos: Insira as seguintes linhas no arquivo /etc/hosts dos 4 servidores: Lembre-se de substituir os IPs pelos IPs dos servidores em seu ambiente # Ip local do servidor master 172.31.22.126 centos-master # Ip local do minion1 172.31.120.16 centos-minion1 # Ip local do minion2 172.31.25.6 centos-minion2 # Ip local do minion3 172.31.123.22 centos-minion3 Feito isto, tente pingar do master para os 3 minions utilizando os nomes especificados no /etc/hosts: [root@kalib1 ~]# ping centos-minion1 PING centos-minion1 (172.31.120.16) 56(84) bytes of data. 64 bytes from centos-minion1 (172.31.120.16): icmp_seq=1 ttl=64 time=1.06 ms [root@kalib1 ~]# ping centos-minion2 PING centos-minion2 (172.31.25.6) 56(84) bytes of data. 64 bytes from centos-minion2 (172.31.25.6): icmp_seq=1 ttl=64 time=0.588 ms [root@kalib1 ~]# ping centos-minion3 PING centos-minion3 (172.31.123.22) 56(84) bytes of data. 64 bytes from centos-minion3 (172.31.123.22): icmp_seq=1 ttl=64 time=1.24 ms Você pode realizar o mesmo teste a partir dos minions, pingando entre si e também para o centos-master. Uma vez que tenhamos certeza de que todos os hosts se comunicam, é hora de instalar mais alguns pacotes necessários. Primeiramente, vamos configurar o repositório do Docker para o CentOS 7: Configurações de repositório retiradas dos repositórios CBS do Centos: https://cbs.centos.org/repos/virt7-docker-common-release/ Vamos criar o seguinte arquivo de repositório: # vim /etc/yum.repos.d/virt7-docker-common-release.repos O conteúdo deste arquivo será o seguinte: [virt7-docker-common-release] name=virt7-docker-common-release baseurl=https://cbs.centos.org/repos/virt7-docker-common-release/x86_64/os/ gpgcheck=0 Este arquivo deverá ser criado nos 4 servidores. Em seguida, vamos atualizar a nossa base de repositórios e pacotes, também nos 4 servidores, bem como habilitar o novo repositório para instalar os pacotes docker e kubernetes: # yum update # yum install -y --enablerepo=","date":"2017-06-24","objectID":"/posts/conhecendo-o-kubernetes-clusters-de/:3:0","tags":["Devops","Docker","Kubernetes"],"title":"Conhecendo O Kubernetes - Clusters De Containers","uri":"/posts/conhecendo-o-kubernetes-clusters-de/"},{"categories":["Tutoriais"],"content":"Configuração Vamos começar com a configuração básica dos serviços envolvidos. Primeiramente, vamos abrir o arquivo de configuração do kubernetes e fazer algumas alterações: /etc/kubernetes/config No arquivo config altere as seguintes linhas: Edite o valor do parâmetro KUBE_MASTER, de forma que nosso master possa ser encontrado pelo nome que definimos no hosts file. O valor original é “–master=https://127.0.0.1:8080”, portanto mudaremos para o seguinte: KUBE_MASTER=\"--master=https://centos-master:8080\" Ainda neste arquivo de configuração, vamos inserir a configuração do serviço ETCD, portanto inclua a seguinte linha ao final do arquivo: KUBE_ETCD_SERVERS=\"--etcd-servers=https://centos-master:2379\" Seu arquivo de configuração deverá estar similar a este: ### # kubernetes system config # # The following values are used to configure various aspects of all # kubernetes services, including # # kube-apiserver.service # kube-controller-manager.service # kube-scheduler.service # kubelet.service # kube-proxy.service # logging to stderr means we get it in the systemd journal KUBE_LOGTOSTDERR=\"--logtostderr=true\" # journal message level, 0 is debug KUBE_LOG_LEVEL=\"--v=0\" # Should this cluster be allowed to run privileged docker containers KUBE_ALLOW_PRIV=\"--allow-privileged=false\" # How the controller-manager, scheduler, and proxy find the apiserver KUBE_MASTER=\"--master=https://centos-master:8080\" KUBE_ETCD_SERVERS=\"--etcd-servers=https://centos-master:2379\" Repita esta mesma configuração nos 4 hosts. Todos eles devem utilizar exatamente os mesmos valores utilizados aqui, apontando KUBE_MASTER e KUBE_ETCD_SERVERS para centos-master, visto que este será o responsável por gerenciar todos os nossos minions. Uma vez que o arquivo de configuração do kubernetes esteja pronto nos 4 hosts, vamos configurar o serviço de API do kubernetes: /etc/kubernetes/apiserver Esta configuração abaixo será apenas para o Master. Edite o valor do parâmetro KUBE_API_ADDRESS, que originalmente é “–insecure-bind-address=127.0.0.1”, de forma que possamos novamente receber comunicação dos demais hosts. KUBE_API_ADDRESS=\"--address=0.0.0.0\" Descomente as linhas KUBE_API_PORT e KUBELET_PORT, para que possamos estabelecer as portas de comunicação com a API: # The port on the local server to listen on. KUBE_API_PORT=\"--port=8080\" # Port minions listen on KUBELET_PORT=\"--kubelet-port=10250\" Em nosso exemplo não utilizaremos o parâmetro KUBE_ADMISSION_CONTROL, o qual nos permite ter mais controles e restrições sobre quais nodes ou minios podem entrar em nosso ambiente, portanto vamos apenas comentar esta linha por enquanto: # default admission control policies # KUBE_ADMISSION_CONTROL=\"--admission-control=NamespaceLifecycle,NamespaceExists,LimitRanger,SecurityContextDeny,ServiceAccount,ResourceQuota\" Nosso arquivo /etc/kubernetes/apiserver deverá estar assim: ## # kubernetes system config # # The following values are used to configure the kube-apiserver # # The address on the local server to listen to. KUBE_API_ADDRESS=\"--address=0.0.0.0\" # The port on the local server to listen on. KUBE_API_PORT=\"--port=8080\" # Port minions listen on KUBELET_PORT=\"--kubelet-port=10250\" # Comma separated list of nodes in the etcd cluster KUBE_ETCD_SERVERS=\"--etcd-servers=https://127.0.0.1:2379\" # Address range to use for services KUBE_SERVICE_ADDRESSES=\"--service-cluster-ip-range=10.254.0.0/16\" # default admission control policies # KUBE_ADMISSION_CONTROL=\"--admission-control=NamespaceLifecycle,NamespaceExists,LimitRanger,SecurityContextDeny,ServiceAccount,ResourceQuota\" # Add your own! KUBE_API_ARGS=\"\" Salve e feche o arquivo. Novamente, esta configuração deve ser feita apenas para o Master. Agora vamos configurar o serviço ETCD: /etc/etcd/etcd.conf Esta configuração abaixo será apenas para o Master. Edite os valores dos parâmetros ETCD_LISTEN_CLIENT_URLS e ETCD_ADVERTISE_CLIENT_URLS, que originalmente apontam para localhost. Como desejamos que nosso etcd escute requisições dos demais hos","date":"2017-06-24","objectID":"/posts/conhecendo-o-kubernetes-clusters-de/:4:0","tags":["Devops","Docker","Kubernetes"],"title":"Conhecendo O Kubernetes - Clusters De Containers","uri":"/posts/conhecendo-o-kubernetes-clusters-de/"},{"categories":["Tutoriais"],"content":"Testando o Cluster com o Kubernetes Agora que temos a configuração básica de nosso Master Controller e de 3 minions, vamos testar nosso cluster. Utilizaremos o utilitário kubectl (KubeControl) disponível com o kubernetes. Caso tenha interesse em ver os parâmetros e funções do mesmo… $ man kubectl Vamos verificar a lista dos nodes ou minions que temos neste momento registrados em nosso Cluster. Vamos digitar alguns comandos em nosso Master Controller (centos-master): [root@kalib1 ~]# kubectl get nodes NAME STATUS AGE centos-minion1 Ready 17m centos-minion2 Ready 15m centos-minion3 Ready 10m Os três nodes criados e configurados anteriormente já são reconhecidos pelo nosso Kubernetes através do Master Controller. Além de registrados, estão com o status Ready, o que indica que estão prontos para funcionar e executar o que precisarmos. Caso deseje conhecer mais parâmetros que a função get do kubectl possui, podemos invocar o manual desta função: $ man kubectl-get Além do status, podemos conseguir diversas outras informações dos nodes através do kubectl: (Ex: kubectl describe nodes) Isto lhe daria informações sobre todos os nodes. Vamos experimentar com um node em específico. [root@kalib1 ~]# kubectl describe node centos-minion1 Name: centos-minion1 Role: Labels: beta.kubernetes.io/arch=amd64 beta.kubernetes.io/os=linux kubernetes.io/hostname=centos-minion1 Taints: \u003cnone\u003e CreationTimestamp: Tue, 20 Jun 2017 19:27:31 +0000 Phase: Conditions: Type Status LastHeartbeatTime LastTransitionTime Reason Message ---- ------ ----------------- ------------------ ------ ------- OutOfDisk False Sun, 25 Jun 2017 01:39:38 +0000 Fri, 23 Jun 2017 17:31:44 +0000 KubeletHasSufficientDisk kubelet has sufficient disk space available MemoryPressure False Sun, 25 Jun 2017 01:39:38 +0000 Tue, 20 Jun 2017 19:27:31 +0000 KubeletHasSufficientMemory kubelet has sufficient memory available DiskPressure False Sun, 25 Jun 2017 01:39:38 +0000 Tue, 20 Jun 2017 19:27:31 +0000 KubeletHasNoDiskPressure kubelet has no disk pressure Ready True Sun, 25 Jun 2017 01:39:38 +0000 Fri, 23 Jun 2017 17:31:54 +0000 KubeletReady kubelet is posting ready status Addresses: 172.31.120.16,172.31.120.16,centos-minion1 Capacity: alpha.kubernetes.io/nvidia-gpu: 0 cpu: 1 memory: 1015348Ki pods: 110 Allocatable: alpha.kubernetes.io/nvidia-gpu: 0 cpu: 1 memory: 1015348Ki pods: 110 System Info: Machine ID: f9afeb75a5a382dce8269887a67fbf58 System UUID: EC2C8A0E-91D6-F54E-5A49-534A6A903FDA Boot ID: 20961efd-c946-481a-97cb-7788209551ae Kernel Version: 3.10.0-327.28.2.el7.x86_64 OS Image: CentOS Linux 7 (Core) Operating System: linux Architecture: amd64 Container Runtime Version: docker://1.12.6 Kubelet Version: v1.5.2 Kube-Proxy Version: v1.5.2 ExternalID: centos-minion1 Non-terminated Pods: (0 in total) Namespace Name CPU Requests CPU Limits Memory Requests Memory Limits --------- ---- ------------ ---------- --------------- ------------- Allocated resources: (Total limits may be over 100 percent, i.e., overcommitted. CPU Requests CPU Limits Memory Requests Memory Limits ------------ ---------- --------------- ------------- 0 (0%) 0 (0%) 0 (0%) 0 (0%) Events: FirstSeen LastSeen Count From SubObjectPath Type Reason Message --------- -------- ----- ---- ------------- -------- ------ ------- 15m 15m 1 {kubelet centos-minion1} Normal Starting Starting kubelet. 15m 15m 1 {kubelet centos-minion1} Warning ImageGCFailed unable to find data for container / 15m 15m 2 {kubelet centos-minion1} Normal NodeHasSufficientDisk Node centos-minion1 status is now: NodeHasSufficientDisk 15m 15m 2 {kubelet centos-minion1} Normal NodeHasSufficientMemory Node centos-minion1 status is now: NodeHasSufficientMemory 15m 15m 2 {kubelet centos-minion1} Normal NodeHasNoDiskPressure Node centos-minion1 status is now: NodeHasNoDiskPressure 15m 15m 1 {kubelet centos-minion1} Warning Rebooted Node centos-minion1 has been rebooted, boot id: 20961efd-c946-481a-97cb-7788209551ae Obviamente recebemos um retorno com muitas informaç","date":"2017-06-24","objectID":"/posts/conhecendo-o-kubernetes-clusters-de/:5:0","tags":["Devops","Docker","Kubernetes"],"title":"Conhecendo O Kubernetes - Clusters De Containers","uri":"/posts/conhecendo-o-kubernetes-clusters-de/"},{"categories":["Tutoriais"],"content":"Criando pods Assim como com o Docker, Ansible e algumas outras ferramentas, utilizaremos a linguagem YAML para criar nossos arquivos de configuração. Criaremos um diretório chamado Builds em nosso Master Controller apenas para melhor organizar nossos arquivos de configuração e ficar mais fácil encontrá-los no futuro: # mkdir Builds # cd Builds Para criarmos Pods, o que fazemos na verdade é criar arquivos de configuração que vão dizer ao Kubernetes qual o estado em que desejamos nossa infraestrutura. O papel do Kubernetes é ler esta configuração e assegurar que o estado de nossa infraestrutura reflita o estado desejado. Para facilitar, vamos utilizar exemplos encontrados na própria documentação do Kubernetes. Comecemos com a criação de um Pod para um servidor web Nginx. Vamos criar um arquivo chamado nginx.yaml dentro do diretório Builds que criamos anteriormente: # vim nginx.yaml No arquivo indicaremos alguns atributos ou variáveis, bem como seus respectivos valores: apiVersion - Indica a versão da API do kubernetes utilizada kind - o tipo de recurso que desejamos metadata - dados referentes ao recurso desejado spec - especificações sobre o que este recurso irá conter Vamos criar um Pod contendo um único container rodando a versão 1.7.9 do nginx bem como disponibilizando a porta 80 para receber conexões. Este deverá ser o conteúdo do arquivo nginx.yaml: apiVersion: v1 kind: Pod metadata: name: nginx spec: containers: - name: nginx image: nginx:1.7.9 ports: - containerPort: 80 Antes de executarmos, vamos nos certificar novamente de duas coisas: Que realmente não temos nenhum Pod criado e ativo; Que não temos nenhum container rodando em nossos nodes. No centos-master: [root@kalib1 Builds]# kubectl get pods No resources found. No centos-minion1: (Execute o mesmo comando nos demais nodes (centos-minion2 e centos-minion3)) [root@kalib2 ~]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES Novamente: Se você não faz ideia do que acabei de digitar, (docker ps) volte e leia um pouco sobre Docker antes de seguir com este artigo. Como podemos ver, não temos nenhum Pod, bem como nenhum container rodando em nossos nodes. Vamos utilizar kubectl create para criar o Pod utilizando o arquivo que criamos nginx.yaml: Executaremos este comando no Master Controller - centos-master [root@kalib1 Builds]# kubectl create -f nginx.yaml pod \"nginx\" created O Kubernetes está dizendo que nosso Pod “nginx” foi criado. Vamos verificar: [root@kalib1 Builds]# kubectl get pods NAME READY STATUS RESTARTS AGE nginx 1/1 Running 0 1m O pod está criado e rodando. Agora, execute novamente docker ps nos 3 nodes para identificar em qual deles o container foi criado. Sim, como não especificamos nada, o Kubernetes vai verificar os recursos disponíveis no momento e vai lançar onde ele achar mais adequado. [root@kalib4 ~]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 6de8e22e1536 nginx:1.7.9 \"nginx -g 'daemon off\" 2 minutes ago Up 2 minutes k8s_nginx.b0df00ef_nginx_default_d4debd3a-594c-11e7-b587-06827a5b32d4_583881e0 ae49b36ae11b gcr.io/google_containers/pause-amd64:3.0 \"/pause\" 2 minutes ago Up 2 minutes k8s_POD.b2390301_nginx_default_d4debd3a-594c-11e7-b587-06827a5b32d4_fb5c834f Sim, existem dois containers rodando. Um deles é o nosso “nginx”, enquanto que o outro é um container padrão do google chamado “/pause”, o qual será responsável pela manutenção de alguns recursos de nosso cluster. Podemos novamente pedir a descrição deste pod que acabamos de criar: [root@kalib1 Builds]# kubectl describe pod nginx Name: nginx Namespace: default Node: centos-minion3/172.31.123.22 Start Time: Sun, 25 Jun 2017 02:20:18 +0000 Labels: \u003cnone\u003e Status: Running IP: 172.17.0.2 Controllers: \u003cnone\u003e Containers: nginx: Container ID: docker://6de8e22e153618271bb6e8095c68070126541331c8acfc3f5d1a654f4b978454 Image: nginx:1.7.9 Image ID: docker-pullable://docker.io/nginx@sha256:e3456c851a152494c3e4ff5fcc26f240206abac0c9d794affb40e0714846c451 Port: 80/TCP State: R","date":"2017-06-24","objectID":"/posts/conhecendo-o-kubernetes-clusters-de/:6:0","tags":["Devops","Docker","Kubernetes"],"title":"Conhecendo O Kubernetes - Clusters De Containers","uri":"/posts/conhecendo-o-kubernetes-clusters-de/"},{"categories":["Tutoriais"],"content":"Monitoramento de serviços e infraestrutura é uma peça fundamental em qualquer corporação. Com as tendências de times cada vez mais ágeis e interativos, automatizar e receber notificações de status de serviços nos mais distintos meios se torna cada vez mais importante. Vejamos como podemos receber notificações do AWS diretamente em um canal do seu time no Slack.","date":"2017-03-11","objectID":"/posts/recebendo-alarmes-do-aws-diretamente/","tags":["Seguranca","Internet","AWS","Sysadmin","DevOps","Slack"],"title":"Recebendo Alarmes Do Aws Diretamente No Slack","uri":"/posts/recebendo-alarmes-do-aws-diretamente/"},{"categories":["Tutoriais"],"content":"Antes de entrar na configuração dos serviços, talvez seja necessário apresentar o [Slack](https://www.slack.com, visto que muitos ainda não conhecem ou utilizam esta poderosa e versátil ferramenta de comunicação instantânea para times. ","date":"2017-03-11","objectID":"/posts/recebendo-alarmes-do-aws-diretamente/:0:0","tags":["Seguranca","Internet","AWS","Sysadmin","DevOps","Slack"],"title":"Recebendo Alarmes Do Aws Diretamente No Slack","uri":"/posts/recebendo-alarmes-do-aws-diretamente/"},{"categories":["Tutoriais"],"content":"O que é o Slack Slack é uma plataforma para comunicação entre times que desejam um ambiente mais dinâmico e ágil. Diferentemente de muitas plataformas de chat disponíveis, como o Google Hangouts, o Slack nos permite criar canais distintos com membros distintos de um mesmo time fazendo parte daquele canal específico. Não, não estou falando de chat em grupo, mas sim canais específicos que permitem integrações com serviços distintos, como receber notificações sobre commits feitos em um repositório ou branch específico no github, notificações de tickets abertos em ferramentas como o Jira, por exemplo, etc. O Slack é completamente programável e escalável, o que nos permite ter inúmeras funcionalidas. Provavelmente não seja necessário apresentar o AWS, ou Amazon Web Services, visto que já está no mercado desde 2006, no entanto cabe um resumo para os que não estão familiarizados com o mesmo (embora o público alvo deste post seja quem já possui alguma familiaridade com AWS). Aws ou Amazon Web Services é uma plataforma de serviços em nuvem segura, oferecendo poder computacional, armazentamento de banco de dados, distribuição de conteúdo e outras funcionalidades. Por que eu deveria ter alarmes e notificações do AWS em um serviço de chat como o Slack quando já recebo estas notificações por email? É verdade que o uso mais comum para envio de alarmes e notificações do AWS costuma ser via email, no entanto fica fácil identificar alguns problemas com este método. O principal e mais recorrente que vejo é o caso de as notificações caírem em um email específico visto por poucas pessoas (na maioria das vezes) ou nem visto sequer, pois geralmente as pessoas ficam cansadas de olhar notificações e ter sua caixa de entrada entupida com eles portanto criam filtros que jogam os emails de notificação para um diretório que dificilmente será checado. Outro problema comum com esta prática é a demora até que alguém leia a notificação no meio de tantos outros na pasta ou filtro criado e, muitas vezes, quando se vê a notificação, o problema já está aguardando uma solução há horas. Deixando claro, não estou defendendo a ideia de abolir as notificações por email. Eu mesmo utilizo ambos, afinal o email continua bastante eficiente para fins de armazenamento e checagem histórica, por exemplo. Uma vez que nos dias atuais os times de TI estão cada vez mais unificados e dinâmicos, buscando incorporar uma mentalidade DevOps e Agile, a comunicação rápida e eficiente se torna um fator primordial para o sucesso de qualquer projeto. Ter um local centralizado para conversar com os demais membros do time, trocar arquivos, detalhes de projetos, receber notificações de commits, prazos, tickets, documentação e, por que não, notificações de monitoramento e alarmes, torna-se essencial. ","date":"2017-03-11","objectID":"/posts/recebendo-alarmes-do-aws-diretamente/:1:0","tags":["Seguranca","Internet","AWS","Sysadmin","DevOps","Slack"],"title":"Recebendo Alarmes Do Aws Diretamente No Slack","uri":"/posts/recebendo-alarmes-do-aws-diretamente/"},{"categories":["Tutoriais"],"content":"Nossa solução Vamos então entender como funcionaria uma solução para enviar as notificações e alarmes do AWS para o Slack. O que utilizaremos: No Slack: Um plugin ou Slack App chamado Incoming WebHooks O nome de um canal para envio das notificações No AWS: Serviço SNS Topic Serviço CloudWatch Serviço Lambda Function Vamos lá… ","date":"2017-03-11","objectID":"/posts/recebendo-alarmes-do-aws-diretamente/:2:0","tags":["Seguranca","Internet","AWS","Sysadmin","DevOps","Slack"],"title":"Recebendo Alarmes Do Aws Diretamente No Slack","uri":"/posts/recebendo-alarmes-do-aws-diretamente/"},{"categories":["Tutoriais"],"content":"Slack Vamos começar escolhendo o canal no Slack no qual desejo receber a minha notificação ou alarme: #devops Estou supondo que você já utiliza o Slack e já possui um time criado no mesmo. Caso ainda não, crie um time no Slack seguindo os passos descritos no site oficial antes de seguir em frente… ;] O próximo passo é configurar a integração instalando o Plugin ou Slack App Incoming WebHooks. Para isto, acesse a página de apps de seu time no Slack: https://SEUTIME.slack.com/apps Pesquise por Incoming WebHooks e você terá apenas um resultado, portanto clique sem medo. Clique no pequeno lápis que se encontrará no canto direito para editar as configurações do Incoming WebHook. Os únicos campos que precisaremos editar neste momento são os seguintes: Post to Channel - Aqui indicarei o meu canal: #devops Customize Name - Aqui indicarei um nome qualquer: AWS-Alerts Importante: Repare que nesta página de configurações ele lhe passará uma entrada ou URL com o código para o seu WebHook. Esta informação estará listada em Webhook URL e será algo como: https://hooks.slack.com/services/T434P71A4/U4G3JUG13/kPjvXY4Kd8wPm4TvrEqhN6Dv. Copie esta informação em algum local de fácil acesso pois precisaremos desta URL para a configuração que faremos a seguir no AWS. Salve suas configurações e vamos configurar os serviços do AWS para que nosso WebHook possa receber as informações devidamente. ","date":"2017-03-11","objectID":"/posts/recebendo-alarmes-do-aws-diretamente/:2:1","tags":["Seguranca","Internet","AWS","Sysadmin","DevOps","Slack"],"title":"Recebendo Alarmes Do Aws Diretamente No Slack","uri":"/posts/recebendo-alarmes-do-aws-diretamente/"},{"categories":["Tutoriais"],"content":"Amazon Web Services Se você já possui alguma familiaridade com o AWS, sabe que existem duas formas principais para administração e gerenciamento de nossos serviços: Pela interface web de gerenciamento (GUI) OU pela linha de comandos através da AWS CLI Tool que se comunica com a API do AWS. Este procedimento, assim como praticamente todos os outros, pode ser realizado por ambos os meios. Se você também gosta de automação, provavelmente prefere utilizar a CLI, no entanto irei listar aqui o procedimento em ambos os meios. Passo 1: Criando um SNS Topic para receber os alarmes 1.1 - Pela Interface Web de Gerenciamento (GUI) A partir da Dashboard principal, clique ou busque pelo serviço SNS; Crie um novo SNS Topic: No menu da lateral esquerda, clique em Topics; Clique em Create new topic; Preencha os campos Name (obrigatório) e Display Name (opcional) para o seu tópico. Para este exemplo utilizarei aws-slack-alerts como Name e aws-slack como Display Name; (O Display Name só é necessário em caso de você também desejar enviar notificações por SMS) Clique em Create Topic Agora você já deve ser capaz de ver seu SNS Topic na lista. 1.2 - Pela AWS CLI Tool Estou assumindo que se você optou por utilizar este método, é porque já possui sua CLI configurada e autenticando em sua conta do AWS com sua chave. Caso você não saiba do que estou falando, sugiro que siga a documentação oficial para isto. Pela CLI tool, digite o seguinte comando, indicando a região na qual você deseja criar seu tópico e o nome desejado: aws sns create-topic --region us-west-1 --name aws-slack-alerts IMPORTANTE: Você receberá um identificador (TopicArn) para este alarme. Você precisará dele no passo seguinte. Caso queira ter certeza, você pode listar seus tópicos utilizando: aws sns list-topics Passo 2: Criando um Alarme no serviço CloudWatch 2.1 - Pela Interface Web de Gerenciamento (GUI) A partir da Dashboard principal, clique ou busque pelo serviço CloudWatch; Crie um novo Alarme: Clique em Alarms; Clique no botão Create Alarm; Escolha a categoria do alarme desejado. Para este exemplo utilizarei ELB Metric \u003e Per-LB Metrics (Dentre as várias categorias disponíveis, esta se refere à Load Balancers); Selecione a métrica exata desejada. No caso deste exemplo, preciso selecionar a métrica e o Load Balancer desejado. Ao escolher a métrica e o alvo (em meu caso um Load Balancer) clique em Next. Neste exemplo eu escolhi a métrica HTTPCode_Backend_5XX (para monitorar 500 errors) e um Load Balancer chamado LB-GuySpyV3; O próximo passo é definir um nome e uma descrição para este Alarme, bem como definir as triggers e períodos de monitoramento. Neste exemplo utilizei o nome LB-GuySpyV3-ELB_500 para meu alarme; (Não entrarei em detalhes quanto ao uso das triggers, visto que para cada tipo ou categoria de métrica, as triggers serão diferentes, bem como o cenário de seu ambiente e nível de criticidade. Em resumo, se você deseja monitorar o uso de CPU de um determinado servidor, a trigger seria o gatilho que ativaria o alarme, por exemplo: Só quero ser alarmado se o uso de CPU neste servidor ou instância for \u003e= 90% e assim permanecer por pelo menos 60 segundos, ou por dois períodos seguidos de 60seg.) Na seção Actions da configuração do Alarme defina o State e indique que a notificação deverá ser enviada (Send notification to) para o SNS Topic que criamos anteriormente. Para este exemplo optei por State is ALARM e decidi enviar as notificações para aws-slack-alerts, sendo este o SNS Topic que criei no início; Finalize clicando em Create Alarm. 2.2 - Pela AWS CLI Tool Novamente… Estou assumindo que se você optou por utilizar este método, é porque já possui sua CLI configurada e autenticando em sua conta do AWS com sua chave. Caso você não saiba do que estou falando, sugiro que siga a documentação oficial para isto. Pela CLI tool, digite o seguinte comando, indicando os atributos abaixo: region (Região); alarm-name (Nome do alarme); alarm-description (Descrição do alarme); alarm-acti","date":"2017-03-11","objectID":"/posts/recebendo-alarmes-do-aws-diretamente/:2:2","tags":["Seguranca","Internet","AWS","Sysadmin","DevOps","Slack"],"title":"Recebendo Alarmes Do Aws Diretamente No Slack","uri":"/posts/recebendo-alarmes-do-aws-diretamente/"},{"categories":["Tutoriais"],"content":"Cada vez mais precisamos de soluções ágeis para deploy de aplicações e serviços e as soluções de containers surgiram com este propósito. Conheça o Docker, uma solução open source simples e prática, embora robusta, para utilização de containers no Linux.","date":"2015-08-20","objectID":"/posts/docker-uma-alternativa-elegante-para/","tags":["DevOps","Software Livre","Segurança","Linux","Ubuntu","Internet","Docker","Containers"],"title":"Docker - Uma Alternativa Elegante Para Containers No Linux","uri":"/posts/docker-uma-alternativa-elegante-para/"},{"categories":["Tutoriais"],"content":"Cada vez mais precisamos de soluções ágeis para deploy de aplicações e serviços e as soluções de containers surgiram com este propósito. Conheça o Docker, uma solução open source simples e prática, embora robusta, para utilização de containers no Linux. ","date":"2015-08-20","objectID":"/posts/docker-uma-alternativa-elegante-para/:0:0","tags":["DevOps","Software Livre","Segurança","Linux","Ubuntu","Internet","Docker","Containers"],"title":"Docker - Uma Alternativa Elegante Para Containers No Linux","uri":"/posts/docker-uma-alternativa-elegante-para/"},{"categories":["Tutoriais"],"content":"O que são containers? Antes de falar sobre o Docker, é importante que se entenda o conceito de um container, portanto vamos começar do básico. A imagem acima, logomarca do Docker, deixa claro o que é um container. A baleia, representando um navio, carregando diversos caixotes ou containers ilustra o conceito físico de um container. Nada mais do que um enorme caixote que possui o intuito de isolar algo. Quando um grande navio transporta mercadorias de um porto para outro, ele costuma trazer diversos containers separando estas mercadorias, de forma que as coisas não fiquem misturadas e bagunçadas. A forma de separação vai depender dos critérios de organização utilizados pela embarcação, seja por proprietário, seja por categoria de produtos, etc. De qualquer forma, embora cada container possua seus elementos próprios, todos os containers compartilham alguns recursos básicos, como por exemplo a embarcação, que é o meio de transporte para todos os containers ali contidos. Da mesma forma se dá no mundo dos computadores, onde o conceito de containers surgiu para separar e isolar alguns recursos e aplicações, otimizando os recursos que servem como base e que podem ser utilizados de forma compartilhada, como por exemplo o kernel do Sistema Operacional. De certa forma isto nos faz lembrar um pouco da virtualização, onde cada máquina virtual compartilha os recursos da máquina física, no entanto existe uma diferença clara no contexto de containers, visto que em um cenário de virtualização você precisará possuir um SO instalado na máquina física, com seu kernel e todos os seus recursos, e um SO instalado em sua máquina virtual, também com seu kernel e todos os seus recursos. Quando falamos em containers, imagine que você só precisará do kernel, bem como vários outros recursos, na máquina que será a hospedeira do container (a embarcação). Containers Linux surgiram como uma tecnologia chave para empacotamento e entrega de aplicativos, combinando a leveza do isolamento de aplicativos com a flexibilidade de métodos de deploy baseados em imagens. Uma das formas mais simples de se imaginar a vantagem da utilização de containers é imaginar que você possui uma empresa que hospeda servidores de aplicações para seus clientes. Se um novo cliente surge querendo hospedar a aplicação dele, você subirá uma nova máquina virtual, o que inclui todo um novo sistema operacional, enquanto que em uma solução baseada em containers você poderá ter apenas a sua máquina com um único kernel Linux provendo as priorizações de recursos (CPU, memória, I/O, rede, etc.) sem a necessidade de dar boot em um novo sistema operacional (máquinia virtual) na qual rodará a aplicação deste cliente. Dizem que uma imagem vale mais que mil palavras… Na imagem acima temos o cenário convencional com a utilização de Máquinas Virtuais. Em suma, temos um host físico, com seu respectivo SO e kernel. Acima deles temos a camada de virtualização ou HyperVisor, enquanto que acima desta teremos as máquinas virtuais, com seus respectivos SOs (cada um com seu kernel) instalados. No caso temos 3 VMs, com 3 SOs (cada um com seu kernel). Na camada acima encontramos o que realmente é necessário para o app do cliente funcionar, que são as bibliotecas e os binários. Por fim, o App do cliente em si. Vejamos como fica o cenário com a utilização de containers, docker neste caso… No cenário com o Docker percebemos que a camada de SO das VMs sumiu, visto que ela não é mais necessária. Ao invés de Máquinas Virtuais, agora nós temos 3 containers, onde cada container roda os binários e bibliotecas de um SO, porém se aproveitando do kernel já existente no Host. Com este grau de modularização nós ganhamos maior flexibilidade e agilidade no deploy de ambientes e aplicações. ","date":"2015-08-20","objectID":"/posts/docker-uma-alternativa-elegante-para/:1:0","tags":["DevOps","Software Livre","Segurança","Linux","Ubuntu","Internet","Docker","Containers"],"title":"Docker - Uma Alternativa Elegante Para Containers No Linux","uri":"/posts/docker-uma-alternativa-elegante-para/"},{"categories":["Tutoriais"],"content":"Docker Uma das vantagens da utilização do Docker é a existência de um repositório de imagens prontas que ficam disponibilizadas livremente para quem desejar utilizar. Seja uma imagem pronta de um container com CentOS, Ubuntu, etc.. Já existem centenas e centenas de imagens prontas para uso, sendo esta uma base de compartilhamento comunitário, mas… Vamos ao que interessa… Nos exemplos a seguir, estou utilizando o Ubuntu Server 15.04, visto que estou atualmente realizando uma POC de VPS com um novo host, portanto aproveitarei para fazer disto uma parte de meus testes nesta VPS. Sinta-se livre para utilizar sua máquina física com Ubuntu, com Debian, ou mesmo uma máquina virtual, caso não goste de realizar testes em sua máquina física, o resultado será o mesmo. Para que tudo funcione como esperamos, só existem 2 pré-requisitos a serem atendidos: ","date":"2015-08-20","objectID":"/posts/docker-uma-alternativa-elegante-para/:2:0","tags":["DevOps","Software Livre","Segurança","Linux","Ubuntu","Internet","Docker","Containers"],"title":"Docker - Uma Alternativa Elegante Para Containers No Linux","uri":"/posts/docker-uma-alternativa-elegante-para/"},{"categories":["Tutoriais"],"content":"Mão na massa 1- O kernel do Linux que será utilizado deve ser igual ou superior ao 3.8; 2- Caso você esteja realizando os testes em uma VM, seria interessante que sua máquina física tivesse comunicação com a VM. Isso pode ser testado com um ping da máquina física para a VM. No caso de sua máquina virtual ser instalada com interface gráfica, esta comunicação não será necessária, pois o único momento em que utilizaremos isto será para abrir um navegador e fazer um teste de acesso ao endereço da máquina virtual. Vamos lá. Para ter a certeza de que você atende o pré-requisito de kernel, utilize o comando “uname -r”: kalib@cloudcaverna:~$ uname -r 3.19.0-25-generic Estou com o kernel 3.19, portanto superior ao kernel 3.8 que é o pré-requisito mínimo. Vamos em frente. Primeiramente, vamos instalar o Docker. Seja lá qual for sua distribuição Linux, digite o comando: (O comando deve ser executado com o usuário root ou com o comando sudo!) # curl -sSL https://get.docker.com | sh Ele baixará e executará um script de instalação, no meu caso do Ubuntu ele irá instalar um repositório e em seguida instalará o docker. O próximo passo será iniciar o serviço do docker: # /etc/init.d/docker start [ ok ] Starting docker (via systemctl): docker.service. O docker possui uma série de scripts/comandos próprios para facilitar a sua administração, como por exemplo um script de ps, para que possamos ter a certeza de que ele está rodando e, além disso, saber se existem containers em execução, da mesma forma que faríamos com o ps do linux para ver os processos em andamento. # docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES Podemos ver que o docker está rodando, no entanto nenhum container está em execução. Na verdade, não temos nenhum container criado, portanto obviamente não poderia estar em execução. Além do ps, podemos utilizar o script images para ver quais imagens de containers já possuímos para uso: # docker images REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE Da mesma forma, não temos ainda nenhuma imagem baixada para uso. Uma vez que estamos falando de containers, conforme dito anteriormente, a ideia é isolar ao máximo e otimizar o que precisamos para este container, portanto precisamos informar o processo que desejamos iniciar no container em questão. Vamos criar um container do Ubuntu, por exemplo, na versão 15.04, lançada em Abril deste ano, e vamos iniciar juntamente com ele o processo /bin/bash. O comando utilizado será: docker run -i -t ubuntu:15.04 /bin/bash # docker run -i -t ubuntu:15.04 /bin/bash Unable to find image 'ubuntu:15.04' locally 15.04: Pulling from library/ubuntu 6e6a100fa147: Pull complete 13c0c663a321: Pull complete 2bd276ed39d5: Pull complete 013f3d01d247: Already exists library/ubuntu:15.04: The image you are pulling has been verified. Important: image verification is a tech preview feature and should not be relied on to provide security. Digest: sha256:b2d4940544e515d4bc62b2a9ad3e6137b3e1e0937a41fdc1f0f30d12935e5b09 Status: Downloaded newer image for ubuntu:15.04 root@d70562e7533c:/# É importante reparar que na primeira linha de execução ele me trouxe um alerta informando que não foi possível encontrar a imagem “ubuntu:15.04” localmente. Como disse acima, não temos ainda nenhuma imagem baixada, portanto ele não encontrou localmente e foi baixar diretamente no repositório de imagens do docker. O procedimento foi extremamente rápido, certo? Acredite ou não, você já possui um container Ubuntu rodando em sua máquina. ;] Ainda não acredita? Repare novamente no seu prompt de comandos, veja que logo que ele finalizou o processo ele lhe deixou em um prompt “estranho”. No caso do meu exemplo acima, perceba que ao concluir o processo ele me deixou com o prompt assim: root@d70562e7533c:/# Não, minha máquina não se chama d70562e7533c. Tenho certeza de que a sua também não se chama.. seja lá qual for a combinação de caracteres que lhe foi apresentada no prompt. Na verdade, sempre que iniciamos um container, o comportam","date":"2015-08-20","objectID":"/posts/docker-uma-alternativa-elegante-para/:3:0","tags":["DevOps","Software Livre","Segurança","Linux","Ubuntu","Internet","Docker","Containers"],"title":"Docker - Uma Alternativa Elegante Para Containers No Linux","uri":"/posts/docker-uma-alternativa-elegante-para/"},{"categories":["Impressões"],"content":"Assista ao documentário que conta toda a trajetória do ativista Aaron Swartz, do seu nascimento ao ato que terminou de forma trágica sua vida.","date":"2014-08-03","objectID":"/posts/assista-ao-documentario-sobre-aaron/","tags":["Software Livre","Segurança","Cultura Hacker","Literatura","Internet","Privacidade"],"title":"Assista Ao Documentário Sobre Aaron Swartz O Menino Da Internet","uri":"/posts/assista-ao-documentario-sobre-aaron/"},{"categories":["Impressões"],"content":"Assista ao documentário que conta toda a trajetória do ativista Aaron Swartz, do seu nascimento ao ato que terminou de forma trágica sua vida. ","date":"2014-08-03","objectID":"/posts/assista-ao-documentario-sobre-aaron/:0:0","tags":["Software Livre","Segurança","Cultura Hacker","Literatura","Internet","Privacidade"],"title":"Assista Ao Documentário Sobre Aaron Swartz O Menino Da Internet","uri":"/posts/assista-ao-documentario-sobre-aaron/"},{"categories":["Impressões"],"content":"Introdução Informação é poder. Mas, como todo poder, há aqueles que querem mantê-la para si mesmos. O patrimônio cultural e científico do mundo, publicado ao longo dos séculos em livros e revistas, está cada vez mais szendo digitalizado e trancado por um punhado de corporações privadas. Enquanto isso, aqueles que foram bloqueados não estão em pé de braços cruzados. Eles estão bisbilhotando em buracos e escalando cercas libertando as informações trancadas pelos editores e compartilhando com seus amigos. Mas toda essa ação acontece no escuro, escondida no subterrâneo. É chamado de roubo ou pirataria, como se compartilhar uma riqueza de conhecimentos fosse o equivalente de saquear um navio e matar sua tripulação. Mas compartilhar não é imoral - é um imperativo moral. Só os cegos pela ganância se recusam a deixar um amigo fazer uma cópia. Não há justiça em seguir leis injustas. É hora de virmos para a luz e, na grande tradição de desobediência civil, declararmos a nossa oposição a este roubo privado da cultura pública. -Manifesto do guerrilheiro ao acesso livre Este é apenas um trecho do manifesto assinado por Aaron, entitulado “Manifesto do guerrilheiro ao acesso livre”. ","date":"2014-08-03","objectID":"/posts/assista-ao-documentario-sobre-aaron/:1:0","tags":["Software Livre","Segurança","Cultura Hacker","Literatura","Internet","Privacidade"],"title":"Assista Ao Documentário Sobre Aaron Swartz O Menino Da Internet","uri":"/posts/assista-ao-documentario-sobre-aaron/"},{"categories":["Impressões"],"content":"Documentário Recentemente foi lançado um documentário de Brian Knappenberger sobre Aaron Swartz, o qual foi considerado um dos principais nomes da internet e luta pela liberdade de acesso ao conhecimento dos últimos anos. Para quem ainda não sabe do que se trata, Aaron Swartz foi um dos criadores do RSS bem como do famoso site de notícias e debates Reddit.Após alguns anos lutando e enfrentando a justiça americana Aaron cometeu suicídio. Aaron estava sendo condenado a cerca de 50 anos de prisão, bem como a pagar um montante superior a U$ 4 milhões em multas por querer tornar públicos os artigos acadêmicos e científicos que eram mantidos na base do JSTOR, o qual vendia o acesso a estes artigos que, na visão de Aaron, deveriam ser de domínio e acesso público. Aaron sempre defendeu e lutou para que o conhecimento fosse de livre acesso a todos. Lutou tanto que acabou sendo covardemente perseguido e pressionado pelo governo americano, o que acabou por lhe deixar exausto, psicologicamente e financeiramente, ao ponto de ele desistir da luta ao invés de simplesmente “assumir” que estava errado e aceitar os “acordos” que lhe foram oferecidos pela justiça americana. Seu crime? A curiosidade. A fome por conhecimento. Também a vontade de expor este conhecimento a todos que o desejassem. Para quem por algum motivo ainda não conhece o recurso de legendas ou caption do YoutTube, caso a legenda do filme não apareça automaticamente, basta clicar no botão de legendas/caption, habilitando-o, conforme apresentado na imagem abaixo: Link para o vídeo: https://www.youtube.com/watch?v=2uj1EeiuK5U Abraços, ","date":"2014-08-03","objectID":"/posts/assista-ao-documentario-sobre-aaron/:2:0","tags":["Software Livre","Segurança","Cultura Hacker","Literatura","Internet","Privacidade"],"title":"Assista Ao Documentário Sobre Aaron Swartz O Menino Da Internet","uri":"/posts/assista-ao-documentario-sobre-aaron/"},{"categories":["Tutoriais"],"content":"Utilize o sysctl para alterar parâmetros do kernel com o mesmo em execução.","date":"2014-02-13","objectID":"/posts/alterando-os-parametros-do-kernel/","tags":["Linux","Seguranca","Cultura Hacker"],"title":"Alterando Os Parâmetros Do Kernel Em Tempo Real Com O Systcl","uri":"/posts/alterando-os-parametros-do-kernel/"},{"categories":["Tutoriais"],"content":"O kernel, em se tratando de sistemas operacionais, é o núcleo e componente mais importante da maioria dos computadores. Basicamente, serve de ponte entre os aplicativos e o processamento real de dados feito a nível de hardware. É ele o responsável por gerenciar os recursos do sistema, podendo oferecer uma camada de abstração de nível mais baixo para os recursos, como processadores e dispositivos de entrada/saída, que os softwares aplicativos devem controlar para realizar sua função. Com o GNU/Linux não é diferente. O núcleo Linux (Linux Kernel) forma a estrutura do sistema operacional GNU/Linux. Como é de se esperar, o kernel possui diversos parâmetros configurados que definirão as características do seu sistema, controle de dispositivos, módulos, drivers, etc. Por vezes faz-se necessário alterar algum parâmetro do kernel para alguma tarefa ou rotina específica, portanto que tal ganhar tempo e alterar um ou mais parâmetros do kernel on the fly?! O comando sysctl pode ajudar nesta tarefa. Ele ajuda a configurar os parâmetros do kernel em tempo de execução. Para listar os atuais parâmetros de seu kernel digite: [kalib@tuxcaverna ~]$ sysctl -a abi.vsyscall32 = 1 debug.exception-trace = 1 dev.cdrom.autoclose = 1 dev.cdrom.autoeject = 0 dev.cdrom.check_media = 0 dev.cdrom.lock = 1 dev.hpet.max-user-freq = 64 dev.mac_hid.mouse_button2_keycode = 97 dev.mac_hid.mouse_button3_keycode = 100 dev.mac_hid.mouse_button_emulation = 0 dev.scsi.logging_level = 0 fs.aio-max-nr = 65536 fs.aio-nr = 41192 fs.binfmt_misc.status = enabled fs.dentry-state = 177183 161128 45 0 0 0 fs.dir-notify-enable = 1 fs.epoll.max_user_watches = 1209446 fs.file-max = 586836 fs.file-nr = 8992 0 586836 fs.inode-nr = 96800 290 fs.inotify.max_user_watches = 8192 fs.lease-break-time = 45 kernel.sched_cfs_bandwidth_slice_us = 5000 kernel.sched_child_runs_first = 0 kernel.version = #1 SMP PREEMPT Fri Jan 31 10:22:54 CET 2014 kernel.watchdog = 1 kernel.watchdog_thresh = 10 kernel.yama.ptrace_scope = 1 net.core.bpf_jit_enable = 0 net.core.busy_poll = 0 net.ipv4.cipso_cache_bucket_size = 10 net.ipv4.conf.all.accept_local = 0 O retorno deste comando é bastante extenso, portanto colei aqui apenas algumas linhas aleatórias de meu resultado. Para alterar temporariamente um parâmetro, utilize o parâmetro -w do sysctl, indicando a variável que deseja alterar e o novo valor que será utilizado para a mesma. [kalib@tuxcaverna ~]$ sysctl -w {nome-da-variável=valor} No caso acima a(s) alteração(ões) será(ão) perdida(s) após a reinicialização do sistema. Caso deseje realizar alterações permanentes, edite o arquivo /etc/sysctl.conf e em seguida aplique suas modificações com o parâmetro -p do sysctl. [kalib@tuxcaverna ~]$ sysctl -p Desta forma, após a reinicialização suas modificações permanecerão ativas. Happy Hacking! ","date":"2014-02-13","objectID":"/posts/alterando-os-parametros-do-kernel/:0:0","tags":["Linux","Seguranca","Cultura Hacker"],"title":"Alterando Os Parâmetros Do Kernel Em Tempo Real Com O Systcl","uri":"/posts/alterando-os-parametros-do-kernel/"},{"categories":["Impressões"],"content":"Experimente a nova distribuição baseada no Arch Linux voltada para pentesters e demais profissionais de segurança da informação.","date":"2014-01-30","objectID":"/posts/blackarch-linux-uma-nova-distribuicao/","tags":["Linux","Seguranca","Cultura Hacker","Arch Linux"],"title":"Blackarch Linux - Uma Nova Distribuição Para Pentesters","uri":"/posts/blackarch-linux-uma-nova-distribuicao/"},{"categories":["Impressões"],"content":"Experimente a nova distribuição baseada no Arch Linux voltada para pentesters e demais profissionais de segurança da informação. ","date":"2014-01-30","objectID":"/posts/blackarch-linux-uma-nova-distribuicao/:0:0","tags":["Linux","Seguranca","Cultura Hacker","Arch Linux"],"title":"Blackarch Linux - Uma Nova Distribuição Para Pentesters","uri":"/posts/blackarch-linux-uma-nova-distribuicao/"},{"categories":["Impressões"],"content":"Introdução Uma boa novidade para os profissionais de segurança: BlackArch! Para quem, assim como eu, gosta de como as coisas funcionam no Arch Linux essa é uma notícia particularmente boa, visto que o BlackArch não se trata realmente de uma nova distribuição, mas sim de uma extensão para o Arch Linux. Como assim? Bom, você possui duas opções para utilizar o BlackArch, sendo uma delas como uma distribuição completa, através de um Live CD, por exemplo, e a outra como uma extensão (um repositório de pacotes) para o Arch Linux, onde você poderá apenas inserir um repositório em sua já existente distribuição Arch Linux e ter acesso ao conjunto de ferramentas do BlackArch. O BlackArch, atualmente, possui suporte para as arquiteturas i686 e x86_64, com previsão de suporte para ARM em breve (Sim, meu RaspBerry poderá se tornar uma ferramenta para pentests). No mais, o BlackArch hoje possui mais de 600 ferramentas, estando este número crescendo constantemente, e utiliza grupos modulares de pacotes, facilitando a instalação dos mesmos. A ISO Live trás diversos gerenciadores de janelas ou ambientes gráficos, como o dwm, Fluxbox, Openbox, Awesome, Wmii, i3 e Spectrwm. É claro, ele também trás um instalador capaz de instalar a partir do fonte. Dentre as ferramentas existentes estão: 3proxy, 42zip, acccheck, aesfix, against, airflood, airoscript, bluepot, blueprint, braces, bss, bully, cisco-ocs, cmospwd, dbd, dc3dd, deblaze, dhcpig, enumiax, fakedns, … Vocẽ não espera que eu liste todos os mais de 600, certo? Openbox Black OpenBox ","date":"2014-01-30","objectID":"/posts/blackarch-linux-uma-nova-distribuicao/:1:0","tags":["Linux","Seguranca","Cultura Hacker","Arch Linux"],"title":"Blackarch Linux - Uma Nova Distribuição Para Pentesters","uri":"/posts/blackarch-linux-uma-nova-distribuicao/"},{"categories":["Impressões"],"content":"Configurando como um Repositório Não Oficial Se você já possui o Arch Linux instalado e deseja apenas inserir o BlackArch como um repositório em sua distro, execute os seguintes comandos como root, os quais servirão para assinar os pacotes: *(Se você não possui o Arch Linux instalado e/ou simplesmente deseja rodar o Live CD ou instalar o mesmo por completo, seja em uma máquina física ou virtual, siga para a seção Instalando o BlackArch Linux utilizando a Live-ISO. # wget -q https://blackarch.org/keyring/blackarch-keyring.pkg.tar.xz{,.sig} # gpg --keyserver hkp://pgp.mit.edu --recv 4345771566D76038C7FEB43863EC0ADBEA87E4E3 # gpg --keyserver-o no-auto-key-retrieve --with-f blackarch-keyring.pkg.tar.xz.sig # pacman-key --init # rm blackarch-keyring.pkg.tar.xz.sig # pacman --noc -U blackarch-keyring.pkg.tar.xz Em seguida, adicione as seguintes linhas ao seu arquivo /etc/pacman.conf: [blackarch] Server = \u003cmirror_site\u003e/$repo/os/$arch Substitua \u003cmirror_site\u003e por um mirror de sua escolha, preferencialmente um dos mirrors oficiais contidos neste link. Uma vez que você tenha seguido os passos acima, execute: $ sudo pacman -Syyu ","date":"2014-01-30","objectID":"/posts/blackarch-linux-uma-nova-distribuicao/:2:0","tags":["Linux","Seguranca","Cultura Hacker","Arch Linux"],"title":"Blackarch Linux - Uma Nova Distribuição Para Pentesters","uri":"/posts/blackarch-linux-uma-nova-distribuicao/"},{"categories":["Impressões"],"content":"Instalando os pacotes Agora que você já preparou o terreno assinando e configurando o repositório do Black Arch, basta instalar os pacotes em seu Arch Linux. Para listar todas as ferramentas disponíveis, execute: $ sudo pacman -Sgg | grep blackarch | cut -d' ' -f2 | sort -u Para instalar todas as ferramentas, execute: $ sudo pacman -S blackarch Para instalar uma categoria de ferramentas, execute: $ sudo pacman -S blackarch-\u003ccategoria\u003e Para ver as categorias existentes no BlackArch, execute: $ sudo pacman -Sg | grep blackarch ","date":"2014-01-30","objectID":"/posts/blackarch-linux-uma-nova-distribuicao/:3:0","tags":["Linux","Seguranca","Cultura Hacker","Arch Linux"],"title":"Blackarch Linux - Uma Nova Distribuição Para Pentesters","uri":"/posts/blackarch-linux-uma-nova-distribuicao/"},{"categories":["Impressões"],"content":"Instalando o BlackArch Linux utilizando a Live-ISO Antes de mais nada, [baixe a ISO a partir do site oficial](https://blackarch.org/download.html. Em seguida, dê boot na ISO e instale o script de instalação do BlackArch: $ sudo pacman -S blackarch-install-scripts Agora, basta instalar: # blackarch-install Happy Hacking! ","date":"2014-01-30","objectID":"/posts/blackarch-linux-uma-nova-distribuicao/:4:0","tags":["Linux","Seguranca","Cultura Hacker","Arch Linux"],"title":"Blackarch Linux - Uma Nova Distribuição Para Pentesters","uri":"/posts/blackarch-linux-uma-nova-distribuicao/"},{"categories":["Tutoriais"],"content":"Deseja divulgar seu endereço de email em algum local mas tem medo de ser vítima de pishing e passar a receber trocentos emails indesejados por conta disso? Experimente esconder seu endereço de email ao mesmo tempo que o divulga...","date":"2014-01-23","objectID":"/posts/dica-escondendo-seu-endereco-de/","tags":["Linux","Seguranca","Cultura Hacker"],"title":"Dica: Escondendo Seu Endereço De Email Ao Divulgar Seu Endereço De Email","uri":"/posts/dica-escondendo-seu-endereco-de/"},{"categories":["Tutoriais"],"content":"Da mesma forma que alguns animais só conseguem sobreviver utilizando-se de sua capacidade e/ou técnica de camuflar-se, misturando-se assim ao ambiente, para enganar seus predadores naturais, as pessoas do mundo atual praticamente precisam adotar as mesmas técnicas para manter seus endereços de email livres de um turbilhão de emails indesejados com propagandas de viagra, dicas para crescimento peniano, irregularidades em seu CPF, problemas em sua conta bancária, etc, etc. Um dos métodos mais simples e mais utilizado é substituir a @ por alguma outra coisa, como por exemplo: fulanoEMgmail.com fulanoAThotmail.com … Mas existem aqueles que podem preferir levar isto à um nível mais elevado. Que tal fazer de uma forma mais geek? O Linux pode lhe ajudar a fazer isto de forma inusitada, porém eficiente e confiável. Para nosso exemplo, vamos assumir que utilizaremos o email fulano@marcelocavalcante.net. Experimente o seguinte comando: $ echo fulano@marcelocavalcante.net | tr a-z@. n-za-m.@ O retorno será algo como: shynab.zneprybpninypnagr@arg Ilegível, certo? Parabéns, você acaba de “camuflar” ou “esconder” o seu email. Este é o seu endereço de email. Como divulgar ele para que alguém possa entendê-lo? Bom, ao invés de divulgar um endereço de email, você vai divulgar um comando, da seguinte forma: echo shynab.zneprybpninypnagr@arg | tr a-z@. n-za-m.@ Desta forma, quem copiar este comando e o executar em um terminal Linux, terá o seguinte resultado: $ echo shynab.zneprybpninypnagr@arg | tr a-z@. n-za-m.@ fulano@marcelocavalcante.net Desta forma você evita que robôs ou scanners saiam vasculhando seu endereço de email indexando conteúdos aleatórios pela internet e assim, reduzindo as chances de o seu endereço de email cair em listas de SPAM. Legal, certo?! Happy Hacking! ","date":"2014-01-23","objectID":"/posts/dica-escondendo-seu-endereco-de/:0:0","tags":["Linux","Seguranca","Cultura Hacker"],"title":"Dica: Escondendo Seu Endereço De Email Ao Divulgar Seu Endereço De Email","uri":"/posts/dica-escondendo-seu-endereco-de/"},{"categories":["Tutoriais"],"content":"Entediado? Que tal assistir Star Wars pela linha de comando?","date":"2014-01-17","objectID":"/posts/dica-assistir-star-wars-em/","tags":["Linux","Impressões"],"title":"Dica: Assista Star Wars Em Um Console Ou Terminal","uri":"/posts/dica-assistir-star-wars-em/"},{"categories":["Tutoriais"],"content":"Quem disse que o terminal ou linha de comando serve apenas para trabalho e coisas chatas? Está entediado em frente ao seu terminal GNU/Linux? Que tal algo para passar o tempo e, ao mesmo tempo, lhe trazer uma certa nostalgia? Assista Star Wars sem precisar sair de sua linha de comando ou terminal. Tudo o que você precisa digitar é: $ telnet towel.blinkenlights.nl Feito isso, basta apreciar o show… Have fun! ","date":"2014-01-17","objectID":"/posts/dica-assistir-star-wars-em/:0:0","tags":["Linux","Impressões"],"title":"Dica: Assista Star Wars Em Um Console Ou Terminal","uri":"/posts/dica-assistir-star-wars-em/"},{"categories":["Impressões"],"content":"Apostila sobre um dos melhores sistemas open source de firewall disponibilizada gratuitamente, pfSense 2.x!","date":"2014-01-14","objectID":"/posts/dica-apostila-disponibilizada-gratuitamente-pfsense/","tags":["Segurança","Software Livre","Redes","Linux","Free BSD"],"title":"Dica: Apostila Disponibilizada Gratuitamente - Pfsense","uri":"/posts/dica-apostila-disponibilizada-gratuitamente-pfsense/"},{"categories":["Impressões"],"content":"Apostila sobre um dos melhores sistemas open source de firewall disponibilizada gratuitamente, pfSense 2.x! Gostaria de passar adiante a notícia de que o colega Leonardo Damasceno acaba de compartilhar com a comunidade uma apostila de sua autoria sobre o pfSense, de forma a divulgar mais este magnífico sistema, bem como facilitar a vida daqueles que ainda não o dominam. Segue link direto fornecido pelo mesmo para download. A apostila ou livro, como prefira chamar, possui aproximadamente 70 páginas de informações úteis e diretas, sem muitas complicações. Não sabe o que é pfSense? O pfSense é um sistema operacional baseado no Free BSD que pode ser instalado em um computador para servir como um firewall/roteador dedicado em uma rede. Como ferramenta open source, o pfSense tem se destacado nesta função, sendo considerado um dos melhores e mais confiáveis para este trabalho, oferecendo, além de sua estabilidade e confiabilidade, recursos e funções que geralmente são encontrados apenas em firewalls comerciais e caros. Não creio ser necessário lembrar a confiabilidade dos sistemas Free BSD… Embora seja uma versão customizada do Free BSD, não é necessário qualquer conhecimento sobre este sistema para operar o psSense, visto que ele é atualizado e completamente configurado através de uma interface web. Na maioria dos casos o pfSense tem sido aplicado como um firewall de perímetro, roteador, access point wireless, servidor DHCP, servidor DNS e VPN. O mesmo apresenta diversos recursos gráficos para análise de tráfego, pacotes, performance, etc. Além de configurações avançadas para regras de firewall para LAN, WAN e utilizãção de Aliases de forma simples e intuitiva. ","date":"2014-01-14","objectID":"/posts/dica-apostila-disponibilizada-gratuitamente-pfsense/:0:0","tags":["Segurança","Software Livre","Redes","Linux","Free BSD"],"title":"Dica: Apostila Disponibilizada Gratuitamente - Pfsense","uri":"/posts/dica-apostila-disponibilizada-gratuitamente-pfsense/"},{"categories":["Impressões"],"content":"Entenda a importância de bloquear pacotes ou mensagens ICMP indesejadas.","date":"2014-01-10","objectID":"/posts/dica-de-seguranca-previna-ataques/","tags":["Segurança","Software Livre","Redes","Linux"],"title":"Dica De Segurança: Previna Ataques Bloqueando Pacotes Icmp Indesejados","uri":"/posts/dica-de-seguranca-previna-ataques/"},{"categories":["Impressões"],"content":"O protocolo ICMP pode ser utilizado para facilitar diversas rotinas e tarefas importantes de um administrador de redes, tais como na utilização de ferramentas como o ping e o traceroute, mas também pode ser manipulado por pessoas mal intencionadas que podem manipular mensagens ou pacotes ICMP para mapear sua rede. É comum ver administradores de rede se preocupando e fazendo um ótimo trabalho em termos de filtrar o tráfego TCP e/ou UDP, porém quase sempre esquecem de dar a mesma atenção ao tráfego ICMP, sendo este tão crítico quanto os dois anteriores. Uma vez que este protocolo pode ser utilizado para mapear e realizar ataques em sua rede, ele não pode simplesmente ser deixado de lado. ICMP, sigla para Internet Control Message Protocol, é um protocolo integrante do Protocolo IP utilizado para fornecer relatórios de erros à fonte original. Seu tráfego é, basicamente, baseado em mensagens trocadas entre hots, gateways, etc., cujo intuito é, principalmente, reportar erros, como por exemplo um pacote IP que não consegue chegar ao seu destino. Por padrão, alguns servidores e firewalls bloqueiam as respostas ICMP como medida de segurança, tentando assim bloquear os ataques que consistem na sobrecarga da memória, enviando dados (em ping) até o sistema não ter a capacidade de administrar suas próprias funções. Bom, ao mesmo tempo em que é um mecanismo de defesa interessante, este bloqueio total acaba comprometendo e atrapalhando diversas atividades do administrador de redes, não sendo portanto a estratégia mais inteligente a ser adotada. Ao invés de bloquear o ICMP por completo, é mais interessante conhecer o que é bom e o que é ruim em termos de mensagens ICMP, de forma que sejam realizados filtros corretos. A importância desta gangorra é não permitir que o lado ruim do ICMP, como por exemplo ICMP Smurf, Ping of death, ataques com ICMP flood ou ICMP nuke, prejudiquem o administrador de redes que pode tirar proveito de boas ferramentas que se utilizam do ICMP, como o Ping e o Traceroute. A estratégia mais simples, portanto, é utilizar uma regra geral contendo exceções. Bloquear todos os tipos de tráfego ICMP; Permitir ping – CMP Echo-Request outbound (saída) e Echo-Reply inbound (entrada); Permitir traceroute – TTL-Exceeded e Port-Unreachable inbound (entrada); Permitir path MTU – ICMP Fragmentation-DF-Set inbound (entrada). É claro que este é apenas um exemplo, visto que você poderá permitir mais ou menos, de acordo com a sua necessidade. Não deixemos pobre a nossa configuração, facilitando as coisas para ataques quando isto pode ser facilmente bloqueado. Happy Hacking! ","date":"2014-01-10","objectID":"/posts/dica-de-seguranca-previna-ataques/:0:0","tags":["Segurança","Software Livre","Redes","Linux"],"title":"Dica De Segurança: Previna Ataques Bloqueando Pacotes Icmp Indesejados","uri":"/posts/dica-de-seguranca-previna-ataques/"},{"categories":["Tutoriais"],"content":"Entenda a importância de criptografar a partição de swap e como fazê-lo com o ecryptfs.","date":"2014-01-03","objectID":"/posts/criptografando-sua-particao-swap-com/","tags":["Seguranç","Software Livre","Redes","Linux","Arch Linux"],"title":"Criptografando Sua Partição Swap Com O Ecryptfs","uri":"/posts/criptografando-sua-particao-swap-com/"},{"categories":["Tutoriais"],"content":"Criptografia (Do grego kryptós, “escondido”, e gráphein, “escrita”) nada mais é do que o estudo e aplicação de técnicas com o intuito de ocultar informações, transformando a informação original em algo ilegível, exceto para seu destinatário final, o qual possui a chave ou método que será utilizado para tornar a informação legível novamente. Apesar de muitas pessoas acharem que criptografia é algo novo, o uso de mensagens cifradas é bastante antigo. Em tempos passados a cifragem de mensagens era utilizada, principalmente em assuntos de guerra. De acordo com estudos históricos, o primeiro uso documentado da criptografia foi em torno de 1900 a.c., no Egito, quando um escriba usou hieróglifos fora do padrão numa inscrição. Ao que interessa… Muitas pessoas, por alguma razão (como por exemplo performance ou não gostar da ideia de digitar gigantescas senhas duranto o boot), acabam não utilizando uma LVM encriptada. Para estas pessoas existe a opção de criptografar arquivos e diretórios após a instalação do SO através de softwares como o eCryptfs. Mas, além disto, existe um outro aspecto interessante e importante que, por muitas vezes (para não dizer quase sempre) é esquecido: criptografar a swap. Se você é usuário GNU/Linux, muito provavelmente já sabe o que é Swap. Ela é especialmente utilizada em computadores mais antigos e que possuem pouca memória RAM. Nestes casos, um espaço do disco rígido é utilizado como swap para servir de auxílio à memória RAM em diferentes tarefas quando a mesma não for o suficiente para realizar aquelas tarefas. Por questões óbvias, a swap não é tão rápida quanto a memória principal e, além disso, a swap também possui seus pontos críticos em relação a segurança. A questão mais crítica da swap em termos de segurança é o fato de ela, conforme já dito, não estar localizada em sua RAM, mas sim em seu disco rígido, escrevendo informações nesta partição, deixando assim rastros de suas atividades no próprio disco rígido. Por exemplo, caso você utilize softwares de criptografia em seu computador, mas não possua sua swap criptografada, você corre o risco de ter as senhas de chaves que você digita salvas em sua swap (disco rígido). Algo não desejado, certo? Para criptografar a sua swap, primeiramente instale os pacotes necessários: No Arch Linux [kalib@tuxcaverna ~]$ sudo pacman -S ecryptfs-utils cryptsetup No Debian ou derivados [kalib@tuxcaverna ~]$ sudo apt-get install ecryptfs-utils cryptsetup Em seguida, precisamos literalmente criptografar a swap utilizando o seguinte comando: [kalib@tuxcaverna ~]$ sudo ecryptfs-setup-swap Neste momento, sua partição swap será desmontada, encriptada e montada novamente. Para certificar-se de que o procedimento funcionou, digite o seguinte comando: [kalib@tuxcaverna ~]$ sudo blkid | grep swap Você deverá receber as informações sobre sua partição de swap, inclusive o indicativo cryptswap. Como medida preventiva contra erros durante o boot, edite o arquivo /etc/fstab, retirando a entrada da swap não encriptada, deixando em seu lugar a entrada para a swap encriptada. Happy Hacking! ","date":"2014-01-03","objectID":"/posts/criptografando-sua-particao-swap-com/:0:0","tags":["Seguranç","Software Livre","Redes","Linux","Arch Linux"],"title":"Criptografando Sua Partição Swap Com O Ecryptfs","uri":"/posts/criptografando-sua-particao-swap-com/"},{"categories":["Tutoriais"],"content":"Entenda um pouco sobre a rede Tor e veja como utilizá-la","date":"2013-12-30","objectID":"/posts/navegacao-anonima-atraves-da-rede/","tags":["Segurança","Software Livre","Redes","Impressões"],"title":"Navegação Anônima Através Da Rede Tor","uri":"/posts/navegacao-anonima-atraves-da-rede/"},{"categories":["Tutoriais"],"content":"O ano de 2013 foi marcado por diversos acontecimentos de grande repercussão e, sem sombra de dúvidas, um deles foi o escândalo causado pelo vazamento de dados que provaram que algumas instituições, dentre elas a NSA (Agência de Segurança dos Estados Unidos), estavam espionando diversas entidades, empresas e até mesmo pessoas físicas nas mais diversas regiões do globo. Escândalos a parte, estas denúncias acabaram despertando um pouco mais (uma pena que não tenha sido muito mais) nas pessoas o interesse em preservar sua privacidade. ","date":"2013-12-30","objectID":"/posts/navegacao-anonima-atraves-da-rede/:0:0","tags":["Segurança","Software Livre","Redes","Impressões"],"title":"Navegação Anônima Através Da Rede Tor","uri":"/posts/navegacao-anonima-atraves-da-rede/"},{"categories":["Tutoriais"],"content":"Tor Sendo assim, nada mais justo que dedicar o último post do ano ao Tor. Ainda vivemos em um mundo (principalmente nosso querido Brasil) onde as pessoas parecem simplesmente não se importar com o quesito privacidade. Não é difícil encontrar praticamente todas as informações sobre a maioria das pessoas pois elas mesmas fazem questão de expor isto aos sete ventos através das redes e mídias sociais. Divulgam dezenas de fotos de sua pessoa, bem como de seus parentes, informam dados pessoais, rotinas, locais que frequentam, horários, local de trabalho, amizades, áreas de interesse, etc. A lista é longa… Felizmente algumas pessoas já começaram a atentar para a importância de manter sua privacidade e, para tal, passaram a buscar maneiras alternativas para driblar estas espionagens e outras formas de golpes tão comuns hoje em dia, mantendo assim o seu anonimato durante sua navegação. A rede Tor, ou The Onion Router, surgiu basicamente com este propósito. Tor é uma rede de computadores distribuída cuja finalidade primária é manter o anonimato na internet. Seu objetivo básico é garantir a privacidade e anonimato do usuário que está navegando através desta rede. Apesar de o uso do Tor ser simplificado em sistemas GNU/Linux, visto que a maioria das distribuições disponibilizam o pacote do Tor, também existem versões para sistemas Windows e Mac OS. Trata-se de uma rede de túneis criptografados, onde os roteadores da rede são computadores de usuários comuns que estão rodando um programa e possuem acesso à internet. Basicamente, o usuário instala um programa, tor-cliente, em seu computador e este funcionará como um proxy para o mesmo. Os demais programas que o usuário utiliza para navegar na internet (navegador, emule, etc.) deverão ser configurados para navegar através deste proxy. A partir daí, quando o usuário digitar em seu navegador o endereço destino, https://www.google.com por exemplo, ao invés de a sua requisição passar por roteadores convencionais para atingir o destino, ele passará por túneis criptografados da rede Tor, para então chegar ao seu destino. Nestes túneis a sua requisição e informações passam por vários nós da rede Tor. Um exemplo prático do anonimato provido pelo Tor é a verificação do seu próprio IP. Caso deseje realizar o teste, experimente acessar o endereço https://www.meuip.com.br antes de instalar e configurar o Tor em sua máquina. Este site lhe informará o seu atual endereço IP, no caso o endereço será o do seu roteador de acesso à rede pública. Em seguida, tente acessar novamente o mesmo endereço após ter instalado e configurado o Tor. Você perceberá que ele não retornará o seu endereço IP, mas sim um endereço IP qualquer de um nó da rede Tor. Ou seja, isto atrapalha a vida de quem quer que deseje rastrear a sua máquina a partir de um endereço que você tenha acessado ou mesmo de um email que você tenha enviado. ","date":"2013-12-30","objectID":"/posts/navegacao-anonima-atraves-da-rede/:1:0","tags":["Segurança","Software Livre","Redes","Impressões"],"title":"Navegação Anônima Através Da Rede Tor","uri":"/posts/navegacao-anonima-atraves-da-rede/"},{"categories":["Tutoriais"],"content":"Instalação do Tor no Arch Linux Conforme informei no início, o Tor está disponível para praticamente todos os sistemas operacionais, mas vou focar a explicação de instalação para a minha distribuição, Arch Linux, embora o processo seja bastante similar para as demais distribuições GNU/Linux. Instale o Tor: [kalib@tuxcaverna ~]$ sudo pacman -S tor Como um opcional, instale também o frontend ou GUI, o qual é desenvolvido em QT, vidalia. O vidalia, além de controlar o processo Tor, permite-lhe ver e configurar o status do Tor, monitorar o uso de banda e ver, filtrar ou realizar pesquisas em mensagens de log, etc. [kalib@tuxcaverna ~]$ sudo pacman -S vidalia Inicie/Habilite o serviço utilizando o systemd. A configuração padrão do Tor deverá funcionar para a maioria dos usuários, mas caso deseje alterar algo, verifique a documentação do Tor e altere as configurações em /etc/tor/torrc. Para utilizar um programa através da rede Tor, configure-o para utilizar o endereço 127.0.0.1 ou localhost como endereço proxy SOCKS5 através da porta 9050 (porta padrão do Tor) ou 9051 (porta padrão utilizada quando se configura com o vidalia). A rede Tor possui uma espécie de domínio próprio com terminação .onion, acessível apenas através da própria rede Tor. Páginas com este domínio são parte da chamada Deep Web, mas isto será assunto para um outro post por ser algo polêmico e extenso. Desejo a todos um feliz ano novo com liberdade, privacidade e anonimato, quando necessário! Happy Hacking! ","date":"2013-12-30","objectID":"/posts/navegacao-anonima-atraves-da-rede/:2:0","tags":["Segurança","Software Livre","Redes","Impressões"],"title":"Navegação Anônima Através Da Rede Tor","uri":"/posts/navegacao-anonima-atraves-da-rede/"},{"categories":["Tutoriais"],"content":"Veja como é fácil descobrir senhas salvas pelo usuário no Firefox.","date":"2013-12-27","objectID":"/posts/vulnerabilidade-no-firefox-descobrindo-senhas/","tags":["Firefox","Software Livre","Segurança"],"title":"Vulnerabilidade No Firefox: Descobrindo Senhas Salvas","uri":"/posts/vulnerabilidade-no-firefox-descobrindo-senhas/"},{"categories":["Tutoriais"],"content":"Uma coisa é certa… usuários teimam em salvar senhas em navegadores para facilitar suas vidas durante a navegação na internet. Seja em emails, redes sociais, serviços online ou qualquer outra coisa, a opção Salvar sua senha parece possuir um enorme magnetismo ou um centro gravitacional extremamente denso a ponto de atrair o usuário para tal. Será que as pessoas não entendem o quão perigosa é a ideia de salvar sua senha onde quer que seja? É, praticamente, o mesmo risco assumido por quem anota suas senhas em post-its e os colam em seu monitor ou mesa. Hoje um colega me procurou para saber como recuperar uma senha que ele não lembrava mais. Já conhecendo o histórico do mesmo eu tinha certeza que ele tinha salvo esta senha no navegador. Então lhe mostrei como ele, ou qualquer outra pessoa, conseguiria facilmente descobrir todas as senhas salvas em seu navegador Firefox. A experiência foi boa por dois motivos: Ele conseguiu descobrir sua senha; (a qual ele provavelmente não esqueceria se tivesse o costume de digitá-la sempre que necessário ao invés de salá-la no navegador) Ele entendeu o risco que ele corre com esta prática absurda; Vejamos o quão simples (para não dizer estúpido) é o procedimento para descobrir as senhas salvas pelo usuário no navegador Firefox. Clique no menu Firefox que se encontra no canto superior esquerdo do navegador; Selecione a opção Preferências no menu e em seguida, novamente, Preferências; Na aba Segurança, clique no botão Senhas Salvas; Repare que na janela que será apresentada você terá uma lista de sites/serviços e usuários que deixaram suas senhas salvas. Nesta janela, clique no botão Mostrar Senhas; Agora você poderá ver as senhas salvas em texto plano, limpo e claro. Lição aprendida: Não salve suas senhas! ","date":"2013-12-27","objectID":"/posts/vulnerabilidade-no-firefox-descobrindo-senhas/:0:0","tags":["Firefox","Software Livre","Segurança"],"title":"Vulnerabilidade No Firefox: Descobrindo Senhas Salvas","uri":"/posts/vulnerabilidade-no-firefox-descobrindo-senhas/"},{"categories":["Tutoriais"],"content":"Utilizando o comando strace para realização de análise e troubleshooting em tempo de execução","date":"2013-12-19","objectID":"/posts/dica-rapida-linux-troubleshooting-em/","tags":["Linux","Software Livre","Segurança"],"title":"Dica Rápida Linux: Troubleshooting Em Tempo De Execução Com Strace","uri":"/posts/dica-rapida-linux-troubleshooting-em/"},{"categories":["Tutoriais"],"content":"Se algum dia você já precisou realizar uma análise para troubleshoot de algum comando em tempo de execução e não soube como fazê-lo, seus problemas acabaram. O strace faz justamente isso. Já trabalhei em servidores de clientes comprometidos pós-invasão cujos comandos padrões Unix haviam sido substituídos por comandos similares (ao menos em nome) que realizam outras tarefas sem o conhecimento dos administradores dos mesmos. O strace serve justamente para estes, bem como outros, casos. Ele lhe indica exatamente tudo o que acontece por baixo dos panos em seu sistema. Vejamos um exemplo. [kalib@tuxcaverna ~]$ date Qui Dez 19 08:41:55 BRT 2013 Agora vejamos a diferença com o uso do strace. [kalib@tuxcaverna ~]$ strace date execve(\"/usr/bin/date\", [\"date\"], [/* 59 vars */]) = 0 brk(0) = 0x21df000 access(\"/etc/ld.so.preload\", R_OK) = -1 ENOENT (No such file or directory) open(\"/etc/ld.so.cache\", O_RDONLY|O_CLOEXEC) = 3 fstat(3, {st_mode=S_IFREG|0644, st_size=274630, ...}) = 0 mmap(NULL, 274630, PROT_READ, MAP_PRIVATE, 3, 0) = 0x7fe0d3f3d000 close(3) = 0 open(\"/usr/lib/libc.so.6\", O_RDONLY|O_CLOEXEC) = 3 read(3, \"\\177ELF\\2\\1\\1\\3\\0\\0\\0\\0\\0\\0\\0\\0\\3\\0\u003e\\0\\1\\0\\0\\0\\20\\34\\2\\0\\0\\0\\0\\0\"..., 832) = 832 fstat(3, {st_mode=S_IFREG|0755, st_size=2031229, ...}) = 0 mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fe0d3f3c000 mmap(NULL, 3840528, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x7fe0d39b8000 mprotect(0x7fe0d3b58000, 2097152, PROT_NONE) = 0 mmap(0x7fe0d3d58000, 24576, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x1a0000) = 0x7fe0d3d58000 mmap(0x7fe0d3d5e000, 14864, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_ANONYMOUS, -1, 0) = 0x7fe0d3d5e000 close(3) = 0 mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fe0d3f3b000 mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fe0d3f3a000 arch_prctl(ARCH_SET_FS, 0x7fe0d3f3b700) = 0 mprotect(0x7fe0d3d58000, 16384, PROT_READ) = 0 mprotect(0x60d000, 4096, PROT_READ) = 0 mprotect(0x7fe0d3f81000, 4096, PROT_READ) = 0 munmap(0x7fe0d3f3d000, 274630) = 0 brk(0) = 0x21df000 brk(0x2200000) = 0x2200000 open(\"/usr/lib/locale/locale-archive\", O_RDONLY|O_CLOEXEC) = 3 fstat(3, {st_mode=S_IFREG|0644, st_size=1863120, ...}) = 0 mmap(NULL, 1863120, PROT_READ, MAP_PRIVATE, 3, 0) = 0x7fe0d37f1000 close(3) = 0 open(\"/etc/localtime\", O_RDONLY|O_CLOEXEC) = 3 fstat(3, {st_mode=S_IFREG|0644, st_size=714, ...}) = 0 fstat(3, {st_mode=S_IFREG|0644, st_size=714, ...}) = 0 mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fe0d3f80000 read(3, \"TZif2\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\3\\0\\0\\0\\3\\0\\0\\0\\0\"..., 4096) = 714 lseek(3, -438, SEEK_CUR) = 276 read(3, \"TZif2\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\3\\0\\0\\0\\3\\0\\0\\0\\0\"..., 4096) = 438 close(3) = 0 munmap(0x7fe0d3f80000, 4096) = 0 fstat(1, {st_mode=S_IFCHR|0600, st_rdev=makedev(136, 2), ...}) = 0 mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fe0d3f80000 write(1, \"Qui Dez 19 08:42:47 BRT 2013\\n\", 29Qui Dez 19 08:42:47 BRT 2013 ) = 29 close(1) = 0 munmap(0x7fe0d3f80000, 4096) = 0 close(2) = 0 exit_group(0) = ? +++ exited with 0 +++ O strace não é instalado por padrão em todas as distribuições, portanto é possível que você precise instalá-lo com o seu gerenciador de pacotes. Além do uso regular, ele possui diversos parâmetros que podem melhorar ou filtrar o seu uso. Você pode verificar a lista de parâmetros em seu manual de uso: [kalib@tuxcaverna ~]$ man strace","date":"2013-12-19","objectID":"/posts/dica-rapida-linux-troubleshooting-em/:0:0","tags":["Linux","Software Livre","Segurança"],"title":"Dica Rápida Linux: Troubleshooting Em Tempo De Execução Com Strace","uri":"/posts/dica-rapida-linux-troubleshooting-em/"},{"categories":["Aleatórios"],"content":"Tardou (alguns anos) mas saiu.. Sobre mim criado.","date":"2013-12-16","objectID":"/posts/sobre-mim-dot-dot-dot/","tags":["Impressões","Linux","Software Livre","Segurança","Literatura"],"title":"Sobre Mim: Tarda Mas Não Falha","uri":"/posts/sobre-mim-dot-dot-dot/"},{"categories":["Aleatórios"],"content":"Tarda, mas não falha… Reza o antigo ditado. Da mesma forma, digo-lhes que tardou, mas não falhou. Confesso que nunca parei para elaborar a página “Sobre mim” deste blog. O link existia no topo, mas sempre esteve “Em construção”. Preguiça? Falta de interesse? Esquecimento? Acho que um pouco de cada. Hoje fui surpreendido por uma pessoa que acabou caindo no blog e em seguida me questionou sobre o porque de o blog já existir a tanto tempo e até hoje a página “Sobre mim” continuar contendo apenas as palavras “Em construção”. Isto me fez tomar vergonha na cara.. e hoje inseri conteúdo nesta página. Agora sim… ;] ","date":"2013-12-16","objectID":"/posts/sobre-mim-dot-dot-dot/:0:0","tags":["Impressões","Linux","Software Livre","Segurança","Literatura"],"title":"Sobre Mim: Tarda Mas Não Falha","uri":"/posts/sobre-mim-dot-dot-dot/"},{"categories":["Tutoriais"],"content":"Utilizando o comando pv para dar o efeito de texto sendo digitado, assim como nos filmes e séries de TV.","date":"2013-12-05","objectID":"/posts/dica-rapida-linux-efeito-de/","tags":["Linux","Software Livre"],"title":"Dica Rápida Linux: Efeito De Texto Sendo Digitado O Pv Resolve","uri":"/posts/dica-rapida-linux-efeito-de/"},{"categories":["Tutoriais"],"content":"Certamente você já cansou de ver em filmes e/ou séries de TV cenas nas quais um monitor apresenta um texto que, aparentemente, está sendo digitado em tempo real. É claro que eles não possuem uma pessoa digitando aquele texto ou série de comandos no momento da gravação. Então, que tal aprender uma forma de fazer isto no Linux? O comando pv realiza perfeitamente este trabalho, podendo inclusive interagir com outros aplicativos e comandos. Mão na massa… Antes de mais nada você precisará instalar o pv em sua distribuição. No Arch Linux, eu utilizo o pacman da forma convencional: [kalib@tuxcaverna ~]$ sudo pacman -S pv O pv está disponível nos repositórios de praticamente todas as distribuições, portanto utilize o gerenciador de pacotes de sua preferência para instalá-lo. A utilização é simples, bastando que você utilize algum comando que, de alguma forma, exponha algum texto na tela e em seguida redirecione esta saída para o pv. O pv possui diversos parâmetros, mas eu gosto particularmente de utilizar -qL, onde o q significa “quiet” e o L significa latência, em seguida insiro um valor para a latência. Vamos ao exemplo: [kalib@tuxcaverna ~]$ echo \"Primeiro teste com pv\" | pv -qL 20 Primeiro teste com pv Se você digitar o mesmo comando, verá que ele irá escrever o texto na tela de forma “automática”: “Primeiro teste com pv”. É claro, em uma gravação de Hollywood a linha na qual o comando foi passado não deveria aparecer, no caso: [kalib@tuxcaverna ~]$ echo “Primeiro teste com pv” | pv -qL 20. Que tal inserir um clear antes de nosso comando para limpar a tela antes da execução desejada? [kalib@tuxcaverna ~]$ clear \u0026\u0026 echo \"Primeiro teste com pv\" | pv -qL 20 Perceba que desta vez o comando digitado não aparece na tela. A única informação que será exibida será Primeiro teste com pv. Diminuindo ou aumentando o valor da latência você diminuirá ou aumentará a velocidade de digitação do texto que você escolheu. Como informei no início, você pode unir o pv com outros programas ou comandos. Que tal fazer com que um texto um pouco maior seja exibido? Para este teste, eu criei um arquivo texto chamado testepv, conforme pode ser visto abaixo: [kalib@tuxcaverna ~]$ cat testepv Não obstante, a contínua expansão de nossa atividade oferece uma interessante oportunidade para verificação de todos os recursos funcionais envolvidos. A prática cotidiana prova que o desenvolvimento contínuo de distintas formas de atuação nos obriga à análise de alternativas às soluções ortodoxas. Por conseguinte, a competitividade nas transações comerciais estende o alcance e a importância da gestão inovadora da qual fazemos parte. Neste caso, o texto pode ser digitado automaticamente com o pv, da seguinte forma: [kalib@tuxcaverna ~]$ clear \u0026\u0026 cat testepv | pv -qL 20 Legal? Que tal utilizarmos algo ainda melhor? Já ouviu falar no figlet? É outro comando/aplicativo Linux que muitas pessoas desconhecem. Comece instalando-o em seu sistema, caso você já não o possua. O figlet desenha o seu texto de uma forma um pouco mais enfeitada, se comparado ao puro cat ou echo. Exemplo: [kalib@tuxcaverna ~]$ figlet \"Teste do Figlet\" _____ _ _ _____ _ _ _ |_ _|__ ___| |_ ___ __| | ___ | ___(_) __ _| | ___| |_ | |/ _ \\/ __| __/ _ \\ / _` |/ _ \\ | |_ | |/ _` | |/ _ \\ __| | | __/\\__ \\ || __/ | (_| | (_) | | _| | | (_| | | __/ |_ |_|\\___||___/\\__\\___| \\__,_|\\___/ |_| |_|\\__, |_|\\___|\\__| |___/ Nesse caso, vamos fazer com que o efeito figlet também pareça estar sendo digitado automaticamente e em tempo real: [kalib@tuxcaverna ~]$ clear \u0026\u0026 figlet \"Teste do Figlet\" | pv -qL 30 Resultado interessante, certo? Da mesma forma, o pv pode ser utilizado com diversos outros aplicativos que trazem alguma saída no terminal, como o cowsay e muitos outros. A sua criatividade é o limite. Have fun! ,,/_ ","date":"2013-12-05","objectID":"/posts/dica-rapida-linux-efeito-de/:0:0","tags":["Linux","Software Livre"],"title":"Dica Rápida Linux: Efeito De Texto Sendo Digitado O Pv Resolve","uri":"/posts/dica-rapida-linux-efeito-de/"},{"categories":["Impressões"],"content":"As treze relíquias é um livro cativante e envolvente. Um enredo repleto de misticismo e ocultismo envolve os personagens principais que tentam impedir que um ocultista liberte diversos demônios no planeta Terra.","date":"2013-11-25","objectID":"/posts/recomendacao-bibliografica-as-treze-reliquias/","tags":["Literatura","Cultura"],"title":"Recomendação Bibliográfica: As Treze Relíquias","uri":"/posts/recomendacao-bibliografica-as-treze-reliquias/"},{"categories":["Impressões"],"content":"Sem sombra de dúvidas o livro superou minhas expectativas. Apesar de a sinopse passar a impressão de que se trata de mais um livro com temática sobrenatural voltado a um público mais jovem, a leitura revela o oposto. Certamente um livro que pode agradar diversas faixas etárias, trazendo foco no ocultismo, antigas religiões, artefatos mágicos, sexo e assassinatos com incrível crueldade, tudo isto em uma trama muito bem elaborada e descrita. Por se tratar de assuntos que gosto, o livro prendeu minha atenção desde o início, visto que os autores souberam mesclar bem os diferentes temas em uma história conexa e personagens interessantes. O fato de ser uma leitura bastante paralela, visto que acontecem muitas coisas ao mesmo tempo, torna o enredo mais atraente ainda, além de tornar a leitura mais rápida. Sinopse retirada do site da Livraria Saraiva: Há mais de sete décadas treze crianças foram designadas para cuidar de artefatos antigos, dotados com um poder primitivo e letal. As relíquias, como foram chamadas, deveriam ser mantidas por seus guardiões em total segurança e afastadas umas das outras. Entretanto, agora um homem sinistro e sua amante estão atrás delas, roubando cada peça e eliminando seus protetores, deixando um rastro de crimes violentos. Aparentemente por acaso, a jovem Sarah Miller se envolverá nessa trama perigosa e terá que correr contra o tempo para elucidar os enigmas que rondam sua nova vida. Serão os guardiões seres de outro mundo? Qual será o segredo das relíquias milenares? Por que justamente Sarah foi atraída para esse jogo mortal? Uma história inquietante, povoada de lendas que até hoje rondam nosso imaginário, As treze relíquias mostra que há forças que nunca devem ser despertadas. Boa leitura! ","date":"2013-11-25","objectID":"/posts/recomendacao-bibliografica-as-treze-reliquias/:0:0","tags":["Literatura","Cultura"],"title":"Recomendação Bibliográfica: As Treze Relíquias","uri":"/posts/recomendacao-bibliografica-as-treze-reliquias/"},{"categories":["Tutoriais"],"content":"Consiga informações mais detalhadas sobre um arquivo pela linha de comando através da ferramenta stat","date":"2013-11-22","objectID":"/posts/dica-rapida-linux-informacoes-sobre/","tags":["Linux","Software Livre"],"title":"Dica Rápida Linux: Informações Sobre Arquivos Com O Comando Stat","uri":"/posts/dica-rapida-linux-informacoes-sobre/"},{"categories":["Tutoriais"],"content":"Que os sistemas GNU/Linux possuem uma infinidade de comandos todo mundo sabe, o que nem todos conhecem, na verdade, são alguns comandos simples porém eficientes e importantes. Um deles é justamente o stat. Quando se está em frente ao terminal de um servidor que não possui interface gráfica, tudo o que está a nossa disposição são as ferramentas de linha de comando, portanto é bom conhecer uma boa variedade das mesmas, desde ferramentas para tarefas complexas até ferramentas para as atividades mais simples e banais. A dica que deixo hoje é uma ferramenta que muitas pessoas desconhecem: stat O stat serve para apresentar as informações de status de um arquivo ou sistema de arquivos. Ele apresenta uma série de informações sobre o arquivo que você informar como argumento. Dentre as informações estão o Tamanho, Blocos, Permissões de Acesso, Data e Hora de último acesso, Data e Hora de última modificação, etc. O uso é simples, bastando digitar: stat \u003ccaminho_do_arquivo_ou_sistema_de_arquivos\u003e. [kalib@tuxcaverna ~]$ stat testdisk.log File: “testdisk.log” Size: 102478 Blocks: 208 IO Block: 4096 arquivo comum Device: 804h/2052d Inode: 27001862 Links: 1 Access: (0644/-rw-r--r--) Uid: ( 1000/ kalib) Gid: ( 100/ users) Access: 2013-11-11 11:31:34.360892496 -0300 Modify: 2011-05-10 09:48:46.000000000 -0300 Change: 2011-05-11 15:01:29.019407886 -0300 Birth: - ou [kalib@tuxcaverna ~]$ stat /dev/sda1 File: “/dev/sda1” Size: 0 Blocks: 0 IO Block: 4096 arquivo especial de bloco Device: 5h/5d Inode: 7253 Links: 1 Device type: 8,1 Access: (0660/brw-rw----) Uid: ( 0/ root) Gid: ( 6/ disk) Access: 2013-11-22 08:01:39.246618958 -0300 Modify: 2013-11-22 08:01:39.246618958 -0300 Change: 2013-11-22 08:01:39.246618958 -0300 Birth: - Have fun! ","date":"2013-11-22","objectID":"/posts/dica-rapida-linux-informacoes-sobre/:0:0","tags":["Linux","Software Livre"],"title":"Dica Rápida Linux: Informações Sobre Arquivos Com O Comando Stat","uri":"/posts/dica-rapida-linux-informacoes-sobre/"},{"categories":["Tutoriais"],"content":"Saiba como digitar comandos no Linux sem que eles fiquem registrados no history ou histórico de comandos do sistema.","date":"2013-11-07","objectID":"/posts/dica-rapida-linux-como-nao/","tags":["Linux","Software Livre","Segurança"],"title":"Dica Rápida Linux: Como Não Deixar Rastros No History","uri":"/posts/dica-rapida-linux-como-nao/"},{"categories":["Tutoriais"],"content":"Shhhhhhh…. Que tal digitar seus comandos em uma máquina Linux sem que os mesmos sejam registrados no history do sistema? O history é responsável por armazenar um histórico dos últimos comandos digitados no sistema. Por exemplo: [kalib@tuxcaverna ~]$ history 1 ls 2 mkdir pc 3 cd pc/ 4 ls 5 mkdir pc2 6 ls 7 touch ps2/teste 8 ls 9 touch / ... ... 496 route 497 ifconfig 498 cat teste 499 ls 500 history Como podemos ver, o history me retornou um histórico dos meus últimos 500 comandos, incluindo o próprio comando history, que acabei de digitar. Vejamos o registro de novos comandos: [kalib@tuxcaverna ~]$ echo \"Teste\" Teste [kalib@tuxcaverna ~]$ echo \"Registra isso history\" Registra isso history [kalib@tuxcaverna ~]$ history ... ... 501 echo \"Teste\" 502 echo \"Registra isso history\" 503 history Então, como não deixar registros no history? Utilizaremos os comandos cat e bash para isto: [kalib@tuxcaverna ~]$ cat | bash pwd /home/kalib df -h Sist. Arq. Tam. Usado Disp. Uso% Montado em /dev/sda3 30G 19G 9,3G 67% / dev 2,9G 0 2,9G 0% /dev run 2,9G 860K 2,9G 1% /run tmpfs 2,9G 0 2,9G 0% /dev/shm tmpfs 2,9G 0 2,9G 0% /sys/fs/cgroup tmpfs 2,9G 108K 2,9G 1% /tmp /dev/sda1 99M 23M 69M 25% /boot /dev/sda4 427G 305G 101G 76% /home cd testes pwd /home/kalib/testes Simples, não? Happy hacking… ","date":"2013-11-07","objectID":"/posts/dica-rapida-linux-como-nao/:0:0","tags":["Linux","Software Livre","Segurança"],"title":"Dica Rápida Linux: Como Não Deixar Rastros No History","uri":"/posts/dica-rapida-linux-como-nao/"},{"categories":["Tutoriais"],"content":"Realizando uma auditoria de segurança simples em sistemas Unix like com o Lynis.","date":"2013-10-30","objectID":"/posts/lynis-seguranca-e-auditoria-de/","tags":["Linux","Software Livre","Segurança"],"title":"Lynis: Segurança E Auditoria De Sistemas Linux","uri":"/posts/lynis-seguranca-e-auditoria-de/"},{"categories":["Tutoriais"],"content":"Procurando uma ferramenta de uso simples e rápido que seja capaz de realizar uma auditoria em sistemas Unix like? Talvez o Lynis seja exatamente o que você procura. O Lynis é uma ferramenta para (especialistas) Unix com foco em segurança e auditoria, porque não dizer hardening, de sistemas. Ele escaneia o sistema e vários softwares disponíveis no mesmo com o fim de detectar vulnerabilidades. Além de informações relacionadas a segurança, ele também buscará diversas informações sobre o sistema, pacotes instalados e erros de configuração diversos. Este software ainda é útil e utilizado por outros softwares para ajudar em auditorias automatizadas, gerenciamento de patches de sistemas e escaneamento por vulnerabilidades e malwares. O público alvo do mesmo é composto por especialistas em segurança, pentesters, auditores de sistemas, administradores de redes/sistemas, etc. Dentre suas verificações estão a avaliação dos métodos de autenticação disponíveis, certificados SSL expirados, softwares desatualizados, contas de usuários sem senhas, permissões incorretas em arquivos, erros de configuração, auditoria de firewall, etc. Instalação: No Arch Linux, o pacote se encontra disponível no AUR., portanto o processo de instalação consiste nos seguintes passos: 1. Download do Tarball disponibilizado no AUR. 2. Descompactação do tarball: $ tar -xvzf lynis.tar.gz 3. Entrar no diretório lynis que foi criado e em seguida iniciar a compilação/criação do pacote em si: $ cd lynis $ makepkg 4. Instalação do pacote que foi criado (Apenas este passo com usuário root ou utilizando sudo): # pacman -U lynis-1.3.3-1-any.pkg.tar.xz Caso você utilize o yaourt ou algum outro gerenciador de pacotes do Arch Linux que possua acesso direto aos pacotes do AUR, pode utilizá-los ao invés de utilizar os passos acima: $ yaourt -S lynis Happy Hacking! ","date":"2013-10-30","objectID":"/posts/lynis-seguranca-e-auditoria-de/:0:0","tags":["Linux","Software Livre","Segurança"],"title":"Lynis: Segurança E Auditoria De Sistemas Linux","uri":"/posts/lynis-seguranca-e-auditoria-de/"},{"categories":["Tutoriais"],"content":"Como realizar uma limpeza segura em seu disco rígido utilizando o BleachBit no Linux.","date":"2013-10-23","objectID":"/posts/bleachbit-limpeza-de-disco-no/","tags":["Linux","Software Livre","Segurança"],"title":"Bleachbit: Limpeza De Disco No Linux","uri":"/posts/bleachbit-limpeza-de-disco-no/"},{"categories":["Tutoriais"],"content":"Quando o assunto é segurança da informação, muitas vezes o óbvio é deixado de lado. Se pensa em anti-vírus, firewall, IDS (Intrusion Detection System), etc. Mas e o básico e óbvio? Raramente vejo profissionais preocupados com o lixo existente nos discos rígidos. Com lixo eu quero dizer aqueles arquivos temporários, antigos arquivos de cache que já não são necessários, ou mesmo rastros de informações de arquivos que já foram deletados. Sim, o fato de você deletar arquivos não significa que as informações daqueles arquivos foram completamente apagadas do disco. A “deleção regular de arquivos” não está apagando os dados deletados. Ela está apenas removendo os links dos inodes de arquivos, tornando assim possível a recuperação dos arquivos deletados com algum software forense. ","date":"2013-10-23","objectID":"/posts/bleachbit-limpeza-de-disco-no/:0:0","tags":["Linux","Software Livre","Segurança"],"title":"Bleachbit: Limpeza De Disco No Linux","uri":"/posts/bleachbit-limpeza-de-disco-no/"},{"categories":["Tutoriais"],"content":"Introdução Existem várias alternativas para remover seus arquivos de forma segura. As alternativas poderão variar de acordo com o sistema de arquivos utilizado em seu disco, é claro. Uma das formas mais simples que conheço é através da ferramenta BleachBit. BleachBit é um software livre criado para limpar e liberar espaço em disco, gerenciando assim melhor a sua privacidade e otimizando sistemas computacionais. Criado em 2008 para sistemas GNU/Linux, partiu de um controverso e polêmico debate sobre a necessidade de o GNU/Linux necessitar de uma ferramenta para limpeza de registros. Posteriormente o BleachBit passou a suportar também sistemas Microsoft Windows. Com esta ferramenta você poderá não apenas limpar seu espaço em disco, mas também limpar vários arquivos típicos do sistema que não são necessários na maioria dos casos a longo prazo, arquivos estes que podem dar ao intruso informações desnecessárias sobre suas atividades. Não desejamos isto… ","date":"2013-10-23","objectID":"/posts/bleachbit-limpeza-de-disco-no/:1:0","tags":["Linux","Software Livre","Segurança"],"title":"Bleachbit: Limpeza De Disco No Linux","uri":"/posts/bleachbit-limpeza-de-disco-no/"},{"categories":["Tutoriais"],"content":"Instalação A instalação do mesmo é feita de forma simples e convencional. No caso do archlinux, o pacote se encontra disponível no repositório [community], portanto pode ser instalado regularmente através do pacman. [kalib@tuxcaverna ~]$ sudo pacman -Ss bleachbit [sudo] password for kalib: community/bleachbit 0.9.6-1 Deletes unneeded files to free disk space and maintain privacy [kalib@tuxcaverna ~]$ sudo pacman -S bleachbit Na maioria das distribuições baseadas em Debian, tal como o Ubuntu, o pacote poderá ser instalado através do aptitude ou apt-get: $ sudo apt-get update $ sudo apt-get install bleachbit O BleachBit possui uma interface gráfica simples, na qual você poderá selecionar o que você deseja destruir. Lembre-se que algumas funções são experimentais e podem causar problemas em seu sistema. Mas não há necessidade de se preocupar: O BleachBit lhe informa sobre isto e lhe dá a chance de cancelar a operação selecionada. ;] O BleachBit possui uma vasta lista de cleaners, como ele chama as ferramentas internas de limpeza. Dentre a longa lista, podemos citar alguns como: Adanaxis, Adobe Reader, aMSN, aMule, APT, Audacious, Bash, Beagle, Chromium, Downloader for X, Deep scan, Easytag, ELinks, emesene, Epiphany, Evolution, Exaile, Filezilla, Firefox, Flash, gedit, gFTP, GIMP, etc. A lista é realmente longa. Lista completa de cleaners e demais recursos. Para executar o programa, basta procurar o mesmo através do menu de aplicativos de seu sistema, ou através do comando: [kalib@tuxcaverna ~]$ bleachbit Have fun! ","date":"2013-10-23","objectID":"/posts/bleachbit-limpeza-de-disco-no/:2:0","tags":["Linux","Software Livre","Segurança"],"title":"Bleachbit: Limpeza De Disco No Linux","uri":"/posts/bleachbit-limpeza-de-disco-no/"},{"categories":["Impressões"],"content":"Como nova recomendação bibliográfica deixo a dica do livro Filhos de Éden, Herdeiros de Atlântida. Uma excelente opção para quem gosta de ficção envolvendo anjos, arcanjos e demônios.","date":"2013-10-04","objectID":"/posts/recomendacao-bibliografica-filhos-do-eden/","tags":["Literatura","Cultura"],"title":"Recomendação Bibliográfica: Filhos Do Éden, Herdeiros De Atlântida","uri":"/posts/recomendacao-bibliografica-filhos-do-eden/"},{"categories":["Impressões"],"content":"Anjos, Arcanjos e Demônios… Entidades que sempre despertaram a curiosidade e o interesse de milhares de pessoas. Não diferente, sempre tive um grande apreço por histórias, sejam em filmes ou literatura escrita, que abordem tais entidades. Seguindo a trilha de seu outro livro, A Batalha do Apocalipse, o autor Eduardo Spohr narra com maestria o enredo no qual uma guerra civil acontece entre o Arcanjo Miguel e as tropas revolucionárias de seu irmão, o Arcanjo Gabriel. Uma obra tão recomendada quanto qualquer outra do autor, trás um enredo mais terreno, se comparado ao livro A Batalha do Apocalipse, porém não menos interessante e empolgante. Sinopse retirada do site da Livraria Saraiva: Há uma guerra no céu. O confronto civil entre o arcanjo Miguel e as tropas revolucionárias de seu irmão, Gabriel, devasta as sete camadas do paraíso. Com as legiões divididas, as fortalezas sitiadas, os generais estabeleceram um armistício na terra, uma trégua frágil e delicada, que pode desmoronar a qualquer instante. Enquanto os querubins se enfrentam num embate de sangue e espadas, dois anjos são enviados ao mundo físico com a tarefa de resgatar Kaira, uma capitã dos exércitos rebeldes, desaparecida enquanto investigava uma suposta violação do tratado. A missão revelará as tramas de uma conspiração milenar, um plano que, se concluído, reverterá o equilíbrio de forças no céu e ameaçará toda vida humana na terra. Ao lado de Denyel, um ex-espião em busca de anistia, os celestiais partirão em uma jornada através de cidades, selvas e mares, enfrentarão demônios e deuses, numa trilha que os levará às ruínas da maior nação terrena anterior ao dilúvio – o reino perdido de Atlântida. Boa leitura! ","date":"2013-10-04","objectID":"/posts/recomendacao-bibliografica-filhos-do-eden/:0:0","tags":["Literatura","Cultura"],"title":"Recomendação Bibliográfica: Filhos Do Éden, Herdeiros De Atlântida","uri":"/posts/recomendacao-bibliografica-filhos-do-eden/"},{"categories":["Impressões"],"content":"Vulnerabilidade na tela de bloqueio do iOS 7 permite hack que burla a segurança.","date":"2013-09-20","objectID":"/posts/vulnerabilidade-ios7-hack-na-tela/","tags":["iOS","Segurança","Cultura Hacker"],"title":"Vulnerabilidade Ios7: Hack Na Tela De Bloqueio Permite Burlar Segurança","uri":"/posts/vulnerabilidade-ios7-hack-na-tela/"},{"categories":["Impressões"],"content":"Não é de hoje que as telas de bloqueio (supostas proteções) de smartphones possuem vulnerabilidades. Mal foi lançado o novo iOS 7 e o mesmo já possui uma vulnerabilidade possibilitando a qualquer pessoa utilizar um simples hack para ter acesso à alguns dados do dono do smartphone com o iOS 7. A Apple já notificou sobre a correção de aproximadamente 80 vulnerabilidades que comprometiam a segurança do aparelho mas, aparentemente, algumas passaram despercebidas. Dentre elas, a possibilidade de burlar a proteção de bloqueio do aparelho, o que nos permite acessar, por exemplo, as fotos contidas no aparelho sem a necessidade de conhecer a senha de proteção do mesmo. O processo para reprodução do hack é o seguinte: 1- Quando estiver na tela de proteção com o aparelho bloqueado, deslize seu dedo de baixo para cima, de forma a abrir a Central de Controle. Nela, abra o aplicativo relógio. 2- Abra a sessão Alarme do aplicativo Relógio e pressione o botão Power até que o iOS lhe pergunte se você deseja desligar o aparelho. 3- Toque rapidamente no botão Cancelar e, imediatamente após isto pressione duas vezes o botão Home, sendo que a segunda vez precisa ser por um pouco mais de tempo. Dois segundos são o suficiente. Em seguida, solte o botão Home. 4- Você agora verá o Gerenciador de Tarefas com as aplicações em execução. Escolha a aplicação Câmera e a partir dela você poderá nevegar pelas fotos armazenadas no aparelho. Na prática… Lindo… C0ngr4tul4ti0n5 4ppl3! Let’s H4ck and H4v3 Fun! ","date":"2013-09-20","objectID":"/posts/vulnerabilidade-ios7-hack-na-tela/:0:0","tags":["iOS","Segurança","Cultura Hacker"],"title":"Vulnerabilidade Ios7: Hack Na Tela De Bloqueio Permite Burlar Segurança","uri":"/posts/vulnerabilidade-ios7-hack-na-tela/"},{"categories":["Tutoriais"],"content":"Possui um arquivo texto com vários Gigas e deseja limpar seu conteúdo sem abrir o mesmo? Saiba como...","date":"2013-09-11","objectID":"/posts/dica-rapida-linux-como-limpar/","tags":["Linux","Software Livre","Arch Linux"],"title":"Dica Rápida Linux: Como Limpar O Conteúdo De Um Arquivo Texto Sem Abrir O Mesmo","uri":"/posts/dica-rapida-linux-como-limpar/"},{"categories":["Tutoriais"],"content":"Arquivos de log, por vezes, podem ser muito extensos. Tão extensos que torna-se praticamente impossível a leitura de seu conteúdo com um editor de textos como o vim ou vi. Além disso, muitos deles podem chegar a ocupar Gigas e mais Gigas de seu espaço em disco, o que pode acabar sendo um desperdício de espaço em seu sistema de arquivos. Hoje passei por um problema deste tipo. Ao atualizar meu Arch Linux, percebi que comecei a receber erros devido ao meu espaço em disco o qual era apontado como “insuficiente”. O fato é que é muito comum em distribuições Linux utilizarmos um particionamento de forma a isolarmos um pouco cada partição para fins específicos. No meu caso, verifiquei que a minha partição raíz estava mesmo completamente cheia. [kalib@tuxcaverna ~]$ df -h / Sist. Arq. Tam. Usado Disp. Uso% Montado em /dev/sda3 30G 30G 0M 100% / Para resolver meu problema comecei limpando os pacotes que ficam em cache desnecessariamente através do pacman: [kalib@tuxcaverna ~]$ pacman -Sc Em seguida resolvi verificar quanto de espaço eu estava consumindo com logs de sistema: [root@tuxcaverna ~]# cd /var/log [root@tuxcaverna ~]# du -h . O comando acima me mostrou que meu diretório de logs estava consumindo mais de 13G. Insano, certo? Na verdade, não. É comum que ao longo dos meses, ou mesmo anos, o sistema acumule logs e mais logs. Uma quantia absurda e, muitas vezes, desnecessária de informações. Como trata-se de meu notebook pessoal e não estou tendo qualquer erro em meu sistema, resolvi limpar estes logs, portanto o primeiro passo é identificar os maiores arquivos. No meu caso foram os arquivos: everything.log kernel.log daemon.log Uma vez que cada um destes arquivos possuía mais de 3G, resolvi limpá-los completamente. A saída mais rápida e KISS? /dev/null neles. [root@tuxcaverna ~]# cat /dev/null \u003eeverything.log Isto limpará completamente o conteúdo do arquivo de texto informado. Vejamos o simples exemplo a seguir: Vamos criar um arquivo de texto vazio chamado teste.txt. [root@tuxcaverna ~]# touch teste.txt Em seguida, vamos inserir algum conteúdo no mesmo: [root@tuxcaverna ~]# echo \"Testando\" \u003eteste.txt Verifiquemos se meu texto realmente foi inserido no arquivo: [root@tuxcaverna ~]# cat teste.txt Testando Tudo certo. Agora vamos limpar o mesmo: [root@tuxcaverna ~]# cat /dev/null \u003eteste.txt Agora, vamos confirmar se o mesmo foi mesmo zerado: [root@tuxcaverna ~]# cat teste.txt [root@tuxcaverna ~]# Missão cumprida. Apenas para constar a diferença: [kalib@tuxcaverna ~]$ df -h / Sist. Arq. Tam. Usado Disp. Uso% Montado em /dev/sda3 30G 16G 13G 56% /","date":"2013-09-11","objectID":"/posts/dica-rapida-linux-como-limpar/:0:0","tags":["Linux","Software Livre","Arch Linux"],"title":"Dica Rápida Linux: Como Limpar O Conteúdo De Um Arquivo Texto Sem Abrir O Mesmo","uri":"/posts/dica-rapida-linux-como-limpar/"},{"categories":["Impressões"],"content":"Bug entre kernel 3.10.x e placas wifi broadcom resolvido para o kernel 3.11.x","date":"2013-09-03","objectID":"/posts/correcao-do-bug-entre-kernel/","tags":["Linux","Software Livre","Redes"],"title":"Correção Do Bug Entre Kernel Linux E Placas Broadcom","uri":"/posts/correcao-do-bug-entre-kernel/"},{"categories":["Impressões"],"content":"Bug capturado e tratado! Diversas pessoas se depararam com intermináveis erros de kernel panic após atualizar seu kernel para a versão 3.10.6 (e posteriores) quando utilizavam placas wireless da Broadcom. O erro reportado foi tratado e, apesar de ainda não estar resolvido no último kernel lançado, 3.10.10, já se encontra na árvore de Linus Torvalds, conforme código e correção podem ser vistos através do seguinte link: mac80211: add a flag to indicate CCK support for HT clients O problema se dava com o módulo brcm80211 que não conseguia lidar adequadamente com o envio de frames com taxas CCK como parte de uma sessão A-MPDU. Apesar de outros drivers/módulos da broadcom conseguirem conectar-se sem o kernel panic logo na inicialização do sistema, estes ainda podem enfrentar problemas em outros momentos sem esta correção. O patch corrige o erro reportado com módulos brcmsmac bem como outros. Atualmente estou utilizando o último kernel disponibilizado, o 3.10.10. Apesar de a correção ainda não ter saído nesta versão, estou utilizando uma versão do kernel com o patch já aplicado. Esperemos pelo kernel 3.11 que deverá ser lançado nos próximos dias e que, por sua vez, deverá resolver este problema definitivamente. ","date":"2013-09-03","objectID":"/posts/correcao-do-bug-entre-kernel/:0:0","tags":["Linux","Software Livre","Redes"],"title":"Correção Do Bug Entre Kernel Linux E Placas Broadcom","uri":"/posts/correcao-do-bug-entre-kernel/"},{"categories":["Tutoriais"],"content":"Dicas para tornar seu SSH ainda mais seguro.","date":"2013-08-28","objectID":"/posts/tornando-seu-ssh-mais-seguro/","tags":["Linux","Software Livre","Segurança","Redes","SSH"],"title":"Tornando Seu Ssh Mais Seguro","uri":"/posts/tornando-seu-ssh-mais-seguro/"},{"categories":["Tutoriais"],"content":"O SSH (Secure Shell) é um dos protocolos mais utilizados atualmente para transferência de arquivos ou mesmo conexão remota, principalmente em ambientes Linux/Unix e, por si só, já tem se provado ser confiável e seguro. O mesmo passou a ser o principal substituto ao TELNET por possuir a vantagem da criptografia na conexão entre o cliente e o servidor, além da possibilidade de criação de túneis, o que chamamos de tunneling, oferecendo assim a capacidade de redirecionar pacotes de dados. Mas não é por isso que devemos nos descuidar… Sempre existe espaço para melhorias. As configurações do servidor SSH, geralmente, ficam localizadas em /etc/ssh/sshd_config. Vale lembrar que a cada alteração feita neste arquivo será necessário reiniciar o serviço SSH para que suas alterações possam ser efetivadas. Indo ao que interessa: 1- Altere a porta de escuta do SSH Por padrão o SSH aceita conexões na porta 22, portanto é importante alterar esta porta para dificultar as tentativas de ataques aleatórios de brute-force que buscam máquinas que disponibilizam o SSH através da porta padrão. Preferivelmente, é interessante optar por uma porta posterior a 1024, visto que a maioria dos softwares de escaneamento de portas e serviços não fazem uma varredura por portas muito altas. Esta é geralmente uma das primeiras configurações no arquivo /etc/ssh/sshd_config, conforme pode ser visto abaixo: Port 22 2- Permita apenas o protocolo SSH 2 Dependendo de sua distribuição Linux, o padrão poderá ser a utilização de ambos os protocolos, 1 e 2. A versão 1 do protocolo SSH possui vulnerabilidades bastante conhecidas, portanto é preferível que utilize apenas o protocolo de versão 2, diminuindo assim suas chances de um ataque de inserção, por exemplo, conforme possível com a versão 1 do protocolo. Procure pela seguinte linha de configuração e altere-a mantendo apenas a opção 2: Protocol 2,1 3- Decida quais usuários poderão logar-se via SSH Permitir que qualquer usuário possa logar-se via SSH não é aconselhável, da mesma forma que permitir que o usuário root efetue login via SSH também é extremamante desencorajado devido às vulnerabilidades envolvidas. Por possuírem determinados (ou todos, no caso do root) privilégios no sistema, alguns usuários simplesmente não devem ter permissão de login via SSH, evitando assim que alguém utilize ferramentas de brute-force e consiga, por quebra de senha, logar-se em seu servidor com um usuário privilegiado. Para proibir o login do usuário root via SSH, altere a seguinte linha para no: PermitRootLogin yes Para definir quais usuários poderão ter acesso via SSH, insira o nome dos mesmos na seguinte linha, conforme exemplo abaixo: AllowUsers usuario1 usuario2 usuario3 4- Utilize uma chave pública DSA como mecanismo de autenticação Ao invés de utilizar nomes de usuários e senhas para autenticar-se via SSH, você pode utilizar chaves públicas DSA. Outra opção é utilizar ambos os mecanismos, usuário e senha + chave. Uma das maiores vantagens de se utilizar chaves como mecanismo de autenticação é que você impossibilitará o acesso indevido através de ataques de força bruta ou brute force, pois você não precisará de um login e senha para logar-se ao servidor ou estação. Ao invés disso, você utilizará um par de chaves - uma pública e uma privada. No cenário de chaves DSA, a chave privada fica em sua máquina e uma cópia da chave pública fica no servidor que você deseja acessar via SSH. Ao tentar logar-se em um servidor configurado para autenticação via chave DSA, o mesmo verifica as chaves de ambos os lados e, se elas combinarem, autoriza seu login, caso contrário nega sua conexão. No arquivo de configuração do servidor SSH você irá procurar os seguintes parâmetros e deixá-los da seguinte forma: RSAAuthentication yes PubkeyAuthentication yes AuthorizedKeysFile %h/.ssh/authorized_keys Caso você deseje utilizar apenas a autenticação por chaves DSA, você precisará desabilitar a autenticação por senha, deixando como no o seguinte parâmetro: Pass","date":"2013-08-28","objectID":"/posts/tornando-seu-ssh-mais-seguro/:0:0","tags":["Linux","Software Livre","Segurança","Redes","SSH"],"title":"Tornando Seu Ssh Mais Seguro","uri":"/posts/tornando-seu-ssh-mais-seguro/"},{"categories":["Tutoriais"],"content":"Como remover todos os arquivos em um diretório no linux exceto os arquivos com uma determinada extensão.","date":"2013-08-23","objectID":"/posts/dia-rapida-linux-como-deletar/","tags":["Linux","Software Livre"],"title":"Dica Rápida Linux: Como Deletar Todos Os Arquivos Exceto Alguns Com Extensões Específicas","uri":"/posts/dia-rapida-linux-como-deletar/"},{"categories":["Tutoriais"],"content":"Como remover todos os arquivos em um diretório no linux exceto os arquivos com uma determinada extensão. É comum termos diretórios repletos de arquivos dos mais diferentes tipos e extensões, certo?! E quando desejamos remover vários arquivos ao mesmo tempo? Bom, o linux nos permite utilizar o comando rm para remover diversos arquivos ao mesmo tempo, certo? Da mesma forma, podemos facilmente excluir todos os arquivos de um determinado tipo ou extensão, conforme exemplo abaixo: $ rm *.py O comando acima remove todos os arquivos com extensão .py (geralmente arquivos de código fonte Python) do diretório atual. Mas e se desejarmos remover não apenas os arquivos de código Python, mas também os de código Ruby? Da mesma forma, podemos apenas inserir esta nova informação: $ rm *.py *.rb Simples… nenhuma novidade. Ok, mas e se desejarmos o caminho oposto? Se ao invés de especificar o que eu desejo deletar, eu preferir especificar o que eu não desejo deletar? Porque eu desejaria isso? A ideia não é complicar, mas sim simplificar. Imaginemos que eu possuo um diretório com não apenas 2 ou 3 tipos de arquivos diferentes, mas sim 10, 20 ou mesmo 30. Eu apenas desejo manter os arquivos de 2 tipos ou extensões. Já imaginaram qual seria o tamanho do comando seguindo a linha de raciocínio acima? Algo como… $ rm *.py *.rb *.txt *.doc *.odt *.png *.jpg *.sh *.bat *.c *.bkp *.ppt *.pl ... ... ... ... Cansei antes mesmo de digitar todos. Agora deve ter ficado claro o porque de ser mais simples poder especificar apenas o que não desejo que seja deletado. Vamos supor que eu possuo um diretório no qual se encontram os meus arquivos de diversos tipos e extensões, conforme listados abaixo: $ ls arq2.avi arq2.cdr arq2.doc arq2.html arq2.mp3 arq2.php arq2.ppt arq2.vob arq.c arq.dbf arq.gif arq.mov arq.odt arq.png arq.rb arq2.bat arq2.cdx arq2.exe arq2.jpg arq2.mp4 arq2.pl arq2.py arq.avi arq.cdr arq.doc arq.html arq.mp3 arq.php arq.ppt arq.vob arq2.c arq2.dbf arq2.gif arq2.mov arq2.odt arq2.png arq2.rb arq.bat arq.cdx arq.exe arq.jpg arq.mp4 arq.pl arq.py Como podemos ver, temos arquivos de diversas extensões. Agora, supondo que eu desejo remover todos, exceto os arquivos com as extensões .rb e .py: $ rm !(*.rb|*.py) Nosso resultado? $ ls arq2.py arq2.rb arq.py arq.rb Feito. Oi, simples assim… ","date":"2013-08-23","objectID":"/posts/dia-rapida-linux-como-deletar/:0:0","tags":["Linux","Software Livre"],"title":"Dica Rápida Linux: Como Deletar Todos Os Arquivos Exceto Alguns Com Extensões Específicas","uri":"/posts/dia-rapida-linux-como-deletar/"},{"categories":["Impressões"],"content":"Nova versão do KDE, 4.11, liberada e já disponível nos repositórios do Arch Linux.","date":"2013-08-19","objectID":"/posts/kde-4-dot-11-lancado/","tags":["Arch Linux","Linux","Software Livre","KDE","Impressões"],"title":"Kde 4.11 Lançado E Disponível No Arch Linux","uri":"/posts/kde-4-dot-11-lancado/"},{"categories":["Impressões"],"content":"Em 14 de Agosto de 2013 a comunidade KDE anunciou oficialmente a última release do Ambiente de Trabalho KDE, a versão 4.11. Nesta última versão o projeto incorporou grandes atualizações na Área de Trabalho, Aplicações e plataforma de Desenvolvimento, oferecendo, além de correções, novas funcionalidades, das quais muitas serão importantes para a próxima evolução da plataforma KDE. Este último lançamento é dedicado a memória de Atul “toolz” Chitnis, um dos maiores representantes do movimento de Software Livre e Open Source na Índia e, também, um dos maiores responsáveis pela existência do projeto KDE na Índia. Atul deixou-nos no dia 3 de Junho, após uma longa batalha contra o Câncer. Que sua alma descanse em paz, é o desejo de todos os membros do projeto KDE e, certamente, de muitas outras pessoas que o conheceram. A versão 4.11 do KDE irá receber um suporte de longo prazo, enquanto é preparada a transição para a versão 5. Além de melhorias para as funcionalidades básicas, como uma barra de tarefas mais suave, um item de bateria mais inteligente e uma mesa de mistura de som melhorada, a introdução do KScreen também trouxe um tratamento mais inteligente de vários monitores ao ambiente de trabalho. Além disso, esta release trouxe ainda algumas melhorias de performance em grande escala, combinadas com alguns ajustes de usabilidade, para que o KDE possa ter uma experiência de utilização global mais agradável. Programadores que utilizam as linguagens Python e JavaScript poderão perceber melhorias no Kate, o qual passou a trazer alguns plugins extras que melhoram a produtividade na escrita de código nesta ferramenta. O KDE PIM e o Dolphin também foram alvos de melhorias de performance, tornando-se mais rápidos e ganhando novas funcionalidades, sem mencionar, é claro, as aplicações educacionais do KDE, as quais receberam muitas novas funcionalidades. No Arch Linux, é claro, os pacotes já estão disponíveis nos repositórios oficiais. Se você já utiliza o KDE e deseja atualizar para esta nova versão, basta executar o já conhecido comando de atualizãção, através do gerenciador de pacotes pacman: # pacman -Syu Se você utiliza um gerenciador de pacotes alternativo, como o Yaourt, pode realizar a sua atualização como de costume também. Segue comando completo para usuários do yaourt: # yaourt -Syu --aur Maiores informações sobre esta release podem ser encontradas em https://community.kde.org/KDE_SC/4.11_Release_Notes Divirtam-se com o novo KDE! ;] ","date":"2013-08-19","objectID":"/posts/kde-4-dot-11-lancado/:0:0","tags":["Arch Linux","Linux","Software Livre","KDE","Impressões"],"title":"Kde 4.11 Lançado E Disponível No Arch Linux","uri":"/posts/kde-4-dot-11-lancado/"},{"categories":["Impressões"],"content":"Navegador anti-censura do Pirate Bay supera expectativas e atinge mais de 100.000 downloads em poucos dias.","date":"2013-08-16","objectID":"/posts/navegador-anti-censura-do-pirate/","tags":["Seguranca","Liberdade","Censura"],"title":"Navegador Anti Censura Do Pirate Bay Supera 100.000 Downloads","uri":"/posts/navegador-anti-censura-do-pirate/"},{"categories":["Impressões"],"content":"Para quem ainda não sabe, o The Pirate Bay (TPB) é auto-intitulado “O tracker BitTorrent mais resiliente da galáxia”. De fato, ninguém pode negar a referência do The Pirate Bay no mundo dos torrents, certo?! O projeto foi criado entre 2003 e 2004 pela organização anticopyright sueca Piratbyrån, tornando-se independente em meados de Outubro de 2004. Entre idas e vindas, o The Pirate Bay lança uma nova afronta direta às autoridades e empresas que sempre tentaram impedir suas atividades. O Pirate Browser. O Pirate Browser é o navegador lançado pelo projeto The Pirate Bay, cuja proposta é ser um navegador anti-censura, o qual permite que pessoas possam burlar filtros de acesso existentes em provedores de internet (ISP) e, assim, possam acessar sites bloqueados pelos mesmos. O navegador foi lançado em forma de presente aos seus usuários, visto ter sido lançado na data de comemoração de 10 anos do serviço. Não tratando-se de um navegador realmente novo, o Pirate Browser é na verdade uma versão customizada do já conhecido navegador Firefox, da Mozilla. O diferencial é que ele vem equipado com alguns plugins e patches, como um cliente Tor, bem como otimizações para acelerar o carregamento de páginas, através de configurações de proxy. A equipe do The Pirate Bay faz questão de informar que a ferramenta é apenas uma forma de burlar as censuras impostas na Internet, não garantindo qualquer anonimato aos usuários da mesma, conforme palavras de Winston, um dos responsáveis pelo projeto: Não está fornecendo anonimato, tampouco seguro ao ponto de esconder sua identidade. O PirateBrowser foi feito apenas para contornar a censura e o bloqueio de sites. Se fizéssemos um navegador completamente anônimo, apenas iríamos tornar a navegação mais lenta. - Winston. Com menos de 5 dias após seu lançamento, o navegador já recebeu mais de 100.000 downloads através do link direto e arquivo torrent oficial, o qual estava sendo compartilhado por mais de 5.000 pessoas no momento de seu lançamento. Apesar de os próprios responsáveis pelo projeto afirmarem estar supresos pela quantidade de downloads, visto que eles realmente não esperavam por isto, afirmam que esta é apenas a primeira ferramenta que o projeto The Pirate Bay lançará. Não imaginei que se disseminaria assim tão rapidamente. Acredito que as pessoas realmente querem acessar os sites que seus governos e cortes estão tentando esconder deles. - Winston. Para quem não conhece, ou pouco conhece, a história do projeto The Pirate Bay, recomendo fortemente o filme TPB AFK: The Pirate Bay Away from Keyboard. Trata-se de um documentário sobre a vida dos três fundadores do site de compartilhamento de arquivos The Pirate Bay, dirigido por Simon Klose. As gravações do documentário começaram no verão de 2008, e foram concluídas em 25 de Agosto de 2012. E a vida segue… ","date":"2013-08-16","objectID":"/posts/navegador-anti-censura-do-pirate/:0:0","tags":["Seguranca","Liberdade","Censura"],"title":"Navegador Anti Censura Do Pirate Bay Supera 100.000 Downloads","uri":"/posts/navegador-anti-censura-do-pirate/"},{"categories":["Impressões"],"content":"Incompatibilidade causada entre kernel 3.10.6 e placas wireless broadcom resultam em kernel panic.","date":"2013-08-14","objectID":"/posts/incompatibilidade-kernel-linux-3-dot/","tags":["Linux","Redes","Software Livre","Arch Linux"],"title":"Incompatibilidade Kernel Linux 3.10.6 E Placa Wireless Broadcom","uri":"/posts/incompatibilidade-kernel-linux-3-dot/"},{"categories":["Impressões"],"content":"Kernel Panic! Foi com isto que me deparei logo pela manhã ao chegar no trabalho ao ligar meu notebook. Ontem rodei o habitual # pacman -Syu para atualizar meu Arch Linux. Dentre as atualizações estava a nova versão estável do kernel linux: 3.10.6 Hoje descobri que esta versão estava resultando em kernel panic para os usuários de placas wireless Broadcom. Sim, sou um deles. Após algumas buscas em logs, percebi que o problema estava se dando com minha placa wireless. Logo ao iniciar o notebook, após alguns segundos, tudo travava e eu recebia o aviso de kernel panic. Desabilitando minha placa wireless consegui manter o notebook funcionando normalmente. Ao pesquisar, percebi que tratava-se de bug nesta versão do kernel. Solução? Downgrade no kernel linux. Para quem ainda possui a versão anterior, 3.10.5 no diretório de cache, basta executar a instalação local com o pacman. Com o seguinte comando você pode descobrir se o pacote ainda se encontra em seu cache: $ ls /var/cache/pacman/pkg/ | grep linux-3.10.5 Caso você ainda possua o pacote, basta digitar: # pacman -U /var/cache/pacman/pkg/linux-3.10.5-1-x86_64.pkg.tar.xz O nome do pacote poderá ser diferente para você. Estou utilizando a versão x64 do Arch. Por enquanto é melhor manter a versão anterior do kernel, ao menos até o lançamento da versão 3.11, na qual o problema já foi resolvido. ","date":"2013-08-14","objectID":"/posts/incompatibilidade-kernel-linux-3-dot/:0:0","tags":["Linux","Redes","Software Livre","Arch Linux"],"title":"Incompatibilidade Kernel Linux 3.10.6 E Placa Wireless Broadcom","uri":"/posts/incompatibilidade-kernel-linux-3-dot/"},{"categories":["Tutoriais"],"content":"Dica rápida sobre como melhorar a política e a segurança de senhas de usuários no Linux.","date":"2013-08-12","objectID":"/posts/dica-rapida-linux-melhorando-a/","tags":["Linux","Software Livre","Segurança","Impressões"],"title":"Dica Rápida Linux: Melhorando a Política De Senhas","uri":"/posts/dica-rapida-linux-melhorando-a/"},{"categories":["Tutoriais"],"content":"Na dica anterior mencionei o uso do comando chage para forçar a alteração de senha por parte do usuário em sistemas Linux, mas e se além disso fosse possível melhorar esta prática, tornando a política de senhas de usuários um pouco mais segura? O chage também nos permite determinar quando exatamente desejamos que a senha daquele usuário expire, de forma que ele será forçado a criar uma nova senha após aquele determinado tempo. Isto é útil para evitar que uma mesma senha seja utilizada por um longo período de tempo. Particularmente, gosto de forçar a alteração de senhas a cada mês, mas isto dependerá dos sistemas que são acessados e de o quão críticas são as informações e sistemas em jogo. O comando chage altera o número de dias entre a alteração de uma senha e sua alteração anterior. Esta informação fica registrada no sistema e será utilizada para determinar quando um usuário precisará alterar sua senha. Esta e outras configurações ficam armazenadas no arquivo de configuração /etc/login.defs, o qual determina configurações que englobem todos os usuários do sistema, inclusive um período máxima antes de uma senha ser expirada. Para verificar as informações sobre quando uma senha expira, digite: # chage -l NomeDoUsuário O comando acima lhe retornará informações gerais sobre aquela conta, tais como: data de última mudança de senha, data em que a senha irá expirar, status atual da senha, número mínimo entre troca de senhas, número máximo entre troca de senhas, número de dias de alerta sobre a mudança de senha, etc. Para efetivar a política de mudança de senha após um determinado tempo, você pode editar diretamente o arquivo /etc/shadow ou utilizar o comando chage, o qual recomendo ao invés do /etc/shadow. No arquivo /etc/shadow, a ordem dos campos é a seguinte: {NomeDeUsuário}:{Senha}:{ÚltimaAlteraçãoDeSenha}:{Minimum_days}:{Maximum_days}:{Warn}:{Inactive}:{Expire}: Onde, Minimum_days: Quantididade mínima de dias entre alterações de senhas. Ex: Uma quantia mínima de dias antes que o usuário possa alterar sua senha. Maximum_days: Quantidade máxima de dias pelos quais uma senha será válida (após os quais os o usuário é forçado a alterar sua senha). Warn: O número de dias antes de a senha expirar nos quais o usuário será alertado sobre a sua senha expirar em breve. Expire: Quantidade de dias desde 1 de Janeiro de 1970 em que a conta expirará. Ex: uma data específica pode ser informada para que, a partir de tal data a senha não possa mais ser utilizada. Conforme informei anteriormente, costumo recomendar a utilização do comando chage ao invás da edição do arquivo /etc/shadow, o que minimiza as chances de erros. # chage -M 60 -m 7 -W 7 NomeDeUsuário Onde, da mesma forma, M = Maximum_days, m = Minimum_days e W = warn. Bom proveito… ","date":"2013-08-12","objectID":"/posts/dica-rapida-linux-melhorando-a/:0:0","tags":["Linux","Software Livre","Segurança","Impressões"],"title":"Dica Rápida Linux: Melhorando a Política De Senhas","uri":"/posts/dica-rapida-linux-melhorando-a/"},{"categories":["Impressões"],"content":"Recomendação bibliográfica Livro Gravidade, de Tess Gerritsen.","date":"2013-08-08","objectID":"/posts/recomendacao-bibliografica-gravidade/","tags":["Literatura","Impressões"],"title":"Recomendação Bibliográfica: Gravidade","uri":"/posts/recomendacao-bibliografica-gravidade/"},{"categories":["Impressões"],"content":"O livro da vez se chama Gravidade, de Tess Gerritsen. Tess Gerritsen é, sem sombra de dúvidas, uma autora que conquistou um lugar (ou vários) bastante especial em minha estante. A cada livro que leio fico mais fascinado com a facilidade e maestria com a qual ela consegue cativar o leitor e ao mesmo tempo fazer com que o mesmo se sinta imerso no cenário Faço das palavras de Stephen King as minhas ao afirmar: Tess Gerritsen é leitura obrigatória em minha casa. - Stephen King O livro aborda uma missão rotineira da NASA para uma estação espacial onde existe uma tripulação que precisa substituir um de seus astronatuas por motivos pessoais que o fazem precisar voltar ao planeta Terra. Diversas experiências ocorrem em paralelo na estação, enviadas por cientistas do mundo inteiro, com o intuito de ver os resultados de suas pesquisas em um ambiente com micro gravidade. Mas, como nem tudo é um mar de rosas, uma série de incidentes acaba por gerar situações complicadas, comprometendo a vida de diversos tripulantes e até mesmo a do planeta Terra. O fato de Tess Gerritsen ter visitado pessoalmente as instalações reais da NASA, oportunidade na qual conversou com pessoas da instituição sobre diversos assuntos, tornou suas referências e relatos extremamente realistas e atraentes. Segue sinopse retirada do site da Livraria Saraiva: A pesquisadora Emma Watson está prestes a realizar a missão mais importante de sua vida: estudar o comportamento da vida terrestre no espaço. Escolhida pela Nasa para conduzir uma série de experimentos sobre o comportamento de organismos unicelulares, a Dra. Watson logo descobre a natureza aterrorizante desses organismos e precisa correr contra o tempo para conter uma doença mortal que pode ameaçar a Terra. Tess Gerritsen se aventura no campo do desconhecido, e o resultado é este suspense que mistura, de forma brilhante, ficção científica e medicina. Sem sombra de dúvidas recomendo a leitura deste livro a todos os interessados em ficção científica e suspense. ","date":"2013-08-08","objectID":"/posts/recomendacao-bibliografica-gravidade/:0:0","tags":["Literatura","Impressões"],"title":"Recomendação Bibliográfica: Gravidade","uri":"/posts/recomendacao-bibliografica-gravidade/"},{"categories":["Tutoriais"],"content":"Como forçar usuário a alterar senha após primeiro login.","date":"2013-08-06","objectID":"/posts/dica-rapida-linux-forcar-usuario/","tags":["Linux","Software Livre","Servidor","SysAdmin","Senha","Segurança"],"title":"Dica Rápida Linux: Forçar Usuário a Trocar Senha Após Primeiro Login","uri":"/posts/dica-rapida-linux-forcar-usuario/"},{"categories":["Tutoriais"],"content":"É natural encontrar pessoas que utilizam linux a pouco tempo (ou que nunca utilizaram) questionando aspectos simples que seguem o jargão: “Mas no Windows eu consigo fazer isso, enquanto que no Linux….” Isso não é novidade alguma e, de fato, é um comportamento esperado, embora demonstre apenas uma mera falta de boa vontade para pesquisar um pouco. O fato é que por vezes encontro pessoas me questionando sobre alguns destes recursos em falta no mundo Linux, quando na verdade eles, na grande maioria das vezes, não estão em falta. Um exemplo recente disto se deu quando um colega (não se preocupe, seu nome está a salvo) me perguntou: Porque o Linux não tem um recurso para forçar um usuário a alterar sua senha após o primeiro login? Isso me ajuda muito como SysAdmin em servidores Windows. Devo concordar com ele no sentido de que este recurso ajuda muito a vida de um SysAdmin. Sejamos justos, as pessoas vivem esquecendo suas senhas. Segunda-feira? Dia mundial do “esqueci minha senha, você pode gerar outra por favor?” Porém, devo acrescentar que o Linux possui sim este recurso (e não é uma novidade). O chage é apenas uma das formas de o fazer. Supondo que seu usuário esqueceu sua senha e você deseja possibilitar que ele crie uma nova. Você pode mudar a senha dele para qualquer coisa que venha em sua mente, por exemplo: 123mudar456 Em seguida, digite o seguinte comando: # chage -d 0 {nome-do-usuário} Supondo que eu tenha alterado a senha do usuário linus.torvalds para 123mudar456, o comando seria: # chage -d 0 linus.torvalds O parâmetro -d determina quando a senha do mesmo expira, ou deverá ser trocada. Você pode determinar uma data específica, a qual deve ser indicada no formato AAAA-MM-DD, porém, ao invés da data, o 0 indica que a senha deverá ser trocada após o primeiro login daquele usuário. Simples, certo?! ","date":"2013-08-06","objectID":"/posts/dica-rapida-linux-forcar-usuario/:0:0","tags":["Linux","Software Livre","Servidor","SysAdmin","Senha","Segurança"],"title":"Dica Rápida Linux: Forçar Usuário a Trocar Senha Após Primeiro Login","uri":"/posts/dica-rapida-linux-forcar-usuario/"},{"categories":["Eventos"],"content":"Evento sobre Ruby on Rails para mulheres em Fortaleza.","date":"2013-08-04","objectID":"/posts/rails-girls-em-fortaleza-um/","tags":["Eventos","Ruby","Rails"],"title":"Rails Girls Em Fortaleza - Um Palco Para a Criatividade Feminina","uri":"/posts/rails-girls-em-fortaleza-um/"},{"categories":["Eventos"],"content":"E se sua namorada/esposa/irmã/mãe/vizinha/filha da vizinha/… pudesse finalmente entender que tanto código é esse que você digita no computador? Talvez esta seja a sua oportunidade.. ou melhor, a dela! ","date":"2013-08-04","objectID":"/posts/rails-girls-em-fortaleza-um/:0:0","tags":["Eventos","Ruby","Rails"],"title":"Rails Girls Em Fortaleza - Um Palco Para a Criatividade Feminina","uri":"/posts/rails-girls-em-fortaleza-um/"},{"categories":["Eventos"],"content":"Rails Girls O vídeo acima é da primeira edição, ocorrida na Finlândia, em 2010. O Rails Girls é um evento mundial, o qual acontece em datas diferentes em diversas cidades pelo mundo, inclusive Fortaleza. Seguindo a descrição oficial do evento… Nosso objetivo é dar ferramentas e uma comunidade para que as mulheres entendam tecnologia e desenvolvam suas próprias ideias. Fazemos isto fornecendo uma grande experiência em construção de coisas e tornando a tecnologia mais acessível. Aprenda a desenho, prototipação, programação básica e seja apresentada ao mundo da tecnologia. O Rails Girls nasceu na Finlândia, mas hoje em dia é uma comunidade global de voluntários, sem fins lucrativos. Mais uma vez Fortaleza será a sede de um Rails Girls no Brasil. Venha participar desse curso, totalmente gratuito, com dois dias intensivos onde poderá aprender muito sobre o mundo do desenvolvimento de software utilizando Ruby on Rails e ver que computador não é “coisa de menino”. E o melhor, você não precisa saber nada sobre programação! Basta ter vontade de aprender coisas novas. Quando? 16-17 de Agosto, 2013 Venha aprender como desenvolver aplicativos web com a ajuda de excelentes coaches. Você precisa de um laptop, curiosidade e imaginação. Maiores informações, programação e inscrições podem ser feitas através deste link. Abraços! ","date":"2013-08-04","objectID":"/posts/rails-girls-em-fortaleza-um/:1:0","tags":["Eventos","Ruby","Rails"],"title":"Rails Girls Em Fortaleza - Um Palco Para a Criatividade Feminina","uri":"/posts/rails-girls-em-fortaleza-um/"},{"categories":["Impressões"],"content":"Einstein dizia: O tempo é relativo e não pode ser medido exatamente do mesmo modo e por toda parte. - Portanto, quem sou eu para julgar?","date":"2013-08-01","objectID":"/posts/renascimento-dot-dot-dot-de/","tags":["Impressões"],"title":"Renascimento... De Cara Nova","uri":"/posts/renascimento-dot-dot-dot-de/"},{"categories":["Impressões"],"content":"Einstein dizia: “O tempo é relativo e não pode ser medido exatamente do mesmo modo e por toda parte.” r É claro, isto não justifica o fato de eu ter abandonado o blog por mais de um ano, mas me dá uma certa sensação de…conforto. Se Albert Einstein afirmava que o tempo é relativo, quem sou eu para questionar isto? 1 ano sem postar… 1 mês sem postar… 1 semana sem postar.. o tempo é relativo, certo?! :p O fato é que, se é para voltar depois de tanto tempo inativo, que seja com alguma novidade. Novidade? Nosso amigo Einstein também dizia, “Faça as coisas o mais simples que você puder, porém não se restrinja às mais simples.” Para os que não lembram/conheciam meu antigo blog, se é que existe razão para não lembrar (1 semana sem postar não é nada…¬¬), abaixo segue uma pequena imagem do mesmo. Colorido, certo?! Um tanto quanto… cheio?! Ou, como dizem meus parceiros de surf: Mó crowd, velho Novamente seguindo os sábios pensamentos de Einstein, pensei: Porque não algo simples? Cá estamos nós. Um blog mais limpo, menos colorido, etc. Mas, a aparência não é tudo o que mudou. Toda a arquitetura e código por baixo do blog também mudaram. O antigo blog era mantido com o CMS WordPress, o que me serviu muito bem durante alguns anos, mas resolvi experimentar algo novo. Octopress, cujo lema é: A blogging framework for hackers, ou, Um framework de blogs para hackers. O Octopress é um framework para o Jekyll, o gerador de páginas estáticas usado pelo Github Pages. O mesmo funciona de forma bastante simples, lembrando a filosofia KISS (Keep It Simple Stupid), ou seja, simples do sentido de simplicidade e não de facilidade de uso. Como bom usuário de Arch Linux, defendo a filosofia KISS em vários aspectos, portanto resolvi trazê-la para meu blog também. “A coisa mais bela que o homem pode experimentar é o mistério. É essa emoção fundamental que está na raiz de toda ciência e toda arte.” Quem acha que a frase acima é de Albert Einstein, acertou… Por nunca ter utilizado o Octopress antes, nem mesmo a linguagem de marcação “markdown”, a qual é utilizada para criação de páginas e posts no Octopress, me senti tentado a experimentar e ver no que isso pode dar. Vamos ver no que isso vai dar… Abraços, ","date":"2013-08-01","objectID":"/posts/renascimento-dot-dot-dot-de/:0:0","tags":["Impressões"],"title":"Renascimento... De Cara Nova","uri":"/posts/renascimento-dot-dot-dot-de/"},{"categories":["Impressões"],"content":"Mais uma recomendação de leitura. Um excelente livro que mistura ação, aventura e magia.","date":"2012-02-06","objectID":"/posts/recomendacao-bibliografica-mago-e-vidro/","tags":["Impressões","Literatura"],"title":"Recomendação Bibliográfica: Mago E Vidro - A Torre Negra IV","uri":"/posts/recomendacao-bibliografica-mago-e-vidro/"},{"categories":["Impressões"],"content":"Depois de minhas longas férias, estou de volta e começando os posts do ano com uma recomendação bibliográfica: Mago e Vidro, o quarto volume da saga A Torre Negra. Para quem não conhece a saga, sugiro a leitura dos 3 links a seguir: A Torre Negra vol I - O Pistoleiro A Torre Negra vol II - A Escolha dos Três A Torre Negra vol III - As Torres Devastadas Neste 4º livro, o consagrado autor Stephen King deixa um pouco de lado a trama inicial na qual os personagens estavam buscando a Torre Negra e foca as mais de 800 páginas do livro no passado do Pistoleiro Roland, mais especificamente em sua adolescência e suas primeiras aventuras. Juntamente com seus companheiros Cuthbert e Alain, Roland se apaixona e faz amigos e inimigos durante o que parecia uma simples missão passada por seu pai. Para quem já iniciou a saga, recomendo fortemente a continuação e, para quem ainda não iniciou e está sem um bom livro para ler, vale a pena pegar o primeiro livro desta aventura. Segue breve sinopse do livro: A estranha e inesquecível odisséia de Roland de Gilead em busca da Torre Negra continua. No quarto volume da série imaginada por Stephen King, novos perigos ameaçam o ka-tet de Roland - formado por Jake, Eddie Dean, Susannah e Oi. Mago e Vidro retoma a eletrizante narrativa interrompida em As Terras Devastadas. Depois de enfrentar a terrível ameaça do monotrilho Blaine, o último pistoleiro e seus seguidores desembarcam na cidade de Topeka, no Kansas, e retomam o caminho do Feixe de Luz que conduz à Torre Negra. Roland revela então aos companheiros a história de seu passado, e a trágica perda de seu grande amor de juventude, a bela Susan Delgado. Prosseguindo em sua jornada, o ka-tet chega a um palácio de vdro verde onde encontra ninguem menos do que o antigo nêmesis de Roland: Marten Broadcloak, conhecido em alguns mundos como Randall Flagg, em outros como Richard Fannin,e em outro ainda como John Farson, o Homem Bom. E Roland e seus companheiros descobrem então uma pavorosa verdade sobre o passado do pistoleiro… Inspirada no universo imaginário de J.R.R. Tolkien e no poema épico do século XIX “Childe Roland à Torre Negra Chegou”, A Torre Negra mstura ficção científica, fantasia e terror numa narrativa que forma um verdadeiro mosaivo da cultura popular cotemporânea. Abraços ","date":"2012-02-06","objectID":"/posts/recomendacao-bibliografica-mago-e-vidro/:0:0","tags":["Impressões","Literatura"],"title":"Recomendação Bibliográfica: Mago E Vidro - A Torre Negra IV","uri":"/posts/recomendacao-bibliografica-mago-e-vidro/"},{"categories":["Tutoriais"],"content":"Que tal saber um pouco mais sobre o que lhe cerca virtualmente? Conexões de rede às quais sua máquina está ligada, tabelas de roteamento, estatísticas de interfaces, conexões mascaradas, multicasting, etc..?","date":"2011-12-13","objectID":"/posts/netstat-saiba-o-que-esta/","tags":["Impressões","Linux","Redes","Segurança","Software Livre"],"title":"Netstat Saiba O Que Esta Rolando Em Seu Ambiente","uri":"/posts/netstat-saiba-o-que-esta/"},{"categories":["Tutoriais"],"content":"Saudações pessoal, Que tal saber um pouco mais sobre o que lhe cerca virtualmente? Conexões de rede às quais sua máquina está ligada, tabelas de roteamento, estatísticas de interfaces, conexões mascaradas, multicasting, etc.. ? Apesar de muitos conhecerem o netstat, poucos sabem que ele é capaz de tudo isso e mais um pouco. O netstat é sem sombra de dúvidas uma rica ferramenta que possui inúmeros comandos e combinações que sequer cabem em um artigo simples como este post. A ideia vai ser apenas apresentar algumas opções que podem ser bem interessantes no dia a dia de um administrador de redes/sysadmin. Vamos lá… ","date":"2011-12-13","objectID":"/posts/netstat-saiba-o-que-esta/:0:0","tags":["Impressões","Linux","Redes","Segurança","Software Livre"],"title":"Netstat Saiba O Que Esta Rolando Em Seu Ambiente","uri":"/posts/netstat-saiba-o-que-esta/"},{"categories":["Tutoriais"],"content":"Netstat ","date":"2011-12-13","objectID":"/posts/netstat-saiba-o-que-esta/:1:0","tags":["Impressões","Linux","Redes","Segurança","Software Livre"],"title":"Netstat Saiba O Que Esta Rolando Em Seu Ambiente","uri":"/posts/netstat-saiba-o-que-esta/"},{"categories":["Tutoriais"],"content":"1 Listar todas as portas, incluindo portas que estão sendo escutadas e portas que não estão: ","date":"2011-12-13","objectID":"/posts/netstat-saiba-o-que-esta/:1:1","tags":["Impressões","Linux","Redes","Segurança","Software Livre"],"title":"Netstat Saiba O Que Esta Rolando Em Seu Ambiente","uri":"/posts/netstat-saiba-o-que-esta/"},{"categories":["Tutoriais"],"content":"1.1 Para listar TODAS as portas, podemos utilizar o parâmetro -a: [root@tuxcaverna ~]# netstat -a Active Internet connections (servers and established) Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 localhost.localdo:55481 *:* LISTEN tcp 0 0 *:60634 *:* LISTEN tcp 0 0 *:6881 *:* LISTEN tcp 0 0 172.16.1.6:46714 gru03s08-in-f20.1:https TIME_WAIT tcp 0 0 172.16.1.6:40899 gx-in-f138.1e1:www-http ESTABLISHED tcp 0 0 localhost.localdo:48742 localhost.localdo:55481 ESTABLISHED tcp 0 0 172.16.1.6:48643 125-233-152-234.d:21990 TIME_WAIT tcp 0 0 172.16.1.6:46717 gru03s08-in-f20.1:https TIME_WAIT tcp 0 0 172.16.1.6:57293 apache2-fungi.:www-http TIME_WAIT tcp 0 0 172.16.1.6:36444 gru03s05-in-f22.1:https ESTABLISHED tcp 0 0 172.16.1.6:57659 gru03s06-in-f1:www-http ESTABLISHED tcp 0 0 localhost.localdo:55481 localhost.localdo:48742 ESTABLISHED tcp 0 0 172.16.1.6:50581 gru03s06-in-f23.1:https ESTABLISHED tcp 0 0 172.16.1.6:39979 sn1msg1010828.phx.:msnp ESTABLISHED ... Não coloquei a saída inteira, pois era bem extensa e ainda temos muitos parâmetros para ver. Onde existe XXX.XX.X.XX, obviamente, era o endereço IP que ocultei por puro protesto pela alta no preço do amendoim. ","date":"2011-12-13","objectID":"/posts/netstat-saiba-o-que-esta/:1:2","tags":["Impressões","Linux","Redes","Segurança","Software Livre"],"title":"Netstat Saiba O Que Esta Rolando Em Seu Ambiente","uri":"/posts/netstat-saiba-o-que-esta/"},{"categories":["Tutoriais"],"content":"1.2 Para listar todas as portas UDP, utilizamos os parâmetros -au: [root@tuxcaverna ~]# netstat -au Active Internet connections (servers and established) Proto Recv-Q Send-Q Local Address Foreign Address State udp 0 0 *:bootpc *:* udp 0 0 *:49119 *:* udp 0 0 *:mdns *:* ","date":"2011-12-13","objectID":"/posts/netstat-saiba-o-que-esta/:1:3","tags":["Impressões","Linux","Redes","Segurança","Software Livre"],"title":"Netstat Saiba O Que Esta Rolando Em Seu Ambiente","uri":"/posts/netstat-saiba-o-que-esta/"},{"categories":["Tutoriais"],"content":"1.3 Para listar todas as portas TCP, utilizamos os parâmetros -at: [root@tuxcaverna ~]# netstat -at Active Internet connections (servers and established) Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 localhost.localdo:39307 *:* LISTEN tcp 0 0 *:64758 *:* LISTEN tcp 0 0 XXX.XX.X.XX:54293 gru03s06-in-f21.1:https ESTABLISHED tcp 1 0 XXX.XX.X.XX:58732 sn1msg3020104.sn1.:msnp CLOSE_WAIT ","date":"2011-12-13","objectID":"/posts/netstat-saiba-o-que-esta/:1:4","tags":["Impressões","Linux","Redes","Segurança","Software Livre"],"title":"Netstat Saiba O Que Esta Rolando Em Seu Ambiente","uri":"/posts/netstat-saiba-o-que-esta/"},{"categories":["Tutoriais"],"content":"2 Listar os Sockets que estão no estado Listening ou escuta: ","date":"2011-12-13","objectID":"/posts/netstat-saiba-o-que-esta/:1:5","tags":["Impressões","Linux","Redes","Segurança","Software Livre"],"title":"Netstat Saiba O Que Esta Rolando Em Seu Ambiente","uri":"/posts/netstat-saiba-o-que-esta/"},{"categories":["Tutoriais"],"content":"2.1 Para listar todas no estado Listening, utilizamos o parâmetro -l: [root@tuxcaverna ~]# netstat -l Active Internet connections (only servers) Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 localhost.localdo:39307 *:* LISTEN tcp 0 0 *:64758 *:* LISTEN Active UNIX domain sockets (only servers) Proto RefCnt Flags Type State I-Node Path unix 2 [ ACC ] STREAM LISTENING 10443 @/tmp/.ICE-unix/1396 unix 2 [ ACC ] STREAM LISTENING 8262 /var/run/xdmctl/dmctl/socket unix 2 [ ACC ] STREAM LISTENING 8277 /var/run/xdmctl/dmctl-:0/socket ","date":"2011-12-13","objectID":"/posts/netstat-saiba-o-que-esta/:1:6","tags":["Impressões","Linux","Redes","Segurança","Software Livre"],"title":"Netstat Saiba O Que Esta Rolando Em Seu Ambiente","uri":"/posts/netstat-saiba-o-que-esta/"},{"categories":["Tutoriais"],"content":"2.2 Para listar apenas as portas TCP no estado Listening, utilizamos os parâmetros -lt: [root@tuxcaverna ~]# netstat -lt Active Internet connections (only servers) Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 localhost.localdo:39307 *:* LISTEN tcp 0 0 *:64758 *:* LISTEN ","date":"2011-12-13","objectID":"/posts/netstat-saiba-o-que-esta/:1:7","tags":["Impressões","Linux","Redes","Segurança","Software Livre"],"title":"Netstat Saiba O Que Esta Rolando Em Seu Ambiente","uri":"/posts/netstat-saiba-o-que-esta/"},{"categories":["Tutoriais"],"content":"2.3 Para listar apenas as portas UNIX em estado Listening, utilizamos os parâmetrox -lx: [root@tuxcaverna ~]# netstat -lx Active UNIX domain sockets (only servers) Proto RefCnt Flags Type State I-Node Path unix 2 [ ACC ] STREAM LISTENING 10443 @/tmp/.ICE-unix/1396 unix 2 [ ACC ] STREAM LISTENING 8262 /var/run/xdmctl/dmctl/socket unix 2 [ ACC ] STREAM LISTENING 8277 /var/run/xdmctl/dmctl-:0/socket ","date":"2011-12-13","objectID":"/posts/netstat-saiba-o-que-esta/:1:8","tags":["Impressões","Linux","Redes","Segurança","Software Livre"],"title":"Netstat Saiba O Que Esta Rolando Em Seu Ambiente","uri":"/posts/netstat-saiba-o-que-esta/"},{"categories":["Tutoriais"],"content":"3. Apresentar as estatísticas para cada protocolo: ","date":"2011-12-13","objectID":"/posts/netstat-saiba-o-que-esta/:1:9","tags":["Impressões","Linux","Redes","Segurança","Software Livre"],"title":"Netstat Saiba O Que Esta Rolando Em Seu Ambiente","uri":"/posts/netstat-saiba-o-que-esta/"},{"categories":["Tutoriais"],"content":"3.1 Para apresentar as estatísticas de todos os protocolos, utilizamos o parâmetro -s: [root@tuxcaverna ~]# netstat -s Ip: 98790 total packets received 54 with invalid headers 2 with invalid addresses 0 forwarded 0 incoming packets discarded 94778 incoming packets delivered 79070 requests sent out Icmp: 0 ICMP messages received 0 input ICMP message failed. ICMP input histogram: 0 ICMP messages sent 0 ICMP messages failed ICMP output histogram: Tcp: 2019 active connections openings 2 passive connection openings 10 failed connection attempts 161 connection resets received 14 connections established 88977 segments received 75703 segments send out 297 segments retransmited 0 bad segments received. 216 resets sent Udp: 2986 packets received 0 packets to unknown port received. 0 packet receive errors 3080 packets sent 0 receive buffer errors 0 send buffer errors ... ... ","date":"2011-12-13","objectID":"/posts/netstat-saiba-o-que-esta/:1:10","tags":["Impressões","Linux","Redes","Segurança","Software Livre"],"title":"Netstat Saiba O Que Esta Rolando Em Seu Ambiente","uri":"/posts/netstat-saiba-o-que-esta/"},{"categories":["Tutoriais"],"content":"3.2 Para apresentar as estatísticas do protocolo TCP (ou) UDP, utilizamos os parâmetros -st (ou) -su: [root@tuxcaverna ~]# netstat -st Tcp: 2031 active connections openings 2 passive connection openings 10 failed connection attempts 164 connection resets received 10 connections established 89257 segments received 76010 segments send out 297 segments retransmited 0 bad segments received. 219 resets sent ou [root@tuxcaverna ~]# netstat -su Udp: 3012 packets received 0 packets to unknown port received. 0 packet receive errors 3107 packets sent 0 receive buffer errors 0 send buffer errors ","date":"2011-12-13","objectID":"/posts/netstat-saiba-o-que-esta/:1:11","tags":["Impressões","Linux","Redes","Segurança","Software Livre"],"title":"Netstat Saiba O Que Esta Rolando Em Seu Ambiente","uri":"/posts/netstat-saiba-o-que-esta/"},{"categories":["Tutoriais"],"content":"4 Apresentar o PID (ID do prcesso) e os nomes de programas: ","date":"2011-12-13","objectID":"/posts/netstat-saiba-o-que-esta/:1:12","tags":["Impressões","Linux","Redes","Segurança","Software Livre"],"title":"Netstat Saiba O Que Esta Rolando Em Seu Ambiente","uri":"/posts/netstat-saiba-o-que-esta/"},{"categories":["Tutoriais"],"content":"4.1 Neste caso utilizamos o netstat com o parâmetro -p para receber a informação de “PID/Nome do Programa” na saída do netstat. Esta opção é muito útil para debugar e identificar qual programa está rodando em uma porta específica. O parâmetro -p pode ser combinado com demais parâmetros: [root@tuxcaverna ~]# netstat -pt Active Internet connections (w/o servers) Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 XXX.XX.X.X:6881 83-228-34-45.btc-:11729 SYN_RECV - tcp 0 0 XXX.XX.X.X:39508 200.123.194.16:www-http ESTABLISHED 30741/chromium tcp 0 0 XXX.XX.X.X:36321 208.46.17.59:www-http ESTABLISHED 30741/chromium tcp 0 0 XXX.XX.X.X:57411 65.55.142.101:https ESTABLISHED 3292/python2 tcp 0 0 XXX.XX.X.X:6881 bd3e1c77.virtua.c:59298 ESTABLISHED 20447/qbittorrent ","date":"2011-12-13","objectID":"/posts/netstat-saiba-o-que-esta/:1:13","tags":["Impressões","Linux","Redes","Segurança","Software Livre"],"title":"Netstat Saiba O Que Esta Rolando Em Seu Ambiente","uri":"/posts/netstat-saiba-o-que-esta/"},{"categories":["Tutoriais"],"content":"5 Não resolver host, porta ou nome de usuário: ","date":"2011-12-13","objectID":"/posts/netstat-saiba-o-que-esta/:1:14","tags":["Impressões","Linux","Redes","Segurança","Software Livre"],"title":"Netstat Saiba O Que Esta Rolando Em Seu Ambiente","uri":"/posts/netstat-saiba-o-que-esta/"},{"categories":["Tutoriais"],"content":"5.1 Utiliza-se o parâmetro -an quando não se deseja receber na saída do netstat informações de host, porta ou usuarios com seus respectivos nomes resolvidos. Ao invés destas informações virão números: [root@tuxcaverna ~]# netstat -an Active Internet connections (servers and established) Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 0.0.0.0:61108 0.0.0.0:* LISTEN tcp 0 0 0.0.0.0:6881 0.0.0.0:* LISTEN tcp 0 0 127.0.0.1:49155 0.0.0.0:* LISTEN ","date":"2011-12-13","objectID":"/posts/netstat-saiba-o-que-esta/:1:15","tags":["Impressões","Linux","Redes","Segurança","Software Livre"],"title":"Netstat Saiba O Que Esta Rolando Em Seu Ambiente","uri":"/posts/netstat-saiba-o-que-esta/"},{"categories":["Tutoriais"],"content":"5.2 Se você não quizer descartar as 3 informações de uma vez, pode optar por ocultar apenas uma em específico, conforme abaixo: [root@tuxcaverna ~]# netstat -a –numericports ou [root@tuxcaverna ~]# netstat -a -numeric-hosts ou [root@tuxcaverna ~]# netstat -a numeric-users ","date":"2011-12-13","objectID":"/posts/netstat-saiba-o-que-esta/:1:16","tags":["Impressões","Linux","Redes","Segurança","Software Livre"],"title":"Netstat Saiba O Que Esta Rolando Em Seu Ambiente","uri":"/posts/netstat-saiba-o-que-esta/"},{"categories":["Tutoriais"],"content":"6 Que tal ter uma saída contínua de informações em tempo real? Para isso usa-se o parâmetro -c, que vai atualizar as informações do netstat a cada segundo: [root@tuxcaverna ~]# netstat -c Active Internet connections (w/o servers) Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 XXX.XX.X.X:57411 65.55.142.101:https ESTABLISHED tcp 0 0 XXX.XX.X.X:6881 bd3e1c77.virtua.c:59298 ESTABLISHED tcp 1 0 XXX.XX.X.X:49920 sn1msg2010605.phx.:msnp CLOSE_WAIT tcp 0 0 XXX.XX.X.X:45554 111-240-177-108.dy:8921 TIME_WAIT ","date":"2011-12-13","objectID":"/posts/netstat-saiba-o-que-esta/:1:17","tags":["Impressões","Linux","Redes","Segurança","Software Livre"],"title":"Netstat Saiba O Que Esta Rolando Em Seu Ambiente","uri":"/posts/netstat-saiba-o-que-esta/"},{"categories":["Tutoriais"],"content":"7 Encontrar famílias de endereços não suportadas em seu sistema: Utilizamos o parâmetro –verbose. Repare que nas últimas linhas do retorno teremos algo como: [root@tuxcaverna ~]# netstat -c netstat: no support for `AF IPX' on this system. netstat: no support for `AF AX25' on this system. netstat: no support for `AF X25' on this system. netstat: no support for `AF NETROM' on this system. ","date":"2011-12-13","objectID":"/posts/netstat-saiba-o-que-esta/:1:18","tags":["Impressões","Linux","Redes","Segurança","Software Livre"],"title":"Netstat Saiba O Que Esta Rolando Em Seu Ambiente","uri":"/posts/netstat-saiba-o-que-esta/"},{"categories":["Tutoriais"],"content":"8 Para apresentar informações de rotas do kernel utilizamos o parâmetro -r: [root@tuxcaverna ~]# netstat -r Kernel IP routing table Destination Gateway Genmask Flags MSS Window irtt Iface default 172.16.1.1 0.0.0.0 UG 0 0 0 wlan0 172.16.1.0 * 255.255.255.0 U 0 0 0 wlan0 …ou, pode-se utilizar -rn para apresentar em formato numérico ao invés de nomes de hosts. ","date":"2011-12-13","objectID":"/posts/netstat-saiba-o-que-esta/:1:19","tags":["Impressões","Linux","Redes","Segurança","Software Livre"],"title":"Netstat Saiba O Que Esta Rolando Em Seu Ambiente","uri":"/posts/netstat-saiba-o-que-esta/"},{"categories":["Tutoriais"],"content":"9 Para descobrir em qual porta um determinado programa está rodando utilizamos os parâmetros -ap: [root@tuxcaverna ~]# netstat -ap Active Internet connections (servers and established) Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 *:61108 *:* LISTEN 3452/wish tcp 0 0 *:6881 *:* LISTEN 20447/qbittorrent tcp 0 0 localhost.localdo:49155 *:* LISTEN 4010/GoogleTalkPlug tcp 0 269 172.16.1.3:58742 52.60.in-addr.arp:12814 FIN_WAIT1 - tcp 0 0 172.16.1.3:6881 bd3e1c77.virtua.c:59298 ESTABLISHED 20447/qbittorrent ","date":"2011-12-13","objectID":"/posts/netstat-saiba-o-que-esta/:1:20","tags":["Impressões","Linux","Redes","Segurança","Software Livre"],"title":"Netstat Saiba O Que Esta Rolando Em Seu Ambiente","uri":"/posts/netstat-saiba-o-que-esta/"},{"categories":["Tutoriais"],"content":"9.1 Se quizer especificar o programa, ao invés de o procurar em uma extensa lista, utilize um filtro com o grep da seguinte forma: [root@tuxcaverna ~]# netstat -ap | grep chromium unix 2 [ ACC ] STREAM LISTENING 252100 30741/chromium /tmp/.org.chromium.Chromium.bSJLzX/SingletonSocket unix 3 [ ] STREAM CONNECTED 309051 30741/chromium unix 3 [ ] STREAM CONNECTED 308785 30741/chromium ","date":"2011-12-13","objectID":"/posts/netstat-saiba-o-que-esta/:1:21","tags":["Impressões","Linux","Redes","Segurança","Software Livre"],"title":"Netstat Saiba O Que Esta Rolando Em Seu Ambiente","uri":"/posts/netstat-saiba-o-que-esta/"},{"categories":["Tutoriais"],"content":"9.2 Se ao invés de especificar o programa, você quizer especificar uma porta e saber o que está rodando nela, pode-se utilizar o filtro do grep da seguinte forma: [root@tuxcaverna ~]# netstat -an | grep ‘:80’ ","date":"2011-12-13","objectID":"/posts/netstat-saiba-o-que-esta/:1:22","tags":["Impressões","Linux","Redes","Segurança","Software Livre"],"title":"Netstat Saiba O Que Esta Rolando Em Seu Ambiente","uri":"/posts/netstat-saiba-o-que-esta/"},{"categories":["Tutoriais"],"content":"10 Para terminar, podemos utilizar o parâmetro -i para listar nossas interfaces de rede: [root@tuxcaverna ~]# netstat -i Kernel Interface table Iface MTU Met RX-OK RX-ERR RX-DRP RX-OVR TX-OK TX-ERR TX-DRP TX-OVR Flg eth0 1500 0 0 0 0 0 0 0 0 0 BMU lo 16436 0 662 0 0 0 662 0 0 0 LRU wlan0 1500 0 157377 0 4 0 133487 0 0 0 BMRU Se desejar informações mais detalhadas sobre cada interface, pode-se utilizar a combinação de parâmetros -ie: [root@tuxcaverna ~]# netstat -ie Kernel Interface table eth0: flags=4099\u003cUP,BROADCAST,MULTICAST\u003e mtu 1500 metric 1 ether a4:ba:db:d7:41:c0 txqueuelen 1000 (Ethernet) RX packets 0 bytes 0 (0.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 0 bytes 0 (0.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 device interrupt 47 base 0xc000 Happy Hacking… ","date":"2011-12-13","objectID":"/posts/netstat-saiba-o-que-esta/:1:23","tags":["Impressões","Linux","Redes","Segurança","Software Livre"],"title":"Netstat Saiba O Que Esta Rolando Em Seu Ambiente","uri":"/posts/netstat-saiba-o-que-esta/"},{"categories":["Impressões"],"content":"Bom, aparentemente um banco alemão acredita que alguns projetos/instituições merecem ser ajudados financeiramente pelo seu impacto/importância. Que tal votar e ajudar?","date":"2011-10-24","objectID":"/posts/que-tal-ajudar-o-projeto/","tags":["Impressões","KDE","Linux","Software Livre"],"title":"Que Tal Ajudar O Projeto Kde Com Apenas 1 Minuto Do Seu Tempo","uri":"/posts/que-tal-ajudar-o-projeto/"},{"categories":["Impressões"],"content":"Não acredita? Bom, aparentemente um banco alemão acredita que alguns projetos/instituições merecem ser ajudados financeiramente pelo seu impacto/importância. Sim, o projeto KDE está fazendo parte desta lista, mas para conseguir a doação de 1000 euros por parte deste banco, o projeto KDE precisa do seu voto. Sim, apenas seu voto que não leva mais que 1 minuto. Se você utiliza o KDE no seu dia a dia, acredito que este seu 1 minuto já é um ótimo “pagamento” ao projeto que lhe ajuda diariamente a resolver suas tarefas. O banco alemão ING DiBa está doando 1000 euros para 1000 associações. A seleção será feita via votação online, portanto, se você der um voto para o KDE eV, temos boa chance de ser um dos vencedores. O dinheiro será utilizado pelo KDE para financiar sprints, viagens, servidores, etc. Como fazer para ajudar? 1- Acesse KDE Ajuda e clique em “Stimme abgeben”. 2- Preencha seu email e o código captcha, clicando em seguida em “absenden”. 3- Você receberá um email para confirmar o voto - clique no primeiro link deste email. 4- No website - clique em “Stimme abgeben”. Você tem direito a 3 votos por conta de email. Vamos que vamos. Abraços, ","date":"2011-10-24","objectID":"/posts/que-tal-ajudar-o-projeto/:0:0","tags":["Impressões","KDE","Linux","Software Livre"],"title":"Que Tal Ajudar O Projeto Kde Com Apenas 1 Minuto Do Seu Tempo","uri":"/posts/que-tal-ajudar-o-projeto/"},{"categories":["Eventos"],"content":"Neste fim de semana foi publicada a programação oficial do 3º Dia Livre, encontro para usuários, profissionais ou entusiastas do movimento de Software Livre no Ceará.","date":"2011-10-17","objectID":"/posts/3-dia-livre-programacao-definida/","tags":["Dia Livre","Impressões","Java","Linux","Software Livre","Tux-ce"],"title":"3 Dia Livre Programacao Definida","uri":"/posts/3-dia-livre-programacao-definida/"},{"categories":["Eventos"],"content":"Neste fim de semana foi publicada a programação oficial do 3º Dia Livre, encontro para usuários, profissionais ou entusiastas do movimento de Software Livre no Ceará. Esta 3ª edição contará com 4 palestras de temas bem diversificados como podem ver na grade abaixo: Horário Palestra Palestrante 08:00 - 08:10 Abertura Todos 08:10 - 09:00 CRUD Flex com Java Alessandro Moreira 09:10 - 10:00 Gerenciando Nuvens Privadas com o Xen Cloud Platform Lorscheider Santiago 10:10 - 11:00 Gerenciando Projetos com Ferramentas Livres Paulo Cesar C. Branco 11:10 - 12:00 Arduino - Desenvolvendo com Hardware Livre Marcelo Melo Ainda não sabe o que é o Dia Livre? Clique aqui para conhecer! As inscrições continuam abertas para esta 3ª edição que acontecerá no dia 12 de Novembro, Sábado, na Faculdade Estácio FIC. Clique aqui e faça sua inscrição gratuita. Abraços, ","date":"2011-10-17","objectID":"/posts/3-dia-livre-programacao-definida/:0:0","tags":["Dia Livre","Impressões","Java","Linux","Software Livre","Tux-ce"],"title":"3 Dia Livre Programacao Definida","uri":"/posts/3-dia-livre-programacao-definida/"},{"categories":["Eventos"],"content":"Já estão abertas as inscrições para o 3º Dia Livre em Fortaleza.","date":"2011-10-11","objectID":"/posts/3-dia-livre-inscricoes-abertas/","tags":["Dia Livre","Impressões","Linux","Software Livre","Tux-ce"],"title":"3 Dia Livre: Inscricões Abertas","uri":"/posts/3-dia-livre-inscricoes-abertas/"},{"categories":["Eventos"],"content":"Já estão abertas as inscrições para o 3º Dia Livre em Fortaleza. Para quem ainda não teve a oportunidade de participar de nenhuma edição, o Dia Livre é um encontro bimestral organizado pela Tux-CE que busca aproximar os profissionais e entusiastas do Software Livre. Além de proporcionar um momento de entretenimento e conhecimento, através de palestras e apresentações sobre os mais diversos assuntos ligados à tecnologias e Software Livre como um todo, o Dia Livre é uma excelente oportunidade para aumentar o seu networking ou círculo profissional. Após a 1ª edição ocorrida na Faculdade Farias Brito e a 2ª na SecrelNet Business, anunciamos agora a 3ª edição que acontecerá na Faculdade FIC Estácio no dia 12 de Novembro, Sábado. As inscrições são gratuitas! Não perca tempo e garanta a sua vaga através do site do Dia Livre: www.dialivre.net Abraços, ","date":"2011-10-11","objectID":"/posts/3-dia-livre-inscricoes-abertas/:0:0","tags":["Dia Livre","Impressões","Linux","Software Livre","Tux-ce"],"title":"3 Dia Livre: Inscricões Abertas","uri":"/posts/3-dia-livre-inscricoes-abertas/"},{"categories":["Tutoriais"],"content":"Já é sabido que a maior vulnerabilidade dentro das empresas ou mesmo computadores pessoais são justamente os próprios funcionários ou usuários.","date":"2011-09-27","objectID":"/posts/politica-de-senhas-no-linux/","tags":["Arch Linux","Cultura Hacker","Debian","Impressões","Linux","Segurança","Software Livre"],"title":"Política De Senhas No Linux: Senhas Com Data Para Expirar","uri":"/posts/politica-de-senhas-no-linux/"},{"categories":["Tutoriais"],"content":"Já é sabido que a maior vulnerabilidade dentro das empresas ou mesmo computadores pessoais são justamente os próprios funcionários ou usuários. p Manter uma boa política de senhas é fundamental para garantir a segurança básica de suas informações e tentar minimizar as chances de alguém ter acesso indevido a elas. Vou apresentar dicas simples para uma boa política de senhas que vão além das dicas comuns como “mantenha uma senha que contenha mais de 8 caracteres, sendo eles números, letras minúsculas, maiúsculas e caracteres especiais…”. Em escritórios é importante haver também uma política de troca de senha regular. Mas, como forçar os usuários a seguirem essa política de troca de senha regular? Evitando que o mesmo se logue caso não troque a senha de forma periódica, claro. Vamos começar pelo básico. ","date":"2011-09-27","objectID":"/posts/politica-de-senhas-no-linux/:0:0","tags":["Arch Linux","Cultura Hacker","Debian","Impressões","Linux","Segurança","Software Livre"],"title":"Política De Senhas No Linux: Senhas Com Data Para Expirar","uri":"/posts/politica-de-senhas-no-linux/"},{"categories":["Tutoriais"],"content":"1 Definindo a complexidade das senhas de usuários: Para definir a complexidade, precisaremos alterar a configuração de definição de senhas de usuários. O processo pode ser diferente, de acordo com a sua distribuição. Arch Linux: Edite o arquivo passwd que se encontra em /etc/pam.d/passwd, da seguinte forma: vim /etc/pam.d/passwd_ Debian, Ubuntu, RedHat, CentOS e outras: vim /etc/pam.d/system-auth_ Configure sua linha de senha de forma que fique algo parecido com o seguinte: password required pam_cracklib.so difok=3 minlen=10 ucredit=3 ocredit=2 retry=3 Onde: difok=3 -\u003e Informa a quantidade de caracteres que podem se repetir em relação à última senha. Por exemplo: Se minha antiga senha era “kalib” e eu tento usar “kalamba” como nova senha, receberei uma informação de erro, pois eu repeti 3 letras que já existem na senha anterior “kal”. minlen=10 -\u003e Informa qual a quantidade mínima de caracteres aceitos para a senha do usuário. No exemplo, o mínimo de caracteres aceitos serão 10, caso contrário será apresentada uma mensagem de erro solicitando que o usuário tente uma nova senha. ucredit=3 -\u003eInforma a quantidade de letras maiúsculas que deverão compor minha senha. No exemplo, eu precisarei utilizar no mínimo 3 letras em maiúsculo, ou “Uper Characters” em minha nova senha. ocredit=2 -\u003e Informa a quantidade de “outros caracteres” ou caracteres especiais, como por exemplo *, \u0026, %, $, _, etc. retry=3 -\u003e Informa quantas vezes o usuário vai poder tentar, em caso de senha indevida, antes de receber a mensagem de erro. Outros parâmetros que podem ser utilizados são os seguintes: dcredit=x -\u003e Informa a quantidade de dígitos que deverão ser utilizados como números na senha, onde x é o número mínimo desejado. lcredit=x -\u003e Informa a quantidade de caracteres minúsculos, ou “Lower Characters”, mínimos em sua senha. ","date":"2011-09-27","objectID":"/posts/politica-de-senhas-no-linux/:1:0","tags":["Arch Linux","Cultura Hacker","Debian","Impressões","Linux","Segurança","Software Livre"],"title":"Política De Senhas No Linux: Senhas Com Data Para Expirar","uri":"/posts/politica-de-senhas-no-linux/"},{"categories":["Tutoriais"],"content":"2 Definindo que a nova senha não poderá ser igual às anteriores: No mesmo arquivo do ponto anterior, iremos inserir o parâmetro remember na linha conforme exemplo: password sufficient pam_unix.so use_authtok md5 shadow remember=10 remember=10 -\u003e Informa que a nova senha não poderá ser igual às últimas 10 senhas utilizadas por este usuário. Agora que já sabemos como definir uma política para criação de senhas seguras, vamos conhecer o “chage”, que nos ajudará a definir a política de datas ou validade das senhas. ","date":"2011-09-27","objectID":"/posts/politica-de-senhas-no-linux/:2:0","tags":["Arch Linux","Cultura Hacker","Debian","Impressões","Linux","Segurança","Software Livre"],"title":"Política De Senhas No Linux: Senhas Com Data Para Expirar","uri":"/posts/politica-de-senhas-no-linux/"},{"categories":["Tutoriais"],"content":"3 Checando as políticas de validade de senhas de um determinado usuário: # chage -l usuário O comando acima verifica os atributos de validade daquela senha, e lhe retornará algo similar ao seguinte: \u003cem\u003eLast password change : May 11, 2011\u003c/em\u003e \u003cem\u003ePassword expires : never\u003c/em\u003e \u003cem\u003ePassword inactive : never\u003c/em\u003e \u003cem\u003eAccount expires : never\u003c/em\u003e \u003cem\u003eMinimum number of days between password change : 0\u003c/em\u003e \u003cem\u003eMaximum number of days between password change : 99999\u003c/em\u003e \u003cem\u003eNumber of days of warning before password expires : 7\u003c/em\u003e As informações acima apresentam dados como data de última mudança de senha, data de expiração, tempo de inatividade, quantidade mínima de dias para se trocar a senha antes de a mesma expirar, etc. ","date":"2011-09-27","objectID":"/posts/politica-de-senhas-no-linux/:3:0","tags":["Arch Linux","Cultura Hacker","Debian","Impressões","Linux","Segurança","Software Livre"],"title":"Política De Senhas No Linux: Senhas Com Data Para Expirar","uri":"/posts/politica-de-senhas-no-linux/"},{"categories":["Tutoriais"],"content":"4 Criando uma “validade” ou período de expiração para a senha de um determinado usuário: \u003cem\u003e# chage -M 99999 linustorvalds\u003c/em\u003e Este comando vai desabilitar o período de validade da senha, informando que a mesma não expira nunca. \u003cem\u003e# chage -M 50 -m 7 -W 7 linustorvalds\u003c/em\u003e Este comando aplica a política de senha para o usuário “linustorvalds” onde: -M 50 -\u003e Define que a senha será válida por um máximo de 50 dias, quando a mesma deverá ser trocada. -m 7 -\u003e Define o número mínimo de dias em que o usuário poderá trocar sua senha antes do período especificado para expiração. Caso o usuário possa trocar a qualquer momento ou dia, o valor deverá ser 0. -W 7 -\u003e Número de dias antes de expirar nos quais o usuário vai receber alertas informando que sua senha irá expirar. Caso você deseje especificar um dia exato no qual a senha de determinado usuário vai expirar, você pode utilizar o parâmetro -E seguido da data desejada no formato AAAA-MM-DD. Além disto, você pode desejar que a senha do usuário “linustorvalds” seja trocada no próximo login do mesmo. Neste caso você poderá utilizar o parâmetro -d, conforme exemplo abaixo: \u003cem\u003e# chage -d 0 linuxtorvalds\u003c/em\u003e O -d significa quantidade de dias também. \u003cstrong\u003eÉ\u003c/strong\u003e isso pessoal. \u003cstrong\u003eH\u003c/strong\u003eave fun! ","date":"2011-09-27","objectID":"/posts/politica-de-senhas-no-linux/:4:0","tags":["Arch Linux","Cultura Hacker","Debian","Impressões","Linux","Segurança","Software Livre"],"title":"Política De Senhas No Linux: Senhas Com Data Para Expirar","uri":"/posts/politica-de-senhas-no-linux/"},{"categories":["Aleatórios"],"content":"Um feliz dia do programador para todos aqueles que, profissionalmente, curiosamente ou mesmo por mera falta do que fazer escrevem ou já escreveram linhas de código!","date":"2011-09-13","objectID":"/posts/feliz-dia-do-programador/","tags":["Impressões","Java","Python","Ruby","Software Livre"],"title":"Feliz Dia Do Programador","uri":"/posts/feliz-dia-do-programador/"},{"categories":["Aleatórios"],"content":"Saudações pessoal, Um feliz dia do programador para todos aqueles que, profissionalmente, curiosamente ou mesmo por mera falta do que fazer escrevem ou já escreveram linhas de código! Esta profissão que na maior parte das vezes não trá$ o retorno e$perado, o que apenas demonstra o quão apaixonados por linha de código são essas pessoas… e por problemas. Desafiador…estressante…cansativo…divertido…prazeroso… Como em qualquer “casamento”… na alegria e na tristeza! Obviamente que eu não vou colocar em todas as centenas de linguagens de programação que existem.. portanto, se a sua linguagem favorita não foi homenageada abaixo, não fique triste. São muitas..difícil lembrar de todas.. O que vale é a intenção. Abraço! ","date":"2011-09-13","objectID":"/posts/feliz-dia-do-programador/:0:0","tags":["Impressões","Java","Python","Ruby","Software Livre"],"title":"Feliz Dia Do Programador","uri":"/posts/feliz-dia-do-programador/"},{"categories":["Eventos"],"content":"2º Dia Livre - Últimos dias para inscrições! \u0026 Site da Tux-CE em obras!","date":"2011-09-08","objectID":"/posts/2-dia-livre-ultimos-dias/","tags":["Dia Livre","Impressões","Linux","Software Livre","Tux-ce"],"title":"2 Dia Livre: Últimos Dias Para Inscrições - Site Da Tux Ce Em Obras","uri":"/posts/2-dia-livre-ultimos-dias/"},{"categories":["Eventos"],"content":"Saudações amigos! Para quem não sabe ainda, a Tux-CE está organizando um encontro regular para os usuários e profissinais de Software Livre, bem como interessados e curiosos sobre o tema. O nome dado ao projeto é Dia Livre. ","date":"2011-09-08","objectID":"/posts/2-dia-livre-ultimos-dias/:0:0","tags":["Dia Livre","Impressões","Linux","Software Livre","Tux-ce"],"title":"2 Dia Livre: Últimos Dias Para Inscrições - Site Da Tux Ce Em Obras","uri":"/posts/2-dia-livre-ultimos-dias/"},{"categories":["Eventos"],"content":"Dia Livre Um encontro simples e rápido que costuma acontecer a cada 2 meses em diferentes locais para facilitar a presença de todos. A próxima edição será no dia 11 de Setembro, Domingo. Estes são os últimos dias para inscrições através de nossa página. 11 de Setembro, Domingo – A partir das 08:00 Local: SecrelNet Business Av. Dom Luís, 500 – 20º Andar (Shopping Aldeota, em frente a praça Portugal) – Fortaleza, CE ","date":"2011-09-08","objectID":"/posts/2-dia-livre-ultimos-dias/:1:0","tags":["Dia Livre","Impressões","Linux","Software Livre","Tux-ce"],"title":"2 Dia Livre: Últimos Dias Para Inscrições - Site Da Tux Ce Em Obras","uri":"/posts/2-dia-livre-ultimos-dias/"},{"categories":["Eventos"],"content":"Grade A grade desta edição será a seguinte: Horário Palestra Palestrante 08:00 - 08:10 Abertura Todos 08:10 - 09:00 Software Livre – Que bicho é esse? Diego Monte 09:10 - 10:00 Turbine sua produtividade com o Firefox Victor Carvalho 10:10 – 10:30 CoffeeBreak e bate papo Todos 10:40 – 11:30 LibreOffice na prática Lucas Filho Gostaria de aproveitar o post e comunicar que a página da Tux-CE está passando por uma grande migração, portanto estará indisponível, como alguns já devem ter percebido, pelos próximos 7 dias. Abraços, ","date":"2011-09-08","objectID":"/posts/2-dia-livre-ultimos-dias/:2:0","tags":["Dia Livre","Impressões","Linux","Software Livre","Tux-ce"],"title":"2 Dia Livre: Últimos Dias Para Inscrições - Site Da Tux Ce Em Obras","uri":"/posts/2-dia-livre-ultimos-dias/"},{"categories":["Impressões"],"content":"Afastado do blog como explicado no post anterior, mas não afastado de minha leitura diária.","date":"2011-09-07","objectID":"/posts/recomendacao-bibliografica-a-guerra-dos/","tags":["Impressões","Literatura"],"title":"Recomendação Bibliográfica: A Guerra Dos Tronos - As Crônicas De Gelo E Fogo Vol I","uri":"/posts/recomendacao-bibliografica-a-guerra-dos/"},{"categories":["Impressões"],"content":"Afastado do blog como explicado no post anterior, mas não afastado de minha leitura diária. O livro da vez, para variar, foi um presente de minha namorada, Mari. A Guerra dos tronos é o primeiro livro da trilogia Crônicas de Gelo e Fogo. Pouco provável que alguém não tenha ouvido falar dessa trilogia que fez e continua fazendo um grande sucesso, seja em forma de livros ou em forma de uma série de televisão de mesmo nome. Como bom amante de livros(e filmes) épicos, fiquei curioso em relação a esta história desde que bati os olhos pela primeira vez na capa de seus livros. O livro é de autoria do escritor e roteirista estadunidense George Raymond Richard Martin, declarado em 2011 pela revista TIMES como uma das 100 pessoas mais influentes do mundo. Apesar de suas 592 páginas, a leitura é leve e desperta a curiosidade. Em uma terra onde o verão pode durar décadas e o inverno uma vida, os problemas estão apenas começando. O frio está de volta e, nas florestas ao norte de Winterfell, forças sobrenaturais se espalham por trás da Muralha que protege a região. No centro do conflito estão os Stark do reino de Winterfell, uma família tão áspera quanto as terras que lhe pertencem. Dos lugares onde o frio é brutal, até os distantes reinos de plenitude e sol, George R. R. Martin narra uma história de lordes e damas, soldados e mercenários, assassinos e bastardos, que se juntam em um tempo de presságios malignos. Entre disputas por reinos, tragédias e traições, vitória e terror, o destino dos Stark, seus aliados e seus inimigos é incerto. Mas cada um está se esforçando para ganhar este conflito mortal: a guerra dos tronos. Boa leitura! ","date":"2011-09-07","objectID":"/posts/recomendacao-bibliografica-a-guerra-dos/:0:0","tags":["Impressões","Literatura"],"title":"Recomendação Bibliográfica: A Guerra Dos Tronos - As Crônicas De Gelo E Fogo Vol I","uri":"/posts/recomendacao-bibliografica-a-guerra-dos/"},{"categories":["Aleatórios"],"content":"Longo tempo sem publicar algo no blog, mas cá estou novamente.","date":"2011-09-06","objectID":"/posts/casa-nova-em-todos-os/","tags":["Impressões"],"title":"Casa Nova Em Todos Os Sentidos","uri":"/posts/casa-nova-em-todos-os/"},{"categories":["Aleatórios"],"content":"Saudações pessoal! Longo tempo sem publicar algo no blog, mas cá estou novamente. A verdade é que passei por um período um tanto quanto conturbado. Estive em busca de um novo apartamento com a família, mudanças em meus horários da faculdade, trabalhos profissionais, projetos pessoais, projetos de software livre, estudo de novo idioma, etc. Muita coisa mudou. Mudanças, quando acontecem todas ao mesmo tempo, podem nos deixar um tanto quanto esgotados. Foi basicamente isto o que aconteceu. Mas, agora que consegui me organizar novamente, acredito que seja hora de voltar tudo ao seu ritmo natural. Acabei decidindo que depois de tanto tempo afastado e com tantas mudanças recentes, como por exemplo minha moradia, que mudou após longos 25 anos morando no mesmo local, talvez fosse a hora de mudar a casa também de meus posts. Porque não um novo espaço para o blog? Novo host, nova “decoração”, etc. Cá estamos, eu e o blog, de volta. Acredito que agora voltemos às atividades normais e rotineiras. Nos vemos no próximo post. Abraços! ","date":"2011-09-06","objectID":"/posts/casa-nova-em-todos-os/:0:0","tags":["Impressões"],"title":"Casa Nova Em Todos Os Sentidos","uri":"/posts/casa-nova-em-todos-os/"},{"categories":["Eventos"],"content":"Gostaria de comunicar que a grade para o 1º Dia Livre já foi fechada e liberada.","date":"2011-07-19","objectID":"/posts/dia-livre-inscricoes-e-grade/","tags":["Cultura Hacker","Dia Livre","Impressões","Linux","Redes","Segurança","Software Livre","Tux-ce"],"title":"Dia Livre - Inscrições E Grade Do Evento","uri":"/posts/dia-livre-inscricoes-e-grade/"},{"categories":["Eventos"],"content":"Gostaria de comunicar que a grade para o 1º Dia Livre já foi fechada e liberada. É hora de se inscrever no Dia Livre! Gostaria de comunicar que a grade para o 1º Dia Livre já foi fechada e liberada. Neste sábado estarei ministrando a palestra “Software Livre e Cultura Hacker: Tenha ética e ganharás respeito” na Faculdade Farias Brito durante o 1º Dia Livre. Segue grade do encontro: Horário Palestra Palestrante 08:00 - 08:10 Abertura Todos 08:10 - 09:00 Bacula - Solução livre de Backup Diego Monte 09:10 - 10:00 Criando soluções automatizadas com ShellScript Rafael de Carvalho Farias 10:00 - 10:20 CoffeeBreak Todos 10:30 - 11:20 Software Livre e a Cultura Hacker: Tenha Ética e Ganharás Respeito Marcelo Cavalcante 11:30 - 11:50 Sorteio de brindes e encerramento Todos Q****uando? 23 de Julho, Sábado – A partir das 08:00 Onde? Faculdade Farias Brito Rua Castro Monte, 1364 Varjota – Fortaleza, CE Serão realizados dois sorteios ao final do encontro: 1 camisa da Tux-CE; 1 livro: The Art of Community - O’Reilly Nos vemos lá! ","date":"2011-07-19","objectID":"/posts/dia-livre-inscricoes-e-grade/:0:0","tags":["Cultura Hacker","Dia Livre","Impressões","Linux","Redes","Segurança","Software Livre","Tux-ce"],"title":"Dia Livre - Inscrições E Grade Do Evento","uri":"/posts/dia-livre-inscricoes-e-grade/"},{"categories":["Impressões"],"content":"Para quem não sabe, hoje é o lançamento da primeira edição da Revista Segurança Digital","date":"2011-07-01","objectID":"/posts/lancada-a-primeira-edicao-da/","tags":["Cultura Hacker","Impressões","Linux","Literatura","Redes","Segurança","Segurança Digital","Software Livre"],"title":"Lançada a Primeira Edição Da Revista Segurança Digital","uri":"/posts/lancada-a-primeira-edicao-da/"},{"categories":["Impressões"],"content":"Saudações pessoal. Para quem não sabe, hoje é o lançamento da primeira edição da Revista Segurança Digital. Segurança Digital é o mais novo projeto no qual estou engajado e espero poder ajudar no que for possível para a constante melhoria do projeto. É com grande satisfação que estamos fazendo o lançamento oficial de nosso projeto com a primeira edição da Revista Segurança Digital. Neste mês de Julho a revista aborda aspectos mais genéricos em relação à Segurança da Informação como um todo. Desde as técnicas de FootPrinting e Varredura para identificação de vulnerabilidades e possíveis brechas até estratégias e mecanismos de Enumeração para reconhecimento de ambientes. Com a matéria sobre Enumeração explicamos a importância de se fazer um mapeamento completo do alvo, que consiste em descobrir o máximo de informações possíveis sobre o mesmo, desde sistema operacional até mesmo versões de anti-vírus, firewall, aplicativos instalados, etc. Recentemente todos perceberam que vários ataques de DoS e DDoS foram realizados à sites do Governo, Petrobras, dentre outros. Um artigo com uma breve explicação sobre como funcionam estes ataques é apresentado como forma de ilustrar de forma básica o funcionamento de um DoS/DDoS. Resolvemos fazer uma breve apresentação sobre o BackTrack, uma distribuição Linux voltada para testes de segurança. Nesta matéria apresentamos alguns de seus recursos e ferramentas que podem ser utilizadas no dia-a-dia de qualquer profissional de Segurança da Informação para facilitar suas tarefas e análises, bem como auxiliar em projetos de PenTesting. Aproveitamos para informar sobre a mais nova parceria realizada entre o Projeto Segurança Digital e a empresa de consultoria e soluções livres 4Linux que é líder no mercado no que diz respeito à soluções de tecnologia com ferramentas livres bem como treinamentos especializados nos mais diversos segmentos da computação como redes, bancos de dados, segurança, programação, dentre outros. Não deixe de fazer o download desta edição e conferir o resultado desta força tarefa inicial. Esperamos que gostem. ","date":"2011-07-01","objectID":"/posts/lancada-a-primeira-edicao-da/:0:0","tags":["Cultura Hacker","Impressões","Linux","Literatura","Redes","Segurança","Segurança Digital","Software Livre"],"title":"Lançada a Primeira Edição Da Revista Segurança Digital","uri":"/posts/lancada-a-primeira-edicao-da/"},{"categories":["Impressões"],"content":"Após mais um período conturbado na faculdade estou de volta ao blog com uma recomendação bibliográfica.","date":"2011-06-15","objectID":"/posts/recomendacao-bibliografica-as-brumas-de/","tags":["Impressões","Literatura"],"title":"Recomendação Bibliográfica: As Brumas De Avalon Vol II - A Grande Rainha","uri":"/posts/recomendacao-bibliografica-as-brumas-de/"},{"categories":["Impressões"],"content":"Após mais um período conturbado na faculdade estou de volta ao blog com uma recomendação bibliográfica. Desta vez estou concluindo a leitura do segundo volume da série As Brumas de Avalon, que aborda a história do Rei Artur através de uma visão das mulheres da época. Para quem não conhece e/ou não acompanhou o post sobre o primeiro volume, As Brumas de Avalon - A Senhora da Magia, fica o link. Neste segundo volume, As Brumas de Avalon - A Grande Rainha, o embate religioso entre o catolicismo e o paganismo se torna ainda mais intenso quando é chegado o momento da grande batalha prometida onde o Rei Artur quebra o juramento feito aos pagãos e seguidores da Antiga Religião. Através do juramento, Artur conseguiu ser seguido e apoiado por praticamente todos os povos que o seguiríam no combate contra os saxões com a promessa de o mesmo utilizar a bandeira do Dragão, anteriormente utilizada por seu pai, como forma de demonstrar que Artur não seguiria apenas a bandeira cristã, mas que respeitaria todas as formas de culto religioso. Esta era a promessa para que todos os povos pudessem se unir e lutar ao seu lado para unificar a Bretanha. Uma vez que Artur, se deixando levar pela mente extremamente cristã de sua esposa, resolve quebrar a promessa e levar ao campo de batalha apenas a bandeira cristã, muitos povos retiram o seu apoio oferecido ao combate. Sua irmã, e mãe de seu filho, Morgana, passa a ganhar maior destaque neste segundo volume pela mudança de seu comportamento onde, praticamente, abre mão de seu papel como sacerdotisa para viver experiências pessoais de isolamento que a fazem perder boa parte dos acontecimentos do mundo real. Para quem curte ficção, misticismo, paganismo e embates religiosos, com certeza será uma boa leitura. Abraços, ","date":"2011-06-15","objectID":"/posts/recomendacao-bibliografica-as-brumas-de/:0:0","tags":["Impressões","Literatura"],"title":"Recomendação Bibliográfica: As Brumas De Avalon Vol II - A Grande Rainha","uri":"/posts/recomendacao-bibliografica-as-brumas-de/"},{"categories":["Eventos"],"content":"Gostaria de comunicar sobre o lançamento oficial do site do Dia Livre que se deu ontem, Domingo.","date":"2011-05-16","objectID":"/posts/dia-livre-lancamento-oficial-do/","tags":["Cultura Hacker","Impressões","Linux","Software Livre"],"title":"Dia Livre - Lançamento Oficial Do Site","uri":"/posts/dia-livre-lancamento-oficial-do/"},{"categories":["Eventos"],"content":"Gostaria de comunicar sobre o lançamento oficial do site do Dia Livre que se deu ontem, Domingo. Recentemente escrevi sobre um encontro regular que pretendemos organizar para usuários e profissionais de Software Livre em nossa região. Ontem o site do Dia Livre foi lançado oficialmente e servirá de ponto de acesso e informações sobre tudo o que envolve o mesmo, como fotos, vídeos, inscrições, agenda, notícias, etc. Em suas várias edições pretendemos abordar os mais diversos temas que rondam o mundo da tecnologia e do Software Livre como desenvolvimento, design, redes, segurança, bancos de dados, segurança, etc. Além de tecnologia, o evento também tende a abordar temas ligados à cultura, inclusão digital e social, dentre outros aspectos de importância e relevância similar. Ainda não sabe o que é o Dia Livre? Que tal visitar a página de apresentação do evento? Deseja se manter informado? Você também pode seguir o @dia_livre no twitter e ficar por dentro do que rola. Em breve teremos maiores notícias sobre a primeira edição. Abraços! ","date":"2011-05-16","objectID":"/posts/dia-livre-lancamento-oficial-do/:0:0","tags":["Cultura Hacker","Impressões","Linux","Software Livre"],"title":"Dia Livre - Lançamento Oficial Do Site","uri":"/posts/dia-livre-lancamento-oficial-do/"},{"categories":["Tutoriais"],"content":"Para aqueles que também não curtem de forma alguma a aparência padrão GTK do Wicd e não conhecem ainda a interface que foi lançada posteriormente em QT, fica a dica: Troquem com urgência!","date":"2011-04-28","objectID":"/posts/wicd-kde-tornando-seu-wicd/","tags":["Arch Linux","Impressões","KDE","Linux","Software Livre"],"title":"Wicd Kde - Tornando Seu Wicd No Kde Mais Amigavel","uri":"/posts/wicd-kde-tornando-seu-wicd/"},{"categories":["Tutoriais"],"content":"Saudações pessoal, Para aqueles que também não curtem de forma alguma a aparência padrão GTK do Wicd e não conhecem ainda a interface que foi lançada posteriormente em QT, fica a dica: Troquem com urgência! E o network-manager? Bom, o network-manager é um excelente(sendo modesto) gerenciador de redes para o Linux, porém infelizmente ele peca muito em sua interface para o KDE. Compare o network-manager em suas interfaces gtk (Gnome) e qt (KDE) e entenderá o que eu digo. A versão para KDE é extremamente confusa e bagunçada em comparação com a interface para o Gnome. Eis que muitas distribuições começaram a sugerir a utilização do Wicd como gerenciador de redes para quem utiliza o KDE. No Arch, por exemplo, encorajamos fortemente o uso do Wicd com o KDE ao invés do network-manager. Sim, sempre utilizei ele, porém… E então? Meio bizarro, certo?! Alguém havia pensado em dizer “Mas ele não é tão feio..”? Bom, que tal apresentar uma alternativa a isto? O wicd-kde! Como uma imagem vale mais que mil palavras: Mais amigável certo? Uma interface mais limpa, organizada e bonita. Bem ao estilo “clean”, como alguns preferem dizer. Mas, deixando um pouco a frescura de lado. Não recomendo a utilização da interface em qt apenas por questões de estética. A verdade é que o seu ambiente fica mais limpo com esta interface. Limpo? Sim. Se você utiliza o KDE mas possui aplicações em gtk, por consequência você possuirá uma série de bibliotecas instaladas em seu ambiente para fazer com que esta aplicação em gtk funcione da maneira correta. Porém, se você instala uma aplicação em qt, pouca coisa adicional será necessária, visto que seu sistema já está preparado para rodar este tipo de aplicação. Digamos que é uma união: Útil ao Agradável! E a parte que interessa? Instalar, instalar, instalar! Infelizmente, nem todas as distribuições empacotaram o wicd-kde até então, mas se você é usuário Arch Linux, a sua vida será mais fácil. O pacote wicd-kde encontra-se pronto no AUR. O processo é o já manjado: 1- Baixar o arquivo compactado: $ wget https://aur.archlinux.org/packages/wicd-client-kde-git/wicd-client-kde-git.tar.gz 2- descompactar: $ tar -xvzf wicd-client-kde-git.tar.gz 3- entrar no diretório e em seguida executar o PKGBUILD para geração do pacote em si: $ cd wicd-client-kde-git $ makepkg 4- Instalar o pacote gerado: pacman -U wicd-client-kde-git-20110426-1-x86_64.pkg.tar.xz Feito. ;] Have Fun! Abraços! ","date":"2011-04-28","objectID":"/posts/wicd-kde-tornando-seu-wicd/:0:0","tags":["Arch Linux","Impressões","KDE","Linux","Software Livre"],"title":"Wicd Kde - Tornando Seu Wicd No Kde Mais Amigavel","uri":"/posts/wicd-kde-tornando-seu-wicd/"},{"categories":["Aleatórios"],"content":"Para quem ainda não sabe, a Tux-CE está lançando os novos modelos de suas camisas e está coletando a listagem de pessoas interessadas em comprar a(s) sua(s).","date":"2011-04-27","objectID":"/posts/novas-camisas-da-tux-ce/","tags":["Impressões","Tux-ce"],"title":"Novas Camisas Da Tux-Ce - Solicite a Sua","uri":"/posts/novas-camisas-da-tux-ce/"},{"categories":["Aleatórios"],"content":"Para quem ainda não sabe, a Tux-CE está lançando os novos modelos de suas camisas e está coletando a listagem de pessoas interessadas em comprar a(s) sua(s). n O valor ainda não está 100% definido, pois o valor vai depender da quantidade de camisas. Caso tenha interesse, preencha este formulário e em breve entraremos em contato com você para informar valores e saber se você realmente irá querer seguir com seu pedido. Interessado? Confira todos os modelos disponíveis em Aqui. Preencha o formulário para solicitar a(s) sua(s) Aqui. Abraços! ","date":"2011-04-27","objectID":"/posts/novas-camisas-da-tux-ce/:0:0","tags":["Impressões","Tux-ce"],"title":"Novas Camisas Da Tux-Ce - Solicite a Sua","uri":"/posts/novas-camisas-da-tux-ce/"},{"categories":["Aleatórios"],"content":"Se você é ou conhece algum usuário de Arch Linux aqui no Ceará, favor entrar em contato.","date":"2011-04-26","objectID":"/posts/procura-se-usuarios-de-arch/","tags":["Arch Linux","Impressões","Linux","Software Livre"],"title":"Procura-Se Usuários De Arch Linux No Ceará","uri":"/posts/procura-se-usuarios-de-arch/"},{"categories":["Aleatórios"],"content":"Se você é ou conhece algum usuário de Arch Linux aqui no Ceará, favor entrar em contato. Infelizmente não estamos em condições de oferecer recompensas financeiras pelas denúncias ou comparecimentos voluntários. Quem sabe, uma cervejinha ou duas, até que rola. Brincadeiras a parte, de fato estamos buscando usuários do Arch Linux em nosso estado. O fato é que o Arch Linux Brasil como um todo vem começando uma campanha de “localização” de usuários em diversos estados como uma forma de estreitar as relações entre estes. A ideia é procurar uma forma de fazer com que os usuários de Arch Linux possam ter uma maior interação entre si, o que facilita na organização de encontros, eventos, install fests, etc. No momento estamos mapeando e buscando interessados na ideia, portanto fica o convite: Se você é usuário do Arch Linux e mora no Ceará ou conhece algum usuário do Arch Linux por aqui, passe a informação. Por favor se identifique através do seguinte link: Arch Fórum. Abraços! ","date":"2011-04-26","objectID":"/posts/procura-se-usuarios-de-arch/:0:0","tags":["Arch Linux","Impressões","Linux","Software Livre"],"title":"Procura-Se Usuários De Arch Linux No Ceará","uri":"/posts/procura-se-usuarios-de-arch/"},{"categories":["Tutoriais"],"content":"Cansado de apenas poder assistir aquele webcast ou vídeo-aula online? E se estiver em um local sem conec﻿tividade? Porque dor de cabeça? Sou usuário Linux! Obrigado por ter a ideia de criar o Linux e facilitar nossas vidas Linus. ;]","date":"2011-04-20","objectID":"/posts/como-download-de-webcasts-mms/","tags":["Arch Linux","Impressões","Linux","Software Livre"],"title":"Como? Download De Webcasts Mms E Rtmp?","uri":"/posts/como-download-de-webcasts-mms/"},{"categories":["Tutoriais"],"content":"Cansado de apenas poder assistir aquele webcast ou vídeo-aula online? E se estiver em um local sem conec﻿tividade? Porque dor de cabeça? Sou usuário Linux! Obrigado por ter a ideia de criar o Linux e facilitar nossas vidas Linus. ;] Recentemente me deparei com esta problemática. Como realizar o download deste tipo de conteúdo? Ao checar o código fonte da página que exibia o vídeo, vi que eram streamings dos protocolos mms ou rtmp, o que, aparentemente, dificultava o download. Para quem mais estiver passando por este problema, segue a solução. Aliás, as soluções. Uma vez que, através do código fonte você consiga identificar a URL completa do arquivo mmc ou rmtp, fica fácil utilizar alguma das metodologias a seguir. A primeira opção é a aplicação Mimms. Esta é a forma mais simples e prática com arquivos do tipo mms. Para usuários do Arch Linux, já existe um pacote pronto no AUR. A instalação, segue o padrão de arquivos baixados do AUR: 1- Download do Tarball; 2- Descompatar: $ tar -xvzf mimms.tar.gz 3- Acessar o diretório e efetuar a compilação do pacote: $ cd mimms \u0026\u0026 makepkg 4- Instalar o pacote que lhe foi gerado: # pacman -U mimms-3.2.1-2-any.pkg.tar.xz Feito. Agora é só executar da seguinte forma: $ mimms mms://url_de_origem_do_streaming/arquivo_streaming.wmv Será que isso funciona mesmo? Experimente: $ mimms [mms://wms.andrew.cmu.edu/001/pausch.wmv](mms://wms.andrew.cmu.edu/001/pausch.wmv) Oi, simples assim. Outra alternativa? Utilizando o Mencoder: Não é tão simples quanto o mimms, mas também é rápido e prático. O comando que deve ser utilizado? mencoder mms://url_de_origem_do_streaming/arquivo_streaming.wmv -o arquivo_streaming.wmv -oac copy -ovc copy Um pouco mais complexo, certo? Mas funciona. E quanto aos arquivos de streaming que utilizam o protocolo rtmp? Neste caso a opção é utilizarmos o rtmpdump. Sim, claro.. Se você utiliza o Arch Linux, sua vida continua simplificada: # pacman -S rtmpdump Pronto, está instalado. ;] A execução do mesmo também é bastante simples, precisando apenas especificar a origem e o destino do streaming em questão. Segue sintaxe: rtmpdump -r \"rtmpe://url_de_origem_do_streaming/arquivo_streaming.wmv\" -o arquivo.streaming.flv --resume Have fun! ;] Abraços! ","date":"2011-04-20","objectID":"/posts/como-download-de-webcasts-mms/:0:0","tags":["Arch Linux","Impressões","Linux","Software Livre"],"title":"Como? Download De Webcasts Mms E Rtmp?","uri":"/posts/como-download-de-webcasts-mms/"},{"categories":["Eventos"],"content":"Acredito que boa parte, se não praticamente todos, os usuários de Software Livre em nossa região já ouviram falar, ou participaram, do Flisol - Festival Latino Americano de Instalação de Software Livre.","date":"2011-04-19","objectID":"/posts/encontros-sobre-software-livre-escolha/","tags":["Cultura Hacker","Flisol","Impressões","Linux","Software Livre","Tux-ce"],"title":"Encontros Sobre Software Livre - Escolha Um Nome","uri":"/posts/encontros-sobre-software-livre-escolha/"},{"categories":["Eventos"],"content":"Saudações pessoal, Acredito que boa parte, se não praticamente todos, os usuários de Software Livre em nossa região já ouviram falar, ou participaram, do Flisol - Festival Latino Americano de Instalação de Software Livre. É um encontro legal, rolam palestras interessantes e podemos bater um papo com pessoas do ramo, fazendo novos amigos e/ou contatos profissionais. Lado ruim? Acontece apenas uma vez por ano. :/ E se tivéssemos um encontro com a comunidade local de Software Livre com uma maior regularidade? Que tal 4, 5 ou até mesmo 6 encontros destes por ano? Palestras, bate-papo, mesa-redonda, etc. Gostou da ideia? A Tux-CE está com uma proposta neste sentido. A ideia é termos um mini-evento com maior frequência em nossa região como forma de fortalecer a ideia do Software Livre e ao mesmo tempo aumentar a integração entre nós, usuários e profissionais do ramo. Uma forma de beneficiar a todos. Se você não pode ir hoje, em breve você terá outra chance. Não fica perto da sua casa? Na próxima edição poderá ser mais próximo de você. A ideia não é substituir ou concorrer com o Flisol, mesmo porque será um evento infinitamente menor, mas sim somar. Ser uma opção a mais para a nossa comunidade de Software Livre. Um evento simples e rápido onde podemos ter palestras e bate papos sobre software livre, linux, cultura hacker, redes, segurança, programação, etc. Por se tratar de um evento comunitário, nada mais justo que deixar a comunidade ajudar a moldar o evento como um todo. Acreditamos que o início de tudo, está na escolha do nome. Na semana passada coletamos várias sugestões de nomes em nossa lista. Todos os nomes sugeridos, sem excessão, foram inseridos em nossa pesquisa com o mesmo peso. Agora chegou a hora de definir o nome. Gostaria de ajudar? Sinta-se convidado a votar em nossa enquete que encontra-se na página da Tux-CE através deste link. Contamos com o seu voto para nos ajudar a iniciar este movimento. Abraços! ","date":"2011-04-19","objectID":"/posts/encontros-sobre-software-livre-escolha/:0:0","tags":["Cultura Hacker","Flisol","Impressões","Linux","Software Livre","Tux-ce"],"title":"Encontros Sobre Software Livre - Escolha Um Nome","uri":"/posts/encontros-sobre-software-livre-escolha/"},{"categories":["Eventos"],"content":"Algumas pessoas já me perguntaram nos últimos 3 dias porque eu não estava no Flisol Fortaleza este ano. -Cara, nem lhe vi lá pelo Flisol correndo pra cima e pra baixo esse ano.-","date":"2011-04-13","objectID":"/posts/flisol-quixada-relato-e-parabens/","tags":["Arch Linux","Cultura Hacker","Flisol","Impressões","Jogos","Linux","Segurança","Software Livre","Tux-ce"],"title":"Flisol Quixadá -  Relato E Parabéns","uri":"/posts/flisol-quixada-relato-e-parabens/"},{"categories":["Eventos"],"content":"Saudações galera! Algumas pessoas já me perguntaram nos últimos 3 dias porque eu não estava no Flisol Fortaleza este ano. “Cara, nem lhe vi lá pelo Flisol correndo pra cima e pra baixo esse ano.” Bom, como eu havia informado anteriormente, mas nem todos devem ter notado (certo Rodrigo, hehehe), este ano estive no Flisol de Quixadá. A oportunidade de palestrar por lá surgiu e resolvi mudar o ambiente do meu Flisol este ano. Logo na sexta-feira, dia em que cheguei em Quixadá, tive duas boas primeiras impressões: 1- O clima estava melhor do que o de Fortaleza. Sim, já não aguentava mais o nosso calor infernal. Por mais que eu já estivesse esperando um calor ainda maior, fiquei surpreso ao perceber que o tempo estava mais fresco. Talvez por conta da umidade… 2- Poucos minutos depois de minha chegada esbarro com o Ronaldo, também membro da Tux-CE, que optou por também palestrar no Flisol de Quixadá. Nos esbarramos no Hotel mesmo, já que acabamos ficando no mesmo. Já que citei o Hotel, gostaria de fazer dois agradecimentos. Primeiro ao Samy e demais membros da organização que possam ter feito os contatos com hotéis e agilizado nossa reserva por lá. Obrigado Samy e demais envolvidos. Segundo, a todos do Hotel Monólitos que nos receberam super bem e prestaram um excelente serviço. Logo na sexta aproveitamos para descansar depois de uma semana corrida de trabalho em Fortaleza. Eu e Ronaldo fomos para um restaurante que ficava próximo ao Hotel, onde tomamos umas cervejinhas e comemos uma excelente carne. No domingo fui descobrir que neste mesmo restaurante fazem a melhor bisteca que já comi na minha vida. Portanto, se alguém tiver a chance de visitar Quixadá, não deixe de comer uma bisteca caprichada no Ponto da Bisteca. O Araújo, que estava no time de organização do evento, acabou nos encontrando por lá rapidamente nesta noite. No sábado, optei por ir bem cedo ao evento. Sim, gosto de ver as coisas por trás dos bastidores. Não gosto de apenas chegar, palestrar e ir embora. Minha primeira surpresa do dia? Uma equipe de aproximadamente 30 pessoas na equipe de organização do Flisol! o.O Bom, sei que no dia já parabenizei a todos eles, várias vezes por sinal, mas deixo novamente os parabéns. Estive envolvido direta ou indiretamente em todas as edições do Flisol Fortaleza desde o ano de 2006 e nunca vi uma equipe de organização com tanta gente disposta a ajudar. Vocês estão de parabéns. Depois de “participar” como ouvinte da primeira reunião do dia com a equipe de organização do evento, os preparativos de última hora começaram e aproveitei para conhecer o local do evento, dar uma volta, etc. O evento aconteceu na Faculdade Católica Rainha do Sertão, que por sinal é linda e bem arborizada. O evento contou com duas apresentações de abertura: Um show de humor e um grupo de dança. Infelizmente não lembro o nome do Humorista ou do grupo de dança para deixar os devidos créditos. Mas, ambos estão de parabéns também. Ainda durante a apresentação de humor tive minha segunda surpresa do dia. Um dos integrantes do time de organização me chamou para um canto mais afastado do ginásio e me fez um convite para uma breve filmagem que eles estavam preparando. Como não estava esperando por isso, acabei tendo de improvisar algo. Mas deu tudo certo, espero. o.O Em seguida tive minha terceira surpresa do dia. O evento contou com uma rápida mesa de cerimônia para abertura oficial do evento, para a qual fui convidado de surpresa, Samy vocẽ me paga onde foi dada uma breve explicação sobre o intuito e importância do evento bem como do Software Livre como um todo para a comunidade em geral. Após esta breve apresentação foram iniciadas as palestras. E como fui o primeiro palestrante do dia, tive a minha quarta surpresa no evento. Sim, muitas surpresas logo no período da manhã. hehe A surpresa? A enorme quantidade de pessoas que estavam ali sentadas assistindo minha palestra. Por achar que não teria a menor condição de palestrar sem microfone acabei optando por utiliz","date":"2011-04-13","objectID":"/posts/flisol-quixada-relato-e-parabens/:0:0","tags":["Arch Linux","Cultura Hacker","Flisol","Impressões","Jogos","Linux","Segurança","Software Livre","Tux-ce"],"title":"Flisol Quixadá -  Relato E Parabéns","uri":"/posts/flisol-quixada-relato-e-parabens/"},{"categories":["Impressões"],"content":"Como citou o grande Stephen King, -Esta é a história de vampiros que você não pode perder: 15 páginas são suficientes para cativá-lo; depois de 30, você se descobrirá prisioneiro, lendo noite adentro. Um livro com a força dos épicos.-","date":"2011-04-12","objectID":"/posts/recomendacao-bibliografica-a-passagem/","tags":["Impressões","Literatura"],"title":"Recomendação Bibliográfica: A Passagem","uri":"/posts/recomendacao-bibliografica-a-passagem/"},{"categories":["Impressões"],"content":"Como citou o grande Stephen King, “Esta é a história de vampiros que você não pode perder: 15 páginas são suficientes para cativá-lo; depois de 30, você se descobrirá prisioneiro, lendo noite adentro. Um livro com a força dos épicos.” Para quem, assim como eu, adora ficção, vampiros e contos que exploram o sobrenatural, mas que ao mesmo tempo está cansado de tanta babaquice e melação como Crepúsculo, Vampire Diaries, etc… Esta orba de Justin Cronin promete ser uma excelente pedida. E se os vampiros não são algo tão sobrenatural assim? E se eles pudessem ser criados em laboratórios? Em A Passagem a história se inicia com agentes do FBI que escolhem a dedo prisioneiros condenados à morte para participarem como “voluntários” de um programa secreto do governo. Uma falha na segurança das instalações secretas do governo onde os experimentos com estes condenados eram feitos permite a fuga destes que já não mais são homens. O experimento militar ao qual eles eram submetidos lhes dá força e velocidade infinitamente superiores a dos seres humanos comuns. Além destas características, a sensibilidade ao sol e a capacidade de regeneração de seus corpos de forma extremamente rápida juntam-se ao comportamento animal e sedento de sangue tiram os últimos sinais de humanidade destas criaturas. Em estado de alerta a humanidade começa a viver uma enorme crise. Cidades e países inteiros começam a efetuar um evacuamento massivo e a quantidade de pessoas infectadas pelo vírus começa a crescer rapidamente. Em poucos anos a humanidade parece perdida, até que se descobre que alguns poucos sobreviventes começam a formar grupos e fortificações para viverem isolados buscando se proteger destes infectados da forma como podem. Ao meio de tudo isso a humanidade encontra-se vivendo com medo da noite, sobrevivendo de forma precária, vivenciando a morte a cada dia. Alguns acontecimentos começam a rondar Amy, a única criança que passou pelos mesmos experimentos mas conseguiu escapar na noite da fuga dos virais. O problema é que Amy parece não ter se tornado uma criatura, como as demais cobaias. Tudo leva a crer que ela continua um ser humano comum, porém a sensibilidade à luz solar e o fato de ela não ter envelhecido fisicamente com o passar das décadas acaba gerando dúvidas em todos os que estão ao seu redor. O mais esquisito parece ser a reação dela frente aos virais, bem como a reação deles ao se aproximarem dela. Sem dúvida alguma, uma leitura que recomendo. Agradeço, novamente, à minha namorada Mari que, como sempre, me presenteia com excelentes livros. ;] Segue sinopse do mesmo retirada da livraria Saraiva: Esta é a história de vampiros que você não pode perder: 15 páginas são suficientes para cativá-lo; depois de 30, você se descobrirá prisioneiro, lendo noite adentro. Um livro com a força dos épicos.” – Stephen King Primeiro, o imprevisível: a quebra de segurança em uma instalação secreta do governo norte-americano põe à solta um grupo de condenados à morte usados em um experimento militar. Infectados com um vírus modificado em laboratório que lhes dá incrível força, extraordinária capacidade de regeneração e hipersensibilidade à luz, tiveram os últimos traços de humanidade substituídos por um comportamento animalesco e uma insaciável sede de sangue. Depois, o inimaginável: ao escurecer, o caos e a carnificina se instalam, e o nascer do dia seguinte revela um país – talvez um planeta – que nunca mais será o mesmo. A cada noite, a população humana se reduz e cresce o número de pessoas contaminadas pelo vírus assustador. Tudo o que resta aos poucos sobreviventes é uma longa luta em uma paisagem marcada pelo medo da escuridão, da morte e de algo ainda pior. Enquanto a humanidade se torna presa do predador criado por ela mesma, o agente Brad Wolgast, do FBI, tenta proteger Amy, uma órfã de 6 anos e a única criança usada no malfadado experimento que deu início ao apocalipse. Mas, para Amy, esse é apenas o começo de uma longa jornada – através de décadas e mil","date":"2011-04-12","objectID":"/posts/recomendacao-bibliografica-a-passagem/:0:0","tags":["Impressões","Literatura"],"title":"Recomendação Bibliográfica: A Passagem","uri":"/posts/recomendacao-bibliografica-a-passagem/"},{"categories":["Eventos"],"content":"Para quem ainda não conhece, o Flisol - Fórum Latino Americano de Instalação de Software Livre - é um dos maiores eventos do mundo no que diz respeito ao movimento de Software Livre. O evento é realizado anualmente e ocorre de forma simultânea em diversas cidades da América Latina, totalizando mais de 120 cidades em aproximadamente 20 países. O Flisol é um evento descentralizado, onde diversas comunidades organizam e realizam seu festival, de forma voluntária, tendo como principal objetivo promover o uso de Software Livre, apresentando sua filosofia, alcance, avanços e desenvolvimento ao público em geral.","date":"2011-04-07","objectID":"/posts/flisol-ceara-fortaleza-quixada-e/","tags":["Cultura Hacker","Flisol","Impressões","Linux","Software Livre","Tux-ce"],"title":"Flisol Ceará: Fortaleza, Quixadá E Russas","uri":"/posts/flisol-ceara-fortaleza-quixada-e/"},{"categories":["Eventos"],"content":"Para quem ainda não conhece, o Flisol - Fórum Latino Americano de Instalação de Software Livre - é um dos maiores eventos do mundo no que diz respeito ao movimento de Software Livre. O evento é realizado anualmente e ocorre de forma simultânea em diversas cidades da América Latina, totalizando mais de 120 cidades em aproximadamente 20 países. O Flisol é um evento descentralizado, onde diversas comunidades organizam e realizam seu festival, de forma voluntária, tendo como principal objetivo promover o uso de Software Livre, apresentando sua filosofia, alcance, avanços e desenvolvimento ao público em geral. O evento é gratuito e aberto a todo o público: curiosos, interessados e amantes do Software Livre. Nesse dia os voluntários propõe a instalação de Software Livre, como distribuições de Gnu/Linux, sistemas BSD, e aplicativos livres para Windows em geral. Alguns eventos também contam com palestras, oficinas, salas de degustação e gravações de mídias (live-CD/DVD e/ou pendrives). O objetivo do Flisol, além de promover o uso de Software Livre em geral, é também o de criar interações entre usuários e desenvolvedores, promovendo um momento para troca de experiências, conhecimentos ou mesmo um bate papo agradável que pode resultar em futuros projetos ou apenas amizades. Diferente dos anos anteriores, este ano não estarei presente em Fortaleza durante o Flisol, mas a Tux-CE marcará presença como de costume no Install Fest para atender e ajudar aos interessados. Estarei no Flisol de Quixadá ministrando as palestras: Cultura Hacker - Tenha Ética e Ganharás Respeito Software Livre - Nunca vi nem comi, eu só ouço falar! Este ano teremos 3 edições do Flisol em nosso estado, portanto escolha a mais próxima de você e marque presença. Em Fortaleza: Local: Vila das Artes Endereço: Rua 24 de Maio, 1221, Centro Telefone: 85 3252-1444 Em Quixadá: Local: Faculdade Católica do Sertão Endereço: Rua Juvêncio Alves, 660, Centro Telefone: 88 3412-6700 Em Russas: Local: Escola Estadual Manuel Matoso Filho Endereço: Rua Cel. Perdigão Sobrinho, 433, Centro Telefone: 88 3411-8550 L****embrando que, apesar de ser um evento gratuito, sempre estamos recebendo doações de alimentos não perecíveis no evento que irão beneficiar entidades e órgãos diversos, portanto não esqueça o seu 1kg de alimento não perecível. Maiores informações sobre o Flisol Ceará, através deste link. Nos vemos no Flisol. Abraços! ","date":"2011-04-07","objectID":"/posts/flisol-ceara-fortaleza-quixada-e/:0:0","tags":["Cultura Hacker","Flisol","Impressões","Linux","Software Livre","Tux-ce"],"title":"Flisol Ceará: Fortaleza, Quixadá E Russas","uri":"/posts/flisol-ceara-fortaleza-quixada-e/"},{"categories":["Impressões"],"content":"Bom, de fato foi o que aconteceu. O KDE 4.6.2 foi lançado e para demonstrar que a briga entre usuários KDE x GNOME simplesmente não faz sentido, esta release foi batizada de -Congrats-, parabéns em português, em homenagem ao lançamento do GNOME 3 que teve mesma data.","date":"2011-04-07","objectID":"/posts/kde-4-6-2-lancado/","tags":["Arch Linux","Impressões","KDE","Linux","Software Livre"],"title":"Kde 4.6.2 Lançado - Parabéns Ao Gnome","uri":"/posts/kde-4-6-2-lancado/"},{"categories":["Impressões"],"content":"Estranho o título? Bom, de fato foi o que aconteceu. O KDE 4.6.2 foi lançado e para demonstrar que a briga entre usuários KDE x GNOME simplesmente não faz sentido, esta release foi batizada de “Congrats”, parabéns em português, em homenagem ao lançamento do GNOME 3 que teve mesma data. Realmente é deplorável quando as listas, fórums e canais estão infectados com insultos contra ambiente gráfico X ou distribuição Y. É claro que sempre vão existir diferenças e brincadeiras sobre qual é o melhor, quem tem vantagem, etc. Afinal, somos humanos e temos gostos diferentes, certo?! Assim como existem piadas e brincadeiras entre torcedores de times opostos, no mundo da computação isso sempre vai existir também. O problema é quando se torna algo de mal gosto ou agressivo. Enfim… Para demonstrar que o projeto KDE realmente não liga para estas briguinhas infantis, e que não encara o projeto GNOME como um oponente que deve ser batido, a nova release do KDE 4.6.2 recebeu o nome de “Congrats” para homenagear o tão esperado lançamento do GNOME 3. Segue um pequeno trecho traduzido da notícia oficial no site do KDE: “Com o codinome “Congrats\" (parabéns) dedicamos este lançamento para os nossos amigos no lado GNOME, que lançam uma nova versão principal hoje.” Muitas melhorias chegaram com esta release, no geral correções de bugs ou melhorias de performance. Para detalhes do changelog, acesse este link. Claro, se você é usuário Arch Linux, já pode ter o seu KDE 4.6.2, que encontra-se disponível nos repositórios do pacman. Basta atualizar seu sistema, caso já tenha o KDE instalado em outra versão: pacman -Syu Que isto sirva de exemplo para nós, usuários. ;] Abraços! ","date":"2011-04-07","objectID":"/posts/kde-4-6-2-lancado/:0:0","tags":["Arch Linux","Impressões","KDE","Linux","Software Livre"],"title":"Kde 4.6.2 Lançado - Parabéns Ao Gnome","uri":"/posts/kde-4-6-2-lancado/"},{"categories":["Eventos"],"content":"Gostaria de lembrar a todos os interessados que amanhã teremos o III Pylestras aqui em Fortaleza.","date":"2011-03-23","objectID":"/posts/iii-pylestras-neste-sabado/","tags":["Impressões","Python","Software Livre"],"title":"III Pylestras Neste Sábado","uri":"/posts/iii-pylestras-neste-sabado/"},{"categories":["Eventos"],"content":"Gostaria de lembrar a todos os interessados que amanhã teremos o III Pylestras aqui em Fortaleza. Se você não faz ideia sobre o que seja Python ou sabe que é uma linguagem de programação mas não conhece maiores detalhes sobre a mesma, recomendo a leitura destes links bem como sua participação no evento, que com certeza será bem interessante. The Zen Of Phyton Porque Python? Porque escolhi Python - Python para SysAdmins O evento consiste em 4 palestras conforme apresentadas abaixo: Pyoquê? That n00b is behaving like a bloody git Não desperdice seu tempo, use Django extensions SQLAlchemy - Desenvolvendo uma aplicação com Python O evento acontecerá na Faculdade Farias Brito no horário entre 8:00 e 12:00. Além das palestras o evento contará com um sorteio do livro Python e Django - Desenvolvimento Ágil de Aplicações Web. O evento está sendo organizado pelo pessoal do PUG-CE (Python User Group Ceará). Para maiores detalhes sobre o evento, visite a página: Aqui! Abraços! ","date":"2011-03-23","objectID":"/posts/iii-pylestras-neste-sabado/:0:0","tags":["Impressões","Python","Software Livre"],"title":"III Pylestras Neste Sábado","uri":"/posts/iii-pylestras-neste-sabado/"},{"categories":["Tutoriais"],"content":"É um vírus? É um trojan? É um spyware? Não, é um rootkit mesmo.","date":"2011-03-16","objectID":"/posts/rootkit-esse-bicho-morde-proteja/","tags":["Arch Linux","Cultura Hacker","Impressões","Linux","Redes","Segurança","Software Livre"],"title":"Rootkit: Esse Bicho Morde, Proteja-Se","uri":"/posts/rootkit-esse-bicho-morde-proteja/"},{"categories":["Tutoriais"],"content":"Você sabe o que é rootkit? Nunca vi, nem comi, eu só ouço falar! ","date":"2011-03-16","objectID":"/posts/rootkit-esse-bicho-morde-proteja/:0:0","tags":["Arch Linux","Cultura Hacker","Impressões","Linux","Redes","Segurança","Software Livre"],"title":"Rootkit: Esse Bicho Morde, Proteja-Se","uri":"/posts/rootkit-esse-bicho-morde-proteja/"},{"categories":["Tutoriais"],"content":"Introdução É um vírus? É um trojan? É um spyware? Não, é um rootkit mesmo. A verdade é que ainda não existe um consenso em relação ao que o rootkit é de fato. Muitos dizem que é um tipo de vírus, alguns dizem que é um trojan, como você chamaria? Eu prefiro chamar de malware, que, ao pé da letra, seria um termo utilizado para algum aplicativo contendo código malicioso. o.O Acho que seria um meio termo aceitável para que possamos utilizar como base. Mas esse bicho morde? É de comer? Bom, em tese um Rootkit é um tipo de malware, como expliquei acima, cuja principal intenção é se camuflar, impedindo que seu código seja encontrado por qualquer antivírus. Teoricamente, é exatamente isto que ele tenta fazer. Passar despercebido. De fato a grande maioria dos antivírus não são capazes de rastrear Rootkits justamente por conta do seu comportamento. É aí que surgiram ferramentas especializadas neste tipo de busca. Alguns antivírus, os mais caros, já agregam excelentes ferramentas para buscar rootkits. Mas, como eles conseguem se camuflar tão bem? ","date":"2011-03-16","objectID":"/posts/rootkit-esse-bicho-morde-proteja/:1:0","tags":["Arch Linux","Cultura Hacker","Impressões","Linux","Redes","Segurança","Software Livre"],"title":"Rootkit: Esse Bicho Morde, Proteja-Se","uri":"/posts/rootkit-esse-bicho-morde-proteja/"},{"categories":["Tutoriais"],"content":"Rootkits Estas aplicações, rootkits, têm a capacidade de interceptar as solicitações feitas ao sistema operacional, podendo alterar o seu resultado. Imagine que você está utilizando sua máquina e seu sistema operacional solicita a leitura ou abertura de um determinado arquivo, podendo ser a seu mando ou mesmo do antivírus, por exemplo, o rootkit intercepta os dados que são requisitados e faz uma filtragem dessa informação, deixando passar apenas o que ele deseja, ou seja, código não infectado. E o que acontece? O antivírus ou qualquer outra ferramenta ficam impossibilitadas de encontrar o arquivo malicioso ou o código, dependendo do caso. Não é incomum encontrar o Rootkit como não apenas uma aplicação, mas um conjunto de aplicações ou, como também chamamos, toolkit. Resumidamente poderíamos dizer que é um programa com código malicioso que busca se esconder de softwares de segurança e do usuário utilizando diversas técnicas avançadas de programação para tal. Geralmente escondem suas chaves nos registros do sistema operacional e escondem seus processos no gerenciador de tarefas, o que torna uma missão quase impossível para um usuário identificar por conta própria. Outra prática comum de quem escreve rootkits é fazer com que eles se escondam em drivers de hardware, que são arquivos de sistema fundamentais para que o sistema operacional funcione corretamente com seus dispositivos. O nome RootKit é por conta da função para a qual o mesmo é desenvolvido. Primeiramente ele é um kit de funcionalidades e códigos maliciosos cujo objetivo é se infiltrar nos sistemas de forma silenciosa e despercebida, geralmente liberando um *backdoor para que o invasor possa posteriormente acessar o sistema infectado com privilégios de super usuário ou usuário administrador (root). Para quem nunca ouviu falar em backdoors, a explicação pode ter parecido um tanto quanto confusa, portanto aqui vai a nota de rodapé: Backdoor é, assim como na tradução ao pé da letra, uma porta dos fundos. Uma falha de segurança intencional que possibilita a invasão do seu sistema de forma que o invasor possa ter este acesso e controle com um mínimo de trabalho. Sem mais papo furado, vamos conhecer algumas ferramentas que buscam rootkits em seu Linux. ","date":"2011-03-16","objectID":"/posts/rootkit-esse-bicho-morde-proteja/:2:0","tags":["Arch Linux","Cultura Hacker","Impressões","Linux","Redes","Segurança","Software Livre"],"title":"Rootkit: Esse Bicho Morde, Proteja-Se","uri":"/posts/rootkit-esse-bicho-morde-proteja/"},{"categories":["Tutoriais"],"content":"Ferramentas ","date":"2011-03-16","objectID":"/posts/rootkit-esse-bicho-morde-proteja/:3:0","tags":["Arch Linux","Cultura Hacker","Impressões","Linux","Redes","Segurança","Software Livre"],"title":"Rootkit: Esse Bicho Morde, Proteja-Se","uri":"/posts/rootkit-esse-bicho-morde-proteja/"},{"categories":["Tutoriais"],"content":"RKHUNTER A primeira ferramenta que vou apresentar se chama rkhunter, que é a minha favorita. Se, assim como eu, você for usuário do Arch Linux, poderá encontrar o rkhunter no AUR através deste link. A instalação é simples e segue o padrão de qualquer instalação a partir do AUR, conforme passos abaixo: 1- Descompacte o arquivo: [kalib@tuxcaverna downloads]$ tar -xvzf rkhunter.tar.gz 2- Acesse o diretório criado: [kalib@tuxcaverna downloads]$ cd rkhunter/ 3- Execute o PKGBUILD para criação do pacote em si: [kalib@tuxcaverna rkhunter]$ makepkg 4- Com o pacote criado, basta instalar: [kalib@tuxcaverna rkhunter]$ sudo pacman -U rkhunter-1.3.8-1-any.pkg.tar.xz Feito. Seu rkhunter está pronto para ser utilizado, mas como toda e qualquer aplicação de varredura, como antivírus, por exemplo, é sempre recomendado atualizar sua base de dados antes de iniciar a busca, portanto digite o seguinte para atualizar a base com as propriedades dos arquivos existentes: rkhunter –propupd Em seguida é a hora de atualizar a base de dados do rkhunter em si: rkhunter –update Agora, vamos vasculhar o sistema: rkhunter -c Você terá uma listagem das checagens parecida com esta: Perceba que é tudo apresentado de forma simples e objetiva. No final da checagem ele gera um arquivo onde ele armazena todas as informações que ele registrou bem como lhe aponta uma descrição dos resultados da busca. ","date":"2011-03-16","objectID":"/posts/rootkit-esse-bicho-morde-proteja/:3:1","tags":["Arch Linux","Cultura Hacker","Impressões","Linux","Redes","Segurança","Software Livre"],"title":"Rootkit: Esse Bicho Morde, Proteja-Se","uri":"/posts/rootkit-esse-bicho-morde-proteja/"},{"categories":["Tutoriais"],"content":"TIGER Esta será a nossa segunda ferramenta. O Tiger é uma ferramenta de segurança que não pensa tanto na aparência, portanto não espere uma tela tão amigável e colorida quanto a do rkhunter. ;] A instalação da mesma no Arch Linux também se dá através do pacote do AUR que pode ser encontra neste link. A instalação segue o mesmo procedimento que utilizamos no rkhunter, conforme abaixo: [kalib@tuxcaverna downloads]$ tar -xvzf tiger.tar.gz [kalib@tuxcaverna downloads]$ cd tiger/ [kalib@tuxcaverna tiger]$ makepkg [kalib@tuxcaverna tiger]$ sudo pacman -U tiger-3.2.3-2-x86_64.pkg.tar.xz Finalizado. Para executar, basta rodar: tiger Ele iniciará a busca e lhe trará uma interface. Assim como o rkhunter, no ato de finalização ele irá gerar um arquivo com o relatório da checagem. Ele lhe informará o caminho do arquivo, mas provavelmente será em /var/log/tiger/. ","date":"2011-03-16","objectID":"/posts/rootkit-esse-bicho-morde-proteja/:3:2","tags":["Arch Linux","Cultura Hacker","Impressões","Linux","Redes","Segurança","Software Livre"],"title":"Rootkit: Esse Bicho Morde, Proteja-Se","uri":"/posts/rootkit-esse-bicho-morde-proteja/"},{"categories":["Tutoriais"],"content":"CHKROOTKIT Agora vamos para a terceira e última ferramenta deste post. Para usuário Arch, desta vez a instalação é ainda mais simples do que as duas anteriores, visto que o pacote já se encontra nos repositórios do pacman. [kalib@tuxcaverna ~]$ sudo pacman -S chkrootkit Instalado! Assim como o Tiger, o chkroot também possui uma interface simples sem cores ou enfeites, conforme pode ser visto abaixo: Apesar de não ser colorida e enfeitada, é uma interface bem simples e de fácil entendimento, concordam? Claro, não existem apenas estas ferramentas para busca de rootkits e códigos maliciosos, mas levaria muito tempo para escrever sobre todos ou ao menos a maioria. No mais, acho que já é um bom começo para um entendimento básico sobre o que é esse tal Rootkit e o que esse bicho faz. Com estas ferramentas as chances de algum rootkit passar despercebido em seu ambiente Linux já são bem limitadas. Abraços! ","date":"2011-03-16","objectID":"/posts/rootkit-esse-bicho-morde-proteja/:3:3","tags":["Arch Linux","Cultura Hacker","Impressões","Linux","Redes","Segurança","Software Livre"],"title":"Rootkit: Esse Bicho Morde, Proteja-Se","uri":"/posts/rootkit-esse-bicho-morde-proteja/"},{"categories":["Eventos"],"content":"Como muitos de vocês já devem saber, estamos nos aproximando do mês de Abril, significando que o Flisol vem aí. Para quem ainda não conhece, o Flisol - Fórum Latino Americano de Instalação de Software Livre - é um dos maiores eventos do mundo no que diz respeito ao movimento de Software Livre.","date":"2011-03-10","objectID":"/posts/flisol-fortaleza-2011-inscricoes-e/","tags":["Cultura Hacker","Flisol","Impressões","Linux","Software Livre","Tux-ce"],"title":"Flisol Fortaleza 2011: Inscrições E Chamada De Trabalhos","uri":"/posts/flisol-fortaleza-2011-inscricoes-e/"},{"categories":["Eventos"],"content":"Saudações pessoal! Como muitos de vocês já devem saber, estamos nos aproximando do mês de Abril, significando que o Flisol vem aí. Para quem ainda não conhece, o Flisol - Fórum Latino Americano de Instalação de Software Livre - é um dos maiores eventos do mundo no que diz respeito ao movimento de Software Livre. O evento é realizado anualmente e ocorre de forma simultânea em diversas cidades da América Latina, totalizando mais de 120 cidades em aproximadamente 20 países. O Flisol é um evento descentralizado, onde diversas comunidades organizam e realizam seu festival, de forma voluntária, tendo como principal objetivo promover o uso de Software Livre, apresentando sua filosofia, alcance, avanços e desenvolvimento ao público em geral. O evento é gratuito e aberto a todo o público: curiosos, interessados e amantes do Software Livre. Nesse dia os voluntários propõe a instalação de Software Livre, como distribuições de Gnu/Linux, sistemas BSD, e aplicativos livres para Windows em geral. Alguns eventos também contam com palestras, oficinas, salas de degustação e gravações de mídias (live-CD/DVD e/ou pendrives). O objetivo do Flisol, além de promover o uso de Software Livre em geral, é também o de criar interações entre usuários e desenvolvedores, promovendo um momento para troca de experiências, conhecimentos ou mesmo um bate papo agradável que pode resultar em futuros projetos ou apenas amizades. Desde sua primeira edição em 2006, Fortaleza conta com seu festival composto por um público maior a cada ano. Em nossa edição, sempre contamos com palestras além do já tradicional Install Fest. As inscrições para o evento já começaram através do seguinte link: FlisolCE - Inscrições. É importante que as inscrições sejam realizadas para posterior entrega de certificados bem como dados estatísticos que geramos a cada ano juntamente com as demais cidades e países que também sediam o evento. As submissões de palestras também já se iniciaram e vão até o dia 20/03 através do seguinte link: FlisolCE - Submissão de Palestras. Para maiores informações sobre o evento e novidades, acompanhe o site do evento ou siga no twitter @flisolceara. Abraços! ","date":"2011-03-10","objectID":"/posts/flisol-fortaleza-2011-inscricoes-e/:0:0","tags":["Cultura Hacker","Flisol","Impressões","Linux","Software Livre","Tux-ce"],"title":"Flisol Fortaleza 2011: Inscrições E Chamada De Trabalhos","uri":"/posts/flisol-fortaleza-2011-inscricoes-e/"},{"categories":["Eventos"],"content":"Gostaria de lembrar a todos os interessados que amanhã teremos o II Pylestras aqui em Fortaleza.","date":"2011-02-25","objectID":"/posts/amanha-ii-pylestras-python-user/","tags":["Impressões","Python","Software Livre"],"title":"Amanhã II Pylestras: Python User Group Ceará","uri":"/posts/amanha-ii-pylestras-python-user/"},{"categories":["Eventos"],"content":"Gostaria de lembrar a todos os interessados que amanhã teremos o II Pylestras aqui em Fortaleza. Se você não faz ideia sobre o que seja Python ou sabe que é uma linguagem de programação mas não conhece maiores detalhes sobre a mesma, recomendo a leitura destes links bem como sua participação no evento, que com certeza será bem interessante. ","date":"2011-02-25","objectID":"/posts/amanha-ii-pylestras-python-user/:0:0","tags":["Impressões","Python","Software Livre"],"title":"Amanhã II Pylestras: Python User Group Ceará","uri":"/posts/amanha-ii-pylestras-python-user/"},{"categories":["Eventos"],"content":"Python The Zen Of Phyton Porque Python? Porque escolhi Python - Python para SysAdmins ","date":"2011-02-25","objectID":"/posts/amanha-ii-pylestras-python-user/:1:0","tags":["Impressões","Python","Software Livre"],"title":"Amanhã II Pylestras: Python User Group Ceará","uri":"/posts/amanha-ii-pylestras-python-user/"},{"categories":["Eventos"],"content":"II Pylestras O evento consiste em 3 palestras conforme apresentadas abaixo: * Testes com framework Django/Python com data factory _ * Arduino: Soluções para um mundo moderno_ _ * Técnicas para preparação e desenvolvimento de sites com Django_ O evento acontecerá na Fa7 (Faculdade 7 de Setembro) no horário entre 8:30 e 12:00. Além das palestras o evento contará com um sorteio do livro Python e Django - Desenvolvimento Ágil de Aplicações Web. O evento está sendo organizado pelo pessoal do PUG-CE (Python User Group Ceará). Para maiores detalhes sobre o evento, visite a página e faça sua inscrição: Aqui! Abraços! ","date":"2011-02-25","objectID":"/posts/amanha-ii-pylestras-python-user/:2:0","tags":["Impressões","Python","Software Livre"],"title":"Amanhã II Pylestras: Python User Group Ceará","uri":"/posts/amanha-ii-pylestras-python-user/"},{"categories":["Tutoriais"],"content":"Bom, para quem não conhece nada sobre Brute-Force ou apenas ouviu falar vagamente mas não tem certeza sobre o que realmente é um ataque deste tipo, sugiro dar uma lida em meu último post, onde apresentei algumas informações sobre brute-force bem como uma ferramenta que podemos utilizar para testar nossos sites e verificar o quão vulneráveis eles estão a este tipo de ataque.","date":"2011-02-15","objectID":"/posts/brute-force-o-dirb-dirbuster/","tags":["Arch Linux","Cultura Hacker","Impressões","Java","Kubuntu","Linux","Redes","Segurança","Software Livre"],"title":"Brute Force: O Dirb... Dirbuster Lhe Ajuda a Identificar Vulnerabilidades Em Seu Site","uri":"/posts/brute-force-o-dirb-dirbuster/"},{"categories":["Tutoriais"],"content":"Bom, para quem não conhece nada sobre Brute-Force ou apenas ouviu falar vagamente mas não tem certeza sobre o que realmente é um ataque deste tipo, sugiro dar uma lida em meu último post, onde apresentei algumas informações sobre brute-force bem como uma ferramenta que podemos utilizar para testar nossos sites e verificar o quão vulneráveis eles estão a este tipo de ataque. Segue link para o mesmo: ","date":"2011-02-15","objectID":"/posts/brute-force-o-dirb-dirbuster/:0:0","tags":["Arch Linux","Cultura Hacker","Impressões","Java","Kubuntu","Linux","Redes","Segurança","Software Livre"],"title":"Brute Force: O Dirb... Dirbuster Lhe Ajuda a Identificar Vulnerabilidades Em Seu Site","uri":"/posts/brute-force-o-dirb-dirbuster/"},{"categories":["Tutoriais"],"content":"Introdução Brute-Force? O Dirb lhe ajuda a identificar vulnerabilidades em seu site!. Agora que já conhecemos um pouco sobre as técnicas de brute-force e a ferramenta Dirb, que tal conhecer outra mais apresentável? Me refiro ao DirBuster. Uma aplicação multithread desenvolvida pelo OWASP (The Open Web Application Security Project) que tem como objetivo realizar brute-force em diretórios e nomes de arquivos na web. Assim como o Dirb, o DirBuster trabalha em cima de dicionários ou listas. Ao todo ele trás 9 listas que podem ser utilizadas para nossas varreduras e testes. Como todas as suas listas foram criadas na unha, após exaustívas pesquisas e buscas na web por nomes mais utilizados para arquivos e diretórios em servidores web, o DirBuster mostra-se extremamente efetivo para este tipo de atividade conseguindo encontrar até mesmo os arquivos mais ocultos e escondidos. Mas se você não ficar satisfeito, nós garantimos a devolução do seu dinheiro, com apenas utilizar o modelo de dicionários, o DirBuster ainda lhe possibilita o ataque de brute-force mais purista. Tentativa e erro com combinações possíveis de caracteres. Claro, se você tem muito poder de processamento e tempo sobrando, boa sorte. ;] Legal Kalib, quer dizer que agora posso sair invadindo sites? o.O Como diria o Chaves: Ai que burrrrroooo.. dá zero pra ele… Não amigo. O meu intuito não é incentivar ou apresentar qualquer mecanismo ou técnica para este tipo de atividade. O DirBuster não foi feito para este propósito e nem conseguirá efetuar isto. Ele não fará nenhum tipo de exploit em arquivos ou diretórios que ele encontre. O DirBuster serve exatamente para identificar possíveis alvos para estes tipos de ataque, o que nos permite agir de forma corretiva ou preventiva em nossos servidores web. ;] ","date":"2011-02-15","objectID":"/posts/brute-force-o-dirb-dirbuster/:1:0","tags":["Arch Linux","Cultura Hacker","Impressões","Java","Kubuntu","Linux","Redes","Segurança","Software Livre"],"title":"Brute Force: O Dirb... Dirbuster Lhe Ajuda a Identificar Vulnerabilidades Em Seu Site","uri":"/posts/brute-force-o-dirb-dirbuster/"},{"categories":["Tutoriais"],"content":"Instalação Chega de lenga lenga.. vamos ao que interessa! Como instalar? Bom, se você utiliza Arch Linux, pode pegar o pacote no AUR através do seguinte link(Lembrem-se de votar nele): AUR - Dirbuster. Feito isto, basta seguir o procedimento padrão para pacotes do AUR. 1- Descompactar: $ tar -xvzf dirbuster.tar.gz 2- Entrar no diretório dirbuster e gerar o pacote: $ makepkg 3- Instalar o pacote: $ sudo pacman -U dirbuster-0.12-1-x86_64.pkg.tar.xz Feito. ;] Outras distribuições? Não tenho certeza se o pessoal de outras distribuições empacotou o DirBuster, portanto provavelmente você vai precisar baixar o arquivo compactado do site oficial do projeto. Busquei tanto no Debian quanto no (K)Ubuntu 10.10 e em nenhum destes encontrei o DirBuster nos repositórios através do aptitude. Portanto se você não utiliza o Arch, segue link para download da ferramenta: Dirbuster. ","date":"2011-02-15","objectID":"/posts/brute-force-o-dirb-dirbuster/:2:0","tags":["Arch Linux","Cultura Hacker","Impressões","Java","Kubuntu","Linux","Redes","Segurança","Software Livre"],"title":"Brute Force: O Dirb... Dirbuster Lhe Ajuda a Identificar Vulnerabilidades Em Seu Site","uri":"/posts/brute-force-o-dirb-dirbuster/"},{"categories":["Tutoriais"],"content":"Dirbuster Mas qual a cara do bicho? Como explicado antes, ele funciona parecido com o Dirb, porém em uma interface GUI (gráfica). Como podem ver, é uma interface simples e de fácil manuseio. Vamos aos pontos: 1- No campo Target, você deverá inserir a URL que será alvo do seu brute-force de diretórios e arquivos web. 2- Logo abaixo, vocẽ escolhe se deseja utilizar apenas GET ou HEAD \u0026 GET. 3- Agora é a vez de escolher quantas threads deseja utilizar. Quanto maior o número de threads, mais requisições simultâneas você estará utilizando. ;] 4- Abaixo você deverá escolher o tipo de brute-force. Baseado em dicionários, neste caso você deverá escolher um dos dicionários que a ferramenta já lhe disponibiliza através do seguinte caminho: /opt/DirBuster/ Baseado em brute-force puro. Neste caso você deverá escolher qual conjunto de caracteres deseja que sejam utilizados, quantidade mínima e máxima de caracteres por tentativa. 5- Em seguida é a hora de escolher os filtros: Deseja fazer brute-force apenas em diretórios? Arquivos também? Modo recursivo? Extensões em branco? Diretório inicial para o scan? Que tipo de extensão?… E como é o retorno que ele me dá? Bom, vou escolher meu alvo e vou utilizar 20 threads em simultâneo. Não vou deixar a ferramenta rodando por muito tempo pois estou apenas fazendo uma demonstração. Como podem ver, filtrei para que o brute-force comece no diretório raiz (/) e optei pela maior lista que o DirBuster possui como dicionário. Deixei rodando por cerca de 30 segundos e já tive o seguinte resultado. A parte borrada no início da imagem não é um defeito. Vocês não pensaram que eu iria deixar exposto o alvo no qual fiz o teste, certo? No caso, optei pelo site de uma de nossas instituições de ensino. Bom, a imagem acima é um exemplo do retorno que consigo com a ferramenta. É a visão em Lista. Além dela você pode optar pela visão em árvore, que, como o nome informa, lhe trará a árvore de diretórios, sub-diretórios e arquivos que foram encontrados. Abaixo um exemplo da visão em árvore: O resultado, mesmo deixando a ferramenta rodando por apenas 30 segundos, foi o esperado. Um espantoso caso de descuido com a segurança do site. Alguns leves exemplos que me chamaram a atenção na lista que consegui: Um diretório de administração exposto desta forma indicando que existe uma sessão do site com acesso permitido apenas para administradores. O que isso me leva a crer? Que quem conseguir acesso a esta sessão consegue manipular o sistema do site? O que nos leva a uma posterior análise da página index contida nele que possibilita uma tentativa de brute-force de login e senha? psssiiiuuuu… o.O Um diretório para uploads de Arquivos? Que tal testar ele? Apenas usuários administradores possuem permissão de upload? Ou alunos conseguem fazer upload de fotos, trabalhos, por exemplo? De qualquer forma, isso me indica que existe a possibilidade de eu subir arquivos para o servidor deles. Que tal um script em php que me permitiria ter um console shell no servidor deles para inclusão, exclusão, edição, etc.. ? pssiiiiuuuu… o.O Pode não ser nada.. mas também pode ser muita coisa.. O que um diretório chamado “gerencia” faz ali tão exposto e com um nome tão… tão… discreto? o.O psssiiiuuuuu Acho que já conseguiram entender um pouco do que o DirBuster faz. Abraços! Happy Hacking… PS: Wrong developers! Never play security by obscurity! ","date":"2011-02-15","objectID":"/posts/brute-force-o-dirb-dirbuster/:3:0","tags":["Arch Linux","Cultura Hacker","Impressões","Java","Kubuntu","Linux","Redes","Segurança","Software Livre"],"title":"Brute Force: O Dirb... Dirbuster Lhe Ajuda a Identificar Vulnerabilidades Em Seu Site","uri":"/posts/brute-force-o-dirb-dirbuster/"},{"categories":["Impressões"],"content":"É isso aí pessoal, ontem o projeto KDE liberou o KDE 4.6 com muitas melhorias e o pessoal do Arch já saiu na frente, claro. Sim, se você usa Arch, não precisa esperar, pode atualizar seu KDE com o seu rotineiro # pacman -Syu.","date":"2011-01-27","objectID":"/posts/lancado-kde-4-6-sim/","tags":["Arch Linux","Impressões","KDE","Linux","Software Livre"],"title":"Lançado Kde 4.6 - Sim, Claro, Se Você Usa Arch, Não Precisa Esperar","uri":"/posts/lancado-kde-4-6-sim/"},{"categories":["Impressões"],"content":"- DEV do Arch, qual é sua missão? - Empacotar antes de qualquer distribuição! - DEV do Arch o que é que você faz? - Eu empacoto coisas que assustam o Satanás! É isso aí pessoal, ontem o projeto KDE liberou o KDE 4.6 com muitas melhorias e o pessoal do Arch já saiu na frente, claro. Sim, se você usa Arch, não precisa esperar, pode atualizar seu KDE com o seu rotineiro _# _pacman -Syu. Dentre as grandes mudanças, gostaria de destacar o suporte nativo ao UPower, UDev e UDisks que podem ser utilizados ao invés do depreciado HAL. Para isso, o pacote hal deixa de ser uma dependência do kdebase-workspace e pode ser removido do seu sistema. Outra novidade é que com a última atualização do Phonon, os DEVs declararam que o backend Xine não será mais mantido e precisará do PulseAudio para funcionar; você realmente deveria pensar em trocar para o GStreamer ou VLC backend. Várias melhorias foram implementadas também em contexto geral no Plasma Workspaces que ganhou, dentre outras coisas, um novo sistema de Activities, lhe permitindo uma associação mais fácil de aplicações com atividades específicas e particulares como trabalho ou atividades de casa. Várias mudanças no Kwin, o gerenciador de janelas do Plasma, também foram implementadas para melhorar a performance do mesmo e ao mesmo tempo tornar mais leve para o sistema como um todo. E se eu tiver um netbook? O KDE 4.6 também trouxe uma série de novos recursos que facilitam e tornam o sistema ainda mais leve para este tipo de usuário. O Plasma Netbook, otimizado para computadores mais portáteis, se tornou ainda mais leve e fácil de se utilizar através de uma tela touchscreen. Várias modificações no dolphin, correções de bugs e aparência também foram implementadas, mas… se eu for realmente listar todas as modificações, posso acabar perdendo meu emprego, portanto vou apenas lhes deixar o link do site oficial onde podem ser encontradas todas as mudanças desta release: KDE 4.6 Release Notes. Abraços! ","date":"2011-01-27","objectID":"/posts/lancado-kde-4-6-sim/:0:0","tags":["Arch Linux","Impressões","KDE","Linux","Software Livre"],"title":"Lançado Kde 4.6 - Sim, Claro, Se Você Usa Arch, Não Precisa Esperar","uri":"/posts/lancado-kde-4-6-sim/"},{"categories":["Tutoriais"],"content":"Como diria a Feiticeira (não lembro o nome real dela), não é feitiçaria, é tecnologia!","date":"2010-12-29","objectID":"/posts/chaveamento-de-interfaces-de-rede/","tags":["Arch Linux","Impressões","Linux","Redes","Software Livre"],"title":"Chaveamento De Interfaces De Rede - Placas Broadcom","uri":"/posts/chaveamento-de-interfaces-de-rede/"},{"categories":["Tutoriais"],"content":"Como diria a Feiticeira (não lembro o nome real dela), não é feitiçaria, é tecnologia! ","date":"2010-12-29","objectID":"/posts/chaveamento-de-interfaces-de-rede/:0:0","tags":["Arch Linux","Impressões","Linux","Redes","Software Livre"],"title":"Chaveamento De Interfaces De Rede - Placas Broadcom","uri":"/posts/chaveamento-de-interfaces-de-rede/"},{"categories":["Tutoriais"],"content":"Introdução Como já expliquei no outro post, tive problemas com meu notebook e por isso passei muito tempo afastado do blog. Bom, recentemente comprei outro e cá estou novamente em casa. Mas, como nem tudo é um mar de rosas… toda mudança trás impactos positivos e negativos. A máquina escolhida foi um Dell Vostro 3300. Com certeza uma excelente máquina e que eu não deixaria de recomendar para ninguém. Para quem comprou algum Dell recentemente, ou pensou em comprar, não deve ser uma novidade que estas máquinas, em sua grande maioria, estão trazendo chipsets wireless da Broadcom, ao invés dos Intel. Quando pensei em comprar, refleti bastante sobre isto, visto que os drivers para broadcom no linux já tiveram um passado um tanto quanto nebuloso em se tratando de Wireless. Resolvi encarar e não me arrependo. A performance está excelente. O driver realmente funcionou como deveria funcionar porém tive um pequeno problema. Utilizo KDE como gerenciador de janelas em meu ArchLinux e Wicd como gerenciador de redes. Estava tudo funcionando bem mas ao reiniciar a máquina um certo dia percebo que o Wicd não havia encontrado nenhuma rede wireless. o.O Reinicio novamente e ele volta a encontrar. Feitiçaria? Fiquei curioso e resolvi reiniciar novamente e… funcionou. Pensei: “Foi apenas um susto..ela devia querer descansar..” Mas no dia seguinte ao ligar em casa percebi que, novamente, a interface wireless não foi encontrada pelo Wicd. Lembrei do fato anterior e reiniciei novamente. A interface continuava sem funcionar no Wicd. Lhes poupando dos testes que resolvi fazer para isolar o problema, descobri que as vezes a minha interface wireless estava subindo como eth0, as vezes subindo como eth1. Isso, obviamente, deixava o Wicd confuso, pois na configuração dele é necessário especificar qual será a interface wireless e qual será a wired (cabeada). Portanto, quando o notebook subia com a wireless na eth1, o Wicd funcionava numa boa, mas quando subia na eth0 o Wicd continuava tentando escanear redes wireless com a eth1, portanto não funcionava. Após algumas pesquisas descobri que este é um acontecimento comum em relação ao driver da broadcom. Este chaveamento ou swap de interfaces de rede acontece realmente de forma aleatória. ","date":"2010-12-29","objectID":"/posts/chaveamento-de-interfaces-de-rede/:1:0","tags":["Arch Linux","Impressões","Linux","Redes","Software Livre"],"title":"Chaveamento De Interfaces De Rede - Placas Broadcom","uri":"/posts/chaveamento-de-interfaces-de-rede/"},{"categories":["Tutoriais"],"content":"Solução Como resolver? Amarrando a interface ao nome, literalmente. A placa começou a funcionar da forma esperada após vincular via regra o MAC da interface ao nome que eu desejava para ela. Desta forma, na hora de subir, ambas passam a subir de acordo com a regra que eu especifiquei, o que resolveu o problema pois a interface wireless passou a sempre subir com o mesmo nome, evitando que o Wicd tentasse escanear com uma interface que não existe. Sem mais papo furado.. mãos à obra! Antes de mais nada é necessário criar, caso você já não possua, o arquivo /etc/udev/rules.d/10-network.rules acrescentando o seguinte conteúdo: SUBSYSTEM==\"net\", ATTR{address}==\"aa:bb:cc:dd:ee:ff\", NAME=\"eth0\" SUBSYSTEM==\"net\", ATTR{address}==\"aa:bb:cc:dd:ee:ff\", NAME=\"eth1\" o.O wtf? Bom, com isto você estará deixando claro para o sistema qual o nome que deverá ser atribuído para cada interface. Você deverá apenas substituir o “aa:bb:cc:dd:ee:ff” e “ff:ee:dd:cc:bb:aa” pelos respectivos endereços MAC das interfaces. O valor dos campos NAME podem ser alterados de acordo com sua vontade, por exemplo: eth0 para a cabeada e wlan0 para a wireless. Caso não saiba como conseguir o endereço MAC de suas interfaces, utilize o seguinte comando: # ifconfig | grep HW Isso lhe dará um retorno parecido com o seguinte: eth0 Link encap:Ethernet HWaddr **A4:BA:DB:D7:41:C0** eth1 Link encap:Ethernet HWaddr **1C:65:9D:6E:65:1B** Os endereços MAC são os valores que destaquei acima. ATENÇÃO: Apesar de o MAC constantemente ser escrito com letras em maiúsculo como apresentado acima, no caso do arquivo 10-network.rules você deverá utilizar letras em minúsculo. Exato, o arquivo é case sensitive, portanto só funcionará desta forma. Caso você receba uma saída parecida com a minha e queira se certificar de qual dos dois endereços MAC é o que realmente representa a interface wireless pode testar com os seguintes comando: # iwlist eth0 scanning e...﻿ # iwlist eth1 scanning Você perceberá que terá resultados diferentes. O que retornar um scan completo de redes wireless disponíveis, obviamente, é a interface Wireless. ;] Após ter escolhido o nome que deseja para cada uma de suas interfaces pode salvar o arquivo de regra. ATENÇÃO²: Certifique-se de atualizar o seu arquivo /etc/rc.conf para evitar que os nomes das interfaces estejam diferentes das que você criou no arquivo de regras. É isto.. agora sua interface funcinoará da forma esperada. Abraços! ","date":"2010-12-29","objectID":"/posts/chaveamento-de-interfaces-de-rede/:2:0","tags":["Arch Linux","Impressões","Linux","Redes","Software Livre"],"title":"Chaveamento De Interfaces De Rede - Placas Broadcom","uri":"/posts/chaveamento-de-interfaces-de-rede/"},{"categories":["Impressões"],"content":"Pessoal, recentemente surgiram algumas notícias de fontes suspeitas informando que o Linux está em menos de 1% dos computadores desktop existentes no mundo hoje.","date":"2010-10-15","objectID":"/posts/somos-menos-de-1-o/","tags":["Arch Linux","Cultura Hacker","Impressões","Linux","Software Livre"],"title":"Somos Menos De 1% - Usuários Linux Cadastrem-Se","uri":"/posts/somos-menos-de-1-o/"},{"categories":["Impressões"],"content":"Pessoal, recentemente surgiram algumas notícias de fontes suspeitas informando que o Linux está em menos de 1% dos computadores desktop existentes no mundo hoje. Será verdade? Todos podemos ver claramente o quanto o Linux vem crescendo e ganhando espaço hoje em dia. Lembro que em 2005, quando entrei na faculdade, ao perguntar para meus colegas de faculdade, poucos conheciam ou já haviam chegado perto de uma máquina com Linux. Hoje a realidade é outra, cerca de 50% dos colegas já, ao menos uma vez, utilizaram uma máquina com Linux, seja em seu trabalho, seja no Banco, lan house, etc. O Linux está ficando mais forte a cada dia entre os usuários domésticos. Começaram um projeto web para tentar quebrar este mito: https://www.dudalibre.com/gnulinuxcounter?lang=en Se você possui um desktop, ou mais, com linux, talvez você queira contabilizar o seu voto. Além de contabilizar quantas máquinas desktop utilizam Linux, ele ainda separa por ranking de países e distribuições. Se serve de incentivo, ainda estamos abaixo dos hermanos argentinos. ¬¬ Vamos dar um gás né galera? Abraços! ","date":"2010-10-15","objectID":"/posts/somos-menos-de-1-o/:0:0","tags":["Arch Linux","Cultura Hacker","Impressões","Linux","Software Livre"],"title":"Somos Menos De 1% - Usuários Linux Cadastrem-Se","uri":"/posts/somos-menos-de-1-o/"},{"categories":["Eventos"],"content":"É hora de separar suas melhores garrafas de cerveja café e seus melhores números de telefones para pedidos de pizza. O Hacking'n Roll Fortaleza vai começar!","date":"2010-10-12","objectID":"/posts/hackingn-roll-fortaleza/","tags":["Cultura Hacker","Impressões"],"title":"Hacking Roll Fortaleza","uri":"/posts/hackingn-roll-fortaleza/"},{"categories":["Eventos"],"content":"É hora de separar suas melhores garrafas de cerveja café e seus melhores números de telefones para pedidos de pizza. O Hacking’n Roll Fortaleza vai começar! O evento soa mais como um desafio ao velho estilo Capture The Flag. Para quem conhece e acompanha a Defcon, o Capture The Flag não será nenhuma surpresa. Aos que não conhecem, se trata de um desafio, ou melhor uma série de desafios/questões que devem ser resolvidos em um determinado tempo. Neste Hacking’n Roll serão um total de 25 questões/desafios que deverão ser resolvidos em 24 horas. Começará num sábado às 8:00 e dura até domingo às 8:00. Estas 24 horas serão o tempo que os participantes terão para tentar resolver o máximo de desafios/questões possíveis. Ao final do evento será disponibilizado um ranking com os resultados dos participantes e os melhores estarão qualificados para o curso Hacking 101, treinamento na área de segurança da informação ministrado pelo INSERT, Information Security Research Team. Para maiores informações e inscrições, basta acessar a página do Hacking’n Roll. Good Hacking! ","date":"2010-10-12","objectID":"/posts/hackingn-roll-fortaleza/:0:0","tags":["Cultura Hacker","Impressões"],"title":"Hacking Roll Fortaleza","uri":"/posts/hackingn-roll-fortaleza/"},{"categories":["Impressões"],"content":"Porque não começar com uma recomendação bibliográfica? Afinal, ganhei um excelente livro de minha namorada e o estou adorando. Acho que seria a melhor forma de voltar ao ar.","date":"2010-09-30","objectID":"/posts/recomendacao-bibliografica-a-batalha-do/","tags":["Impressões","Literatura"],"title":"Recomendação Bibliográfica: a Batalha Do Apocalipse","uri":"/posts/recomendacao-bibliografica-a-batalha-do/"},{"categories":["Impressões"],"content":"Como já diz o ditado, quem é vivo sempre aparece. Passado um período um tanto quanto turbulento resolvi passar o aspirador no blog e voltar a postar. Porque não começar com uma recomendação bibliográfica? Afinal, ganhei um excelente livro de minha namorada e o estou adorando. Acho que seria a melhor forma de “voltar ao ar”. A recomendação deste mês é uma história fascinante de um autor brasileiro que conseguiu destaque imenso com esta obra. O carioca Eduardo Sophr, algumas vezes comparado à J. R. R. Tolkien, criador de O Senhor dos Anéis, é um enorme exemplo para toda a comunidade literária brasileira, visto que começou sua jornada na literatura praticamente sozinho, sem ajuda de grandes editoras. Optou por iniciar as vendas de seu livro por conta própria, da forma mais tradicional possível com impressões, envio pelos correios, divulgação na internet, etc. Posteriormente abriu sua própria editora. Em sua ficção “A Batalha do Apocalipse”, o autor descreve uma envolvente história na qual o mundo está envolvido em uma enorme guerra entre os seres celestiais. A história se inicia contando a já conhecida história da criação do mundo, onde Deus leva 6 dias para toda a criação e resolve descansar no sétimo dia. O detalhe é que 1 dia no mundo celestial equivale a centenas de milhares de anos no mundo terreno. Desde de o momento da criação divina, um ambiente de inveja e cobiça começa a reinar no mundo celestial pelo fato de Deus ter dado aos homens alguns atributos importantes que foi negado aos seres celestiais, Anjos, Arcanjos e outros, como por exemplo a alma e o lívre-arbítrio. Ao resolver descansar durante todo o sétimo dia, Deus deixa o encargo e todas as responsabilidades nas mãos de um único Arcanjo que supostamente deveria manter a ordem das coisas enquanto descansava. O Arcanjo Miguel, após receber esta grande responsabilidade, começa a agir de acordo com seus próprios pensamentos e começa a arquitetar uma grande mudança como forma de assumir os poderes e a personificação divina ele mesmo, passando a reinar por completo sob a humanidade. Como forma de atingir esta meta, começa ele mesmo a causar grandes catástrofes na humanidade como o grande dilúvio bíblico, tentativa frustrada de acabar com todos os seres humanos que, segundo ele, acabaríam por destruir o planeta com seu comportamento egoísta e ambicioso. Logo, alguns Anjos e Arcanjos começam a questionar estas atitudes e passam a discordar sobre as intenções de Miguel em apenas servir a vontade divina. Começa então uma guerra entre os seres celestiais onde alguns são expulsos dos céus, sendo confinados a viver na terra por milhares de anos acompanhando todas as tragetórias da humanidade como por exemplo mudanças de civilizações, guerras mundiais, etc. Realmente é uma leitura bastante envolvente e interessante. Ainda não terminei a leitura mas estou ancioso para ver no que vai dar. Segue breve sinopse disponibilizada no site da Livraria Saraiva: Há muitos e muitos anos, tantos quanto o número de estrelas no céu, o paraíso celeste foi palco de um terrível levante. Um grupo de anjos guerreiros, amantes da justiça e da liberdade, desafiou a tirania dos poderosos arcanjos, levantando armas contra seus opressores. Expulsos, os renegados foram forçados ao exílio e condenados a vagar pelo mundo dos homens até o Dia do Juízo Final. Mas eis que chega o momento do Apocalipse, o tempo do ajuste de contas. Único sobrevivente do expurgo, Ablon, o líder dos renegados, é convidado por Lúcifer, o Arcanjo Negro, a se juntar às suas legiões na Batalha do Armagedon, o embate final entre o céu e o inferno, a guerra que decidirá não só o destino do mundo, mas o futuro da humanidade. Das ruínas da Babilônia ao esplendor do Império Romano, das vastas planícies da China aos gelados castelos da Inglaterra medieval, A Batalha do Apocalipse não é apenas uma viagem pela história humana - é também uma jornada de conhecimento, um épico empolgante, repleto de lutas heroicas, magia, romance e suspense. A","date":"2010-09-30","objectID":"/posts/recomendacao-bibliografica-a-batalha-do/:0:0","tags":["Impressões","Literatura"],"title":"Recomendação Bibliográfica: a Batalha Do Apocalipse","uri":"/posts/recomendacao-bibliografica-a-batalha-do/"},{"categories":["Aleatórios"],"content":"E você pensava que o cara da informática, escravo dos escravos, não tinha direito a nada a não ser trabalhar, eim?!","date":"2010-07-30","objectID":"/posts/parabens-dia-do-administrador-de/","tags":["Cultura Hacker","Impressões"],"title":"Parabéns: Dia Do Administrador De Redes E Sistemas","uri":"/posts/parabens-dia-do-administrador-de/"},{"categories":["Aleatórios"],"content":"É isso aí… E você pensava que o cara da informática, escravo dos escravos, não tinha direito a nada a não ser trabalhar, eim?! Também temos o nosso dia. Parabéns a todos os Administradores de Redes e Sistemas. Hoje, última sexta-feira de julho é o SysAdminDay. Você que é um usuário comum e que vive reclamando do pessoal de TI de sua empresa, aproveite este dia para lhes parabenizar pelo trabalho prestado seja durante o dia, noite e, porque não, madrugada. É isso aí…E você pensava que o cara da informática, escravo dos escravos, não tinha direito a nada a não ser trabalhar, eim?!Também temos o nosso dia.Parabéns a todos os Administradores de Redes e Sistemas. Hoje, última sexta-feira de julho é o SysAdminDay. Você que é um usuário comum e que vive reclamando do pessoal de TI de sua empresa, aproveite este dia para lhes parabenizar pelo trabalho prestado seja durante o dia, noite e, porque não, madrugada. No link do SysAdminDay existem maiores informações, fotos, vídeos dentre outras coisas interessantes em relação ao nosso trabalho. Abraços! ","date":"2010-07-30","objectID":"/posts/parabens-dia-do-administrador-de/:0:0","tags":["Cultura Hacker","Impressões"],"title":"Parabéns: Dia Do Administrador De Redes E Sistemas","uri":"/posts/parabens-dia-do-administrador-de/"},{"categories":["Impressões"],"content":"A recomendação bibliográfica deste mês se chama O Símbolo Perdido, o último lançamento de Dan Brown. Para quem não conhece, se é que alguém ainda não ouviu falar, Dan Brown é o escritor norte-americano que tornou-se mundialmente famoso depois das polêmicas geradas com o lançamento de seu best-seller O Código da Vinci.","date":"2010-07-27","objectID":"/posts/recomendacao-bibliografica-o-simbolo-perdido/","tags":["Impressões","Literatura"],"title":"Recomendação Bibliográfica: O Símbolo Perdido","uri":"/posts/recomendacao-bibliografica-o-simbolo-perdido/"},{"categories":["Impressões"],"content":"Saudações pessoal! Que tal um pouco mais de leitura? A recomendação bibliográfica deste mês se chama O Símbolo Perdido, o último lançamento de Dan Brown. Para quem não conhece, se é que alguém ainda não ouviu falar, Dan Brown é o escritor norte-americano que tornou-se mundialmente famoso depois das polêmicas geradas com o lançamento de seu best-seller O Código da Vinci. Antes de O Código da Vinci o autor já havia escrito outros três excelentes livros que, por algum motivo, passaram um tanto quanto escondidos até as polêmicas do quarto livro que despertou interesse mundial em suas obras anteriores. Com isto, Dan Brown conseguiu um feito memorável ao ter seus 4 primeiros livros simultaneamente na lista de mais vendidos do The New York Times. Em ordem cronológica, seus lançamentos foram: Fortaleza Digital - 1998 Anjos e Demônios - 2000 Ponto de Impacto - 2001 O Código Da Vinci - 2003 O Símbolo Perdido - 2009 Particularmente, acho as 3 obras anteriores melhores do que o próprio _O _Código da Vinci, o que não torna este último um livro ruim. Sua última obra, intitulada_ O Sìmbolo Perdido_, é mais uma aventura vivida pelo já conhecido personagem Robert Langdon, que também protagonizou Anjos e Demônios e O Código da Vinci. Mantendo o tópico de assuntos místicos e de Ordens místicas, neste livro Robert Langdon é responsável por evitar que antigos segredos guardados pela Franco-Maçonaria caiam em mãos erradas, o que poderia despertar segredos e conhecimentos antigos inimagináveis que poderiam ser um mal à toda a humanidade. Estou na metade do livro mas já posso recomendar sem sombra de dúvidas. Uma leitura agradável e pouco cansativa que nos prende do começo ao fim. Segue sinopse retirada do site da livraria saraiva: Depois de ter sobrevivido a uma explosão no Vaticano e a uma caçada humana em Paris, Robert Langdon está de volta com seus profundos conhecimentos de simbologia e sua brilhante habilidade para solucionar problemas. Em O símbolo perdido, o célebre professor de Harvard é convidado às pressas por seu amigo e mentor Peter Solomon - eminente maçom e filantropo - a dar uma palestra no Capitólio dos Estados Unidos. Ao chegar lá, descobre que caiu numa armadilha. Não há palestra nenhuma, Solomon está desaparecido e, ao que tudo indica, correndo grande perigo. Mal’akh, o sequestrador, acredita que os fundadores de Washington, a maioria deles mestres maçons, esconderam na cidade um tesouro capaz de dar poderes sobre-humanos a quem o encontrasse. E está convencido de que Langdon é a única pessoa que pode localizá-lo. Vendo que essa é sua única chance de salvar Solomon, o simbologista se lança numa corrida alucinada pelos principais pontos da capital americana: o Capitólio, a Biblioteca do Congresso, a Catedral Nacional e o Centro de Apoio dos Museus Smithsonian. Neste labirinto de verdades ocultas, códigos maçônicos e símbolos escondidos, Langdon conta com a ajuda de Katherine, irmã de Peter e renomada cientista que investiga o poder que a mente humana tem de influenciar o mundo físico. O tempo está contra eles. E muitas outras pessoas parecem envolvidas nesta trama que ameaça a segurança nacional, entre elas Inoue Sato, autoridade máxima do Escritório de Segurança da CIA, e Warren Bellamy, responsável pela administração do Capitólio. Como Langdon já aprendeu em suas outras aventuras, quando se trata de segredos e poder, nunca se pode dizer ao certo de que lado cada um está. Nas mãos de Dan Brown, Washington se revela tão fascinante quanto o Vaticano ou Paris. Em O Símbolo Perdido, ele desperta o interesse dos leitores por temas tão variados como ciência noética, teoria das supercordas e grandes obras de arte, os desafiando a abrir a mente para novos conhecimentos. Boa leitura… ","date":"2010-07-27","objectID":"/posts/recomendacao-bibliografica-o-simbolo-perdido/:0:0","tags":["Impressões","Literatura"],"title":"Recomendação Bibliográfica: O Símbolo Perdido","uri":"/posts/recomendacao-bibliografica-o-simbolo-perdido/"},{"categories":["Tutoriais"],"content":"Se você é da área de tecnologia, com certeza já ouviu falar deste tal Android que vem ganhando cada vez mais notoriedade e mercado no mundo dos smartphones. Não ouviu falar? Sugiro que repense suas escolhas acadêmicas e/ou profissionais. Talvez não tenha feito a escolha certa. Atualize-se.","date":"2010-07-20","objectID":"/posts/que-tal-testar-o-android/","tags":["Android","Google","Impressões","Java","Linux","Software Livre"],"title":"Que Tal Testar O Android Em Seu Linux","uri":"/posts/que-tal-testar-o-android/"},{"categories":["Tutoriais"],"content":"Se você é da área de tecnologia, com certeza já ouviu falar deste tal Android que vem ganhando cada vez mais notoriedade e mercado no mundo dos smartphones. Não ouviu falar? Sugiro que repense suas escolhas acadêmicas e/ou profissionais. Talvez não tenha feito a escolha certa. Atualize-se. O fato é que o Android, como todos já sabemos, é um dos mais “populares” sistemas operacionais atuais para smartphones. Usei a palavra populares entre aspas pelo fato de ele ainda não ser muito utilizado, porém com certeza é muito citado. Desenvolvido inicialmente pela gigante Google, passando a ser mantido posteriormente pela Open Handset Alliance, o Android é um sistema operacional baseado no kernel Linux, permite que qualquer programador desenvolva uma aplicação em java, por exemplo, e controle o dispositivo através de bibliotecas desenvolvidas pela Google. Apenas recentemente o Android vem ganhando realmente mercado em smartphones e aparelhos genéricos, os famosos xing-lings ou MPx da vida. E você? Pensava em testar este tal Android mas não pretendia comprar um smartphone para tal? O Google pensou em você e desenvolveu um emulador SDK para que você possa rodar o Android em sua máquina. Aqui estarei descrevendo o procedimento para instalação no Linux, porém não possui muita diferença e o processo pode ser facilmente adaptado no caso de usuários do OS X ou Windows. Antes de mais nada preciso informar que ele possui como requisito básico o Java. Se você não possui java instalado em sua máquina, esta é a hora de o instalar. Para começar, precisamos baixar o emulador SDK disponibilizado pelo google no link: https://developer.android.com/sdk/index.html No meu caso, estarei trabalhando em cima da versão para Linux. O arquivo baixado está compactado com a extensão .tgz e pode ser descompactado com o comando a seguir: [kalib@tuxcaverna android]$ tar -xvzf android-sdk_r06-linux_86.tgz Ele irá descompactar a pasta android-sdk-linux_86. Entre no diretório e repare que existe um sub-diretório chamado tools dentro dele. Você precisará rodar o executável android que se encontra lá. [kalib@tuxcaverna tools]$ ./android A tela a seguir lhe será apresentada. Agora precisamos instalar o Android em si, portanto vamos começar vendo a lista de aplicativos disponíveis para instalação. Repare que na lateral esquerda existem 5 abas. Vamos trabalhar por enquanto na aba Available Packages. Ao clicar nela, a seguinte tela lhe será apresentada: Clique na seta que se encontra ao lado da opção https://dl-ssl.google.com/android/repository/repository.xml Lhe será exibida uma lista de aplicativos disponíveis para instalação, conforme imagem: No meu caso, vou selecionar apenas a versão 2.2 do Android. Mas, sinta-se livre para selecionar e instalar outras que estejam disponibilizadas. Uma vez que eu tenha selecionado a box do SDK Platform Android 2.2, API 8, revision 2, basta clicar em Install Selected. Ele me apresenta uma janela de confirmação. Basta clicar em Accept e em seguida em Install. Será iniciado o download da(s) aplicação(ões) selecionada(s), conforme imagem abaixo. Ao concluir o download, a tela ficará aguardando que você clique em Close, como na imagem a seguir: Após isto, podemos ir para a aba Installed Packages. Lá veremos a lista do que instalamos. No meu caso, apenas o SDK Platform Android 2.2, API 8, revision 2, como na imagem a seguir: Agora vamos criar o dispositivo virtual. Clique na primeira aba, Virtual Devices, e em seguida clique no botão New… Lhe será apresentada uma tela pedindo as seguintes informações: Name: (Nome que deseja dar para este dispositivo virtual) Target: (Você deve apontar para a API desejada. No meu caso, apontei para o Android 2.2 que instalei) SD Card: (Aqui você define o tamanho que deseja para o arquivo que será o dispositivo virtual) Skin: (Nesta opção você poderá definir a resolução que deseja utilizar ou tamaho de tela) Hardware: (Opções para abstração ou comunicação com o seu hardware) Pode preencher de forma parecida com ","date":"2010-07-20","objectID":"/posts/que-tal-testar-o-android/:0:0","tags":["Android","Google","Impressões","Java","Linux","Software Livre"],"title":"Que Tal Testar O Android Em Seu Linux","uri":"/posts/que-tal-testar-o-android/"},{"categories":["Tutoriais"],"content":"Quantas vezes você já foi surpreendido por alguma falha grave em seu sistema de arquivos, disco rígido ou mesmo por vírus (no caso de quem utiliza Sistemas Operacionais Genéricos) e depois de perder centenas de arquivos e informações se perguntou: Porque eu não fiz backup disso antes?","date":"2010-07-15","objectID":"/posts/simples-solucao-de-backup-sbackup/","tags":["Arch Linux","Cultura Hacker","Impressões","Linux","Segurança"],"title":"Simples Solucao De Backup Sbackup","uri":"/posts/simples-solucao-de-backup-sbackup/"},{"categories":["Tutoriais"],"content":"Quantas vezes você já foi surpreendido por alguma falha grave em seu sistema de arquivos, disco rígido ou mesmo por vírus (no caso de quem utiliza Sistemas Operacionais Genéricos) e depois de perder centenas de arquivos e informações se perguntou: Porque eu não fiz backup disso antes? É natural do ser humano ignorar o ditado “Não deixe para amanhã o que pode ser feito hoje” dando espaço ao mais utilizado e adotado (quase que enraizado na cultura brasileira) “Não faça agora o que pode esperar para amanhã”, e, por consequência desta atitude, milhares de dados são perdidos diariamente no mundo inteiro pela falta de um simples backup. Existem milhares de ferramentas de backup super eficientes para meios corporativos, portanto não abordarei este tópico. Empresas já possuem (ou ao menos deveriam possuir) seus especialistas em TI que conhecem boas soluções e estratégias de backup para garantir a continuidade dos serviços da empresa em casos de necessidade ou perda. Hoje vou apresentar uma ferramenta bem simples e interessante aos usuários domésticos. Sim, backup não é apenas para empresas. Sempre é bom que se tenha backup mesmo em sua máquina doméstica. Não perca sua monografia que levou tanto tempo para ser trabalhada, ou aquele projeto importante, quem sabe até aquelas fotos de 10 anos atrás que você tanto preza. É comum ver amigos fazendo tais backups em dvds, pendrives, email, etc. Porém, isso me parece um tanto quanto amador. Se você realmente preza pelos seus dados, é hora de planejar um backup sério. Lhes apresento o SimpleBackup, ou simplesmente SBackup. Uma apresentação informal rápida… O Simple Backup é uma solução de backup simples para atender as necessidades de usuários desktop. O projeto foi patrocinado pelo Google durante o Google Summer of Code 2005. Instalação? Se você utiliza Arch Linux, basta pedir ao nosso amigo pacman: # pacman -S sbackup OBS: Ele lhe dará duas ferramentas depois de instalado: * Configuração do Backup * Restauração de Bakcup Vamos começar pela Configuração do Backup. E agora, a tão esperada Cara do Bixo. Essa é a tela inicial. Simples e modesta. Sem propagandas ou logomarcas coloridas. O Simple Backup lhe permite fazer backups simples, completos ou incrementais. Nesta primeira tela, você decide a forma desejada. Sugiro que para o primeiro teste, selecione a opção Somente backup manual. Desta forma iremos configurar um backup simples e rápido para testar a ferramenta. Selecionada a opção de “Somente backup manual”, vamos à próxima aba chamada “Inclusões”. Nos será apresentada a tela a seguir: Por padrão ele vai trazer vários diretórios, pode Remover os diretórios que ele lhe trás e adicionar alguns poucos diretórios (de preferência com poucos arquivos, apenas para agilizar nosso teste. ;] Um total de 20 ou 30 MBs já resolve para nosso teste. No meu exemplo, eu desejo backup apenas dos diretórios “/home/kalib/imgs/” e “/home/kalib/amsn_received/”, conforme pode ser visto na imagem anterior. Uma vez que você tenha finalizado a configuração dos diretórios desejados, vamos para a próxima aba: “Exceções” Esta aba servirá para informarmos o que NÃO deverá entrar no backup. Esta sessão se divide em 4 categorias, como pode ser visto na imagem abaixo: 1- Pastas - Aqui você lista quais pastas ou arquivos não deseja incluir no backup. Repare que ele já trás vários diretórios por padrão. Pode remover todos. Por exemplo: Supondo que eu tenha marcado o diretório /home/kalib/imgs/ para backup, porém dentro deste diretório existem os diretórios /imgs1 /imgs2 e /imgs3. Eu não quero o /imgs3 em meu backup, então posso incluir nestas Exceções de Pastas o caminho “/home/kalib/imgs/imgs3/”. Deverá ficar algo como ilustrado a seguir: 2- Tipos de arquivos - Aqui devemos descriminar quais tipos de arquivos iremos deixar fora fora do backup. Novamente, ele já trás vários diretórios por padrão. Pode remover todos. Esta função é útil por exemplo para quem não deseja levar no backup algum tipo de arquivos em específico. Por ","date":"2010-07-15","objectID":"/posts/simples-solucao-de-backup-sbackup/:0:0","tags":["Arch Linux","Cultura Hacker","Impressões","Linux","Segurança"],"title":"Simples Solucao De Backup Sbackup","uri":"/posts/simples-solucao-de-backup-sbackup/"},{"categories":["Impressões"],"content":"Mais uma recomendação para preencher os horários de ócio...","date":"2010-06-23","objectID":"/posts/recomendacao-bibliografica-do-mes-a/","tags":["Impressões","Literatura"],"title":"Recomendação Bibliográfica Do Mês: a Bruxa De Portobello","uri":"/posts/recomendacao-bibliografica-do-mes-a/"},{"categories":["Impressões"],"content":"Mais uma recomendação para preencher os horários de ócio… Como diria um amigo meu, tenhamos um ócio produtivo. A recomendação deste mês tem o título de A Bruxa de Portobello. Este é o novo título do renomado Paulo Coelho. Para quem não o conhece, se é que isso é possível, ele é o autor brasileiro que mais vendeu livros fora do Brasil. Foi consagrado por ser o autor do primeiro livro que vendeu mais do que a própria bíblia. Um de seus livros, O Alquimista, foi consagrado por um influente jornal de Portugal como o livro em língua portuguesa mais vendido no mundo. O autor também ocupa desde 2002 a cadeira de número 21 na Academia Brasileira de Letras. A história é sobre a vida de uma filha de ciganos chamada Sherine Khalil que foi adotada por um casal de libaneses. A mesma mudou-se com seus pais adotivos para Londres por conta de uma guerra civil que estava iniciando no Líbano por volta de 1974-1975. Em Londres seu pai consegue se restabelecer muito bem com a família ao mesmo tempo em que a menina cresce e é educada da melhor forma possível. Ao menos estes eram os planos de seus pais. Athena, como passou a ser conhecida posteriormente, um dia decide largar a faculdade e ter um filho aos 19 anos. Por alguns conflitos entre o casal acabam separando-se e a mesma decide conhecer novos locais bem como uma nova forma de viver por conta das dificuldades encontradas e da ausência de sentido em sua vida. Durante estas viagens conhece pessoas que posteriormente tornam-se Mestres e Discípulos desta que acabou despertando conhecimentos sobre uma antiga tradição que remonta os tempos pagãos nos quais o culto religioso era voltado à uma Deusa chamada de Grande Mãe. Após atrair muitos seguidores a mesma é caçada e apontada como bruxa e adoradora de Satanás. Após tentar defender o direito de exercer a sua, bem como a de muitos outros, liberdade de culto, Athena passa por inúmeras críticas e acusações inclusive judiciais. O fato é que os poderes despertados nela e que por sua vez são passados aos seus seguidores acabam moldando e mudando a vida de todos que a cercam de formas inusitadas. A história, ao invés de ser uma simples narrativa do autor, acontece em forma de relatos que partem de vários personagens que tiveram contato com Athena. Paulo Coelho optou por utilizar esta metodologia para evitar que ele escrevesse a SUA visão de Athena. Optou por relatar apenas a visão daqueles que tinham constante contato com a mesma. Uma leitura agradável e nem um pouco cansativa. Segue breve sinopse retirada do site da livraria Saraiva. “A Bruxa de Portobello”, novo livro de Paulo Coelho, trata das injustiças cometidas pela Igreja no período da inquisição. Além disso, traça um paralelo com a sociedade contemporânea, onde o medo da mudança e o conformismo muitas vezes determinam o curso de nossas vidas. Abraços! ","date":"2010-06-23","objectID":"/posts/recomendacao-bibliografica-do-mes-a/:0:0","tags":["Impressões","Literatura"],"title":"Recomendação Bibliográfica Do Mês: a Bruxa De Portobello","uri":"/posts/recomendacao-bibliografica-do-mes-a/"},{"categories":["Impressões"],"content":"Deveria ser esta a minha expressão de hoje, mas infelizmente não é. Não sei bem o porque, creio que estou tão empolgado com a performance do meu time (Ceará) no campeonato brasileiro que acabei perdendo a atenção que deveria estar voltada para a copa.","date":"2010-06-15","objectID":"/posts/e-hora-de-ser-brasileiro/","tags":["Impressões"],"title":"É Hora De Ser Brasileiro Novamente: Comecem a Rir Falsos Reis","uri":"/posts/e-hora-de-ser-brasileiro/"},{"categories":["Impressões"],"content":"WOW HOJE TEM JOGO DO BRASIL! Deveria ser esta a minha expressão de hoje, mas infelizmente não é. Não sei bem o porque, creio que estou tão empolgado com a performance do meu time (Ceará) no campeonato brasileiro que acabei perdendo a atenção que deveria estar voltada para a copa. O bom de não estar envolto nesta “magia” que contagia e envolve a grande maioria dos brasileiros a cada 4 anos é termos a chance “rara” de observarmos o cenário por um outro ângulo. De repente, é copa do mundo. É hora de todo mundo comprar roupas e acessórios com as cores de nossa bandeira. Como diria MV Bill, “sociedade hipócrita só lembra de ser brasileira na copa!”. É engraçado ver pessoas que não ligam para sua nação e ao menos respeitam a própria cultura que lhes foi concebida no ato de seu nascimento. Pessoas que sentem vergonha de se dizerem “brasileiros” e de repente vestem verde e amarelo para gritar ao mundo todo “Sou Brasileiro!” com uma coragem de orgulho que apenas o esporte pode propiciar. O mais “engraçado”? Bom, creio que seja ver que todos acabam saindo ganhando com a Copa do Mundo. Isso mesmo, até nossos amigos políticos saem ganhando. Porque não? Eles cumprem a parte deles no trato e nós olhamos pro outro lado. Isso mesmo, eles nos entregam o pão (?) e o circo(!), e nós nos prendemos durante quase 40 dias de frente para a televisão. Quem, enquanto ocupando um cargo público e sedento por algum desvio ou roubalheira, desejaria um palco melhor do que a Copa do Mundo que move nações e enfeitiça praticamente 100% do povo brasileiro? É a hora da festa pessoal! - Diz o político XYZ do partido PAdaCM (Partido Aproveitador da Copa do Mundo). É chegada a hora de nossos políticos trabalharem, sancionarem o máximo de leis possíveis que possam beneficiar seus próprios bolsos. Companheiros, nosso tempo é curto daqui a pouco termina a copa e todos começam a observar nossos passos novamentes. Por favor, assinem na última página do documento que lhes foi entregue no início desta sessão. - Solicita o deputado ZYX. E assim começa mais uma Copa do Mundo. É “Pra Frente Brasil!” pra cá… “Vamos ser Hexa!” pra lá.. E “Este projeto de Lei poderia nos ser útil!” por ali… É isso aí.. Pra Frente Brasil! Infelizmente nossa patria está sendo “governada” por aproveitadores e corruptos. “Ordem, Progresso e Perdão.. Na terra onde quem rouba muito não tem punição!” Não me entendam mal. Não estou no papel de quem critica os fans do esporte, muito pelo contrário. Sou um amante do esporte. Amo futebol e procuro não perder um jogo sequer do meu time. Amo a nossa seleção e incentivo fortemente que todos o façam. Porém, antes de mais nada creio que devemos amar o que está por trás das cores da camisa de nossos jogadores. Não façamos da Copa do Mundo uma oportunidade para “nossos” “representantes” fazerem a festa. Sim, espero de coração que nossa seleção volte para o Brasil com mais uma taça. E, agora sim… Pra Frente Brasil! Salve A Seleção! Abraços! ","date":"2010-06-15","objectID":"/posts/e-hora-de-ser-brasileiro/:0:0","tags":["Impressões"],"title":"É Hora De Ser Brasileiro Novamente: Comecem a Rir Falsos Reis","uri":"/posts/e-hora-de-ser-brasileiro/"},{"categories":["Impressões"],"content":"Saudações pessoal! Depois de um longo tempo sem postar venho lhes informar que já podemos ter o KDe 4.4.4 em nosso Arch Linux. O mesmo já seencontra devidamente empacotado e disponível em nossos repositórios. Por se tratar de uma quantidade grande de pacotes (mais de 300 MB), execute o comando para atualizar seu sistema antes de prosseguir com a leitura do post. # pacman -Syu_ Cheers! Ou deveria dizer.. Saúde!? Para quem não sabe, “Cheers” é a expressão utilizada no idioma Inglês ao se fazer um brinde. Sim, seria o nosso bom e velho “Saúde”. Além desta utilização, também pode ser utilizado em geral como um “viva” ou simplesmente um desejo de saúde em uma carta, email ou algo que o valha. Este é o codinome da versão 4.4.4 do KDE que foi liberada ontem, 1 de Junho, pela equipe do projeto. Lançamento este que, façamos justiça, merece mesmo um brinde. Cheers, ou KDE 4.4.4 para os menos íntimos, será o último lançamento da série 4.4 que dará espaço para a próxima release, KDE 4.5, que tem previsão de lançamento para Agosto. Por se tratar apenas de correções de bugs e traduções, todos podem efetuar a atualização sem medo algum de perder configurações ou seja o que for. Dentre as correções, destacam-se: _* Vários bugs na listagem de nomes do gerenciador de arquivos Dolphin foram corrigidos; Bugs relacionados a encodes e arquivos zipados foram corrigidos; Vários bugs nos games do KDE foram corrigidos…_ Dentre outros… Para os curiosos de plantão que desejem já ir conhecendo o que ainda está por vir, a equipe de desenvolvimento do KDE já disponibilizou o primeiro beta da próxima release, KDE 4.5, que deverá estar disponível em Agosto. Maiores informações podem ser obtidas neste link. Abraços! ","date":"2010-06-02","objectID":"/posts/kde-4-4-4-liberado/:0:0","tags":["Arch Linux","Impressões","KDE","Linux","Software Livre"],"title":"Kde 4.4.4 Liberado - Atualize Seu Arch Linux Cheers","uri":"/posts/kde-4-4-4-liberado/"},{"categories":["Impressões"],"content":"Gostaria de parabenizar todos os que ajudam o movimento de Software Livre, seja qual for o projeto e seja qual for a forma de colaboração, porém gostaria de dedicar o post ao trabalho de tradução feito pelo pessoal do KDE Brasil.","date":"2010-05-03","objectID":"/posts/parabens-kde-brasil-100-traduzido/","tags":["Cultura Hacker","Impressões","KDE","Linux","Software Livre"],"title":"Parabéns Kde Brasil! 100% Traduzido","uri":"/posts/parabens-kde-brasil-100-traduzido/"},{"categories":["Impressões"],"content":"Wow… Mais uma importante marca atingida por um projeto nacional! Gostaria de parabenizar todos os que ajudam o movimento de Software Livre, seja qual for o projeto e seja qual for a forma de colaboração, porém gostaria de dedicar o post ao trabalho de tradução feito pelo pessoal do KDE Brasil. Atingimos a marca de 100% do KDE Brasil traduzido! Para quem não tem noção do que isso significa, saibam que são mais de 104.000 linhas traduzidas. Não foram apenas os pacotes principais, mas tudo o que está englobado no KDE. A equipe do KDE Brasil tem trabalho arduamente neste sentido tentando garantir sempre o máximo de suporte aos usuários brasileiros deste que é um dos mais populares gerenciadores de janelas do mundo Linux. Vale lembrar que estes resultados são referentes à versão atual, KDE 4.4 (Stable), o que não desmerece muito o trabalho com a versão que será lançada em breve, KDE 4.5 visto que a mesma também se encontra quase que 100% traduzida, conforme imagem abaixo: A imagem abaixo demonstra claramente a vantagem do time brasileiro em termos de traduções para o KDE em relação aos demais países. Levando em conta que quanto mais “verde”, melhor… podemos ver uma clara vantagem em nosso país em relação à maioria dos demais. Que continue sempre assim. Para aqueles interessados em ajudar nas traduções futuras do KDE, deixo os dois links a seguir: 1- Como Ajudar 2- Onde Ajudar Abraços! ","date":"2010-05-03","objectID":"/posts/parabens-kde-brasil-100-traduzido/:0:0","tags":["Cultura Hacker","Impressões","KDE","Linux","Software Livre"],"title":"Parabéns Kde Brasil! 100% Traduzido","uri":"/posts/parabens-kde-brasil-100-traduzido/"},{"categories":["Eventos"],"content":"Algumas semanas atrás uma amiga me perguntou algumas coisas sobre reciclagem ou reaproveitamento de e-lixo ou lixo eletrônico para os menos íntimos. A mesma não informou estes termos mas a intenção foi parecida. Me perguntou sobre como se descartar corretamente mídias (cds, dvds) ou velhas peças de computador. E como estamos nos aproximando do FLISOL, aproveitei para divulgar uma iniciativa que teremos aqui em Fortaleza no dia 24 de Abril durante o FLISOL - Festival Latino Americano de Instalação de Software Livre.","date":"2010-04-09","objectID":"/posts/lixo-eletronico-nao-sabe-o/","tags":["Cultura Hacker","Flisol","Impressões","Meio Ambiente"],"title":"Lixo Eletrônico: Não Sabe O Que Fazer? O Flisol Sabe","uri":"/posts/lixo-eletronico-nao-sabe-o/"},{"categories":["Eventos"],"content":"Saudações pessoal, todos dispostos a ajudar? Algumas semanas atrás uma amiga me perguntou algumas coisas sobre reciclagem ou reaproveitamento de e-lixo ou lixo eletrônico para os menos íntimos. A mesma não informou estes termos mas a intenção foi parecida. Me perguntou sobre como se descartar corretamente mídias (cds, dvds) ou velhas peças de computador. E como estamos nos aproximando do FLISOL, aproveitei para divulgar uma iniciativa que teremos aqui em Fortaleza no dia 24 de Abril durante o FLISOL - Festival Latino Americano de Instalação de Software Livre. Mas, o que é esse tal e-lixo? Vivo recebendo esses SPAMs em minha caixa de email. Posso reciclar isso? o.O Na verdade e-lixo não tem nada a ver com SPAM, apesar de algumas pessoas acharem que sim. Quando citamos e-lixo, estamos falando de seus aparelhos eletrônicos que, por algum motivo, foram descartados por você. Televisores, aparelhos de DVD, computadores, impressoras, calculadoras, etc, são exemplos de lixo eletrônico que, uma vez que não sejam descartados da forma correta, acabarão em aterros comuns cujo único destino será se tornar um agente poluidor para o solo, água e porque não o ar. Existem várias formas de “dar um fim”, literalmente, a este “bens”. Utilizei a expressão dar um fim, pois é literalmente o que o FLISOL Fortaleza pretende fazer. O objetivo é dar um novo fim a estes objetos. Existem vários projetos que trabalham diretamente com estas “peças” que descartamos. O que para nós não tem mais utilidade, para eles terá um fim que pode surpreender até mesmo o mais criativo artista. Trabalhos como o de meta-reciclagem demonstram a cada dia que este tipo de material pode sim ser utilizado para a criação de novos produtos, sejam eles eletrônicos, partindo dos componentes ainda em funcionamento, ou mesmo utensílios domésticos, enfeites, etc. No FLISOL Fortaleza deste ano teremos um ponto de coleta deste material durante todo o dia do evento. Pentes de memória RAM, HDs, placas de vídeo, placas mãe ou qualquer coisa que o valha estará sendo coletado. Nos vemos lá. Abraços! ","date":"2010-04-09","objectID":"/posts/lixo-eletronico-nao-sabe-o/:0:0","tags":["Cultura Hacker","Flisol","Impressões","Meio Ambiente"],"title":"Lixo Eletrônico: Não Sabe O Que Fazer? O Flisol Sabe","uri":"/posts/lixo-eletronico-nao-sabe-o/"},{"categories":["Aleatórios"],"content":"Fico feliz em escrever-lhes hoje por conta da novidade que lhes apresento.","date":"2010-03-30","objectID":"/posts/produtos-arch-linux/","tags":["Arch Linux","Impressões","Software Livre"],"title":"Produtos Arch Linux","uri":"/posts/produtos-arch-linux/"},{"categories":["Aleatórios"],"content":"Saudações pessoal, Fico feliz em escrever-lhes hoje por conta da novidade que lhes apresento. Cansado de procurar produtos do Arch Linux e nunca encontrar no Brasil? Seus problemas acabaram! O pessoal da LojaGeek.com nos deu essa força. A loja está começando suas atividades agora e já possuem alguns produtos do Arch à nossa disposição. Em contato com eles, me informaram que os produtos atuais são apenas uma prévea do que está por vir. A ideia deles é ter uma loja que apoie de forma real o Software Livre bem como os projetos nacionais. Além dos produtos do Arch eles contam com produtos de outros projetos como bancos de dados, outras distribuições linux, linguagens de programação, etc. Parabéns ao pessoal da LojaGeek.com e obrigado por disponibilizar produtos do Arch, visto que nunca encontrei em nehum outro site brasileiro. Abraços! ","date":"2010-03-30","objectID":"/posts/produtos-arch-linux/:0:0","tags":["Arch Linux","Impressões","Software Livre"],"title":"Produtos Arch Linux","uri":"/posts/produtos-arch-linux/"},{"categories":["Eventos"],"content":"Como eu já havia informado em um outro post, estamos nos aproximando do FLISOL - Festival Latino Americano de Instalação de Software Livre.","date":"2010-03-25","objectID":"/posts/inscricoes-abertas-para-o-flisol/","tags":["Linux","Flisol","Software Livre"],"title":"Inscrições Abertas Para O Flisol Fortaleza 2010","uri":"/posts/inscricoes-abertas-para-o-flisol/"},{"categories":["Eventos"],"content":"Saudações pessoal! Como eu já havia informado em um outro post, estamos nos aproximando do FLISOL - Festival Latino Americano de Instalação de Software Livre. Para maiores informações sobre o evento, visite este link! A novidade agora é o fato de que as inscrições para o evento estão abertas. Garanta sua vaga e escolha juntamente qual distribuição Linux você gostaria de ganhar durante o evento através deste link. Abraços ","date":"2010-03-25","objectID":"/posts/inscricoes-abertas-para-o-flisol/:0:0","tags":["Linux","Flisol","Software Livre"],"title":"Inscrições Abertas Para O Flisol Fortaleza 2010","uri":"/posts/inscricoes-abertas-para-o-flisol/"},{"categories":["Tutoriais"],"content":"O XBMC é um magnífico software para manipulação de multimedia. Com ele você pode facilmente organizar, rotular e manipular seus vídeos, músicas, fotos, etc.","date":"2010-03-24","objectID":"/posts/xbmc-para-manipular-multimedia/","tags":["Arch Linux","Impressões","Linux","Software Livre"],"title":"Xbmc Para Manipular Multimedia","uri":"/posts/xbmc-para-manipular-multimedia/"},{"categories":["Tutoriais"],"content":"Olá pessoal, demorei mas apareci novamente. Como todos sabiam, eu estava sem máquina. Meu notebook deu problemas e fiquei sem ele por um tempo. Acabo de receber e instalar meu novo notebook e agora estou de volta. Seguem fotos da nova máquina.. Agora vai.. hehehe Acho que dá pro gasto por um tempo… [kalib@tuxcaverna ~]$ uname -a Linux tuxcaverna 2.6.32-ARCH #1 SMP PREEMPT Mon Mar 15 20:44:03 CET 2010 x86_64 Intel(R) Core(TM)2 Duo CPU P7550 @ 2.26GHz GenuineIntel GNU/Linux Mas não é sobre isso que eu pretendo falar hoje, mas sim sobre o XBMC para aqueles que ainda não o conhecem. O XBMC é um magnífico software para manipulação de multimedia. Com ele você pode facilmente organizar, rotular e manipular seus vídeos, músicas, fotos, etc. De forma interativa e rápida você pode criar rótulos e menus para navegação rápida sem precisar ficar navegando em todas as pastas do seu computador atrás daqueles vídeos que você deseja assistir. Toda a reprodução acontece dentro do XBMC utilizando-se de outros aplicativos em background o que torna a experiência extremamente agradável para o usuário sem que o mesmo tenha que manipular um aplicativo para ver fotos, um para vídeos e um para mp3, por exemplo. O que mais me impressiona é a simplicidade com que podemos manipular o programa deixando um vídeo rolando e ao mesmo tempo podendo navegar pelo mesmo a procura de um novo vídeo por exemplo. O XBMC se encontra disponível nos repositórios do Arch Linux e pode ser instalado facilmente com: pacman -Sy xbmc Para demais distribuições, pode-se checar a página do projeto para maiores informações. Um vídeo amador de minha máquina nova rodando o xbmc. (Porque gravando com o celular ao invés de um aplicativo para isso? Preguiça ué.. ainda não instalei tudo nessa máquia nova.. :p) Abraços ","date":"2010-03-24","objectID":"/posts/xbmc-para-manipular-multimedia/:0:0","tags":["Arch Linux","Impressões","Linux","Software Livre"],"title":"Xbmc Para Manipular Multimedia","uri":"/posts/xbmc-para-manipular-multimedia/"},{"categories":["Eventos"],"content":"Como todos já devem saber sou militante do movimento de Software Livre e como tal sempre estou engajado em algum projeto/evento que envolva liberdade e compartilhamento de conhecimento. Neste momento estou me focando no FLISOL Fortaleza 2010.","date":"2010-03-12","objectID":"/posts/flisol-fortaleza-2010/","tags":["Cultura Hacker","Impressões","Linux","Software Livre","Tux-ce"],"title":"Flisol Fortaleza 2010","uri":"/posts/flisol-fortaleza-2010/"},{"categories":["Eventos"],"content":"Saudações pessoal! Quem é vivo sempre aparecer… Não, eu não abandonei o blog. Apenas estava sem recursos para continuar postando. Meu notebook resolveu apresentar problemas sérios depois de 4 anos na luta e acabei tendo de comprar outro. Ainda não chegou, portanto ainda está difícil conseguir postar por aqui.. mas cá estou. Como todos já devem saber sou militante do movimento de Software Livre e como tal sempre estou engajado em algum projeto/evento que envolva liberdade e compartilhamento de conhecimento. Neste momento estou me focando no FLISOL Fortaleza 2010. Para quem ainda não conhece o FLISOL, Festival Latinoamericano de Instalação de Software Livre, é um evento anual que acontece, como o próprio nome indica, simultaneamente em toda a América Latina. Mais de 150 cidades sediam o evento com organizações locais que trocam informações e ajuda entre si para tal. Desde 2005 estou direta ou indiretamente engajado na organização do mesmo aqui em Fortaleza, portanto neste ano não poderia ser diferente. Um dos grandes diferenciais, e minha maior motivação, deste ano é o fato de estarmos, também, comemorando o aniversário de 5 anos da Comunidade Tux-CE. O evento se baseia em, basicamente, instalar Software Livre nas máquinas dos visitantes que não possuem experiência ou não se sintam seguros para o fazerem sozinhos, porém em algumas cidades, como é o caso aqui em Fortaleza, optamos por fazer mais do que simplesmente instalações. Sempre temos palestras, apresentações, demonstrações, distribuição de mídias com distribuições Linux e outros softwares livres, etc… Neste ano estamos adotando o recurso de “Páginas Amigas” como uma forma de ajudar e ser ajudado! Bem a cara do Software Livre, certo?! Se você possui um site, blog ou qualquer coisa que o valha, pode submeter-se como uma página amiga do FLISOL. Com isso você terá um banner de seu site, blog ou coisa que o valha exposto em nossa página do FLISOL em troca de um banner do evento no seu. É uma espécie de ajuda mútua onde ambos se beneficiam. Para conseguir mais detahes sobre como se tornar uma página amiga do FLISOL, visite este link. Amanhã mesmo teremos uma reunião de organização do evento na qual discutiremos mais alguns detalhes sobre o mesmo. Em breve volto a publicar maiores detalhes. Abraços! ","date":"2010-03-12","objectID":"/posts/flisol-fortaleza-2010/:0:0","tags":["Cultura Hacker","Impressões","Linux","Software Livre","Tux-ce"],"title":"Flisol Fortaleza 2010","uri":"/posts/flisol-fortaleza-2010/"},{"categories":["Impressões"],"content":"Para quem curte histórias de ficção, os livros do Stephen King são sem sombra de dúvidas um prato cheio. A história de A Torre Negra, composta por 7 volumes, não foje à regra.","date":"2010-02-22","objectID":"/posts/recomendacao-bibliografica-a-torre-negra/","tags":["Impressões","Literatura"],"title":"Recomendação Bibliográfica: A Torre Negra Vol III as Terras Devastadas","uri":"/posts/recomendacao-bibliografica-a-torre-negra/"},{"categories":["Impressões"],"content":"Olá pessoal, após o carnaval estou de volta ao meu blog que ficou abandonado por mais de uma semana. Não pensem que foi descaso. Não estive pulando o carnaval. (Nem gosto disso. o.O) Não viajei e fiquei em casa estudando e trabalhando.. :/ Passou, passou… A recomendação bibliográfica deste mês é na verdade a continuação da saga A Torre Negra de Stephen King. Para quem curte histórias de ficção, os livros do Stephen King são sem sombra de dúvidas um prato cheio. A história de A Torre Negra, composta por 7 volumes, não foje à regra. Para quem não conhece a Saga e/ou não acompanhou meus posts sobre os dois primeiros volumes, sugiro que leia primeiro estes dois links: A Torre Negra vol I - O Pistoleiro A Torre Negra vol II - A escolha dos três Neste terceiro volume de título As Terras Devastadas, o pistoleiro continua sua busca pela Torre Negra juntamente com seus discípulos pelas estranhas Terras Devastadas enfrentando um mundo completamente diferente da realidade vivida até então pelos personagens, mesmo cada um sendo de um espaço diferente no tempo. Com criaturas denominadas como “Guardiães” a missão em busca da Torre Negra se torna uma saga cada vez mais intrigante por conta dos contextos ocultos e divisões no tempo/espaço em que a história acontece e/ou deixa de acontecer. Segue uma breve descrição do livro retirado do site da Saraiva: No terceiro volume da saga “A Torre Negra”, Roland, o último Pistoleiro, se aproxima ainda mais da Torre Negra de seus sonhos e pesadelos - atravessando um deserto amaldiçoado em um mundo macabro que é uma imagem distorcida do nosso próprio mundo. Entre mais uma vez no reino de uma das imaginações mais poderosas de nossa época: a do escritor Stephen King. Espero que curtam. Realmente recomendo a série mesmo ainda estando no terceriro livro. Abraços ","date":"2010-02-22","objectID":"/posts/recomendacao-bibliografica-a-torre-negra/:0:0","tags":["Impressões","Literatura"],"title":"Recomendação Bibliográfica: A Torre Negra Vol III as Terras Devastadas","uri":"/posts/recomendacao-bibliografica-a-torre-negra/"},{"categories":["Impressões"],"content":"Este post é dedicado aos amigos de Portugal que visitam o meu blog, bem como usuários Arch Linux em geral.","date":"2010-02-05","objectID":"/posts/comunidade-arch-linux-portugal/","tags":["Arch Linux","Cultura Hacker","Google","Impressões","Linux","Software Livre"],"title":"Comunidade Arch Linux Portugal","uri":"/posts/comunidade-arch-linux-portugal/"},{"categories":["Impressões"],"content":"Saudações colegas! Ou deveria dizer “Boas”?¿ Este post é dedicado aos amigos de Portugal que visitam o meu blog, bem como usuários Arch Linux em geral. Gostaria de comunicar o nascimento da Comunidade Arch Linux Portugal. É comum encontrarmos usuários em nosso canal de irc que são de Portugal (Tugas). Percebemos facilmente pelo português diferente. Já havíamos percebido a falta de um espaço dedicado a eles. Em contato com o Mkman, um usuário Arch de Portugal, decidimos que estava na hora de mudar essa história. Agora este problema começa a se resolver. A Comunidade Arch Linux Portugal acaba de nascer oficialmente e está procurando ajuda para sua estruturação: Site, fórum, lista e outros serviços. Assim como fazemos no Arch Linux Brasil, dentre outras comunidades Arch Linux em outros países, a comunidade Arch Linux Portugal será o ponto de apoio entre o Arch Linux e os usuários dessa distribuição em seu país. Além de fornecer suporte e ajudar na divulgação da distribuição em Portugal, a comunidade também servirá como uma ponte de colaboração mais direta no projeto Arch Linux internacional, seja com tradução de documentação, empacotamento no AUR, etc. O Arch Linux Portugal já conta com um grupo no GoogleGroups onde podemos trocar ideias e tirar dúvidas. Para se cadastrar, acesse o seguinte endereço: https://groups.google.com/group/archlinux_pt Além da lista de email, o Arch Linux Portugal também já possui um canal de irc na rede freenode: archlinux-pt@irc.freenode.net Para os que não possuem intimidade com o irc, basta utilizar algum cliente irc como o Xchat por exemplo e se conectar na rede freenode através do comando: /server irc.freenode.net Em seguida, basta acessar o canal com o comando: /join #archlinux-pt OBS: “Tugas” interessados em ajudar no projeto de alguma forma, podem se cadastrar no groups do Google ou aparecer no irc e entrar em contato comigo (kalib) ou com o Mkman através do email ttiagosousa at gmail.com. Agora é a vez de vocês “Tugas”. Em nome do Arch Linux Brasil gostaria de destacar que daremos total apoio a vocês no que precisarem. Abraços ","date":"2010-02-05","objectID":"/posts/comunidade-arch-linux-portugal/:0:0","tags":["Arch Linux","Cultura Hacker","Google","Impressões","Linux","Software Livre"],"title":"Comunidade Arch Linux Portugal","uri":"/posts/comunidade-arch-linux-portugal/"},{"categories":["Impressões"],"content":"Tirei férias e estive me mantendo afastado do teclado por este período. Também sou filho de Deus e resolvi aproveitar esse tempo longe do computador. Percebi que isso faz muito bem. ;]","date":"2010-02-01","objectID":"/posts/retornando-das-ferias-novo-planeta/","tags":["Arch Linux","Linux","Software Livre"],"title":"Retornando Das Férias: Novo Planeta Do Archlinux Brasil","uri":"/posts/retornando-das-ferias-novo-planeta/"},{"categories":["Impressões"],"content":"Saudações Pessoal, Como puderam perceber, estive ausente no último mês. Tirei férias e estive me mantendo afastado do teclado por este período. Também sou filho de Deus e resolvi aproveitar esse tempo longe do computador. Percebi que isso faz muito bem. ;] Agora estou de volta e como não poderia deixar de ser, muito trabalho pela frente. Gostaria de aproveitar este post para informar que finalizamos os trabalhos em cima do novo planeta do Archlinux Brasil. A antiga ferramenta que utilizávamos para o planeta (agregador de feeds) estava apresentando algumas falhas e resolvemos mudar. Este trabalho levou algum tempo por conta do período de festas (Natal e Reveillon) bem como férias, mas finalmente o novo planeta está no ar. Se você já fazia parte de nosso planeta, e tenha notado que seu feed está quebrado ou desatualizado, pode me mandar um email ou comentar neste post. Se ainda não faz parte do planeta, mas acha que seu site/blog poderia aparecer em nosso planeta por se encaixar na temática, pode entrar em contato comigo também. Abraços e de volta ao trabalho pessoal… ","date":"2010-02-01","objectID":"/posts/retornando-das-ferias-novo-planeta/:0:0","tags":["Arch Linux","Linux","Software Livre"],"title":"Retornando Das Férias: Novo Planeta Do Archlinux Brasil","uri":"/posts/retornando-das-ferias-novo-planeta/"},{"categories":["Aleatórios"],"content":"Este post vai em homenagem ao mais novo membro de minha família. O Tux!","date":"2009-12-15","objectID":"/posts/o-tux-agora-e-oficialmente/","tags":["Impressões"],"title":"O Tux Agora É Oficialmente Um Membro Da Família","uri":"/posts/o-tux-agora-e-oficialmente/"},{"categories":["Aleatórios"],"content":"Saudações pessoal, Este post vai em homenagem ao mais novo membro de minha família. O Tux! Exatamente, é um lindo labrador. O Tux hoje está completando seus 47 dias de vida e já está se acostumando com sua nova casa onde chegou na última noite. Já possui suas tigelas de água e comida bem como alguns brinquedinhos, mas como ele chegou tarde da noite não deu tempo de comprar tudo ainda. Abaixo uma foto do Tux com sua vovó (minha mãe). Sim, ele esta com cara de sono. Era tarde da noite e ele ainda não havia chegado em sua casa nova. Quem nunca sonhou em ter o Tux em casa? haha Agora eu o tenho. Já até pensei no presente para quando ele completar 1 ano de idade: Uma camisa do ceará! Glorioso alvinegro recém chegado à primeira divisão, elite do futebol brasileiro. Porque não dou agora? Sim, eu sei que ele ficaria lindo de alvinegro, mas venhamos e convenhamos.. um cachorro como um labrador não permanece nesse tamanho por mais de 2 meses… hehehe Melhor aguardar ele estabilizar o seu tamanho. Isso aí.. saindo do banho e dando um bom dia para o Tux.. :p Abraços galera… ","date":"2009-12-15","objectID":"/posts/o-tux-agora-e-oficialmente/:0:0","tags":["Impressões"],"title":"O Tux Agora É Oficialmente Um Membro Da Família","uri":"/posts/o-tux-agora-e-oficialmente/"},{"categories":["Tutoriais"],"content":"Para quem já vem acompanhando este projeto desde seu início, tenho o prazer de anunciar esta novidade nos repositórios do Arch.","date":"2009-12-14","objectID":"/posts/chromium-no-testing-do-arch/","tags":["Arch Linux","Chromium","Cultura Hacker","Impressões","Software Livre"],"title":"Chromium No Testing Do Arch Linux","uri":"/posts/chromium-no-testing-do-arch/"},{"categories":["Tutoriais"],"content":"Saudações pessoal… Já estava na hora eim?! Chromium passando para o repositório [testing] no Arch. Para quem já vem acompanhando este projeto desde seu início, tenho o prazer de anunciar esta novidade nos repositórios do Arch. Por questões de segurança e estabilidade para os usuários como um todo, resolvemos manter também o pacote em nosso repositório nacional [archlinux-br] para evitar que os usuários do chromium tenham que habilitar o [testing] em seus sistemas correndo alguns riscos por pacotes pouco testados. Assim que o mesmo passar para repositórios mais confiáveis como o [extra], estaremos removendo do repositório nacional. Com algumas mudanças nesta versão do pacote, não estamos mais utilizando o snapshot, mas sim a versão já considerada beta do próprio projeto chromium. Para os que já utilizam o repositório [archlinux-br] e já possuem o chromium instalado, basta mandar atualizar seu sistema normalmente com: # pacman -Syu Perceberá que o pacman informará que o chromium-snapshot precisará ser removido para a instalação do chromium. Podem confirmar sem medo algum. Ontem mesmo eu e thotypous realizamos os últimos testes neste sentido e tudo saiu bem. Para aqueles que ainda não utilizam o repositório [archlinux-br] e ainda não possuem o chromium instalado, a dica é a seguinte: 1- Habilite o repositório inserindo as seguintes linhas no arquivo /etc/pacman.conf: [archlinux-br] Server = https://repo.archlinux-br.org/i686_ 2- Atualize seus mirros e instale o chromium: # pacman -Sy chromium Uma terceira opção, indicada para os mais aventureiros, seria habilitar o repositório [testing]. Esta opção eu apenas recomendo para os que estão dispostos a ajudar mais diretamente no desenvolvimento do Arch e que desejem assumir alguns riscos de estabilidade, visto que muitos pacotes ali ainda se encontram em estado de teste. Neste caso, basta descomentar as linhas referente a ele no arquivo /etc/pacman.conf: [testing] Include = /etc/pacman.d/mirrorlist_ Façam bom proveito pessoal. ;] Usem com moderação.. :p Abraços ","date":"2009-12-14","objectID":"/posts/chromium-no-testing-do-arch/:0:0","tags":["Arch Linux","Chromium","Cultura Hacker","Impressões","Software Livre"],"title":"Chromium No Testing Do Arch Linux","uri":"/posts/chromium-no-testing-do-arch/"},{"categories":["Impressões"],"content":"É chegada a hora de mais uma recomendação bibliográfica pessoal. Desta vez trago mais uma com o tema Vampiros.","date":"2009-12-08","objectID":"/posts/recomendacao-bibliografica-o-vampiro-rei/","tags":["Impressões","Literatura"],"title":"Recomendação Bibliográfica: O Vampiro Rei Vol II","uri":"/posts/recomendacao-bibliografica-o-vampiro-rei/"},{"categories":["Impressões"],"content":"É chegada a hora de mais uma recomendação bibliográfica pessoal. Desta vez trago mais uma com o tema “Vampiros”. Na verdade a recomendação deste mês se trata da continuação de uma outra recomendação que eu já havia feito e que pode ser conferida neste link. Este livro continua a história da saga que se iniciou com o livro O Bento e continuada em O Vapiro Rei - Vol I. O da vez, O VAmpiro Rei - Vol II, é o responsável por dar continuidade e encerramento à saga. Quem acompanhou o começo da saga, já conhece a história em que vampiros dominaram o Brasil e os poucos humanos restantes se organizam em fortificações em busca de uma forma de “salvar” o mundo da “praga” vampírica. Soldados escolhidos e “abençoados” que possuem o dom contra os vampiros são entitulados Bentos e unem-se formando estratégias para o inevitável combate final. O líder destes guerreiros bentos é o responsável por agrupar e organizar as estratégias que serão utilizadas pelos humanos neste combate. Neste livro o confronto tão esperado finalmente se realiza entre o líder dos Bentos e o então entitulado Vampiro Rei, que por sua vez exerce a mesma influência que o líder dos guerreiros Bentos porém para sua própria “espécie”, os noturnos, finalmente aparece e começa a organizar o seu exército de vampiros com o objetivo de dominar de vez e acabar com os humanos restantes e suas fortificações. Segue uma pequena descrição do mesmo retirada do site da Livraria Saraiva: Bento Lucas, o guerreiro de luz, e Cantarzo, o “Vampiro-Rei”, finalmente se encontram e protagonizam o grande combate. O “Vampiro-Rei” Vol. 2 é o tomo mais recheado de aventuras, combates e criaturas fantásticas de toda a saga iniciada em Bento. Com uma narrativa envolvente e atual, a saga do guerreiro Lucas é o presente certo para aqueles que buscam se apaixonar pelo hábito da leitura e também para aqueles que já se amarram em literatura há muito tempo. André Vianco não é só certeza de boa leitura, é também a garantia de uma deliciosa e nova experiência. Embarque nessa história e conheça um mundo novo. Espero que curtam. ;] Abraços ","date":"2009-12-08","objectID":"/posts/recomendacao-bibliografica-o-vampiro-rei/:0:0","tags":["Impressões","Literatura"],"title":"Recomendação Bibliográfica: O Vampiro Rei Vol II","uri":"/posts/recomendacao-bibliografica-o-vampiro-rei/"},{"categories":["Impressões"],"content":"Novamente vou dedicar um post para responder uma pergunta que me fizeram. Não é a primeira vez que alguém me pergunta algo e eu resolvo responder em forma de post. Algumas pessoas já me perguntaram o que me leva a preferir Python à outras linguagens de programação. Mas como, coinscidentemente, de ontem para hoje 3 pessoas me fizeram a mesma pergunta, resolvi responder em forma de post e poupar um pouco de saliva (¿dedo no teclado?) e não responder de forma mais completa para um ou outro.","date":"2009-11-21","objectID":"/posts/porque-escolhi-python-python-para/","tags":["Impressões","Python","Software Livre"],"title":"Porquê Escolhi Python: Python Para Sysadmins","uri":"/posts/porque-escolhi-python-python-para/"},{"categories":["Impressões"],"content":"Saudações pessoal… Novamente vou dedicar um post para responder uma pergunta que me fizeram. Não é a primeira vez que alguém me pergunta algo e eu resolvo responder em forma de post. Algumas pessoas já me perguntaram o que me leva a preferir Python à outras linguagens de programação. Mas como, coinscidentemente, de ontem para hoje 3 pessoas me fizeram a mesma pergunta, resolvi responder em forma de post e poupar um pouco de saliva (¿dedo no teclado?) e não responder de forma mais completa para um ou outro. Antes de mais nada gostaria de informar que não sou programador. Trabalho na área de administração de sistemas, redes, segurança, etc, etc, etc, vulgo SysAdmin. Prazer. ;] Se você é SysAdmin com certeza já esbarrou com algumas linguagens de script como Bash, Perl, dentre outras. Provavelmente até já trabalhou com algumas delas. Estas linguagens podem nos ajudar a resolver pequenos problemas bem como automatizar e agilizar tarefas cotidianas de forma a ganhar produtividade e perder menos tempo com aquilo, bem como evitar stress, tédio e fadiga fazendo tarefas mecânicas e repetitivas. Estas linguagens são apenas ferramentas que podem ser utilizadas no dia-a-dia. Mas o que faz uma linguagem ser eficiente? Ela só pode ser considerada eficiente se puder lhe ajudar a ter o seu trabalho feito de uma forma mais produtiva e simples, certo?! Que tal Python dentro deste cenário? A inevitável pergunta acaba aparecendo: O Python é melhor que Perl, Bash, Ruby ou qualquer outra linguagem? Este é o tipo de pergunta que eu não conseguiria responder. A complexidade empregada nesta pergunta impede uma resposta em poucas palavras, visto que a definição de “melhor” varia de acordo com o cenário, bem como os protagonistas envolvidos. Por conta disto, não direi que o Python é melhor ou pior do que outras linguagens, mas vou abordar alguns exemplos que demonstram que a mesma pode ser uma excelente escolha. (¿Escapei bem?) Creio que o primeiro motivo que me leva a adotar Python é a simplicidade de seu código. Se uma linguagem não lhe permite aprender rapidamente e começar a escrever códigos para resolver seus problemas, a mesma acaba perdendo um pouco de credibilidade, certo? Lembrem-se que, como SysAdmin, não tenho tempo para ficar estudando livros e mais livros sobre uma ou outra linguagem. Apenas desejo resolver meu problema atual. Porque perder semanas ou meses estudando uma linguagem para somente então conseguir escrever algum código que realmente produza algo? Bem, o Python nos permite escrever scripts em horas, literalmente falando, ao invés de dias ou semanas. Se, como um SysAdmin, uma linguagem não lhe permite começar os estudos e escrever scripts imediatamente, você deveria realmente se questionar porque você deveria estudar ela. Mas de que me vale uma linguagem que me permite um rápido aprendizado, se a mesma não possui “poder”? Se a mesma não me permite realizar tarefas complexas e robustas? Bem, na verdade este é o segundo motivo pelo qual eu escolhi Python. Esta linguagem nos permite resolver problemas simples como analisar várias linhas de log e nos retirar apenas informações que nos sejam interessantes ou pertinentes gerando um relatório mais limpo e “legível” ao olho humano. Além de tarefas simples assim, o Python também vem sendo bastante utilizado para tarefas com maior grau de complexidade como análises de sequências genômicas, cálculos complexos de física, mecânica, mecatrônica, etc, sistemas web multithread ou mesmo pesadas análises estatísticas. Bom, se você é um SysAdmin, muito provavelmente você nunca precisará de nada disso, mas eu me sinto confortável em saber que estou estudando uma linguagem que me permitirá realizar tarefas mais complexas quando eu precisar. ;] Ok, Python me permite realizar até as tarefas complexas. Mas e a manutenção deste código. Como SysAdmin, não fico editando e revendo meus códigos todo dia. As vezes não entendemos nossos próprios códigos depois de alguns meses sem olhar para eles. O que eu queria","date":"2009-11-21","objectID":"/posts/porque-escolhi-python-python-para/:0:0","tags":["Impressões","Python","Software Livre"],"title":"Porquê Escolhi Python: Python Para Sysadmins","uri":"/posts/porque-escolhi-python-python-para/"},{"categories":["Eventos"],"content":"Gostaria de lhes lembrar que hoje, Sábado - 14 de Novembro, estará acontecendo o primeiro evento de Python do Ceará, PythOnCeará, organizado pela comunidade local de Python - Pug-CE.","date":"2009-11-14","objectID":"/posts/python-no-ceara-pythonceara/","tags":["Impressões","Python","Software Livre"],"title":"Python No Ceará: Pythonceara","uri":"/posts/python-no-ceara-pythonceara/"},{"categories":["Eventos"],"content":"Bom Dia galera… Gostaria de lhes lembrar que hoje, Sábado - 14 de Novembro, estará acontecendo o primeiro evento de Python do Ceará, PythOnCeará, organizado pela comunidade local de Python - Pug-CE. O evento promete ser um marco de startup para os pythonianos locais visto que será o degrau inicial para muitos outros eventos posteriores também organizados pela Pug-CE. O evento será realizado na faculdade 7 Setembro - FA7 - e contará com 4 palestras de temas que envolvem tanto o usuário iniciante que não conhece python como ao usuário avançado. “Por que python?!” – Tiago Freire (@tiagofreire) “Python para Web e Desktop” – Alec Nascimento (@alecnascimento) “Django tem ritmo!” – Italo Maia (@italomaia) “Sokoban com PyS60” – Fábio Cerqueira (@fabiocerqueira) Cada palestra terá duração de 50 minutos havendo uma pequena pausa para o coffee break. =] Recomendo que todos os interessados em conhecer um pouco mais sobre esta linguagem magnífica que é o Python compareça. Mais informações sobre o encontro: local: FA7, em frente a Unifor, sala 35 horário: das 13:00 às 17:30 dia: 14/11/09 Abraços ","date":"2009-11-14","objectID":"/posts/python-no-ceara-pythonceara/:0:0","tags":["Impressões","Python","Software Livre"],"title":"Python No Ceará: Pythonceara","uri":"/posts/python-no-ceara-pythonceara/"},{"categories":["Impressões"],"content":"Acho que todos, ou quase todos, devem ter acompanhado a notícia de que a gigante Google criou uma linguagem de programação chamada Go.","date":"2009-11-12","objectID":"/posts/go-ou-go-linguagem-do/","tags":["Golang","Cultura Hacker","Google","Impressões","Software Livre"],"title":"Go Ou Go!, Linguagem Do Google Cria Primeira Intriga","uri":"/posts/go-ou-go-linguagem-do/"},{"categories":["Impressões"],"content":"Acho que todos, ou quase todos, devem ter acompanhado a notícia de que a gigante Google criou uma linguagem de programação chamada Go. ","date":"2009-11-12","objectID":"/posts/go-ou-go-linguagem-do/:0:0","tags":["Golang","Cultura Hacker","Google","Impressões","Software Livre"],"title":"Go Ou Go!, Linguagem Do Google Cria Primeira Intriga","uri":"/posts/go-ou-go-linguagem-do/"},{"categories":["Impressões"],"content":"Go, a linguagem do Google Muito foi falado em vários sites/blogs sobre as vantagens/desvantagens da mesma. De fato é uma linguagem impressionante que se mostrou bastante eficaz na velocidade com que o compilador trabalha e compila todo o código. Realmente uma velocidade que impressiona a todos. Mesmo tendo achado a sua sintaxe, digamos assim, bastante feia e pouco prática (me lembrou pascal em alguns aspectos), ela realmente merece um estudo um pouco mais aprofundado do que um simples hello world. Apesar de preferir metodologias ágeis e linguagens que sigam esta linha, como python ou ruby, que se utilizam de códigos simples e elegantes, acredito que a linguagem Go pode trazer grande performance em muitos casos. Ainda não pude estudar de forma aprofundada mas já pude ver coisas bacanas na forma como aloca e desaloca memória. Isso realmente me chamou a atenção. Mas, nem tudo é um paraíso. ","date":"2009-11-12","objectID":"/posts/go-ou-go-linguagem-do/:1:0","tags":["Golang","Cultura Hacker","Google","Impressões","Software Livre"],"title":"Go Ou Go!, Linguagem Do Google Cria Primeira Intriga","uri":"/posts/go-ou-go-linguagem-do/"},{"categories":["Impressões"],"content":"Agora são duas? Com tantos rumores sobre o novo lançamento, acabou ficando oculto o fato de que já existia uma linguagem chamada Go! e que o criador da mesma, Francis Maccabe, está inclusive insatisfeito com o lançamento descarado do google. Sim, o mesmo já inclusive se reportou ao Google, como podem ver no link a seguir. O mais intrigante é que o mesmo utilizou a página de report de bugs/issues para o fazer. A pergunta é: Seria a escolha do nome da linguagem um bug a ser reportado? hehe https://code.google.com/p/go/issues/detail?id=9 O mesmo contesta a falta de “criatividade” (?¿) do Google por utilizar o nome Go. Se aquele link não bastou, segue um link de venda do livro do Maccabe escrito em 2007 a cerca da linguagem Go!. https://www.lulu.com/content/paperback-book/lets-go/641689 Como será que o google irá lidar com isso? Terá a decência de agir corretamente e mudar o nome de sua linguagem enfrentando toda a dor de cabeça disto após seu lançamento e divulgação? Ou simplesmente “comprará” a outra ideia, quem sabe oferecendo um emprego ou coisa parecida ao Mccabe?! Que coisa não?! o.O Abraços ","date":"2009-11-12","objectID":"/posts/go-ou-go-linguagem-do/:2:0","tags":["Golang","Cultura Hacker","Google","Impressões","Software Livre"],"title":"Go Ou Go!, Linguagem Do Google Cria Primeira Intriga","uri":"/posts/go-ou-go-linguagem-do/"},{"categories":["Eventos"],"content":"Saudações pessoal, este ano o Ceará On Rails terá sua segunda edição trazendo uma programação mais extensa em relação à anterior, em 2009.","date":"2009-11-05","objectID":"/posts/ceara-on-rails-2010/","tags":["Impressões","Ruby","Software Livre"],"title":"Ceará on Rails 2010","uri":"/posts/ceara-on-rails-2010/"},{"categories":["Eventos"],"content":"Saudações pessoal, este ano o Ceará On Rails terá sua segunda edição trazendo uma programação mais extensa em relação à anterior, em 2009. ","date":"2009-11-05","objectID":"/posts/ceara-on-rails-2010/:0:0","tags":["Impressões","Ruby","Software Livre"],"title":"Ceará on Rails 2010","uri":"/posts/ceara-on-rails-2010/"},{"categories":["Eventos"],"content":"Introdução O Ruby tem ganho bastante destaque nos últimos anos pela sua praticidade e performance enquanto linguagem para desenvolvimento ágil e simples. O Ceará On Rails é um evento que vai trazer boas palestras aos rubistas do Ceará. O evento será realizado no dia 7 de Novembro em Fortaleza na Unifor a partir das 14 horas. Valor da entrada? Apenas uma gentil doação de 2 quilos de alimentos não perecíveis (arroz, feijão, açúcar, etc) que serão doados para a instituição Lar Beneficiente Clara de Assis. O que? Você não acredita na comunidade local e acha que os alimentos serão desviados assim como quase tudo no Brasil? ¬¬ Bom, pode relaxar. Pessoas da própria instituição estarão no evento recebendo pessoalmente os alimentos doados. ","date":"2009-11-05","objectID":"/posts/ceara-on-rails-2010/:1:0","tags":["Impressões","Ruby","Software Livre"],"title":"Ceará on Rails 2010","uri":"/posts/ceara-on-rails-2010/"},{"categories":["Eventos"],"content":"Programação Como grade de programação temos: Horário 14:00 - 14:10 .:: Abertura 14:10 - 15:00 .:: Clemente Gauer - Conhecendo seu MAC por dentro 15:00 - 15:40 .:: Tiago Bastos - Ruby FTW 15:40 - 16:30 .:: Marcos Tapajós - Introdução a banco de dados não relacionais e como utilizar CouchDB no Rails 16:30 - 17:10 .:: Coffee Break 17:10 - 17:30 .:: Alisson Sales - Vivendo no mundo Rails 17:30 - 18:20 .:: Anderson Leite - Tema a definir 18:20 - 19:10 .:: Nando Vieira - Testando Rails apps com RSpec 19:10 - 20:00 .:: Fabio Akita - Tema a definir 20:00 - 20:10 .:: Encerramento E então, nos vemos lá? Abraços ","date":"2009-11-05","objectID":"/posts/ceara-on-rails-2010/:2:0","tags":["Impressões","Ruby","Software Livre"],"title":"Ceará on Rails 2010","uri":"/posts/ceara-on-rails-2010/"},{"categories":["Impressões"],"content":"Novamente estou trazendo uma recomendação bibliográfica. A escolha deste mês se chama Grimpow - O Eleito dos Templários.","date":"2009-10-23","objectID":"/posts/recomendacao-bibliografica-grimpow-o-eleito/","tags":["Impressões","Literatura"],"title":"Recomendação Bibliográfica: Grimpow - O Eleito Dos Templários","uri":"/posts/recomendacao-bibliografica-grimpow-o-eleito/"},{"categories":["Impressões"],"content":"Saudações pessoal.. Novamente estou trazendo uma recomendação bibliográfica. A escolha deste mês se chama Grimpow - O Eleito dos Templários. Ainda não cheguei à metade do livro mas já posso afirmar que sua leitura é bastante interessante. A forma como Rafael Ábalo, seu autor, descreve seus personagens, cenários e cenas nos faz vivenciar a ideia que o mesmo tenta nos passar. Para quem curte contos históricos, Grimpow é uma excelente escolha por nos passar uma perspectiva sobre como se portavam os conhecidos Cavaleiros Templários bem como sua interação com a sociedade medieval, onde eram perseguidos por Papas e invejados por Reis pela autoridade, influência e riqueza adquirida que muitos alegam ser por conta de um antigo segredo desta seleta sociedade na qual os conhecimentos de alquimia lhes permitia transformar pobres metais em ouro através da misteriosa pedra filosofal. A história conta como Gripow, um jovem ladrão criado em uma aldeia pobre esbarra com os mistérios e segredos dos Templários e nos conta por uma nova perspectiva um pouco do que possa ter acontecido. Segue uma breve descrição retirada do site da livraria saraiva: Um cavaleiro morto com moedas de ouro, uma adaga, uma mensagem codificada e uma estranha pedra. Grimpow acaba por descobrir pistas que o levam para os templários e a obtenção da lendária Pedra Filosofal. Surpresas, enigmas e apenas a inteligência do corajoso jovem e seu guardião para desvendar um dos maiores segredos da humanidade. Abraços ","date":"2009-10-23","objectID":"/posts/recomendacao-bibliografica-grimpow-o-eleito/:0:0","tags":["Impressões","Literatura"],"title":"Recomendação Bibliográfica: Grimpow - O Eleito Dos Templários","uri":"/posts/recomendacao-bibliografica-grimpow-o-eleito/"},{"categories":["Impressões"],"content":"Nesta versão 4.3.2 muitos bugs foram corrigidos. Abaixo uma pequena lista das principais mudanças:","date":"2009-10-07","objectID":"/posts/kde-4-3-2-lancado/","tags":["Arch Linux","Impressões","KDE","Linux","Software Livre"],"title":"Kde 4.3.2 Lançado - Sim O Arch Já Disponibilizou","uri":"/posts/kde-4-3-2-lancado/"},{"categories":["Impressões"],"content":"Galera, ontem foi lançada a nova versão do kde. Nesta versão 4.3.2 muitos bugs foram corrigidos. Abaixo uma pequena lista das principais mudanças: Muitos bugs e quebras foram corrigidos trazendo ainda mais estabilidade para o KDE. Os efeitos do Kwin’s Window foram melhorados com algumas correções e acréscimos em renderização. A maioria dos bugs do Kmail foram resolvidos tornando-o mais robusto e eficiente. Opções de salvar os arquivos do Okular também foi melhorada. Muitas outras novidades que podem ser conferidas no changelog completo. Sim.. claro.. o novo KDE já se encontra disponível nos repositórios do Arch Linux. Está esperando o que? # pacman -Syu Abraços ","date":"2009-10-07","objectID":"/posts/kde-4-3-2-lancado/:0:0","tags":["Arch Linux","Impressões","KDE","Linux","Software Livre"],"title":"Kde 4.3.2 Lançado - Sim O Arch Já Disponibilizou","uri":"/posts/kde-4-3-2-lancado/"},{"categories":["Impressões"],"content":"ET ou espécie animal não catalogada?¿","date":"2009-09-17","objectID":"/posts/criatura-estranha-morta-por-adolescentes/","tags":["Impressões","Meio Ambiente"],"title":"Criatura Estranha Morta Por Adolescentes","uri":"/posts/criatura-estranha-morta-por-adolescentes/"},{"categories":["Impressões"],"content":"ET ou espécie animal não catalogada?¿ Esta é a dúvida que está se passando na cabeça de muitas pessoas sobre o ser que foi encontrado e morto no Panamá. A reportagem original apresentou a imagem acima bem como a história do ocorrido na qual 4 adolescentes acharam a criatura e mataram jogando-lhe várias pedras que, segundo eles, foi uma forma de defesa por terem ficado assustados e com medo de serem atacados. Concordo que é um crime matar um ser desta forma, sem ao menos dar tempo de saber de que espécie se trata, mas ao mesmo tempo, não me vejo em posição de criticar por não saber as reais circunstâncias nas quais os garotos encontraram a critura (ou foram encontrados). Muitas pessoas na cidade de Cerro Azul, local onde foi encontrado o ser estranho, bem como parte da imprensa local, estão afirmando que se trata de um ser extra terrestre, enquanto que o especialista em vida silvestre do órgão nacional de meio ambiente Melquiades Ramos disse que o caso está sendo investigado e que as características da criatura são “muito peculiares”. ?¿ Alguns simples exames de DNA poderiam responder se ele se trata de uma misutra de espécies ou de uma nova espécie. Ou seria de um outro planeta? o.O Aguardemos novidades sobre este ser. Segue link com a fonte de onde tirei a imagem bem como o assunto: aqui Abraços ","date":"2009-09-17","objectID":"/posts/criatura-estranha-morta-por-adolescentes/:0:0","tags":["Impressões","Meio Ambiente"],"title":"Criatura Estranha Morta Por Adolescentes","uri":"/posts/criatura-estranha-morta-por-adolescentes/"},{"categories":["Impressões"],"content":"O livro que estou lendo agora se chama A Escolha dos Três. É a continuação da série A Torre Negra, que eu já havia citado em um post anteriormente.","date":"2009-09-08","objectID":"/posts/recomendacao-bibliografica-a-escolha-dos/","tags":["Impressões","Literatura"],"title":"Recomendação Bibliográfica: A Escolha Dos Três - A Torre Negra Vol II","uri":"/posts/recomendacao-bibliografica-a-escolha-dos/"},{"categories":["Impressões"],"content":"Olá pessoal, que tal mais um pouco de leitura para desopilar? O livro que estou lendo agora se chama A Escolha dos Três. É a continuação da série A Torre Negra, que eu já havia citado em um post anteriormente. Pode conferir aqui. Neste segundo volume, a história do pistoleiro continua, precisando desta vez conhecer e resolver alguns enigmas com a participação e interação de 3 personagens distintos que poderão, ou não, dar um novo rumo à aventura. Mais uma vez Stephen King demonstra suas habilidades na arte da literatura com a descrição de cenários e fatos com perfeição em detalhes que conseguem prender a atenção do leitor. Segue uma breve descrição retirada do site da livraria saraiva: Com incansável imaginação, Stephen King dá continuidade à magistral saga épica A Torre Negra. “A Escolha dos Três”, segundo volume da série, lança o protagonista Roland de Gilead em pleno século XX, à medida que ele se aproxima cada vez mais de sua preciosa Torre Negra, sede de todo o tempo e de todo o espaço. Um derradeiro confronto com o homem de preto revela a Roland, nas cartas de um baralho de tarô, aqueles que deverão ajudá-lo em sua busca pela Torre Negra: o Prisioneiro, a Dama das Sombras e a Morte. Para encontrá-los, o último pistoleiro precisará atravessar três intrigantes portas que se erguem na deserta e interminável praia do mar Ocidental. São portas que o levam a um mundo diferente do seu, em outro tempo, de onde ele deverá trazer seus escolhidos: Eddie Dean, um viciado em heroína; Odetta Holmes, uma bela jovem negra que perdeu as pernas em um medonho acidente e sofre de misteriosos lapsos de memória; e o terceiro escolhido, a Morte, que vai embaralhar mais uma vez o destino de todos. A primeira porta o leva à Nova York dos anos 1980 e a Eddie Dean. A segunda transporta o pistoleiro à mesma cidade, mas dessa vez na década de 1960. A Dama das Sombras que Roland encontra atrás dessa segunda porta é Odetta Holmes. Roland e Eddie não demoram a descobrir que a mente de Odetta abriga também a malévola Detta Walker, num evidente distúrbio de dupla personalidade. Com o terceiro escolhido, A Morte, as cartas tornam a se embaralhar e a busca de Roland pela Torre Negra sofre uma nova e imprevisível reviravolta. Abraços ","date":"2009-09-08","objectID":"/posts/recomendacao-bibliografica-a-escolha-dos/:0:0","tags":["Impressões","Literatura"],"title":"Recomendação Bibliográfica: A Escolha Dos Três - A Torre Negra Vol II","uri":"/posts/recomendacao-bibliografica-a-escolha-dos/"},{"categories":["Tutoriais"],"content":"Depois de dominar 100% o plugin flash, chegou a vez do nosso amigo Java.","date":"2009-09-03","objectID":"/posts/chromium-suportando-java-agora/","tags":["Arch Linux","Chromium","Cultura Hacker","Impressões","Java","Software Livre"],"title":"Chromium Suportando Java Agora","uri":"/posts/chromium-suportando-java-agora/"},{"categories":["Tutoriais"],"content":"É isso aí galera.. Depois de dominar 100% o plugin flash, chegou a vez do nosso amigo Java. O chromium já está suportando o plugin java. Hoje posso, finalmente, dizer que o Chromium é meu navegador padrão. Nos últimos dias, a única coisa que eu não fazia no chromium era acessar aplicações que necessitem do java, como por exemplo o site do banco do brasil. Mas estas são sombras passadas… Faça os testes você mesmo. Inicialize seu chromium com a seguinte chamada… $ chromium-browser --enable-plugins --enable-greasemonkey --enable-user-scripts …e seja feliz com tudo que o chromium tem a lhe oferecer. ;] Para aqueles que ainda não conhecem ou não tem o chromium instalado, sugiro a leitura dos seguintes posts anteriores: Aqui Aqui e Aqui Abraços ","date":"2009-09-03","objectID":"/posts/chromium-suportando-java-agora/:0:0","tags":["Arch Linux","Chromium","Cultura Hacker","Impressões","Java","Software Livre"],"title":"Chromium Suportando Java Agora","uri":"/posts/chromium-suportando-java-agora/"},{"categories":["Tutoriais"],"content":"Quem está utilizando o Archlinux devidamente atualizado, pode ter percebido alguns erros relacionados à libjpeg.so ao tentar executar alguma aplicação, como foi o meu caso com o floola, um gerenciador para meu ipod com o qual transfiro e manipulo minhas músicas pelo linux.","date":"2009-08-19","objectID":"/posts/erro-com-a-libjpeg-resolvendo/","tags":["Arch Linux","Linux","Software Livre"],"title":"Erro Com a Libjpeg - Resolvendo No Archlinux","uri":"/posts/erro-com-a-libjpeg-resolvendo/"},{"categories":["Tutoriais"],"content":"Quem está utilizando o Archlinux devidamente atualizado, pode ter percebido alguns erros relacionados à libjpeg.so ao tentar executar alguma aplicação, como foi o meu caso com o floola, um gerenciador para meu ipod com o qual transfiro e manipulo minhas músicas pelo linux. O problema se deu pelo fato de o Archlinux já ter adotado a nova libjpeg. Esta versão 7 possui algumas vantagens em relação a versão anterior, porém muitos aplicativos ainda não foram atualizados para esta nova versão. Este foi o caso do floola por exemplo, que só funciona com a libjpeg6. Segue uma dica simples e rápida para resolver este pequeno problema. 1- Baixe o pacote da libjpeg6 diretamente do AUR através do seguinte link: https://aur.archlinux.org/packages/libjpeg6/libjpeg6.tar.gz 2- Descompacte o arquivo: [kalib@tuxcaverna downloads]$ tar -xvzf libjpeg6.tar.gz 3- Entre no diretório libjpeg6, crie e instale o pacote a partir do PKGBUILD extraído: [kalib@tuxcaverna downloads]$ cd libjpeg6/ [kalib@tuxcaverna libjpeg6]$ makepkg [kalib@tuxcaverna libjpeg6]$ pacman -U libjpeg6-6b-6-i686.pkg.tar.gz Feito isto, pode executar novamente o software que estava apontando o erro. No meu caso foi o floola. Isto resolverá o seu problema. ;] Abraços ","date":"2009-08-19","objectID":"/posts/erro-com-a-libjpeg-resolvendo/:0:0","tags":["Arch Linux","Linux","Software Livre"],"title":"Erro Com a Libjpeg - Resolvendo No Archlinux","uri":"/posts/erro-com-a-libjpeg-resolvendo/"},{"categories":["Impressões"],"content":"Sim, adoro livros com histórias macabras. Suspense e ficção sempre me chamaram bastante atenção.","date":"2009-08-14","objectID":"/posts/recomendacao-bibliografica-do-mes-o/","tags":["Impressões","Literatura"],"title":"Recomendação Bibliográfica Do Mês: O Jardim De Ossos","uri":"/posts/recomendacao-bibliografica-do-mes-o/"},{"categories":["Impressões"],"content":"Sim, adoro livros com histórias macabras. Suspense e ficção sempre me chamaram bastante atenção. A escolha deste mês se chama O Jardim de Ossos. Um presente que ganhei de aniversário da Mari, minha namorada, e com certeza me despertou curiosidade desde o dia em que recebi. O livro além de suspense, possui alguns aspectos de romance, ficção, medicina e histórias de época. O livro é da autora Tess Gerritsen. A mistura de culturas chinesa e americana da autora chamou a atenção em suas obras que costumam misturar suspense e medicina. Algo que muito me chamou a atenção neste livro foi justamente um comentário do grande Stephen King que se encontra na capa do livro: “Tess Gerritsen é leitura obrigatória em minha casa.” Precisa de algo mais? Segue uma pequena descrição retirada do site da livraria Saraiva. A recém-divorciada Julia Hamill acaba de se mudar para a casa de seus sonhos. Tudo parece perfeito, até que, durante a reforma do jardim, ela desenterra um crânio humano que data do século XIX. Em 1830 o estudante de medicina Norris Marshall parte em busca do homem mais perigoso de Boston, a fim de provar sua inocência. Separadas por quase duzentos anos, as duas histórias se desenvolvem de forma precisa e instigante, chegando a um final tão chocante quanto engenhosamente concebido. Espero que gostem… Abraços ","date":"2009-08-14","objectID":"/posts/recomendacao-bibliografica-do-mes-o/:0:0","tags":["Impressões","Literatura"],"title":"Recomendação Bibliográfica Do Mês: O Jardim De Ossos","uri":"/posts/recomendacao-bibliografica-do-mes-o/"},{"categories":["Tutoriais"],"content":"Todos que visitam meu blog já devem estar cansados de saber que estou bastante atento ao projeto chromium e ajudando com o possível para o desenvolvimento e divulgação do mesmo.","date":"2009-08-12","objectID":"/posts/habilitando-plugins-no-chromium/","tags":["Arch Linux","Chromium","Impressões","Linux","Software Livre"],"title":"Habilitando Plugins No Chromium","uri":"/posts/habilitando-plugins-no-chromium/"},{"categories":["Tutoriais"],"content":"Todos que visitam meu blog já devem estar cansados de saber que estou bastante atento ao projeto chromium e ajudando com o possível para o desenvolvimento e divulgação do mesmo. ","date":"2009-08-12","objectID":"/posts/habilitando-plugins-no-chromium/:0:0","tags":["Arch Linux","Chromium","Impressões","Linux","Software Livre"],"title":"Habilitando Plugins No Chromium","uri":"/posts/habilitando-plugins-no-chromium/"},{"categories":["Tutoriais"],"content":"Introdução Bom, eu já havia notificado aqui o fato de que o chromium passou a ter suporte à plugins como o flash por exemplo. De fato ele já suporta os plugins, mas muitos estão me procurando para perguntar porque o chromium cortou o suporte aos plugins, visto que nas builds mais recentes do chromium o suporte parece ter sido cortado, visto que os plugins não estão funcionando a princípio. Mas, porque o meu funciona e o seu não? Não é mágica..nem feitiçaria.. Vamos à realidade. O suporte do chromium aos plugins ainda não está 100% homologado, o que resulta em alguns bugs e falhas, podendo acarretar em uso excessivo de processamento ou outros recursos de sua máquina em alguns casos. Sabendo disso, o projeto chromium adotou a posição de não tornar o suporte à plugins uma opção “default”. ","date":"2009-08-12","objectID":"/posts/habilitando-plugins-no-chromium/:1:0","tags":["Arch Linux","Chromium","Impressões","Linux","Software Livre"],"title":"Habilitando Plugins No Chromium","uri":"/posts/habilitando-plugins-no-chromium/"},{"categories":["Tutoriais"],"content":"Habilitando os plugins Para utilizar os plugins em seu chromium você precisa iniciar o seu chromium com o seguinte parâmetro: $ chromium-browser --enable-plugins Lembrando que nestas novas builds do chromium não existe mais a necessidade de criar os links simbólicos para os plugins. Ele já detecta automaticamente os plugins que você tem instalados. Para testar, pode abrir o seguinte endereço ou mesmo acessar algo como o youtube: about:plugins Caso você ainda não tenha o chromium instalado em sua máquina pode buscar informações na internet sobre como o fazer em sua distro. Caso use Archlinux, pode seguir os passos abaixo: ","date":"2009-08-12","objectID":"/posts/habilitando-plugins-no-chromium/:2:0","tags":["Arch Linux","Chromium","Impressões","Linux","Software Livre"],"title":"Habilitando Plugins No Chromium","uri":"/posts/habilitando-plugins-no-chromium/"},{"categories":["Tutoriais"],"content":"Repositórios Adicione o repositório brasileiro em sua lista de mirrors. Adicione as seguintes linhas em seu arquivo /etc/pacman.conf : [archlinuxbr] Server = https://repo.archlinux-br.org/i686 ou [archlinuxbr] Server = https://repo.archlinux-br.org/x86_64 ","date":"2009-08-12","objectID":"/posts/habilitando-plugins-no-chromium/:2:1","tags":["Arch Linux","Chromium","Impressões","Linux","Software Livre"],"title":"Habilitando Plugins No Chromium","uri":"/posts/habilitando-plugins-no-chromium/"},{"categories":["Tutoriais"],"content":"Instalação Atualize seus mirrors e instale o chromium: # pacman -Sy # pacman -S chromium-snapshot Feito! Bom proveito… ","date":"2009-08-12","objectID":"/posts/habilitando-plugins-no-chromium/:2:2","tags":["Arch Linux","Chromium","Impressões","Linux","Software Livre"],"title":"Habilitando Plugins No Chromium","uri":"/posts/habilitando-plugins-no-chromium/"},{"categories":["Impressões"],"content":"Estive meio ausente nos últimos dias por problemas com minha máquina. Recentemente meu hd queimou e acabei ficando meio inativo. Ontem consegui reinstalar todo o meu sistema operacional (Archlinux) e restaurar todos os meus backups.","date":"2009-08-05","objectID":"/posts/de-volta-e-com-kde/","tags":["Arch Linux","Impressões","Linux","Software Livre","KDE"],"title":"De Volta E Com Kde 4.3","uri":"/posts/de-volta-e-com-kde/"},{"categories":["Impressões"],"content":"Saudações pessoal… Estive meio ausente nos últimos dias por problemas com minha máquina. Recentemente meu hd queimou e acabei ficando meio “inativo”. Ontem consegui reinstalar todo o meu sistema operacional (Archlinux) e restaurar todos os meus backups. Agora sim.. Atividade novamente. ;] De quebra, volto com uma boa notícia. Fans de KDE e usuários do Archlinux podem, desde ontem, comemorar o lançamento do KDE 4.3 que se deu ontem e já se encontra inclusive nos repositórios oficiais do Archlinux. Esta nova versão do KDE conta com várias mudanças no que diz respeito a correção de bugs, mas também em aparência e funcionalidades. O design e os efeitos estão bem mais atraentes como por exemplo a vizualização de pastas de imagens com previews como na imagem a seguir. Outro efeito que muito me chamou a atenção, é a possibilidade de vizualizar e navegar entre arquivos e diretórios que se encontrem em minha área de trabalho apenas por passar o mouse em cima e segurar por um segundo, me possibilitando ver o conteúdo daquela determinada pasta bem como interagir com ela. Ao tirar o mouse de cima, ela some novamente. ;] Confira a imagem a seguir: Para quem, assim como eu, gosta de notas rápidas em seu desktop, o knotes continua surpreendendo, trazendo agora as funções de negrito, sublinhado, centralizado, etc.. Muitas outras coisas novas surgiram, bem como efeitos de área, etc, etc, etc.. Sem mais comentários, experimente e confira as novidades. Se você já possui o kde 4.2 em seu archlinux, pode simplesmente atualizar com o seguinte comando: pacman -Syu Caso ainda não tenha, instale com: pacman -S kde Abraços! ","date":"2009-08-05","objectID":"/posts/de-volta-e-com-kde/:0:0","tags":["Arch Linux","Impressões","Linux","Software Livre","KDE"],"title":"De Volta E Com Kde 4.3","uri":"/posts/de-volta-e-com-kde/"},{"categories":["Tutoriais"],"content":"Eu já havia postado aqui a notícia sobre o lançamento do navegador Chromium para o Linux, bem como o fato de o mesmo se encontrar disponível em nosso repositório nacional do Arch Linux. Na ocasião o projeto chromium ainda era bem imaturo e não possuía nenhum suporte à plugins. Bom, as coisas estão mudando.","date":"2009-07-09","objectID":"/posts/chromium-ganha-suporte-ao-flash/","tags":["Arch Linux","Chromium","Google","Impressões","Linux","Software Livre"],"title":"Chromium Ganha Suporte Ao Flash Por Completo","uri":"/posts/chromium-ganha-suporte-ao-flash/"},{"categories":["Tutoriais"],"content":"Saudações pessoal.. Eu já havia postado aqui a notícia sobre o lançamento do navegador Chromium para o Linux, bem como o fato de o mesmo se encontrar disponível em nosso repositório nacional do Arch Linux. Na ocasião o projeto chromium ainda era bem imaturo e não possuía nenhum suporte à plugins. Bom, as coisas estão mudando. Para quem ainda não sabe, Chromium é o projeto open source que serve de base para o já conhecido Chrome do Google. Ontem saiu uma nova build do chromium que trás suporte total ao flash, precisando-se apenas criar um link simbólico para o seu já existente plugin flash que se encontra no diretório de seu firefox. Esta nova build, já se encontra atualizada em nosso repositório nacional, graças ao nosso amigo Paulo (aka thotypous), e você pode instalar, caso ainda não tenha, ou apenas atualizar o seu com os seguintes comandos: pacman -Sy pacman -S chromium-snapshot Estes comandos irão atualizar sua lista de repositórios e em seguida atualizar/instalar seu chromium. Feito isto, basta criar o link simbólico para o plugin do flash, seguindo a seguinte sequência de comandos: cd /opt/chromium-browser mkdir plugins cd plugins ln -s /usr/lib/mozilla/plugins/libflashplayer.so . Feito isto, execute seu chromium e digite no campo de url: about: Você verá claramente que o plugin flash está instalado. Agora é só correr pro abraço e testar em sites como o youtube por exemplo. Abraços ","date":"2009-07-09","objectID":"/posts/chromium-ganha-suporte-ao-flash/:0:0","tags":["Arch Linux","Chromium","Google","Impressões","Linux","Software Livre"],"title":"Chromium Ganha Suporte Ao Flash Por Completo","uri":"/posts/chromium-ganha-suporte-ao-flash/"},{"categories":["Eventos"],"content":"Depois de dias corridos aqui na empresa, finalmente consegui publicar algumas fotos do FISL bem como um pequeno relato do que achei dessa experiência.","date":"2009-07-07","objectID":"/posts/fisl-2009-foi-que-foi/","tags":["Arch Linux","Cultura Hacker","Impressões","KDE","Linux","Software Livre"],"title":"Fisl 2009 Foi Que Foi","uri":"/posts/fisl-2009-foi-que-foi/"},{"categories":["Eventos"],"content":"Tardo mas não falho.. Depois de dias corridos aqui na empresa, finalmente consegui publicar algumas fotos do FISL bem como um pequeno relato do que achei dessa experiência. Antes do Fisl em si, eu havia combinado, juntamente com o pessoal do Arch Linux Brasil, de passar uns dias conhecendo Gramado, já que todos dizem ser uma cidade linda. De fato.. Ninguém mentiu em relação a isso. As primeiras impressões que tive de Gramado foram excelentes. Uma cidade calma e bonita. O estado de calmaria parece ter sumido logo que cheguei à pousada na qual tínhamos reservas. Lá pude conhecer pessoalmente o pessoal do Arch Linux Brasil com quem eu já trabalhava havia algum tempo, porém apenas virtualmente. De cara pude ver que, como diria meu amigo Carlos, “só tinha doido naquela po***”. Hehehe Pessoal muito amigável e extrovertido. Obrigado Carlos, Hugo, Morgana, Kessia, Nilo, Rafael, Anne e é claro, os que já foram comigo: Mari, Gilfran e Tati. ;] Os dias que passamos em Gramado foram ótimos para conhecer a cidade, tomar um bom vinho e bater papo ou fazer gracinhas. Sem dúvidas foi uma das semanas em que mais ri na vida. Conhecemos alguns locais bacanas e pudemos perceber o respeito e a tranquilidade do povo de lá. Uma cidade que não possui sinais de trânsito e mesmo assim todos os carros param ao menor sinal de pedestre pretendendo atravessar a rua??? o.O Onde estou? Em Gramado é preciso aprender a aproveitar seu tempo ao máximo, portanto não recomendo de forma alguma o passeio das Jardineiras. Hehehe. Foi uma das coisas mais entediantes de minha vida. Ainda bem que tomei iniciativa cedo e não fiquei para o “passeio” completo, visto que em 10 minutos alguns de nós, do Arch Linux Brasil, pedimos ao motorista do ônibus para dar uma parada. Aproveitamos para descer e fomos jogar cartas e tomar um pouco do bom vinho de Gramado. O passeio se resumia em um ônibus rodando a 30 km/h pela cidade ao som da voz do motorista falando a uns 5m/h. o.O Dava sono… hehehe.. Depois de curtir bastante em Gramado, partimos para Porto Alegre. Por lá o evento foi ótimo. Pude conhecer muita gente que só conhecia pela internet, tirar fotos, conhecer projetos, trocar experiências, etc… Além de conhecer os feras do Arch Linux Brasil como Hugo, Carlos, Douglas, Farid, Thiago, Rodrigo, Kessia, Nilo, dentre outros, conheci também algumas figuras como o Fabio, Elgio e o Cabelo, sendo estes três membros do viva o linux. Conheci algumas pessoas do projeto KDE Brasil, ao qual acabei me integrando já tendo começado meus trabalhos esta semana. Vai ser bom ajudar em um projeto grande como este. ;] Também pude conhecer pessoalmente pessoas de outros projetos como o Fedora. Alguns deles eu já conhecia virtualmente. Todos nos receberam muito bens. Alguns até pareciam usuários Arch, de tanto que andavam conosco, como o Bruno e o Rafael. Mas como nem tudo é trabalho e evento. Durante as noites aproveitávamos para sair, conhecer a cidade ou mesmo fazer algumas curtições em nossos próprios Hotéis, o que saia mais barato e as vezes mais divertido. Bom, resumidamente, foram estas as minhas impressões. Abraços ","date":"2009-07-07","objectID":"/posts/fisl-2009-foi-que-foi/:0:0","tags":["Arch Linux","Cultura Hacker","Impressões","KDE","Linux","Software Livre"],"title":"Fisl 2009 Foi Que Foi","uri":"/posts/fisl-2009-foi-que-foi/"},{"categories":["Eventos"],"content":"É isso aí pessoal.. Terceiro dia de FISL e a bagunça rolou solta. Não lembro de ter visto sorrisos hoje na PUC. Apenas insatisfações e caras aborrecidas.","date":"2009-06-26","objectID":"/posts/lula-no-fisl-adeus-liberdade/","tags":["Arch Linux","Cultura Hacker","Impressões","Linux","Software Livre"],"title":"Lula No Fisl - Adeus Liberdade","uri":"/posts/lula-no-fisl-adeus-liberdade/"},{"categories":["Eventos"],"content":"É isso aí pessoal.. Terceiro dia de FISL e a bagunça rolou solta. Não lembro de ter visto sorrisos hoje na PUC. Apenas insatisfações e caras aborrecidas. Como de costume, o FISL não cumpriu a promessa de uma rede decente WIFI. Desde o primeiro dia a wireless do evento não funciona. Cada um tenta se virar de alguma forma.. seja com 3g ou mesmo, como nosso caso no stand do Archlinux Brasil, levando um switch para navegar na rede cabeada sedida pelo evento. Mas, como disse anteriormente, esse “problema” já é praticamente uma marca registrada do evento e como tal não foi a causa da revolta. Portanto, COMPANHEIROS, acreditem.. a causa da revolta geral hoje foi a “visita” de nosso querido Presidente. Nosso Presidente resolveu aparecer hoje no final da tarde. O problema? Simplesmente expulsaram, LITERALMENTE, TODOS que estavam na área principal do evento. Toda a área de stands foi evacuada para averiguação completa da polícia com cães treinados. Sim, se livraram de aproximadamente 8.000 pessoas em poucos minutos com um tratamento no mínimo GROSSO diante da realidade de quem saiu de outro estado, ou mesmo país, teve altos custos com passagens, hospedagens, alimentação e inscrição do evento. Não bastando “expulsar” todos para a “revista” do local, ainda informaram que os stands estariam proibidos para o público inscrito durante todo o dia. Eu, que também estava responsável por um dos stands, recebi a preciosa informação de que apenas algumas (2-3) pessoas de cada stand teriam permissão de entrar no local com apresentação de um determinado broche. À pessoa que me informou isso, perguntei: Qual a utilidade de um stand sem público? Parece brincadeira, mas não é. Se a intenção era deixar nosso Presidente mais “seguro” para aparecer na TV durante sua “visita” ao “evento”, acho que eles conseguiram. Mas, gostaria de saber qual será a justificativa para o fato de nas câmeras aparecerem cerca de 100 pessoas quando o evento possui, na verdade, cerca de 8.000 inscritos. No mínimo é uma falta de respeito para com todos nós. E a pergunta que não quer calar… Onde está a liberdade em um evento, teoricamente, para a comunidade? O Software é Livre, o acesso não!?¡¿ **PS: **Amanhã estarei no evento com meu crachá de cabeça para baixo. Abraços ","date":"2009-06-26","objectID":"/posts/lula-no-fisl-adeus-liberdade/:0:0","tags":["Arch Linux","Cultura Hacker","Impressões","Linux","Software Livre"],"title":"Lula No Fisl - Adeus Liberdade","uri":"/posts/lula-no-fisl-adeus-liberdade/"},{"categories":["Impressões"],"content":"Como já estão acostumados a ver, mensalmente estou inserindo recomendação de algum livro que eu esteja lendo. Bom, porque da mudança desta vez? Como muitos devem saber, estou em Gramado no momento. Sim, estarei no FISL deste ano em Porto Alegre juntamente com o pessoal do Archlinux Brasil. E como tivemos um loongoo vôo, acabei pegando um livro para ler no trajeto.","date":"2009-06-21","objectID":"/posts/recomendacao-bibliografica-do-vooc2bf-o/","tags":["Impressões","Literatura"],"title":"Recomendação Bibliográfica Do Vôo... O Pistoleiro","uri":"/posts/recomendacao-bibliografica-do-vooc2bf-o/"},{"categories":["Impressões"],"content":"Saudações pessoal.. Como já estão acostumados a ver, mensalmente estou inserindo recomendação de algum livro que eu esteja lendo. Bom, porque da mudança desta vez? Como muitos devem saber, estou em Gramado no momento. Sim, estarei no FISL deste ano em Porto Alegre juntamente com o pessoal do Archlinux Brasil. E como tivemos um loongoo voo, acabei pegando um livro para ler no trajeto. Já comecei a leitura e a escolha desta vez se chama O Pistoleiro, da coleção “A Torre Negra” do renomado Stephen King. Stephen King por si só dispensa comentários… Sobre o livro.. Ao escrever esta obra, Stephen King tinha o objetivo de escrever a mais longa obra de romance que já existiu. Parece que seu objetivo foi atingido com esta obra que é dividida em 7 livros, sendo O Pistoleiro o primeiro destes. Esta que é sua segunda edição conta com acréscimos pessoais sobre como o autor lidou com este trabalho como um todo bem como a reação de seus fans após seu acidente de carro que quase lhe custou a vida. Descrição retirada do site da Saraiva: Este livro é o primeiro dos sete volumes de série A Torre Negra, obra mais ambiciosa do escritor Stephen King. “O Pistoleiro” apresenta ao leitor o fascinante personagem de Roland Deschain, último descendente do clã de Gilead, e derradeiro representante de uma linhagem de implacáveis pistoleiros desaparecida desde que o Mundo Médio onde viviam “seguiu adiante”. Para evitar a completa destruição desse mundo já vazio e moribundo, Roland precisa alcançar a Torre Negra, eixo do qual depende todo o tempo e todo o espaço, e verdadeira obsessão para Roland, seu Cálice Sagrado, sua única razão de viver. O pistoleiro acredita que um misterioso personagem, a quem se refere como o homem de preto, conhece e pode revelar segredos capazes de ajudá- lo em sua busca pela Torre Negra, e por isso o persegue sem descanso. Pelo caminho, encontra pessoas que pertencem a seu ka-tet - ou seja, cujo destino está irremediavelmente ligado ao seu. Entre eles estão Alice, uma mulher que Roland encontra na desolada cidade de Tull, e Jake Chambers, um menino que foi transportado para o mundo de Roland depois de morrer em circunstâncias trágicas na Nova York de 1977. Mas o pistoleiro não conseguirá chegar sozinho ao fim da jornada que lhe foi predestinada. Na verdade, sua aventura se estenderá para outros mundos muito além do Mundo Médio, levando-o a realidades que ele jamais sonhara existir. Inteiramente revista pelo autor, esta primeira edição brasileira de “O Pistoleiro” traz também prefácio e introdução inéditos de King. Abraços ","date":"2009-06-21","objectID":"/posts/recomendacao-bibliografica-do-vooc2bf-o/:0:0","tags":["Impressões","Literatura"],"title":"Recomendação Bibliográfica Do Vôo... O Pistoleiro","uri":"/posts/recomendacao-bibliografica-do-vooc2bf-o/"},{"categories":["Eventos"],"content":"Para quem não sabe, anualmente acontece o Fórum Internacional de Software Livre, ou simplesmente FISL, no qual encontram-se pessoas de diferentes partes do país e do mundo para um evento que conta com várias palestras, oficinas, mini-cursos, gincanas, etc..etc..etc..","date":"2009-06-12","objectID":"/posts/fisl-2009-i-encontro-de/","tags":["Arch Linux","Cultura Hacker","Impressões","Linux","Software Livre"],"title":"Fisl 2009 - I Encontro De Usuários Brasileiros Do Arch Linux","uri":"/posts/fisl-2009-i-encontro-de/"},{"categories":["Eventos"],"content":"Para quem não sabe, anualmente acontece o Fórum Internacional de Software Livre, ou simplesmente FISL, no qual encontram-se pessoas de diferentes partes do país e do mundo para um evento que conta com várias palestras, oficinas, mini-cursos, gincanas, etc..etc..etc.. Além da oportunidade de assistir palestras de presenças nacionais e internacionais como Eduardo Maçan (linux-br), Anahuac de Paula Gil (LESP), Sérgio Amadeu, Marcelo Tosatti (RedHat), Richard Stallman (Free Software Foundation), Peter Sunde Kolmisoppi (The Pirate Bay), Scott Balneaves (LTSP), John “Maddog” Hall (Linux Foundation), Alexandre Oliva (Free Software Foundation), dentre outros vários, o FISL também é uma excelente oportunidade para conhecer pessoas com quem, por razões geográficas, não podemos trabalhar presencialmente porém, muitas vezes, já até conhecemos ou trabalhamos juntos virtualmente. (Bem vindo ao mundo do Software Livre). O FISL deste ano acontecerá, como de costume, na PUCRS em Porto Alegre no período entre 24 e 27 de Junho. Além dos corredores lotados de pessoas para se bater um bom papo, trocar cartões de visita, códigos e curriculums, o FISL também conta com os encontros e eventos comunitários. O Arch Linux Brasil não poderia ficar de fora, certo?! Sim, estaremos lá. No FISL 2009 teremos o I Encontro de Usuários Brasileiros do Arch Linux. Não deixem de visitar nosso stand no qual teremos palestras e espaço para tirar dúvidas e bater um bom papo sobre qualquer que seja o tema. Basta procurar um doido chamado Marcelo / aka kalib (como o da foto acima) ou mesmo nosso banner (também na foto acima). Também estaremos vendendo adesivos e cds do Arch Linux. Boa parte da comunidade Arch Linux Brasil, incluindo minha pessoa, estará chegando ao Rio Grande do Sul alguns dias antes do evento. Pretendemos chegar em Gramado no dia 20, onde permaneceremos até o dia 23, véspera do evento. Se você também tem planos de visitar gramado em um destes dias, sinta-se bem vindo ao grupo. Deixe comentários aqui ou mande-me um email com suas informações/contatos como forma de facilitar o encontro. Nos vemos lá pessoal. ","date":"2009-06-12","objectID":"/posts/fisl-2009-i-encontro-de/:0:0","tags":["Arch Linux","Cultura Hacker","Impressões","Linux","Software Livre"],"title":"Fisl 2009 - I Encontro De Usuários Brasileiros Do Arch Linux","uri":"/posts/fisl-2009-i-encontro-de/"},{"categories":null,"content":"Que o mundo da telefonia está sofrendo grandes mudanças com a onda de conectividade web, todo mundo já sabe. A telefonia IP, VOIP, ou simplesmente voz sobre ip, vem expandindo cada vez mais as possibilidades para comunicação instantânea à longa distância à medida que os custos se tornam cada vez menores para o usuário final.","date":"2009-06-08","objectID":"/posts/asterisknow-solucao-eficiente-para-voip/","tags":["Asterisk","Impressões","Linux","Redes","Software Livre"],"title":"Asterisknow - Solução Eficiente Para Voip","uri":"/posts/asterisknow-solucao-eficiente-para-voip/"},{"categories":null,"content":"Que o mundo da telefonia está sofrendo grandes mudanças com a onda de conectividade web, todo mundo já sabe. A telefonia IP, VOIP, ou simplesmente voz sobre ip, vem expandindo cada vez mais as possibilidades para comunicação instantânea à longa distância à medida que os custos se tornam cada vez menores para o usuário final. O número de empresas e orgãos que se utilizam de voip como uma estratégia para redução de custos, bem como aumento da segurança e confiabilidade dos dados, é cada vez maior no mundo todo. Além do setor comercial, cada vez mais usuários domésticos se beneficiam do voip, muitas vezes sem se dar conta disto. Um exemplo clássico são usuários que utilizam softwares como o skype ou gizmo para realizarem ligações pessoais. Então, o que seria o tal AsteriskNow? Em resumo, seria uma distribuição Linux trazendo por padrão todos os pacotes e configurações necessárias para se ter um servidor Asterisk em plena funcionalidade, o que levanta, para muitos, uma segunda pergunta: O que é esse Asterisk? Ele morde? Criado em 1999 por Mark Spencer, da Digium Inc, Asterisk é a solução líder no mundo quando o assunto é telefonia ip Open Source. O Asterisk é um conjunto de ferramentas capazes de lhe fornecer um PBX completo, eficiente e robusto em toda a sua funcionalidade que pode ser de uso pessoal ou comercial. O Asterisk é distribuído sob a licença GNU General Public License, ou simplesmente GNU GPL, estando assim disponível para download de forma totalmente gratuita. Sem sombra de dúvidas, o Asterisk é uma das soluções mais conhecidas no mundo quando o assunto é Open Source, principalmente quando o assunto é VOIP. Ótimo, então o AsteriskNow é apenas uma distribuição Linux trazendo o Asterisk pré-instalado? Não necessariamente. O AsteriskNow é na verdade uma solução VOIP ideal para quem deseja ter um PBX funcional e completo, mas não se sente confiante o suficiente para enfrentar o asterisk e suas linhas de comando. Através de uma interface gráfica amigável, como apresentado na imagem acima, o AsteriskNow trás todos os componentes necessários para o seu ideal funcionamento bem como uma simples instalação para principiantes, descartando possíveis incrementos que poderiam, de alguma forma, depreciar a segurança de seu ambiente. Sem sombra de dúvidas umas excelente oportunidade para quem deseja conhecer as possibilidades que o Asterisk nos proporciona de forma simples e amigável para um primeiro contato. Abraços ","date":"2009-06-08","objectID":"/posts/asterisknow-solucao-eficiente-para-voip/:0:0","tags":["Asterisk","Impressões","Linux","Redes","Software Livre"],"title":"Asterisknow - Solução Eficiente Para Voip","uri":"/posts/asterisknow-solucao-eficiente-para-voip/"},{"categories":["Aleatórios"],"content":"Já faz um tempo que tento separar umas fotos para publicar aqui no blog. Finalmente consegui separar algumas.","date":"2009-06-04","objectID":"/posts/inaugurando-oficialmente-fotos-no-blog/","tags":["Impressões"],"title":"Inaugurando Oficialmente Fotos No Blog","uri":"/posts/inaugurando-oficialmente-fotos-no-blog/"},{"categories":["Aleatórios"],"content":"Olá pessoal… Já faz um tempo que tento separar umas fotos para publicar aqui no blog. Finalmente consegui separar algumas. A partir de hoje estarei mantendo uma página de fotos na qual disponibilizarei algumas galerias de fotos diversas como lazer, trabalho, projetos, etc… Para inaugurar a página de fotos, postei as seguintes galerias: No Trabalho Flisol 2009 (Festival Latino-Americano de Instalação de Software Livre) Pós-Flisol 2009 Acampando em Guaramiranga Na Praia Canadá - Toronto Algumas destas galerias, como é o caso de “Flisol 2009” não serão mais alimentadas e se manterão estáticas, pois o evento não volta atrás, certo?! Porém, estarei posteriormente inserindo as galerias de outros eventos passados. Por outro lado, algumas galerias são dinâmicas como por exemplo “No Trabalho”. Como tal, constantemente esta galeria poderá receber novas fotos do dia-a-dia a medida que formos tirando novas fotos por aqui. O intuito desta sessão de fotos é fazer com que vocês possam me conhecer um pouco melhor, bem como conhecer um pouco do meu dia-a-dia. ;] PS: Este não será o layout padrão da página. Pretendo melhorar o aspecto físico da mesma com uma melhor organização e divisão por páginas de galerias distintas por categoria. É isso..conheçam um pouco sobre minha pessoa visitando a página Fotos ou clicando aqui. Abraços ","date":"2009-06-04","objectID":"/posts/inaugurando-oficialmente-fotos-no-blog/:0:0","tags":["Impressões"],"title":"Inaugurando Oficialmente Fotos No Blog","uri":"/posts/inaugurando-oficialmente-fotos-no-blog/"},{"categories":["Impressões"],"content":"Gostaria de lhes comunicar que o Google Chromium alpha já está pronto e rodando no Arch.","date":"2009-05-28","objectID":"/posts/chromium-pronto-para-o-arch/","tags":["Arch Linux","Chromium","Impressões","Linux","Software Livre"],"title":"Chromium - Pronto Para O Arch","uri":"/posts/chromium-pronto-para-o-arch/"},{"categories":["Impressões"],"content":"Saudações pessoal, tudo tranquilo? Gostaria de lhes comunicar que o Google Chromium alpha já está pronto e rodando no Arch. Fiquei animado ao ver o post do Paulo Matias no qual ele nos passava essa ótima notícia. Sim, uma das vantagens em ser usuário Arch. Novidades aparecem constantemente. É isso mesmo. Você que é usuário Arch Linux já pode fazer inveja à seus coleguinhas.. Como o próprio Paulo já explicou em seu post, vocês podem instalar de duas formas: 1- Baixando o pacote chromium-browser no AUR. 2- Pelo repositório brasileiro do archlinux. Maiores informações no próprio blog do Paulo. Pessoal, essa é nossa chance de ajudar a testar o máximo possível e reportar todos os bugs. Isso vai ajudar o Google a melhorar cada vez mais o Google Chromium para o Linux como um todo. Abraços ","date":"2009-05-28","objectID":"/posts/chromium-pronto-para-o-arch/:0:0","tags":["Arch Linux","Chromium","Impressões","Linux","Software Livre"],"title":"Chromium - Pronto Para O Arch","uri":"/posts/chromium-pronto-para-o-arch/"},{"categories":["Impressões"],"content":"Como muitos já devem saber sou usuário da distribuição Archlinux desde o ano passado à qual tenho me dedicado por ter finalmente achado uma distribuição na qual eu me sinto realmente em casa. Os resultados desta parceria, kalib/arch, passaram a surgir rapidamente, uma vez que comecei a tentar colaborar com a distribuição em minhas primeiras semanas com documentações, traduções, divulgação, suporte, etc.","date":"2009-05-18","objectID":"/posts/entrando-para-a-comissao-do/","tags":["Arch Linux","Cultura Hacker","Impressões","Linux","Software Livre"],"title":"Entrando Para a Comissão Do Archlinux Brasil","uri":"/posts/entrando-para-a-comissao-do/"},{"categories":["Impressões"],"content":"Saudações pessoal… Como muitos já devem saber sou usuário da distribuição Archlinux desde o ano passado à qual tenho me dedicado por ter finalmente achado uma distribuição na qual eu me sinto realmente em casa. Os resultados desta parceria, kalib/arch, passaram a surgir rapidamente, uma vez que comecei a tentar colaborar com a distribuição em minhas primeiras semanas com documentações, traduções, divulgação, suporte, etc. Não demorou muito e o Hugo Dória, até então um dos líderes do projeto Archlinux Brasil, me convidou para ingressar o time de desenvolvedores do Archlinux Brasil. Após votação interna consegui assumir o posto. Obrigado pessoal. ;] Fui muito bem recebido por todos que já eram “da casa”. Foi uma ótima experiência, bem como oportunidade, na qual conheci muitas pessoas e fiz amigos. (Leandro, não vou esquecer da cachaça que você me prometeu..hauhuha) Mas o intuito deste post não é este, mas sim passar a informação que já repassei no site da comunidade. Como muitos já devem saber o projeto Arch Linux Brasil passou por algumas modificações em sua estrutura e corpo de membros. Alguns deles tornaram-se desenvolvedores do Arch nos últimos meses, outros TU, e assim por diante. Arcar com essas funções de maneira satisfatória consome esforço extra dessas pessoas, o que reduz o tempo disponível para o gerenciamento da comunidade Arch-br. Para resolver esta situação a antiga comissão coordenadora do Arch-br decidiu pela criação de um novo time que pudesse efetivamente dar a atenção que o projeto necessita. Após um período de votação entre os developers do Arch-br, a seguinte comissão foi formada: Kessia Pinheiro - aka even Marcelo Cavalcante - aka kalib Rodrigo Flores - aka rodrigoflores O projeto Arch-br gostaria de agradecer a todos os que fizeram da comunidade o que ela é hoje, bem como agradecer o trabalho feito pelos membros anteriores da comissão: Hugo Dória, Paulo Matias e Renato Leão. Somos imensamente gratos a eles por terem segurado esse “buxo” por tanto tempo. Seu trabalho não foi em vão. A nova comissão espera dar continuidade ao andamento do projeto bem como procurar cada vez mais inovar e melhorar a comunidade como um todo, seja em conteúdo, receptividade ou mesmo suporte aos atuais serviços e necessidades de nossa comunidade Arch. Espero poder dar continuidade ao excelente trabalho que foi feito até então juntamente com todo o time de desenvolvedores que temos hoje no Archlinux Brasil. Recomendo também a leitura do post do Hugo no qual se despede do projeto em grande estilo. Abraços ","date":"2009-05-18","objectID":"/posts/entrando-para-a-comissao-do/:0:0","tags":["Arch Linux","Cultura Hacker","Impressões","Linux","Software Livre"],"title":"Entrando Para a Comissão Do Archlinux Brasil","uri":"/posts/entrando-para-a-comissao-do/"},{"categories":["Impressões"],"content":"Tal como já havia feito com Java e HTML (só para citar dois casos), a Microsoft agora investiu ao menos 12 meses de trabalho para tentar fragmentar o ODF no mercado de TI: Uma vergonha.","date":"2009-05-12","objectID":"/posts/so-faltava-essa-microsoft-agora/","tags":["Cultura Hacker","Impressões","Software Livre"],"title":"Só Faltava Essa - Microsoft Agora Tenta Fragmentar O Odf","uri":"/posts/so-faltava-essa-microsoft-agora/"},{"categories":["Impressões"],"content":"Só nos faltava essa eim!? Depois de várias atitudes “questionáveis” em toda a sua história, me deparo com o seguinte texto publicado pelo Vitorio Furusho. Tal como já havia feito com Java e HTML (só para citar dois casos), a Microsoft agora investiu ao menos 12 meses de trabalho para tentar fragmentar o ODF no mercado de TI: Uma vergonha. Juro que tinha me preparado para publicar nesta semana um post elogiando a Microsoft por ter finalmente lançado o SP2 do Office 2007 com suporte nativo ao ODF, mas infelizmente após os testes iniciais de diversos usuários, o que vemos é uma tentativa absurda de enganar os consumidores (que pagaram pelo software) e fragmentar o ODF na indústria de TI. Quando uso o termo fragmentar, me refiro á tática já conhecida de usar a ‘criatividade’ no momento de implementação de um padrão para tornar a sua implementação compatível apenas com a sua ferramenta (que já viu sites que só funcionam no Internet Explorer sabe bem do que estou falando). Por fora os documentos parecem idênticos e compatíveis mais por dentro são completamente diferentes, fragmentando assim a uniformidade esperada com a utilização de um padrão. Um dos primeiros artigo publicado sobre o tema e para o qual chamo a atenção de todos é do Rob Weir, coordenador do OASIS ODF TC (grupo que desenvolve o ODF, do qual faço parte). Chega a ser assustador o que o Office 2007 faz com as planilhas existentes de ODF. Os detalhes técnicos estão todos no blog do Rob, mas em resumo, quando se abre uma planilha ODF (extensão .ods) existente no Office 2007, ele simplesmente elimina todas as fórmulas existentes sem avisar nada ao usuário, deixando nas células apenas os valores do resultado do cálculo das fórmulas (valores estes já previamente armazenados no documento). Se um usuário quiser testar o suporte ao ODF no Office, e sem prestar a devida atenção salvar uma planilha aberta, vai sobrescrever o documento eliminando todas as fórmulas, como se estivesse gravando um documento que foi totalmente digitado. Já vi absurdos na vida, mas nada se compara a isso. Quando se utiliza o Office 2007 para gerar uma nova planilha, as fórmulas serão armazenadas de tal forma que só o Office 2007 (ou o CleverAge, um plug-in de suporte ao ODF para o Office desenvolvido em Open Source com patrocínio da Microsoft) será capaz de ler o documento, acabando com a possibilidade de que qualquer outra aplicação existente seja capaz de ler o documento. Enquanto o primeiro problema simplesmente joga fora toda a inteligência de negócios dentro das planilhas (as fórmulas), o segundo prende o usuário ao Office 2007 para sempre (já vimos este filme antes, não é mesmo ?). A justificativa que a Microsoft poderia usar para isso é a falta de definição de fórmulas em planilhas no ODF 1.0/1.1. Interessante notar que no ODF 1.2 (que é desenvolvido com a participação da Microsoft) este problema já foi resolvido com a criação do OpenFormula. Na primeira tabela comparativa do post do Rob, que resume um teste sobre o mesmo assunto que ele fez há algumas semanas, fica fácil perceber que mesmo sem existir a especificação de fórmulas para planilhas dentro do ODF 1.1, a interoperabilidade entre as aplicações existentes testadas (KOffice, OpenOffice, Google Docs, Symphony e o plug-in da Sun para o Office) existe de fato (com exceção do CleverAge que apresentou alguns problemas). Isso significa que todos os outros desenvolvedores não se preocuparam apenas em ‘cumprir com um requisito de norma’ (ou seja, conformidade), mas também em desenvolver uma aplicação realmente útil e interoperável para seus usuários. O Rob comenta ainda que o conjunto de fórmulas utilizado por todas estas aplicações (com base no OpenOffice) foi desenvolvido com base nas fórmulas existentes no Excel (no mínimo irônico, heim ?). Destaco ainda que os problemas apresentados pelo OpenOffice quando o Rob repetiu seus testes com a versão nova da suíte, foram causados por que os desenvolvedores do OpenOffice 3.0 decidiram incorporar co","date":"2009-05-12","objectID":"/posts/so-faltava-essa-microsoft-agora/:0:0","tags":["Cultura Hacker","Impressões","Software Livre"],"title":"Só Faltava Essa - Microsoft Agora Tenta Fragmentar O Odf","uri":"/posts/so-faltava-essa-microsoft-agora/"},{"categories":["Impressões"],"content":"O filme aborda o Software Livre de forma excepcional traçando paralelos que mostram as mais sutís, porém triviais, diferenças entre software livre, software proprietário, software gratuito, etc...","date":"2009-05-11","objectID":"/posts/que-tal-um-pequeno-filme/","tags":["Cultura Hacker","Impressões","Linux","Literatura","Software Livre"],"title":"Que Tal Um Pequeno Filme Para Descontrair","uri":"/posts/que-tal-um-pequeno-filme/"},{"categories":["Impressões"],"content":"Olá pessoal, depois de um tempo afastado volto trazendo a dica de um pequeno filme que assisti neste fim de semana e recomendo que todos façam download. Trata-se do resultado do trabalho de conclusão do Curso de Comunicação Social do Centro Universitário FIEO, produzido pelo Daniel Bianchi e Johnata Rodrigo. O filme aborda o Software Livre de forma excepcional traçando paralelos que mostram as mais sutís, porém triviais, diferenças entre software livre, software proprietário, software gratuito, etc… Além disso, o filme ainda nos passa uma pequena ideia do que vem acontecendo hoje em dia em termos de utilização e divulgação do software livre como meio viável e rentável. Como os próprios autores pedem: “Assistam, copiem, divulguem e distribuam este pequeno filme.” Segue link para o arquivo torrent: https://www.mininova.org/tor/2571016 ","date":"2009-05-11","objectID":"/posts/que-tal-um-pequeno-filme/:0:0","tags":["Cultura Hacker","Impressões","Linux","Literatura","Software Livre"],"title":"Que Tal Um Pequeno Filme Para Descontrair","uri":"/posts/que-tal-um-pequeno-filme/"},{"categories":["Eventos"],"content":"Como todos sabem, no último sábado tivemos o Flisol 2009. Em Fortaleza, como de costume a Comunidade Tux-CE esteve presente e organizou o Install Fest.","date":"2009-04-29","objectID":"/posts/flisol-2009-fortaleza-obrigado-tux/","tags":["Flisol","Impressões","Linux","Software Livre","Tux-ce"],"title":"Flisol 2009 Fortaleza, Obrigado Tux-Ce","uri":"/posts/flisol-2009-fortaleza-obrigado-tux/"},{"categories":["Eventos"],"content":"Como todos sabem, no último sábado tivemos o Flisol 2009. Em Fortaleza, como de costume a Comunidade Tux-CE esteve presente e organizou o Install Fest. Gostaria de aproveitar o post para agradecer à TODOS os integrantes da Tux-CE por fazerem com que a nossa comunidade seja vista como o é. Sempre tive orgulho de ser membro da Tux-CE, mas nos últimos dias o orgulho só cresceu diante da chuva de elogios que recebemos dos mais diversos meios/orgãos/grupos, etc. Elogios de comunidades de Software Livre, locais e nacionais, Serpro, Professores de escolas que estiveram no evento, Casa Brasil, etc..etc..etc…bem como visitantes que conheceram nosso trabalho durante o evento. Sem dúvida alguma vocês merecem os parabéns. Elogios como “vocês são mais do que uma família, são um grupo de amigos muito bem entrosado que se respeitam e nutrem um trabalho comum que ajuda bastante no engradecimento do Software Livre” não faltaram nos últimos dias e é este tipo de coisa que nos motiva a continuar com nosso trabalho. Obrigado a todos. O evento ocorreu da melhor forma possível com a colaboração de todos. Gostaria de agradecer também o apoio que nos foi dado pelo pessoal do Casa Brasil que nos conseguiu todo o material e atenção de que precisávamos. ;] Tirem suas próprias conclusões acessando a página da Tux-CE e observando as fotos que tiramos por lá, bem como as fotos de nosso “pós-flisol”. Sim, o “pós-flisol” já é uma espécie de “evento” comum para a Tux-CE. hauhuha Fotos do Flisol - https://www.tux-ce.org/portal/image/tid/13 Fotos do Pós Flisol - https://www.tux-ce.org/portal/image/tid/14 Fotos e Geral - https://www.tux-ce.org/portal/image ","date":"2009-04-29","objectID":"/posts/flisol-2009-fortaleza-obrigado-tux/:0:0","tags":["Flisol","Impressões","Linux","Software Livre","Tux-ce"],"title":"Flisol 2009 Fortaleza, Obrigado Tux-Ce","uri":"/posts/flisol-2009-fortaleza-obrigado-tux/"},{"categories":["Eventos"],"content":"O FLISOL - Festival Latinoamericano de Instalação de Software Livre - é o maior evento de divulgação de Software Livre da América Latina. Ele acontece desde 2005 e seu principal objetivo é promover o uso de software livre, apresentando sua filosofia, seu alcance, avanços e desenvolvimento ao público em geral.","date":"2009-04-23","objectID":"/posts/flisol-fortaleza-tux-ce-dara/","tags":["Cultura Hacker","Flisol","Impressões","Linux","Literatura","Software Livre","Tux-ce"],"title":"Flisol Fortaleza - Tux-Ce Dará 3 Livros","uri":"/posts/flisol-fortaleza-tux-ce-dara/"},{"categories":["Eventos"],"content":"O FLISOL (Festival Latinoamericano de Instalação de Software Livre) é o maior evento de divulgação de Software Livre da América Latina. Ele acontece desde 2005 e seu principal objetivo é promover o uso de software livre, apresentando sua filosofia, seu alcance, avanços e desenvolvimento ao público em geral. Com esta finalidade, diversas comunidades locais de software livre (em cada país, em cada cidade/localidade), organizam simultaneamente eventos em que se instala gratuitamente e totalmente legal, software livre nos computadores levados pelos participantes. Também, paralelamente, são oferecidas apresentações, palestras e oficinas, sobre temas locais, nacionais e latinoamericanos sobre Software Livre, com toda sua variedade de expressões: artística, acadêmica, empresarial e social. Como todos sabem, sou membro da comunidade Cearense Tux-CE de Software Livre. A Tux-CE participa ativamente do Flisol Fortaleza desde sua primeira edição. Este ano, como de costume, estaremos organizando o Install Fest por lá. Além de poder sair de lá com o Linux instalado em sua máquina, você ainda pode receber gratuitamente mídias com distribuições Linux. Confira fotos de edições passadas clicando aqui. Mas tudo isso já é padrão e conhecido. Todos os anos fazemos isso. Então o que a Tux-CE trás este ano como novidade? Que tal 3 Livros? Sim, a Tux-CE estará dando 3 livros novos. Quais? 1- Security Power Tools 2- Learning Python 3- Linux Server Hacks Nos vemos lá! I****nformações: Endereço: Rua Celso Tinoco, 1374, atrás do Colégio Jorge Vieira. **Telefone: **(85) 3433-5958 Grade de palestras: https://flisolceara.net/grade/ Exibir mapa ampliado ","date":"2009-04-23","objectID":"/posts/flisol-fortaleza-tux-ce-dara/:0:0","tags":["Cultura Hacker","Flisol","Impressões","Linux","Literatura","Software Livre","Tux-ce"],"title":"Flisol Fortaleza - Tux-Ce Dará 3 Livros","uri":"/posts/flisol-fortaleza-tux-ce-dara/"},{"categories":["Eventos"],"content":"Gostaria de informar que amanhã teremos a segunda edição do Dia Livre aqui em Fortaleza.","date":"2009-04-17","objectID":"/posts/convite-ao-dia-livre/","tags":["Cultura Hacker","Impressões","Jogos","KDE","Linux","Segurança","Software Livre"],"title":"Convite Ao Dia Livre","uri":"/posts/convite-ao-dia-livre/"},{"categories":["Eventos"],"content":"Saudações pessoal! Gostaria de informar que amanhã teremos a segunda edição do Dia Livre aqui em Fortaleza. Neste Sábado acontecerá na Faculdade Integrada do Ceará. Para quem ainda não conhece, é um pequeno encontro da comunidade contando com três palestras. A cada mês, um novo local, sendo este faculdade ou escola, sedia o evento. Nesta edição teremos palestras abordando os seguintes assuntos: GNU/Linux Jogos Gestão de TI e Software Livre Local: FIC - Unidade Moreira Campos (https://www.fic.br/v4/conheca/mapamc.html) Horário: 08:00 - 11:00 Nos vemos lá!? ","date":"2009-04-17","objectID":"/posts/convite-ao-dia-livre/:0:0","tags":["Cultura Hacker","Impressões","Jogos","KDE","Linux","Segurança","Software Livre"],"title":"Convite Ao Dia Livre","uri":"/posts/convite-ao-dia-livre/"},{"categories":["Impressões"],"content":"É isso mesmo. Uma pequena mudança estética em meu notebook e não vou twittar sobre isso. Porque a revolta? ¬¬","date":"2009-04-13","objectID":"/posts/mudanca-em-meu-notebook-e/","tags":["Impressões"],"title":"Mudança Em Meu Notebook E Não Vou Twittar","uri":"/posts/mudanca-em-meu-notebook-e/"},{"categories":["Impressões"],"content":"É isso mesmo. Uma pequena mudança estética em meu notebook e não vou twittar sobre isso. Porque a revolta? ¬¬ Digamos que, após quase 2 meses utilizando o twitter, me dei por vencido e aceitei o fato de que realmente não encontrei utilidades reais para aquilo. Quem disse que eu quero saber o que cada pessoa está fazendo a cada minuto? Dando uma olhada básica neste momento em minha página do twitter verei coisas como: “Cena desagradável logo cedo: a mãe troca a fralda da criança no meio do restaurante em pleno café-da-manhã” “É um absurdo o que a federação paulista de futebol faz com o SPFC” “De volta à realidade. Nunca mais quero ver sol na minha vida” Não sei quanto a vocês, mas este tipo de coisa não acrescenta nada em minha vida. Apenas me toma tempo desnecessário do trabalho ou lazer. A mudança na estética de meu notebook foi através de um lapjack da toshiba. Para quem não sabe, lapjacks são uma espécie de adesivo para notebook. A qualidade é excelente e fica realmente muito bem feito. Além disso, ele ainda lhe permite tirar e colar novamente em um novo notebook, caso você deseje. No site, você pode escolher a foto que desejar e fazer upload para eles na hora da compra ou, caso prefira, pode escolher uma das várias imagens que eles já disponibilizam. Além disso, você especifica qual o modelo de seu toshiba para garantir que o adesivo terá as medidas exatas para o mesmo. Ambas as imagens postadas aqui são do meu toshiba com o seu novo “estilo”. Sim, são os pinguins do filme Madagascar! :p E como disse no título: Não vou twittar isto! Estou aproveitando este post para me despedir oficialmente do twitter. Uma vez que meu período de experiência com o mesmo não me trouxe resultado algum, estou abrindo mão do “serviço”. Abraços ","date":"2009-04-13","objectID":"/posts/mudanca-em-meu-notebook-e/:0:0","tags":["Impressões"],"title":"Mudança Em Meu Notebook E Não Vou Twittar","uri":"/posts/mudanca-em-meu-notebook-e/"},{"categories":["Eventos"],"content":"Para quem não conhece, Ceará On Rails é um evento voltado ao desenvolvimento web ágil com Ruby On Rails. Sua primeira edição foi em Novembro do ano passado. Estive presente e não me arrependi. Hoje teremos a segunda edição do evento. Fica o convite à todos que desejem aparecer por lá para conhecer um pouco mais sobre esta dinâmica e ágil forma de desenvolver para a Web.","date":"2009-04-08","objectID":"/posts/primeiro-encontro-cearaonrails/","tags":["Impressões","Ruby","Software Livre"],"title":"Primeiro Encontro Cearáonrails","uri":"/posts/primeiro-encontro-cearaonrails/"},{"categories":["Eventos"],"content":"Olá pessoal. Para quem não conhece, Ceará On Rails é um evento voltado ao desenvolvimento web ágil com Ruby On Rails. Sua primeira edição foi em Novembro do ano passado. Estive presente e não me arrependi. Hoje teremos a segunda edição do evento. Fica o convite à todos que desejem aparecer por lá para conhecer um pouco mais sobre esta dinâmica e ágil forma de desenvolver para a Web. CearáOnRails – Grupo de Usuários Ruby e Rails do Ceará Website – https://www.cearaonrails.org Lista de Discussão - https://groups.google.com.br/group/cearaonrails Local: Faculdade Christus. Endereço: Campus Dom Luís, está situado na Avenida Dom Luís, 911, Bairro Aldeota, próximo ao Shopping Aldeota. Localização com o Google Maps. Contato: (85) 8884.8466 Data: Dia 08/04/2009 [quarta-feira] das 19:00h as 22:00h no Auditório do primeiro andar. Palestras 19:00 às 19:10 Abertura do Evento. 19:10 às 19:50 Palestra: Roteamento Rails de fora para dentro. Resumo: Entender como é o funcionamento das rotas, como o rails trata as requisições http enviadas a ele por interação de request/response E se há rotas mapeadas no sistema e finalmente como melhor utilizá-las, se tornando url’s intuitivas. Palestrante: **Hermínio Torres - **Ccoordenador/Membro do grupo CearáOnRails e Programador Ruby. 19:50 às 20:40 Palestra: Gerência de Projetos com Scrum.**** Resumo: O Scrum é uma das metodologias de gerência de projetos. O que é Scrum? Os papéis no Scrum. O conceito de Sprint. Product Backlog. Sprint Planning Meeting. Scrum Daily Meeting. Sprint Review. Sprint Retrospective. Palestrante: Liliana Pedrosa Pinheiro Carrhá - Analista de sistemas, especialista em Engenharia de Software. Atuação na coordenação de projetos de desenvolvimento e suporte a soluções com foco em melhoria de processo em desenvolvimento, implantação e treinamento de projetos. Conhecimentos adquiridos: UML, RUP, Scrum, Gerência de Projetos, MPS.Br, CMMI, Java, SQL Server, MySQL, ITIL e Redes. 20:40 às 21:00 Pausa do Evento(Coffe-Break). 21:00 às 21:50 Palestra: Cloud On Rails. Resumo: Entender como é o funcionamento das rotas, saber quais as principais rotas no rails e finalmente como melhor utilizá-las. Palestrante: **Hannes Tydén – **Programador Ruby e Membro do Ruby User Group Berlin, Developer Startup SoundCloud. 21:50 às 22:00 Fechamento do Evento. ","date":"2009-04-08","objectID":"/posts/primeiro-encontro-cearaonrails/:0:0","tags":["Impressões","Ruby","Software Livre"],"title":"Primeiro Encontro Cearáonrails","uri":"/posts/primeiro-encontro-cearaonrails/"},{"categories":["Eventos"],"content":"Já pensou em contribuir para a preservação do meio ambiente?","date":"2009-04-03","objectID":"/posts/ii-mangue-beat/","tags":["Impressões","Meio Ambiente"],"title":"II Mangue Beat","uri":"/posts/ii-mangue-beat/"},{"categories":["Eventos"],"content":"Já pensou em contribuir para a preservação do meio ambiente? II Mangue Beat … para não haver o terceiro!!! Data: 05 de Abril **Horário: **09:00 **Local de encontro: **Posto da entrada do Beach Park na Av.Washington Soares. O Mangue da Sabiaguaba, localizada na foz do rio cocó, encontra-se numa situação delicada. Com o lixo que está acumulado nas margens do rio, as diversas espécies que ali vivem estão sendo prejudicadas. Ajude-nos a preservar o mangue comparecendo para a coleta seletiva que será realizada em parceria com o Museu Natural do Mangue que atua na área a quase dez anos e tem como objetivo a preservação desse ecossistema. Os magues são essenciais para a reprodução e a manutenção das diversas espécies da zona costeira, além de ser um ecossitema indispensável para a subsistência de diversas famílias que dependem de seus recursos. Além do mais, os manguezais são ecosssitemas de maior biodiversidade do planeta, onde se alimentam e reproduzem as mais diversas espécies de peixes, crustáceos, moluscos, aves e mamíferos. Se formos omissos com os problemas atuais, talvez nossos netos não tenham possibidade de ter qualidade de vida adequada e tão pouco a oportunidade de contemplar nossas belezas naturais. Participe dessa luta em prol do Meio Ambiente, Junte-se a nós!!!! Fui no mangue catar lixo, pegar caranguejo e conversar com o urubu Pense global e aja local Realização: G.A.M.A-Grupo de Apoio ao Meio Ambiente Apoio: Museu Natural do Mangue https://www.portalmessejana.com.br/museunaturaldomangue/ Contatos: Luis Carlos ( 88031414 ) OBS: Recomendamos usar chapeu/boné e blusa com mangas longas ou uso de protetores solares. E não esqueçam de levar suas garrafas com água!!! ","date":"2009-04-03","objectID":"/posts/ii-mangue-beat/:0:0","tags":["Impressões","Meio Ambiente"],"title":"II Mangue Beat","uri":"/posts/ii-mangue-beat/"},{"categories":["Impressões"],"content":"Mais uma vez trago uma sugestão bibliográfica para aqueles momentos em que você não aguenta mais tecnologia, se você for dessa área, ou simplesmente busca algum equilíbrio extra entre corpo e mente.","date":"2009-03-30","objectID":"/posts/recomendacao-bibliografica-do-mes-mr/","tags":["Impressões","Literatura"],"title":"Recomendação Bibliográfica Do Mês: Mr X","uri":"/posts/recomendacao-bibliografica-do-mes-mr/"},{"categories":["Impressões"],"content":"Saudações nobres colegas. Mais uma vez trago uma sugestão bibliográfica para aqueles momentos em que você não aguenta mais tecnologia, se você for dessa área, ou simplesmente busca algum equilíbrio extra entre corpo e mente. A minha escolha deste mês é, novamente, um livro de terror/horror. (Sim, adoro esse estilo.) Se trata do livro Mr. X do já consagrado Peter Straub. Para quem é fan do gênero, o nome de Straub não deverá ser nenhuma novidade, já que até mesmo o tão renomado Stephen King admite ser fan incondicional do trabalho de Straub. Segue uma pequena sinopse do livro retirada do site da Livraria Saraiva: Uma imaginação de arrepiar. E que inspira novas histórias. Provavelmente foi uma das impressões de Stephen King sobre os livros de Peter Straub. O gosto pela literatura de Straub foi tão impactante e influente que King acabou escrevendo vários livros em parceria com o ídolo. Peter Straub é conhecido no mundo inteiro por criar thrillers fora do comum, literalmente. King vai mais fundo: “Ninguém na indústria do horror pode se igualar a ele”. “Mr. X” é um livro monstruoso e sobrenatural. Além de arrancar elogios da crítica de prestigiados veículos internacionais, como Publishers Weekly e Chicago Tribune, o autor é adorado por uma legião de leitores de diversas nacionalidades. Straub une personagens de grande dimensão psicológica, explorando as fronteiras da mente humana, com doses caprichadas de razão, fantasia, aventura, carnificina, ritmo e agilidade literária inconfundíveis. Comecei a leitura neste fim de semana e estou adorando o livro. A forma como o autor descreve as situações é realmente impressionante, bem como a forma como ele retrata os fatores psicológicos do personagem principal em seus constantes conflitos. Abraços e boa leitura. ;] ","date":"2009-03-30","objectID":"/posts/recomendacao-bibliografica-do-mes-mr/:0:0","tags":["Impressões","Literatura"],"title":"Recomendação Bibliográfica Do Mês: Mr X","uri":"/posts/recomendacao-bibliografica-do-mes-mr/"},{"categories":["Aleatórios"],"content":"Quantas horas por semana você pensa em seu planeta?? Seria pedir de mais uma hora por ano?","date":"2009-03-26","objectID":"/posts/hora-do-planeta-2009/","tags":["Impressões","Meio Ambiente"],"title":"Hora Do Planeta 2009","uri":"/posts/hora-do-planeta-2009/"},{"categories":["Aleatórios"],"content":"Quantas horas por semana você pensa em seu planeta?? Seria pedir de mais uma hora por ano? Pode parecer estranho, mas apenas uma hora por ano faz uma diferença enorme quando o pensamento é coletivo. A Hora do Planeta é um ato simbólico no qual governos, empresas e a população de todo o mundo são convidados a demonstrar sua preocupação com o aquecimento global e as mudanças climáticas. O gesto simples de apagar as luzes por sessenta minutos, possível em todos os lugares do planeta, tem o significado de chamar para uma reflexão sobre o tema ambiental. Conhecido mundialmente como Earth Hour, a Hora do Planeta será promovida no País pela primeira vez pelo WWF-Brasil e conta com a adesão e apoio do Rio de Janeiro , a primeira cidade brasileira a aderir à iniciativa. Em 2009, a Hora do Planeta será realizada no dia 2****8 de março, das 20h30 às 21h30, e pretende contar com a adesão de mais de mil cidades e 1 bilhão de pessoas em todo o mundo. Mais de 170 cidades de 62 países já confirmaram sua adesão à Hora do Planeta. Realizada pela primeira vez em 2007, a Hora do Planeta contou com a participação de 2,2 milhões de moradores de Sidney, na Austrália. Já em 2008, o movimento contou com a participação de 50 milhões de pessoas, de 400 cidades em 35 países. Simultaneamente apagaram-se as luzes do Coliseu, em Roma, da ponte Golden Gate, em São Francisco e da Opera House, em Sidney, entre outros ícones mundiais. ","date":"2009-03-26","objectID":"/posts/hora-do-planeta-2009/:0:0","tags":["Impressões","Meio Ambiente"],"title":"Hora Do Planeta 2009","uri":"/posts/hora-do-planeta-2009/"},{"categories":["Aleatórios"],"content":"Cadastre-se! Ajude! Clique aqui!","date":"2009-03-26","objectID":"/posts/hora-do-planeta-2009/:0:1","tags":["Impressões","Meio Ambiente"],"title":"Hora Do Planeta 2009","uri":"/posts/hora-do-planeta-2009/"},{"categories":["Tutoriais"],"content":"Em um mundo onde nem tudo é tela preta, as vezes pode ser cansativo programar sem a ajuda de uma IDE. Para projetos grandes e que possuem uma disponibilidade menor de tempo, estas ferramentas de desesenvolvimento são fundamentais. Aqui gostaria de destacar o Eclipse, que como vocês devem saber não é apenas uma IDE para desenvolvimento Java, em conjunto com o plugin Pydev.","date":"2009-03-23","objectID":"/posts/pydev-preparando-o-eclipse-para/","tags":["Arch Linux","Impressões","Linux","Python","Software Livre"],"title":"Pydev: Preparando O Eclipse Para O Python","uri":"/posts/pydev-preparando-o-eclipse-para/"},{"categories":["Tutoriais"],"content":"Em um mundo onde nem tudo é tela preta, as vezes pode ser cansativo programar sem a ajuda de uma IDE. Para projetos grandes e que possuem uma disponibilidade menor de tempo, estas ferramentas de desesenvolvimento são fundamentais. Aqui gostaria de destacar o Eclipse, que como vocês devem saber não é apenas uma IDE para desenvolvimento Java, em conjunto com o plugin Pydev. Neste pequeno passo a passo abordo uma forma simples e direta para se instalar o Pydev transformando seu Eclipse em um ambiente para desenvolvimento em Python. Antes de mais nada, suponho que você já tenha o Eclipse devidamente instalado. Em meu caso, no Arch Linux, instalei através do pacman, portanto estou com a versão 3.4.1, portanto qualquer diferença nos passos seguidos aqui pode ser por diferença em sua versão do Eclipse. Sem mais baboseira, vamos ao processo. **1- **Com seu eclipse rodando, clique na opção Software Updates do menu Help, conforme ilustração: Lhe será exibida uma janela como a seguinte. Selecione a opção Available Software, no canto superior. 2- Nesta janela de Available Software, clique na opção Add Site. Lhe será apresentada uma janela na qual você deve inserir o endereço https://pydev.sourceforge.net/updates e clica em Ok, como na figura abaixo: ERRATA: Correção em 2011 -\u003e Novo endereço para atualizações é: https://pydev.org/updates 3- Após isto, você terá a opção de instalação do Pydev. Selecione a caixa e clique no botão Install que se encontra no canto superior direito da janela, conforme ilustração. Ele começará a carregar a instalação e lhe será apresentada uma tela com a licença do plugin. Basta aceitar a licença e seguir em frente. Após isto, o Eclipse começará a baixar os arquivos necessários e realizará a instalação em si. Após concluída, lhe será pedido para reiniciar o Eclipse para que as alterações tenham efeito. Pode confirmar com Yes. Com isto a instalação já está concluída. Nos resta agora começar um projeto Python. Mãos à obra! 4- Com seu Eclipse reiniciado, clique na opção Preferences da aba Window. 5- Na janela que lhe será apresentada, selecione a aba Pydev e selecione a opção Interpreter - Python. Clicando no botão New, do canto superior Direito, aponte para o caminho onde se encontra seu interpretador Python. (No linux, normalmente será /usr/bin/python.) Lhe será apresentada uma tela como a seguinte. Basta confirmar sem alterações. Repare que agora você terá um interpretador Python instalado, bem como uma lista de Paths para o Python em seu sistema. Novamente confirme clicando em Ok, encerrando aqui nossa configuração do Eclipse para programação com Python. Uma vez que o plugin Pydev está instalado e devidamente configurado, passamos para o passo final. Teste do Python no Eclipse. 6**-** Vamos começar criando um novo projeto seguindo o caminho: File \u003e New \u003e Pydev Project. Escolha um nome para seu projeto e confirme a criação do mesmo clicando em Finish, conforme imagem a seguir: Uma vez que seu projeto foi criado. Ele será listado na barra de projetos localizada no canto esquerdo do Eclipse. Clicando com o botão direito do mouse na pasta src de seu projeto, escolha a opção New \u003e File, conforme ilustração. Com seu arquivo em branco, pode fazer seu teste do python com qualquer código simples, como por exemplo o bom e velho “Hello World”. Pronto pessoal! Agora é só abusar do Python no seu Eclipse. Abraços ","date":"2009-03-23","objectID":"/posts/pydev-preparando-o-eclipse-para/:0:0","tags":["Arch Linux","Impressões","Linux","Python","Software Livre"],"title":"Pydev: Preparando O Eclipse Para O Python","uri":"/posts/pydev-preparando-o-eclipse-para/"},{"categories":["Eventos"],"content":"Saudações galera. É chegada uma grande chance de colaborar com o Archlinux.","date":"2009-03-20","objectID":"/posts/bug-day-do-archlinux-2103/","tags":["Arch Linux","Cultura Hacker","Impressões","Linux","Software Livre"],"title":"Bug Day Do Archlinux 21/03","uri":"/posts/bug-day-do-archlinux-2103/"},{"categories":["Eventos"],"content":"Saudações galera. É chegada uma grande chance de colaborar com o Archlinux. “Neste sábado, dia 21, vai rolar um bug day no projeto Arch Linux. Durante todo o dia tentaremos combater vários relatos de bugs, limpando os desatualizados, consertando aqueles que são triviais (ou possuem um patch pronto) e implementando alguns feature requests. Há uma pequena lista de bugs que podem ser resolvidos facilmente aqui. Bugs muito complicados serão resolvidos depois do Bug Day, já que a intenção aqui é fechar o maior número de relatos possível. Quem desejar acompanhar e ajudar o processo pode entrar no #archlinux-bugs da rede freenode. Provavelmente sempre haverá um desenvolvedor disponível para te ajudar a reportar bugs ou tirar dúvidas.” Maiores informações em: https://wiki.archlinux.org/index.php/Bug_Day_TODO Abraços ","date":"2009-03-20","objectID":"/posts/bug-day-do-archlinux-2103/:0:0","tags":["Arch Linux","Cultura Hacker","Impressões","Linux","Software Livre"],"title":"Bug Day Do Archlinux 21/03","uri":"/posts/bug-day-do-archlinux-2103/"},{"categories":["Impressões"],"content":"Ontem vi a notícia sobre o lançamento da versão 0.3 do aplicativo Gespeak. A mesma foi considerada a primeira versão estável do mesmo. Logo que vi resolvi empacotar para o Arch esta aplicação que poderia vir a ser útil para algumas pessoas, como é o meu caso.","date":"2009-03-13","objectID":"/posts/gespeak-empacotado-hoje-para-o/","tags":["Arch Linux","Asterisk","Impressões","Linux","Python","Software Livre"],"title":"Gespeak Empacotado Hoje Para O Arch","uri":"/posts/gespeak-empacotado-hoje-para-o/"},{"categories":["Impressões"],"content":"Ontem vi a notícia sobre o lançamento da versão 0.3 do aplicativo Gespeak. A mesma foi considerada a primeira versão estável do mesmo. Logo que vi resolvi empacotar para o Arch esta aplicação que poderia vir a ser útil para algumas pessoas, como é o meu caso. Para quem não conhece, o Gespeak é um front end para o Espeak. O Espeak nada mais é que um sintetizador de voz. Como perguntariam alguns amigos meus: “What a porra is this?” Um sintetizador de voz tem como objetivo transformar texto em áudio. Você digita algum texto e o aplicativo converte aquilo em áudio que pode ser utilizado de várias formas. A mais utilizada por mim é na administração de servidores de Voz rodando Asterisk, no qual posso gravar mensagens e utilizar facilmente de acordo com o meu propósito. O Gespeak é desenvolvido em PyGTK e ainda está no começo de seu desenvolvimento. Espero que possamos em breve acompanhar outras funções no mesmo. Eu mesmo já entrei em contato com o pessoal do projeto para solicitar algumas funções básicas que o Espeak possui por padrão via linha de comando. Hoje pela manhã o pacote para o Arch foi criado e já homologado pelo pessoal do projeto no final da tarde. Link do projeto: https://code.google.com/p/gespeak/ Link do pacote no AUR: https://aur.archlinux.org/packages.php?ID=24659 Abraços ","date":"2009-03-13","objectID":"/posts/gespeak-empacotado-hoje-para-o/:0:0","tags":["Arch Linux","Asterisk","Impressões","Linux","Python","Software Livre"],"title":"Gespeak Empacotado Hoje Para O Arch","uri":"/posts/gespeak-empacotado-hoje-para-o/"},{"categories":null,"content":"A bola da vez se chama Sementes no Gelo. Este é para quem gosta de histórias de suspense.","date":"2009-03-11","objectID":"/posts/recomendacao-bibliografica-sementes-no-gelo/","tags":["Impressões","Literatura"],"title":"Recomendação Bibliográfica: Sementes No Gelo","uri":"/posts/recomendacao-bibliografica-sementes-no-gelo/"},{"categories":null,"content":"Saudações pessoal… A bola da vez se chama Sementes no Gelo. Este é para quem gosta de histórias de suspense. Segue descrição retirada do site da Saraiva: Neste novo romance, André Vianco volta a explorar o sobrenatural. Em ´Sementes no Gelo´, o leitor ingressa no mundo de espíritos atormentados, impedidos de reencarnar. Muitos se enraivecem e lançam sua fúria sobre todos que lhe chamam atenção e interpõe em seus caminhos. Um detetive, por acaso, desvenda os mistérios em torno destes espíritos, tornando-se o inimigo número um das perigosas entidades. Andre Vianco afirma ter tido a inspiração e a idéia para compor a obra assistindo a um telejornal onde a matéria tratava sobre embriões congelados e a legislação vigente em vários países. Em todos os países na ocasião era terminantemente proibido descartar os “ovos” fertilizados, que viriam a se tornar embriões viáveis para um futuro implante nas mães com dificuldade de fertilização natural. Com a população mundial de embriões congelados crescendo, o autor imagina um mundo onde esses seres, mesmo que minúsculos e congelados, possuem alma, espírito. Esses espíritos se desenvolvem e em determinada altura ganham o poder de se materializar para seus pais e também para aqueles que praticam violência contra crianças. ","date":"2009-03-11","objectID":"/posts/recomendacao-bibliografica-sementes-no-gelo/:0:0","tags":["Impressões","Literatura"],"title":"Recomendação Bibliográfica: Sementes No Gelo","uri":"/posts/recomendacao-bibliografica-sementes-no-gelo/"},{"categories":null,"content":"Algum dia precisou digitar o mesmo comando em mais de um servidor ou realizar a mesma configuração? Não gostou de ter que executar essa tarefa várias vezes, sendo uma em cada máquina?","date":"2009-03-06","objectID":"/posts/executando-comandos-remotos-em-x/","tags":["Arch Linux","Cultura Hacker","Impressões","KDE","Linux","Redes","Software Livre"],"title":"Executando Comandos Remotos Em X Servidores Com O Konsole","uri":"/posts/executando-comandos-remotos-em-x/"},{"categories":null,"content":"Algum dia precisou digitar o mesmo comando em mais de um servidor ou realizar a mesma configuração? Não gostou de ter que executar essa tarefa várias vezes, sendo uma em cada máquina? Porque não usar a tecnologia a seu favor? Sem muitos truques e malabarismos, o próprio konsole do kde pode resolver isso. Sim, o konsole padrão do kde possui uma função interessante para execução de comandos em múltiplos terminais/servidores. O procedimento é bem simples como vocês podem perceber abaixo. Abra o seu konsole e em seguida inicie uma nova aba no mesmo. Para isso clique em Arquivo e selecione “Nova Aba”. Sua aba será aberta e ficará indicada na barra de baixo. Porém, de nada vale abrirmos mútliplas abas se não pudermos ver as mesmas, certo?! Então clique no botão Exibir e seleciona a opção “Dividir a exibição”. Lhe serão indicadas as possibilidades disponíveis e você pode escolher a que lhe for de melhor agrado. Eu optei pela divisão “Esquerda/Direita”. Agora sim, estamos vendo ambas as abas, certo!? Repare que mesmo vendo ambas, você tem que digitar o comando em uma e em outra. Vamos agora acessar os servidores/terminais remotos nos quais precisamos fazer a operação. Para isso na primeira aba acesse o servidor/estação de sua preferência, repetindo o mesmo na segunda aba. (Não convém especificar aqui como você se logará em outros servidores/terminais. Eu utilizei conexão via ssh em meu exemplo que poderá ser visto no vídeo após o post.) Após estar logado à um servidor/terminal diferente em cada aba, partiremos para o truque de espelhamento/repetição do comando. Clique na opção Editar do konsole e acesse a aba “Copiar a entrada para..”. Lhe será exibida uma janela com suas abas abertas. Uma delas já vem marcada, pois é a que está ativa no momento. Marque a segunda e confirme clicando no botão Ok. Feito isto, repare que os comandos que você executar na Aba primária serão repetidos na seguinte. Simples, certo?! ;] Abaixo disponibilizo um vídeo de demonstração de minha máquina executando a tarefa. (Segue em três formatos para que você escolha o que achar melhor.) Formato ogg Formato avi Formato flv ","date":"2009-03-06","objectID":"/posts/executando-comandos-remotos-em-x/:0:0","tags":["Arch Linux","Cultura Hacker","Impressões","KDE","Linux","Redes","Software Livre"],"title":"Executando Comandos Remotos Em X Servidores Com O Konsole","uri":"/posts/executando-comandos-remotos-em-x/"},{"categories":["Impressões"],"content":"Às vezes até esqueço o quão bom é ser usuário Arch Linux.","date":"2009-03-02","objectID":"/posts/kde-421-ja-no-arch/","tags":["Arch Linux","Cultura Hacker","Impressões","KDE","Redes","Segurança","Software Livre"],"title":"Kde 4.2.1 Já No Arch","uri":"/posts/kde-421-ja-no-arch/"},{"categories":["Impressões"],"content":"Às vezes até esqueço o quão bom é ser usuário Arch Linux. Depois de um fim de semana corrido no trabalho acordo na segunda e como de costume mando um pacman -Syu para atualizar meu sistema. Muitas coisas novas, porém dentre elas alguns pacotes se destacaram. Antes de eu sequer imaginar testar o KDE 4.2.1, ele já estava ali disponível para mim. Confirmei a operação e depois da atualização cá estou eu usando o KDE 4.2.1. Alguns de vocês podem estar se perguntando: Como o Arch consegue fazer um excelente trabalho como esse? Lançar o KDE 4.2.1 antes mesmo de seu lançamento oficial???? Algumas teorias indicam que os desenvolvedores do Arch são de outro planeta, mas…enfim.. não vem ao caso. Fomos presenteados e não a nada de errado nisso. Explico… Já é de costume do pessoal do KDE, liberar sua nova versão para desenvolvedores fazerem testes finais antes de seu lançamento oficial (alguns dias antes), o pessoal do Arch, que não dorme no ponto, se aproveitou disso e já empacotou. Como é bom ser usuário de uma rolling release como o Arch. ","date":"2009-03-02","objectID":"/posts/kde-421-ja-no-arch/:0:0","tags":["Arch Linux","Cultura Hacker","Impressões","KDE","Redes","Segurança","Software Livre"],"title":"Kde 4.2.1 Já No Arch","uri":"/posts/kde-421-ja-no-arch/"},{"categories":["Aleatórios"],"content":"É com grande alegria que venho publicar um dos frutos de meu carnaval. Como alguém que não gosta de axé e forró, aproveitei o feriado para estudar, pegar praia, cinema, barzinho bem como migrar meu blog para a plataforma WordPress.","date":"2009-02-27","objectID":"/posts/de-cara-nova/","tags":["Cultura Hacker","Impressões"],"title":"De Cara Nova","uri":"/posts/de-cara-nova/"},{"categories":["Aleatórios"],"content":"Saudações pessoal… É com grande alegria que venho publicar um dos frutos de meu carnaval. Como alguém que não gosta de axé e forró, aproveitei o feriado para estudar, pegar praia, cinema, barzinho bem como migrar meu blog para a plataforma WordPress. Levei um tempinho para colocar tudo no seu devido lugar e migrar todo o conteúdo do antigo blog, mas agora parece estar tudo em ordem. Também por isso estive meio parado estes dias. Nenhum post novo? Sei, confesso. Aí fica aquele velho papo: “Devo, não nego.. pago quando puder!” Agora de volta à ativa. Abraços ","date":"2009-02-27","objectID":"/posts/de-cara-nova/:0:0","tags":["Cultura Hacker","Impressões"],"title":"De Cara Nova","uri":"/posts/de-cara-nova/"},{"categories":["Impressões"],"content":"Saudações pessoal. É com imensa satisfação que lhes informo que a release 2009.02 do nosso Archlinux foi lançada. Dentre as principais mudanças destacam-se as seguintes:","date":"2009-02-17","objectID":"/posts/arch-iso-200902-liberada-celebrem/","tags":["Arch Linux","Impressões","Linux","Software Livre"],"title":"Arch Iso 2009.02 Liberada, Celebrem","uri":"/posts/arch-iso-200902-liberada-celebrem/"},{"categories":["Impressões"],"content":"Saudações pessoal. É com imensa satisfação que lhes informo que a release 2009.02 do nosso Archlinux foi lançada. Dentre as principais mudanças destacam-se as seguintes: Kernel 2.6.28 Suporte à Ext4 (disponível, inclusive, para a instalação em partição raiz) Capacidade de recuperação e manutenção em partições com ext4 Documentação totalmente atualizada Inclusão do AIF , que está sendo desenvolvido para se tornar o instalador da próxima geração do Arch Diversos bugs corrigidos no instalador ISOs Fallback usando o ISOLINUX de bootloader para aqueles que tiverem problemas com o GRUB Como todos sabem o Arch é uma rolling release e como tal uma nova ISO não necessariamente é uma versão totalmente nova do sistema, uma vez que o próprio pacman pode atualizar completamente seu Arch com um simples -Syu. O novo time de engenheiros de release do Arch estarão cuidando da ISO e versionando-a de acordo com os lançamentos do kernel, ficando a próxima ISO para o kernel 2.6.29. É isso aí… bem vindos ao mundo Arch! ","date":"2009-02-17","objectID":"/posts/arch-iso-200902-liberada-celebrem/:0:0","tags":["Arch Linux","Impressões","Linux","Software Livre"],"title":"Arch Iso 2009.02 Liberada, Celebrem","uri":"/posts/arch-iso-200902-liberada-celebrem/"},{"categories":["Impressões"],"content":"À primeira vista, dar e servir parecem ser a mesma coisa. Em ambas as opções estamos abrindo mão de algo e entregando a alguém, porém existe uma sutil, porém importante, diferença entre estas duas palavras. Aqui irei abordar esta diferença explicando um pouco da filosofia do Software Livre.","date":"2009-02-03","objectID":"/posts/software-livre-dar-ou-servir/","tags":["Cultura Hacker","Impressões","Linux","Software Livre"],"title":"Software Livre - Dar Ou Servir","uri":"/posts/software-livre-dar-ou-servir/"},{"categories":["Impressões"],"content":"À primeira vista, dar e servir parecem ser a mesma coisa. Em ambas as opções estamos abrindo mão de algo e entregando a alguém, porém existe uma sutil, porém importante, diferença entre estas duas palavras. Aqui irei abordar esta diferença explicando um pouco da filosofia do Software Livre. Tenho plena certeza de que não sou o único a já ter sido bombardeado com perguntas tais como: * Porque perder horas desenvolvendo um software e em seguida liberar o código do mesmo? _ * Qual o sentido existente em perder horas do seu dia traduzindo ou escrevendo documentações?_ _ * O que se ganha trabalhando gratuitamente em eventos e/ou projetos de Software Livre?_ _ * Se o mundo é capitalista, como você poderá pagar as suas contas agindo desta forma?_ _ * De que te vale tudo isso se você perdeu horas estudando para adquirir este conhecimento?_ _ Etc…_ Antes de respondermos estas perguntas vamos relembrar como nasceu o Linux, um dos maiores exemplos de Software Livre existente. Originalmente, o kernel Linux foi escrito pelo finlandês Linus Torvalds. Torvalds era do departamento de Computação da Universidade de Helsinki, na Finlândia, onde começou seus estudos em computação e teve seu primeiro contato com o mundo UNIX. A ideia nasceu em cima de sua curiosidade no Sistema Operacional Minix criado por Andrew Tanenbaum, já que era caro para se ter um UNIX em casa e trabalhar em cima do mesmo. O Minix não atendia todas as necessidades de Torvalds, e por isso o mesmo começou a trabalhar em um kernel novo. Foi quando lançou um convite em forma de email na internet: Você suspira pelos bons tempos do Minix-1.1, quando os homens eram homens e escreviam seus próprios “device drivers”? Você está sem um bom projecto em mãos e está desejando trabalhar num S.O. que você possa modificar de acordo com as suas necessidades? Está achando frustrante quando tudo funciona no Minix? Chega de noite ao computador para conseguir que os programas funcionem? Então esta mensagem pode ser exatamente para você. Como eu mencionei há um mês atrás, estou trabalhando numa versão independente de um S.O. similar ao Minix para computadores AT-386. Ele está, finalmente, próximo do estado em que poderá ser utilizado (embora possa não ser o que você está esperando), e eu estou disposto a disponibilizar o código-fonte para ampla distribuição. Ele está na versão 0.02… contudo eu tive sucesso ao executar bash, gcc, gnu-make, gnu-sed, compressão, etc. Nele. Em poucas horas Linus já havia recebido respostas de vários programadores com interesse em ajudar no desenvolvimento do SO que viria a ser o Linux como o conhecemos hoje. Daí pra frente muita coisa rolou com o código do mesmo sendo livremente compartilhado e distribuído para constantes modificações e implementações, bem como continua sendo hoje em sua constante evolução. O Linux é, ainda nos dias de hoje, um dos maiores símbolos do Software Livre e sua filosofia que se baseia no compartilhamento livre de informações. Afinal de contas, Linus Torvalds com esta sua grandiosa colaboração ao mundo, deu ou serviu? Gosto de acreditar que Torvalds contribuiu com um movimento que foi e continua sendo responsável por uma mudança de mentalidade em muitas Empresas, Entidades, Governos e Comunidades quando se trata de colaboração, conhecimento e principalmente Tecnologia da Informação. Não gosto de ver Torvalds como alguém que deu algo ao mundo, mas sim como alguém que serviu a um propósito, já que o mesmo começou e incentivou milhares de pessoas a trabalharem em um sistema operacional livre que na época não se imaginava com um futuro tão promissor. Aproveitando estes argumentos, respondo as perguntas que me foram feitas anteriormente. Não DOU meu tempo. Eu o SIRVO! Hoje eu trabalho, estudo e desempenho atividades extras em projetos relacionados a Software Livre. Para ter um emprego, eu preciso ter alguma habilidade ou conhecimento necessário à alguém. Pode ser difícil acreditar, mas cerca de 60% de meu conhecimento em Linux ou tecnologia em g","date":"2009-02-03","objectID":"/posts/software-livre-dar-ou-servir/:0:0","tags":["Cultura Hacker","Impressões","Linux","Software Livre"],"title":"Software Livre - Dar Ou Servir","uri":"/posts/software-livre-dar-ou-servir/"},{"categories":["Aleatórios"],"content":"Depois de ter sido intimado pelo Hugo Dória resolvi participar da brincadeira. O jogo é interessante e nos trás boas lembranças. ;] Antes de mais nada devo deixar aqui as regras do jogo: Colocar as regras expostas no post Colocar 9 imagens que marcaram a sua infância, pode ser programa de televisão, passatempos, recreações tudo que demonstre sua infância. Explicar cada imagem Indicar 5 pessoas para fazer esse meme Agora meu post em si… Minhas explicações: 1- Cavaleiros do Zodiaco - Acredito que esse desenho vá fazer parte de pelo menos uns 90% dos posts deste tópico. Cavaleiros do Zodiaco marcou a infância de muita gente de nossa geração. Lembro de mim muleque fascinado pelo Shiryu pelo fato de seguir a constelação do dragão com a qual sempre simpatizei. Sim, tinha vários dos bonecos. 2- Kiko - Nunca fui muito fan do programa do Chaves como um todo, mas esperava o programa inteiro só para ver as participações deste personagem que sem dúvida foi um dos melhores que já vi em minha vida em se tratando de humor. 3- Changeman - Seria o equivalente aos power rangers para a mulecada de hoje em dia. Naquela época eu ficava fascinado com os “efeitos especiais” utilizados em combates nesta série. :p 4- Vovó Mafalda - Dessa eu tinha medo. Minha mãe nunca entendeu o porque, mas eu só virava pra tela por causa dos desenhos.. Quando ela começava a falar..eu saia logo de perto. Me marcou..de forma negativa..mas marcou.. nunca mais gostei de palhaços.. :/ 5- Atari - Quem aqui nunca teve um desses?? Meu primeiro video-game, como esquecer? Jogos como king kong animaram muitas noites de insonia em minha infância. 6- Vampiro - Quando mais novo adorava jogar RPG. Meu favorito era justamente este no qual aprendi a ter mais imaginação e despertei um pouco de meu lado criativo durante jogos que duravam semanas e mais semanas. 7- Homem-Aranha - Dentre as minhas histórias em quadrinhos estas realmente se destacavam. Do homem aranha eu tinha a coleção completa. Sempre foi meu herói favorito. Quando criança, imaginava como seria a sensação de se deslocar com aquelas teias. :p 8- Skate - Sim, meu envolvimento com esportes radicais começou cedo. Sempre fui muito esportivo, mas meu início nos esportes radicais começou sem dúvidas com o skate que foi uma das paixões que tive em minha infância. 9- Windows 3.0 - Não dizem que criança só faz o que não presta?! hauhauhauah Inocência é uma coisa linda não é verdade?! hauhauha Ainda bem que todos nós crescemos um dia e passamos a querer fazer coisas de gente grande! :p Depois de listar algumas coisas que tiveram destaque em minha infância, gostaria de conhecer um pouco mais sobre o passado das seguintes pessoas: Gilfran Ribeiro, Kessia (even), Anderson Pereira, Diane e Felipe Morales. ","date":"2009-01-30","objectID":"/posts/meme-infancia-conta-tudo-pra/:0:0","tags":["Impressões"],"title":"Meme Infância: Conta Tudo Pra Tua Mãe Kiko","uri":"/posts/meme-infancia-conta-tudo-pra/"},{"categories":["Impressões"],"content":"É com grande entusiasmo que venho lhes comentar que hoje a equipe de desenvolvimento do KDE liberou a primeira versão estável do tão esperado KDE 4.2. Com maior entusiasmo ainda venho adiantar que, como era de se esperar, o pessoal do Arch Linux se antecipou novamente e já possui o novo KDE em seus repositórios oficiais. Eu mesmo hoje pela manhã fiz meu upgrade com um simples # pacman -Syu.","date":"2009-01-27","objectID":"/posts/kde-42-liberado-e-os/","tags":["Arch Linux","Impressões","KDE","Linux","Software Livre"],"title":"Kde 4.2 Liberado E Os Archers Já Estão Armados","uri":"/posts/kde-42-liberado-e-os/"},{"categories":["Impressões"],"content":"Saudações pessoal… É com grande entusiasmo que venho lhes comentar que hoje a equipe de desenvolvimento do KDE liberou a primeira versão estável do tão esperado KDE 4.2. Com maior entusiasmo ainda venho adiantar que, como era de se esperar, o pessoal do Arch Linux se antecipou novamente e já possui o novo KDE em seus repositórios oficiais. Eu mesmo hoje pela manhã fiz meu upgrade com um simples # pacman -Syu. O KDE 4.2 trás muitas novidades como por exemplo temas mais bem elaborados e uma maior estabilidade na usabilidade dos plasmoids. Por falar em plasmoids, houveram mudanças radicais no Plasma, portanto é extremamente recomendado que se faça um backup de seu ~/.kde4 e remova-o ao instalar o kde 4.2. Porque? Bom, como houveram mudanças radicais no Plasma, os plasmoids que você já tinha não irão funcionar muito bem. Lembrando que isto não é problema, já que ao iniciar o KDE 4.2 pela primeira vez, você pode adicionar novamente os plasmoids que já utilizava e voltar a usar normalmente. ;] E só para completar o assunto Plasma e plasmoids, uma quantidade bem maior de plasmoids está disponível agora nesta versão. Muitos que são bastante interessantes por sinal. Não pensem que as mudanças ficaram apenas no Plasma. Esta versão está mais arrojada e mais estável. Com vários bugs corrigidos bem como mais intuitiva em alguns aspectos..vale a pena conferir. Como o próprio Pierre Schmitz, empacotador do KDE 4.2 no Archlinux, disse: “Mesmo que você tenha odiado o KDE 4.1, dê ao 4.2 uma chance; it really rocks!” Abraços ","date":"2009-01-27","objectID":"/posts/kde-42-liberado-e-os/:0:0","tags":["Arch Linux","Impressões","KDE","Linux","Software Livre"],"title":"Kde 4.2 Liberado E Os Archers Já Estão Armados","uri":"/posts/kde-42-liberado-e-os/"},{"categories":["Impressões"],"content":"Trago aqui uma excelente notícia para os fans do KDE e, é claro, do Archlinux.","date":"2009-01-23","objectID":"/posts/kde-42-liberado-no-testing/","tags":["Arch Linux","Impressões","KDE","Linux","Software Livre"],"title":"Kde 4.2 Liberado No Testing Do Archlinux","uri":"/posts/kde-42-liberado-no-testing/"},{"categories":["Impressões"],"content":"Olá pessoal… Trago aqui uma excelente notícia para os fans do KDE e, é claro, do Archlinux. Ontem entrou no repositório [testing] do Archlinux o tão falado KDE 4.2. A versão 4.1.4, já bastante madura e estável, será a última atualização disponibilizada pelo projeto KDE antes do lançamento oficial do KDE 4.2 que está prevista pelo projeto para o dia 27 de Janeiro. Esta versão parece trazer muitas novidades bem como correção de algumas falhas encontradas. Para aqueles que já desejam testar esta nova versão em seu Arch, basta seguir o seguinte procedimento: Primeiramente, descomentar o repositório [testing] que vem comentado por padrão. Para isso abra com seu editor favorito o arquivo: /etc/pacman.conf e descomente as linhas a seguir: [testing] Include = /etc/pacman.d/mirrorlist Feito isto, pode partir para a instalação normalmente. Para os menos aventureiros e que não gostam de instalar pacotes que ainda se encontram no estado de “testing”, a notícia continua sendo boa. Pois em breve já o teremos saindo do testing para os repositórios oficiais. ;] Abraços ","date":"2009-01-23","objectID":"/posts/kde-42-liberado-no-testing/:0:0","tags":["Arch Linux","Impressões","KDE","Linux","Software Livre"],"title":"Kde 4.2 Liberado No Testing Do Archlinux","uri":"/posts/kde-42-liberado-no-testing/"},{"categories":["Impressões"],"content":"É com grande satisfação que venho informar que desde o começo deste fim de semana o Arch Linux já está com o kernel 2.6.28 em seu repositório core. Depois de mais de uma semana com ele já rodando nos repositórios testing, podemos dizer, ao contrário do que muitos andam afirmando, que o Arch é a primeira distro a adotar o novo kernel.","date":"2009-01-18","objectID":"/posts/kernel-2628-ja-disponivel-para/","tags":["Arch Linux","Impressões","Linux","Software Livre"],"title":"Kernel 2.6.28 Já Disponível Para Os Archers","uri":"/posts/kernel-2628-ja-disponivel-para/"},{"categories":["Impressões"],"content":"Saudações pessoal.. É com grande satisfação que venho informar que desde o começo deste fim de semana o Arch Linux já está com o kernel 2.6.28 em seu repositório core. Depois de mais de uma semana com ele já rodando nos repositórios testing, podemos dizer, ao contrário do que muitos andam afirmando, que o Arch é a primeira distro a adotar o novo kernel. Já fiz meu upgrade e não tive problemas com este kernel. O que você está esperando?? # pacman -Syu # aí rapah! Dentre as novidades do novo kernel, algumas são: suporte para sistema de arquivos ext4 suporte para Wireless USB Kernel Mode Setting, gestão de modos gráficos do kernel novo administrador de memória para chipsets gráficos redução de consumo na reprodução multimídia novos drivers e unificação dos códigos anteriores Você já usa Arch Linux? Com ext3 como seu sistema de arquivos? Quer usar o ext4 mas não deseja reinstalar seu Arch do zero? Seus problemas acabaram. Nosso amigo Hugo Doria escreveu um mini HOW TO para você. Acesse o seguinte link para conferir. AQUI Abraços ","date":"2009-01-18","objectID":"/posts/kernel-2628-ja-disponivel-para/:0:0","tags":["Arch Linux","Impressões","Linux","Software Livre"],"title":"Kernel 2.6.28 Já Disponível Para Os Archers","uri":"/posts/kernel-2628-ja-disponivel-para/"},{"categories":["Impressões"],"content":"A comunidade Archlinux-br criou um repositório nacional para o Archlinux. Nele colocaremos alguns pacotes que ainda não foram colocados no repositório do archlinux.org, por ainda serem pouco populares, ou que não podem ser incluídos (por serem experimentais, por exemplo). Para utilizá-lo, basta adicionar essas duas linhas no pacman.conf antes dos outros repositórios.","date":"2009-01-07","objectID":"/posts/repositorio-brasileiro-arch-linux/","tags":["Arch Linux","Linux","Software Livre"],"title":"Repositório Brasileiro Arch Linux","uri":"/posts/repositorio-brasileiro-arch-linux/"},{"categories":["Impressões"],"content":"Saudaçes pessoal, A comunidade Archlinux-br criou um repositório nacional para o Archlinux. Nele colocaremos alguns pacotes que ainda não foram colocados no repositório do archlinux.org, por ainda serem pouco populares, ou que não podem ser incluídos (por serem experimentais, por exemplo). Para utilizá-lo, basta adicionar essas duas linhas no pacman.conf antes dos outros repositórios. [archlinuxbr] Server = https://repo.archlinux-br.org/i686 ou [archlinuxbr] Server = https://repo.archlinux-br.org/x86_64 A política do repositório é: Adicionar qualquer pacote que esteja no AUR, desde que não seja malicioso ou tenha muitas falhas de segurança (por isso nada de yaourt :-)) ou tenha problema de licença (por exemplo o Virtual Box). Pacotes de softwares experimentais serão adicionados com nomes diferentes, seguindo a mesma política do AUR (ex.: o Qt Technology Preview se chama qt-tp). Para adicionar um pacote, mande um e-mail para repo@archlinux-br.org, dando uma breve explicação e o link para o AUR do pacote. ","date":"2009-01-07","objectID":"/posts/repositorio-brasileiro-arch-linux/:0:0","tags":["Arch Linux","Linux","Software Livre"],"title":"Repositório Brasileiro Arch Linux","uri":"/posts/repositorio-brasileiro-arch-linux/"},{"categories":["Impressões"],"content":"A resposta desta pergunta é muito relativa. Antes de mais nada devemos nos perguntar: O que mesmo é um Hacker?","date":"2009-01-06","objectID":"/posts/archlinux-um-sistema-operacional-para/","tags":["Arch Linux","Impressões","Linux","Software Livre"],"title":"Archlinux - Um Sistema Operacional Para Hackers","uri":"/posts/archlinux-um-sistema-operacional-para/"},{"categories":["Impressões"],"content":"A resposta desta pergunta é muito relativa. Antes de mais nada devemos nos perguntar: O que mesmo é um Hacker? o.O ","date":"2009-01-06","objectID":"/posts/archlinux-um-sistema-operacional-para/:0:0","tags":["Arch Linux","Impressões","Linux","Software Livre"],"title":"Archlinux - Um Sistema Operacional Para Hackers","uri":"/posts/archlinux-um-sistema-operacional-para/"},{"categories":["Impressões"],"content":"Introdução Nos últimos 20 anos a palavra Hacker recebeu diversos tipos de atribuições bastante variadas e por isso mesmo, ainda nos dias de hoje, é difícil definir o que seria um Hacker. Apesar de existirem definições, sempre haverão divergências entre os mais diferentes pontos de vista PESSOAIS. Muitos se orgulham em se dizer um Hacker, enquanto que outros preferem negar de pés juntos por ainda ter receio do sentido errado empregado à esta palavra. De qualquer forma, por trás desta palavra existem fatos incontestáveis. Seguindo este ponto de vista, recomendo, fortemente, que se leia um outro artigo antes de dar continuidade a este. O artigo que chamei de “Cultura Hacker, tenha ética e ganharás respeito” é pré-requisito básico para o entender do pequeno post que se segue. Costumo identificar o Hacker naquele que, antes de mais nada, apresenta uma sede insaciável de conhecimento tecnológico. Aquele que demonstra nas redes de computadores e seu funcionamento uma fonte de busca inesgotável bem como uma profunda curiosidade de entender a forma como as coisas funcionam por trás de um programa atraindo seus olhos para inúmeras linhas de código como forma de lhe garantir, digamos assim, um fim de semana “divertido”. ","date":"2009-01-06","objectID":"/posts/archlinux-um-sistema-operacional-para/:1:0","tags":["Arch Linux","Impressões","Linux","Software Livre"],"title":"Archlinux - Um Sistema Operacional Para Hackers","uri":"/posts/archlinux-um-sistema-operacional-para/"},{"categories":["Impressões"],"content":"Arch Linux Sendo assim, seria o Archlinux um Sistema Operacional para Hackers? Coinscidência ou não, resolvi escrever este post pelo fato de ter sido questionado sobre isso por duas pessoas nesta mesma semana. Aqui respondo a esta pergunta de acordo com o MEU ponto de vista. (Lembrando que a resposta vai variar de acordo com o seu entendimento sobre a palavra Hacker, ok?!) Para os amantes da tecnologia e seus segredos os sistemas operacionais de código aberto sempre se mostraram um prato cheio, justamente pelo fato de você ter a liberdade de explorar seu código podendo assim entender seu funcionamento bem como adaptar de acordo com suas necessidades. Nos últimos 10 anos o Linux tem se destacado muito neste sentido ganhando cada vez mais adeptos. Sendo assim, acabaram por surgir diversos sabores, digamos assim, do Linux. Dentre elas vou destacar aqui o Archlinux. O Archlinux é sim uma excelente escolha para estes famintos por conhecimento. Além das já comuns características do Linux o Arch trás algumas características próprias. Dentre elas, gostamos de dizer que, diferente de muitas distribuições Linux, o Arch não está aí para trabalhar POR você, mas sim COM você. O Arch favorece o aprendizado da tecnologia bem como das funcionalidades e potenciais reais de um sistema Linux por lhe permitir ter um acesso às configurações que são escondidas/camufladas pela grande maioria das distribuições atuais. Configurações que vão desde básicas mudanças para melhoramento de seu Desktop, bem como configurações avançadas de segurança para protocolos que venham a ser utilizados por você em sua estação de trabalho. No Arch você geralmente precisará configurar arquivos e mexer em códigos de scripts, portanto é desejável uma certa “empatia” para com a querida telinha preta, o que não exclui aqueles que querem apenas um Desktop comum e funcional. O fato de desde sua instalação necessitar de uma certa pesquisa de como o fazer, por já pedir alguns conhecimentos com, por exemplo, seu gerenciador de pacotes, o pacman, estimula o usuário a iniciar suas buscas ou googladas já de início. Um prato cheio para quem gosta de fuçar, estudar e pesquisar. Qual hacker não gosta de quebrar a cabeça e correr atrás? o.O Mas, é claro, toda distribuição possui algumas características básicas que a diferenciam das demais, portanto este post não poderia acabar com esta simples diferença, já que a cultura Hacker, dentro de meu ponto de vista, não para por aí. O senso de colaboração é bastante apurado para estes “garotos da rede”. E no que o Arch ajuda quanto a isso? Bom, particularmente já passei por várias comunidades/distribuições Linux. Dentre todas elas, sem dúvida alguma, consigo destacar o Arch como sendo a comunidade mais aberta à colaboração de novos interessados. A comunidade Arch é muito aberta e qualquer usuário do Arch percebe facilmente o quão fácil é contribuir com a distribuição, seja com tradução de documentações, desenvolvimento gráfico, desenvolvimento de código, correção, empacotamento, etc… Em meu ver, estes aspectos citados acima respondem a pergunta original. Tire suas conclusões… Abraços ","date":"2009-01-06","objectID":"/posts/archlinux-um-sistema-operacional-para/:2:0","tags":["Arch Linux","Impressões","Linux","Software Livre"],"title":"Archlinux - Um Sistema Operacional Para Hackers","uri":"/posts/archlinux-um-sistema-operacional-para/"},{"categories":["Aleatórios"],"content":"É com grande alegria que estamos encerrando este ano, meu primeiro com este blog, para a chegada de um novo que com certeza será ainda melhor.","date":"2008-12-24","objectID":"/posts/um-feliz-natal-e-um/","tags":["Impressões"],"title":"Um Feliz Natal E Um Próspero Ano Novo","uri":"/posts/um-feliz-natal-e-um/"},{"categories":["Aleatórios"],"content":"Saudações Pessoal… É com grande alegria que estamos encerrando este ano, meu primeiro com este blog, para a chegada de um novo que com certeza será ainda melhor. Gostaria de deixar aqui meus sinceros agradecimentos a todos que visitam o blog. São vocês que nos motivam a continuar compartilhando informação de alguma forma em larga escala. Um grande abraço… Feliz Natal e um Ano Novo repleto de paz. ","date":"2008-12-24","objectID":"/posts/um-feliz-natal-e-um/:0:0","tags":["Impressões"],"title":"Um Feliz Natal E Um Próspero Ano Novo","uri":"/posts/um-feliz-natal-e-um/"},{"categories":["Impressões"],"content":"Para os que curtem jogos de rpg online e em especial os que curtem o famoso Ragnarok, um dos mais jogados nos dias atuais, esta notícia será muito boa.","date":"2008-12-18","objectID":"/posts/ragnarok-agora-no-archlinux/","tags":["Arch Linux","Jogos","Linux","Software Livre"],"title":"Ragnarok Agora No Archlinux","uri":"/posts/ragnarok-agora-no-archlinux/"},{"categories":["Impressões"],"content":"Para os que curtem jogos de rpg online e em especial os que curtem o famoso Ragnarok, um dos mais jogados nos dias atuais, esta notícia será muito boa. As perguntas sobre como rodar o ragnarok no Linux já estão bastante expostas na internet, recebendo várias respostas, sendo muitas delas bastante complexas ou insuficientes usando-se de gambiarras e mais gambiarras. Graças ao server Off Topic Ragnarok Online e ao nosso amigo wine podemos agora desfrutar sem problemas deste game multiplayer. Inspirado no pessoal do ubuntugames, estou preparando o pacote para o Arch Linux e nos próximos dias devo estar disponibilizando o mesmo para utilização geral. Como podem ver no screenshot abaixo, o jogo já está rodando numa boa. Abraços ","date":"2008-12-18","objectID":"/posts/ragnarok-agora-no-archlinux/:0:0","tags":["Arch Linux","Jogos","Linux","Software Livre"],"title":"Ragnarok Agora No Archlinux","uri":"/posts/ragnarok-agora-no-archlinux/"},{"categories":["Tutoriais"],"content":"Nesta curta dica irei apresentar uma dica simples e rápida de como alterar o endereço MAC de uma interface de rede no Linux.","date":"2008-12-15","objectID":"/posts/alterando-o-endereco-mac-de/","tags":["Linux","Redes","Segurança","Software Livre"],"title":"Alterando O Endereço Mac De Uma Interface No Linux","uri":"/posts/alterando-o-endereco-mac-de/"},{"categories":["Tutoriais"],"content":"Nesta curta dica irei apresentar uma dica simples e rápida de como alterar o endereço MAC de uma interface de rede no Linux. MAC = Media Access Control Assim como nós, seres humanos, possuímos um número de registro físico como o RG, as interfaces de dispositivos de rede também possuem um registro físico que lhes é dedicado já na hora de sua fabricação. Este endereço físico se chama MAC e é formado por 48 bits em forma de hexadecimal. Este protocolo é responsável pelo controle de acesso à rede Ethernet. Um exemplo de endereço MAC seria: 00:A0:D1:58:DF:BC No caso, não existem duas interfaces de rede no mundo com o mesmo endereço MAC. Este valor é único AO SAIR DE FÁBRICA. Mas, como nem tudo na vida são rosas… Existem alguns casos nos quais precisamos identificar, ou mesmo alterar, endereços MAC. Um exemplo de caso em que se é preciso alterar o endereço MAC seria o seguinte: Supondo que eu seja um técnico e estou querendo dar suporte à máquina de um amigo. Este trás sua máquina até minha casa. Minha internet recebe um ip por dhcp de forma amarrada ao meu endereço MAC. Neste caso, para ter acesso à internet pela máquina deste colega para atualizações, eu precisaria momentaneamente alterar o endereço MAC de sua interface de rede. No Linux podemos descobrir qual o endereço MAC de uma interface com o comando ifconfig [interface], como no exemplo a seguir: # ifconfig eth0 Me será retornado um conjunto de informações sobre a interface, incluindo o endereço MAC da mesma, como a seguir: eth0 Link encap:Ethernet HWaddr 00:A0:D1:58:DF:BC inet addr:192.168.1.105 Bcast:192.168.1.255 Mask:255.255.255.0 inet6 addr: fe80::2a0:d1ff:fe58:dfbc/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:54461 errors:0 dropped:0 overruns:0 frame:0 TX packets:46066 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:68669660 (65.4 Mb) TX bytes:5002980 (4.7 Mb) Interrupt:20 Base address:0x4800 O procedimento para se mudar este endereço MAC é: 1- Desabilitar a interface: # ifconfig eth0 down 2- Alterar o MAC: # ifconfig eth0 hw ether XX:XX:XX:XX:XX:XX 3- Subir novamente a interface: # ifconfig eth0 up Simples não?! Feito isto, pode conferir a alteração com o comando ifconfig eth0 novamente. ;] Abraços pessoal… ","date":"2008-12-15","objectID":"/posts/alterando-o-endereco-mac-de/:0:0","tags":["Linux","Redes","Segurança","Software Livre"],"title":"Alterando O Endereço Mac De Uma Interface No Linux","uri":"/posts/alterando-o-endereco-mac-de/"},{"categories":["Impressões"],"content":"Neste romance carregado de dados reais e atualizados sobre um dos maiores mistérios da humanidade, o experiente arqueólogo Jack Howard depara-se com pistas que podem levar à cidade perdida, mencionada ainda na Antiguidade pelo filósofo grego Platão, e que representa a utopia do ideal de sociedade, de harmonia e de fartura. Durante milhares de anos, pesquisadores vêm tentando encontrar Atlântida.","date":"2008-12-08","objectID":"/posts/recomendacao-bibliografica-do-mes-atlantis/","tags":["Impressões","Literatura"],"title":"Recomendação Bibliográfica Do Mês: Atlantis","uri":"/posts/recomendacao-bibliografica-do-mes-atlantis/"},{"categories":["Impressões"],"content":"Em nosso mundo tecnológico o dia parece não ter as mesmas 24 horas das quais as demais pessoas desfrutam. Para os “meros mortais”, pode parecer muitas vezes que nosso dia tem 26 ou até mesmo 28 horas pela quantidade de coisas que fazemos. O que estes “meros mortais” não percebem, é que isto é apenas uma ilusão “idiótica”, restando apenas a verdade de que temos as mesmas “míseras” 24 horas por dia. Tendo tão pouco tempo para fazer tantas coisas, vide trabalho, faculdade, cursos de expansão/especialização, cursos de língua, projetos pessoais, projetos profissionais, família/amigos, lazer, esporte, cultura, etc…, fica complicado administrar e fazer tudo da forma como gostaríamos de fazer. Neste post, gostaria de me focar na falta de tempo para literatura escrita. Sim, nos falta tempo para uma boa leitura de vez em quando. Mesmo com esta falta de tempo, procuro, sempre que possível, estar lendo algum bom livro que não seja sobre tecnologia. O complicado é conseguir 1 hora para me dedicar a leitura, tendo muitas vezes apenas 20/30 minutos por dia para ler, na melhor das hipóteses, já que nem todo dia eu consigo esse tempo. Por isso, muitas vezes levo aproximadamente 1 mês inteiro para ler um único livro. Triste, porém realidade. Sendo assim, resolvi passar a divulgar aqui todo mês a minha escolha atual bem como resumir um pouco a mesma. Este mês optei pelo livro ATLANTIS. “Neste romance carregado de dados reais e atualizados sobre um dos maiores mistérios da humanidade, o experiente arqueólogo Jack Howard depara-se com pistas que podem levar à cidade perdida, mencionada ainda na Antiguidade pelo filósofo grego Platão, e que representa a utopia do ideal de sociedade, de harmonia e de fartura. Durante milhares de anos, pesquisadores vêm tentando encontrar Atlântida. Um dia o arqueólogo marinho Jack Howard e sua equipe tiveram sorte. Enquanto mergulhavam em busca de um naufrágio do tempo de Homero, encontraram ruínas submersas que pareciam ser de Atlântida. Mas a informação vazou e um grupo de terroristas e mercenários fica sabendo que os segredos da Atlântida estavam prestes a ser revelados. Repentinamente, Jack e sua equipe se vêem envolvidos em um jogo de vida e morte. A revelação teria um alto preço.” Esta é a descrição retirada do site www.saraiva.com.br, porém gostaria de lembrar um fato sobre o livro, para não deixar ninguém aqui desprevinido ou me culpando pela recomendação: NÃO COMPRE O LIVRO se você… 1- Não gosta de receber informações em excesso. 2- Não gosta de história, geologia, arqueologia e outras ias… 3- Não tem paciência e quer ver é o enredo em si, ao invés de uma chuva de informações técnicas. Bom, este livro é muito bom, para quem é o oposto do citado acima. Muitos fans de Dan Brown criticaram o livro por esperar que ele seguisse a mesma linha de raciocínio, porém este livro não foi escrito por um escritor literário, mas sim por um arqueólogo, portanto é óbvio que o maior destaque do livro não seria o romance em si, mas sim fatos históricos e científicos. Se você acha que preenche o perfil de leitor para esta obra, realmente recomendo. Abraços ","date":"2008-12-08","objectID":"/posts/recomendacao-bibliografica-do-mes-atlantis/:0:0","tags":["Impressões","Literatura"],"title":"Recomendação Bibliográfica Do Mês: Atlantis","uri":"/posts/recomendacao-bibliografica-do-mes-atlantis/"},{"categories":["Tutoriais"],"content":"Não é de hoje que vejo o nível de alguns pacotes essenciais como o Kernel e o Xorg caírem cada vez mais. É triste porém uma realidade. A maneira como tais pacotes vem sendo lançados sem maiores preocupações está prejudicando a vida de muita gente. Eu fui um deles recentemente ao atualizar o meu Xorg. Para aqueles que também fizeram upgrade recentemente, podem ter aparecido vários problemas.","date":"2008-12-02","objectID":"/posts/resolvendo-alguns-problemas-causados-pelo/","tags":["Arch Linux","Linux","Software Livre"],"title":"Resolvendo Alguns Problemas Causados Pelo Novo Xorg No Arch","uri":"/posts/resolvendo-alguns-problemas-causados-pelo/"},{"categories":["Tutoriais"],"content":"Não é de hoje que vejo o nível de alguns pacotes essenciais como o Kernel e o Xorg caírem cada vez mais. É triste porém uma realidade. A maneira como tais pacotes vem sendo lançados sem maiores preocupações está prejudicando a vida de muita gente. Eu fui um deles recentemente ao atualizar o meu Xorg. Para aqueles que também fizeram upgrade recentemente, podem ter aparecido vários problemas. Aqui apresentarei as soluções que utilizei no ArchLinux para sanar os problemas que me apareceram, sendo eles: 1- O X não subia mais. Simplesmente morria e ficava tudo preto. 2- As teclas especiais do teclado não respondiam mais, como por exemplo as setas direcionais. Vamos às soluções encontradas… 1- O X não sobe mais 1.1- Para este problema, precisei fazer uma pequena busca pelo erro que acontecia, para isso busquei em primeira mão os logs do Xorg. Você pode fazer isso com o seguinte comando: # tail -f /var/log/Xorg.0.log 1.2- Em meu caso, apontou o erro na sintax RgbPath, a qual informava ser incompatível. Muita gente está passando por este problema. A solução neste caso é simples, basta editar o arquivo /etc/X11/xorg.conf e comentar a linha: RgbPath = \"/usr/share/X11/rgb\" 1.3- Ao comentar esta linha, tudo o que fiz foi reinstalar o driver de minha placa de vídeo, para que meu xorg voltasse a funcionar. Como eu utilizo um driver da ATI Radeon que costumo baixar diretamente no site da ATI, segui o procedimento padrão para os drivers baixados do mesmo: 1.3.1- Dar permissão de execução: # chmod +x ati-driver-installer-8-11-x86.x86_64.run 1.3.2- Executar o instalador: # ./ati-driver-installer-8-11-x86.x86_64.run Pronto. Feitos estes passos, eu já conseguia subir meu servidor X numa boa. Com relação ao segundo problema. As teclas… 2- As teclas especiais do teclado não respondem. 2.1- A solução foi simples, bastou uma pequena busca na wiki do ArchLinux com uma dica de como corrigir isto no meu KDE4. Indo para as configurações do sistema e partindo para a configuração de “Regional \u0026 Idioma”. Lá busque a aba “Layout de Teclado”. 2.2- Nesta você precisará habilitar a opção “Habilitar Layouts de Teclado” e selecionar como Modelo de Teclado a opção “Evdev-managed keyboard”. Feito isto, as teclas voltaram a funcionar no meu caso bem como outras pessoas que também testaram. ","date":"2008-12-02","objectID":"/posts/resolvendo-alguns-problemas-causados-pelo/:0:0","tags":["Arch Linux","Linux","Software Livre"],"title":"Resolvendo Alguns Problemas Causados Pelo Novo Xorg No Arch","uri":"/posts/resolvendo-alguns-problemas-causados-pelo/"},{"categories":["Impressões"],"content":"Não é hora de postar sobre Software Livre ou Tecnologia como um todo. Gostaria de dedicar este post ao cenário que estamos presenciando em Santa Catarina, ou melhor, NO BRASIL.","date":"2008-11-28","objectID":"/posts/santa-catarina-precisa-de-voce/","tags":["Impressões"],"title":"Santa Catarina Precisa De Você","uri":"/posts/santa-catarina-precisa-de-voce/"},{"categories":["Impressões"],"content":"Olá pessoal.. Não é hora de postar sobre Software Livre ou Tecnologia como um todo. Gostaria de dedicar este post ao cenário que estamos presenciando em Santa Catarina, ou melhor, NO BRASIL. Em momentos como este pode parecer fácil dar às costas por não estar acontecendo em seu Estado, porém é em seu PAÍS. O seu país pede sua ajuda e você pode colaborar. Segue um trexo de um post que achei de uma catarinese, sobre a visão dela em relação ao que anda acontecendo e sobre como a mídia está abordando o assunto. Para quem não sabe, eu sou catarinense, mais precisamente de Blumenau. Para quem andou em Marte nos últimos dias e não viu a tragédia que se abalou sobre o nosso estado, não se preocupe, a mídia não está repassando todas as informações então você não está tão alienado quanto pensa. O fato é seguinte: a situação não é apenas calamitosa, é desesperadora. Eu vejo na televisão eles falarem “enchente”, “enchente”, “enchente”, o que aconteceu aqui não foi apenas uma enchente. As enchentes do Vale do Itajaí acontecem quando as chuvas enchem o Vale à partir dos munícipios de Taió e Rio do Sul. Então o sistema de contenção de cheias é ativado e as barragens localizadas nesses municipíos são fechadas, impedindo que a água venha toda de uma vez e inunde as cidades abaixo. Desta vez não houve chuva em Taió e Rio do Sul. Foi apenas uma enorme chuva na região de Blumenau, Gaspar, Luis Alves e Rodeio. Tanta chuva (900 milímetros) que o rio não conseguiu dar vazão para as águas que desciam dos morros e encheu 11,9 metros. Teria sido apenas uma enxurrada com enchente que afetaria algumas pessoas se não fosse um detalhe: chovia em SC desde agosto praticamente todos os dias. Quem me conhece sabe como eu reclamava disso e inclusive colocava nos posts aqui do LJ “Chuvamenau”. Tanta chuva já tinha deixado o solo enxarcado. Aqui entra a questão geográfica que as televisões e grandes sites da internet não são capazes de compreender. Como o nome diz: Vale do Itajaí é um vale (ohhhh), ou seja, como um vale é cercado de morros por todos os lados (ohhhh) vide uma vista de Blumenau AQUI. Como se pode ver pela foto: há morros. Muitos morros. A cidade inteira é repleta de morros. Você necessariamente tem que passar de um morro a outro, e a outro, e a outro para chegar em algum lugar. Acontece que com tanta chuva (desde agosto) estes morros estão caindo. Todos eles estão desabando, derretendo feito sorvete em dia de verão de 40ºC. Não há um morro sequer sem deslizamento de terras. A maioria destes morros NÃO sofreram ocupação irregular como a mídia diz. Claro que um e outro sofria desse mal, mas na maioria deles as casas estavam legalizadas, eram terrenos seguros. Tenho conhecidos que perderam tudo. Simplesmente tudo. A casa virou gravetos no chão junto com toda a mobília e o terreno. Nem o terreno ficou. Tem morros sendo completamente interditados porque possuem rachaduras do topo até a base, estão cortados ao meio. A cidade está de fato desabando sobre nossas cabeças. Tem pessoas isoladas devido as quedas de barreiras. Uma das quatro estações de tratamento de água da cidade está sobterrada e o número de mortos divulgados não é o verdadeiro, eles estão omitindo mortes para não aumentar o pânico que se instaurou na cidade. A situação de fato é de pânico. Principalmente porque não há previsão de que pare de chover. Santa Catarina pede ajuda, mas nem sabe por onde começar, o que fazer se tudo começa a desabar ao seu redor? O que fazer quando você sai da sua rua e vê dezenas de famílias descendo um dos morros, carregando tudo o que podem para um abrigo porque a Defesa Civil simplesmente diz que “O local está totalmente condenado”. O que fazer quando as pessoas neste abrigo tem que sair de lá porque até o abrigo passou a estar condenado? As lágrimas caem de pesar pela dor das pessoas que perderam tudo, pela dor das pessoas que perderam entes queridos e principalmente, pela dor das pessoas que não conseguem encontrar seus famíliares. Vinte mortos? Saber que um","date":"2008-11-28","objectID":"/posts/santa-catarina-precisa-de-voce/:0:0","tags":["Impressões"],"title":"Santa Catarina Precisa De Você","uri":"/posts/santa-catarina-precisa-de-voce/"},{"categories":["Impressões"],"content":"Além de excelente linguagem de programação o Python ainda é Zen. Não acredita? Que tal conferir por si só as diretrizes Zen do Python?","date":"2008-11-24","objectID":"/posts/the-zen-of-python/","tags":["Arch Linux","Impressões","Linux","Python","Software Livre"],"title":"the Zen of Python","uri":"/posts/the-zen-of-python/"},{"categories":["Impressões"],"content":"É isso mesmo… Além de excelente linguagem de programação o Python ainda é Zen. Não acredita? Que tal conferir por si só as diretrizes Zen do Python? Aproximadamente todas as distribuições Linux trazem um interpretador python instalado, portanto basta executá-lo com o seguinte comando: $ python Você receberá como resposta algo como o exemplo a seguir: [kalib@tuxcaverna ~]$ python Python 2.6 (r26:66714, Oct 27 2008, 10:50:31) [GCC 4.3.2] on linux2 Type “help”, “copyright”, “credits” or “license” for more information. »\u003e Agora execute o seguinte: import this Como resultado você terá o Zen do Python, como pode ser visto abaixo: import this The Zen of Python, by Tim Peters Beautiful is better than ugly. Explicit is better than implicit. Simple is better than complex. Complex is better than complicated. Flat is better than nested. Sparse is better than dense. Readability counts. Special cases aren’t special enough to break the rules. Although practicality beats purity. Errors should never pass silently. Unless explicitly silenced. In the face of ambiguity, refuse the temptation to guess. There should be one– and preferably only one –obvious way to do it. Although that way may not be obvious at first unless you’re Dutch. Now is better than never. Although never is often better than right now. If the implementation is hard to explain, it’s a bad idea. If the implementation is easy to explain, it may be a good idea. Namespaces are one honking great idea – let’s do more of those! Para sair do interpretador Python, pressionde as teclas Ctrl + D. Abraços ","date":"2008-11-24","objectID":"/posts/the-zen-of-python/:0:0","tags":["Arch Linux","Impressões","Linux","Python","Software Livre"],"title":"the Zen of Python","uri":"/posts/the-zen-of-python/"},{"categories":["Impressões"],"content":"Muitos me perguntam sobre as vantagens do Python e o porque de, dentre tantas linguagens de programação, eu optei por ter o python como minha paixão oficial. Para evitar dar várias respostas à diferentes pessoas, resolvi compilar aqui alguns dos motivos que encontrei e que em minhas pesquisas iniciais me motivaram a escolher o Python como minha linguagem favorita.","date":"2008-11-20","objectID":"/posts/porque-python/","tags":["Impressões","Python","Software Livre"],"title":"Porquê Python","uri":"/posts/porque-python/"},{"categories":["Impressões"],"content":"Muitos me perguntam sobre as vantagens do Python e o porque de, dentre tantas linguagens de programação, eu optei por ter o python como minha paixão oficial. Para evitar dar várias respostas à diferentes pessoas, resolvi compilar aqui alguns dos motivos que encontrei e que em minhas pesquisas iniciais me motivaram a escolher o Python como minha linguagem favorita. Comecemos então pelas origens do Python. A linguagem foi criada em 1989 pelo holandês Guido van Rossum em Amsterdã. Influenciada pela linguagem ABC, desenvolvida no CWI por Guido e outros nas décadas de 70 e 80. ABC tinha um foco bem definido: ser uma linguagem de programação para usuários inteligentes de computadores que não eram programadores: Físicos, Cientistas Sociais, dentre outros. O projeto de sistema operacional distribuído da época, o Amoeba, precisava de uma linguagem de script. Eis que surge então o Python, trazendo como sua base os seguintes aspectos: Elementos que eram bem sucedidos no ABC. Estruturas de dados poderosas inclusas: Listas, Dicionários, Strings, etc.. Usar indentação para delimitar blocos, eliminando chaves. (Eu adoro isso! :p) Fácil extensão (lição aprendida com os erros do ABC) Fácil de portar: além do Amoeba, também era desejado que ele rodasse em Unix, Macintosh e Windows. Influências de Modula-2 e Modula-3: módulos e namespaces Além destes aspectos o python teve alguns “favorecimentos” durante sua criação. Alguns detalhes que contribuíram para sua concepção de sucesso foram: Universidade: pessoas altamente especializadas para desenvolver e opinar os elementos do projeto Descontraído: o nome Python vem da série de humor Monty Python’s Flying Circus Sem prazos, Sem pressão: o desenvolvimento não foi pressionado por estratégias de marketing, prazos, clientes ou qualquer outro fator que pudesse influenciar nas decisões de projeto, resultando em maior qualidade. Software Livre: garante a vida da tecnologia Dentre as características do Python que mais me chamaram à atenção, estão as seguintes: Simplicidade: Python é uma linguagem muito simples. Interpretada: usa máquina virtual, facilita portabilidade. Interativa: pode-se programar interativamente, os comandos são executados enquanto digitados. Facilita testes, desenvolvimento ágil e outros. Orientada a Objetos: Tudo é objeto. Incluindo herança múltipla, conceito apenas parcialmente presente em Java até então. Exceções: Um moderno mecanismo para o tratamento de erros. Coleta de lixo automática: Sistema que elimina os erros causados pelo acúmulo de dados inúteis na memória do computador. Fortemente Tipada: Não existe casts e nem conversão automática. Não se mistura tipos “automagicamente”. :p Tipagem Dinâmica: A tipagem de um objeto é feita em tempo de execução. Um objeto tem tipo, uma variável não. Portabilidade: Portável para diversas arquiteturas como: Unix, Linux, BSD, Macintosh, Solaris, Windows, OS/2, Amiga, AROS, AS/400, BeOS, QNX, Palm OS, VMS, Psion, Acom Risc OS, PlayStation, Sharp Zaurus, Windows CE, PocketPC, etc. Quer mais o que??? Extensível: Facilmente extensível caso deseje parte do seu código em C++ por exemplo por algum motivo. Quer mais? o.O E para os que se perguntam: Python é realmente utilizado por aí? Quem usa? Vejamos…. No Brasil: Embratel: monitoramento das interfaces de backbone e clientes de internet, também existem scripts de uso interno. CPqD: monitoramento de centrais telefônicas. Conectiva (Mandriva): Gerenciamento de pacotes da distribuição Linux e ferramentas de uso interno. Async: desenvolvimento de software de automação comercial. GPr Sistemas: Desenvolvimento de aplicações sob encomenda, sistemas como monitoramento de transporte terrestre via satélite são as soluções já feitas. Outras que também utilizam Python para sistemas web, como: Varig, Serpro, Câmara, Interligis, etc. E no mundo a fora: Industrial Light \u0026 Magic: automação interna: “Sem o Python um projeto do tamanho do Star Wars: Epsódio II, seria muito difícil de sair pronto.” NASA: Repositório de ","date":"2008-11-20","objectID":"/posts/porque-python/:0:0","tags":["Impressões","Python","Software Livre"],"title":"Porquê Python","uri":"/posts/porque-python/"},{"categories":["Eventos"],"content":"O CearáOnRails é um evento solidário que tem como tema o desenvolvimento de sistemas web e pretende divulgar e popularizar a linguagem de desenvolvimento Ruby e o Framework Rails no estado do Ceará. Esta iniciativa contribuirá de modo relevante para promover o uso e a difusão das tecnologias entre pessoas, especialmente profissionais na área e afins, servindo como um veículo de integração, interação e colaboração. Tanto o ruby como o Rails vem mudando a forma de desenvolvimento padrão adotada pelas demais tecnologias.","date":"2008-11-12","objectID":"/posts/ceara-on-rails-ai-vou/","tags":["Impressões","Ruby","Software Livre"],"title":"Ceará on Rails Aí Vou Eu","uri":"/posts/ceara-on-rails-ai-vou/"},{"categories":["Eventos"],"content":"O que é CearáOnRails? ","date":"2008-11-12","objectID":"/posts/ceara-on-rails-ai-vou/:0:0","tags":["Impressões","Ruby","Software Livre"],"title":"Ceará on Rails Aí Vou Eu","uri":"/posts/ceara-on-rails-ai-vou/"},{"categories":["Eventos"],"content":"Introdução O CearáOnRails é um evento solidário que tem como tema o desenvolvimento de sistemas web e pretende divulgar e popularizar a linguagem de desenvolvimento Ruby e o Framework Rails no estado do Ceará. Esta iniciativa contribuirá de modo relevante para promover o uso e a difusão das tecnologias entre pessoas, especialmente profissionais na área e afins, servindo como um veículo de integração, interação e colaboração. Tanto o ruby como o Rails vem mudando a forma de desenvolvimento padrão adotada pelas demais tecnologias. A linguagem Ruby foi criada em 1993 no Japão pelo Yukihiro Matsumoto. Esta só se tornou popular após a primeira apresentação do Framework Rails em 2003 criado por David Heinemeir Hansson, a sua apresentação foi bastante polêmica e mudou a visão sobre a metodologia de desenvolvimento de software. O nosso intuito é apresentar esta nova forma de desenvolver software e quanto ela é poderosa, rápida e produtiva. Com isso tentar mudar a visão atual de desenvolvimento de software na região, ou a implantação dessa nova tecnologia. O ingresso será de 2kgs de alimentos não perecíveis por pessoa (exceto sal) em troca do acesso às palestras. Iremos doar os alimentos arrecadados para a ONG 2A(Acreditando e Aprendendo). O evento além de sua função social e integradora, também permite uma grande difusão da tecnologia e ainda oportuniza o network entre profissionais, estudantes, professores entre outros, que irão comparecer ao evento. ","date":"2008-11-12","objectID":"/posts/ceara-on-rails-ai-vou/:1:0","tags":["Impressões","Ruby","Software Livre"],"title":"Ceará on Rails Aí Vou Eu","uri":"/posts/ceara-on-rails-ai-vou/"},{"categories":["Eventos"],"content":"Realização do CearaOnRails O evento será realizado no dia 14 de Novembro de 2008 das 19:00 às 22:30 horas. Na Faculdade Christus, Avenida Dom Luís, 911, Fortaleza-Ce, no 15º Andar, em Fortaleza-Ceará. A programação prévia estabelecida pela organização será a seguinte: ","date":"2008-11-12","objectID":"/posts/ceara-on-rails-ai-vou/:2:0","tags":["Impressões","Ruby","Software Livre"],"title":"Ceará on Rails Aí Vou Eu","uri":"/posts/ceara-on-rails-ai-vou/"},{"categories":["Eventos"],"content":"Programação 19:00-19:10 Abertura 19:10-19:40 Palestra 1 Palestrante: Tiago Bastos Tema: Onde está o método? Descrição: Uma introdução a recursos avançados da linguagem. Explicando como interceptar chamadas à métodos, monkey patching e avaliação de código. Mercado de trabalho. 19:40-20:40 Palestra 2 Palestrante: Nabucodonosor Coutinho Tema: ORM On Rails Descrição: A camada de persistência do ROR está realmente nos trilhos? A visão de um DBA sobre a camada de persistência do Rails. Analise dos padrões DAO e ActiveRecord. Análise das implementações ActiveRecord e iBatis para Ruby. Análise das implementações Rails ActiveRecord e Hibernate (java). 20:40-21:00 Coffee Break 21:00-22:00 Palestra 3 Palestrante: Fábio Akita Tema: Desenvolvimento fora da Média com Ruby e Rails Descrição: Porque é importante entender as novas tecnologias como Ruby e Rails e como elas agilizam seus projetos web. ","date":"2008-11-12","objectID":"/posts/ceara-on-rails-ai-vou/:3:0","tags":["Impressões","Ruby","Software Livre"],"title":"Ceará on Rails Aí Vou Eu","uri":"/posts/ceara-on-rails-ai-vou/"},{"categories":["Aleatórios"],"content":"Neste post eu deixo a dica de uma loja online na qual você pode encontrar diversos produtos bacanas do Arch Linux. Produtos estes que vão desde camisetas até mesmo shapes de skates ou aventais.","date":"2008-11-10","objectID":"/posts/arch-linux-schwag-uma-loja/","tags":["Arch Linux","Impressões","Linux","Software Livre"],"title":"Arch Linux Schwag - Uma Loja Para O Arch Linux","uri":"/posts/arch-linux-schwag-uma-loja/"},{"categories":["Aleatórios"],"content":"Neste post eu deixo a dica de uma loja online na qual você pode encontrar diversos produtos bacanas do Arch Linux. Produtos estes que vão desde camisetas até mesmo shapes de skates ou aventais (é mole?). O comércio eletrônico vem crescendo a cada dia e ganhando cada vez mais adeptos por sua confiabilidade, agilidade e eficiência, isto tudo sem mencionar o conforto de navegar em shoppings e lojas sem sair de sua cadeira ou poltrona favorita. A comodidade em não perder horas de caminhada ou esperando em filas para atendimento tem atraído cada vez mais clientes para este tipo de comércio. Eu sou um grande adepto de comércio eletrônico e pelo menos uma vez por mês faço algum tipo de compra online sendo os livros os responsáveis pela minha maior parcela destas compras via web. Aproveito para deixar aqui o link para esta incrível loja com produtos do Arch Linux e de outras várias coisas que desejar. Apesar de ser uma loja gringa, vale a pena conferir. Segue Link: Zazzle Archlinux Abraços ","date":"2008-11-10","objectID":"/posts/arch-linux-schwag-uma-loja/:0:0","tags":["Arch Linux","Impressões","Linux","Software Livre"],"title":"Arch Linux Schwag - Uma Loja Para O Arch Linux","uri":"/posts/arch-linux-schwag-uma-loja/"},{"categories":["Impressões"],"content":"Os usuários de Arch Linux, pelo menos alguns deles, talvez já saibam que o Sun Java Runtime Environment (JRE) e o Java Development Kit (JDK) tem passado muito tempo no repositório Extra esperando por algum amor extra. Entretanto, nenhum desenvolvedor se sentiu motivado à manter este pacote.","date":"2008-11-04","objectID":"/posts/java-no-arch-comeca-a/","tags":["Arch Linux","Impressões","Java","Linux","Software Livre"],"title":"Java No Arch Começa a Ser Mais Livre","uri":"/posts/java-no-arch-comeca-a/"},{"categories":["Impressões"],"content":"Os usuários de Arch Linux, pelo menos alguns deles, talvez já saibam que o Sun Java Runtime Environment (JRE) e o Java Development Kit (JDK) tem passado muito tempo no repositório Extra esperando por algum amor extra. Entretanto, nenhum desenvolvedor se sentiu motivado à manter este pacote. Por outro lado, não é novidade que já existe o pacote OPENJDK6, uma implementação open source da JRE e da JDK que funciona perfeitamente bem. Foi decidido mover os pacotes JRE e JDK para o repositório Community, onde Geoffroy Carrier estará tomando conta deles. Ele já até atualizou os pacotes e corrigiu alguns bugs pendentes. Obrigado Geoffroy por sua boa ação. Nenhum pacote dos repositórios oficiais do Arch Linux depende destes pacotes no momento, já que os mesmos já foram recompilados para o OPENJDK6. Entretanto, é bom agradecer à comunidade por entender, e os desenvolvedores que se desculpam por qualquer inconveniente que possa vir a surgir. O mais interessante em meu ver, é o fato de o Arch estar baixando o nível de prioridade destes pacotes, elevando assim a prioridade dos pacotes livres do java em seu lugar. Isto sim é show de bola. Parabéns Arch Linux! ;] Porque movê-los, além da razão já abordada aqui? Bem, nós pretendemos favorecer implementações de código aberto ao invés de implementações de código fechado. Não, sério, porque vocês mudaram eles? Porque o Aaron Griffin disse que o fizesse. :-D (apenas brincando)\" Abraços ","date":"2008-11-04","objectID":"/posts/java-no-arch-comeca-a/:0:0","tags":["Arch Linux","Impressões","Java","Linux","Software Livre"],"title":"Java No Arch Começa a Ser Mais Livre","uri":"/posts/java-no-arch-comeca-a/"},{"categories":["Aleatórios"],"content":"Muitos aqui já conheciam o sistema Linux Counter que servia para contabilizar e registrar usuários Linux como forma de documentar e ter controles estatísticos do crescimento da comunidade Linux mundial. Agora chegou a vez do Asterisk.","date":"2008-10-27","objectID":"/posts/asterisk-counter-seja-contado/","tags":["Asterisk","Linux","Software Livre"],"title":"Asterisk Counter - Seja Contado","uri":"/posts/asterisk-counter-seja-contado/"},{"categories":["Aleatórios"],"content":"Saudações pessoal… Muitos aqui já conheciam o sistema Linux Counter que servia para contabilizar e registrar usuários Linux como forma de documentar e ter controles estatísticos do crescimento da comunidade Linux mundial. Agora chegou a vez do Asterisk. Recentemente foi disponibilizado o Asterisk Counter. O mesmo consiste não apenas em contabilizar os usuários/profissionais de Asterisk como também estabelecer perfis que podem ser inclusive votados com comentários, como uma mini rede social (profissional) no assunto com referências vindas de outros usuários e assim por diante. Segue a dica para você que utiliza ou trabalha com esta excelente tecnologia Livre de Voip. Eu sou o usuário de número 1148, e você? ;] Abraços ","date":"2008-10-27","objectID":"/posts/asterisk-counter-seja-contado/:0:0","tags":["Asterisk","Linux","Software Livre"],"title":"Asterisk Counter - Seja Contado","uri":"/posts/asterisk-counter-seja-contado/"},{"categories":["Tutoriais"],"content":"No Linux sabemos que tudo é um arquivo. Nada depende exclusivamente de extensão ou tipo. Até mesmo os famosos diretórios na verdade não passam de arquivos. O que mostrarei aqui é uma dica rápida e simples de como se aproveitar disto para ocultar de forma simples e rápida alguma informação de texto em um arquivo binário qualquer que o seja. Por mais incrível que possa parecer, não precisaremos de nenhuma mágica ou ferramenta especial para isto. Quem utiliza Linux sabe que o cat ou mesmo o echo são ferramentas padrão em qualquer distribuição. SIM. Precisaremos apenas delas para fazer o truque. Não acredita?","date":"2008-10-24","objectID":"/posts/escondendo-informacoes-em-arquivos-binarios/","tags":["Arch Linux","Cultura Hacker","Linux","Segurança","Software Livre"],"title":"Escondendo Informações Em Arquivos Binários","uri":"/posts/escondendo-informacoes-em-arquivos-binarios/"},{"categories":["Tutoriais"],"content":"Saudações galera… Recentemente um amigo, Michel, me perguntou algo sobre a possibilidade de ocultar informações em arquivos binários, como uma música ou mesmo uma foto. Eu lhe respondi que era possível, e bem simples em termos de conceito, bem como lhe prometi postar esta dica. No Linux sabemos que tudo é um arquivo. Nada depende exclusivamente de extensão ou tipo. Até mesmo os famosos “diretórios” na verdade não passam de arquivos. O que mostrarei aqui é uma dica rápida e simples de como se aproveitar disto para ocultar de forma simples e rápida alguma informação de texto em um arquivo binário qualquer que o seja. Por mais incrível que possa parecer, não precisaremos de nenhuma mágica ou ferramenta especial para isto. Quem utiliza Linux sabe que o cat ou mesmo o echo são ferramentas padrão em qualquer distribuição. SIM. Precisaremos apenas delas para fazer o “truque”. Não acredita? o.O Vamos lá… Antes de mais nada selecione o arquivo que será utilizado para “camuflar” nossa informação. Escolha uma imagem qualquer por exemplo ou outro tipo como áudio, vídeo, compactado, etc… Supondo que você escolheu o arquivo foto.jpg, passaremos ao segundo passo. Supondo que eu queira ocultar a frase “Bem vindo ao Linux” na foto.jpg, o comando seria o seguinte: $ echo \"Bem vindo ao Linux\" \u003e\u003e foto.jpg Simples não é?! Nada de truques ou mágicas. Pode tentar abrir a foto com algum editor de imagens como o Gimp, ou mesmo com um vizualizador de sua preferência. A foto parecerá intacta e normal. Agora tente executá-la com um editor de textes como o cat por exemplo. $ cat foto.jpg Você verá um conjunto de caracteres estranhos, dados sobre a foto em si, porém role até o final do arquivo. Depois de todos os caracteres estranhos, você encontrará a informação que ocultou anteriormente, no nosso caso é a frase “Bem Vindo ao Linux”. Simples não é? Lembrando que o mesmo conceito se aplica caso você deseje utilizar ao invés de uma única frase, todo um texto. Crie o texto com um editor de textos qualquer como o vim por exemplo e salve com o nome texto. Em seguida aplique o comando utilizando desta vez o cat, ao invés do echo: $ cat texto \u003e\u003e foto.jpg Volte a repetir os testes já citados anteriormente para ter certeza do sucesso no processo. Como eu disse..tudo muito simples e sem mistérios. Respondido Michel? ;] Abraço pessoal ","date":"2008-10-24","objectID":"/posts/escondendo-informacoes-em-arquivos-binarios/:0:0","tags":["Arch Linux","Cultura Hacker","Linux","Segurança","Software Livre"],"title":"Escondendo Informações Em Arquivos Binários","uri":"/posts/escondendo-informacoes-em-arquivos-binarios/"},{"categories":["Impressões"],"content":"Não sei até que ponto nossa cidade vai chegar. Não poder mais nem assistir um filme no shopping é um absurdo!","date":"2008-10-20","objectID":"/posts/assalto-no-cinema-do-iguatemifortaleza/","tags":["Impressões"],"title":"Assalto No Cinema Do Iguatemi/fortaleza","uri":"/posts/assalto-no-cinema-do-iguatemifortaleza/"},{"categories":["Impressões"],"content":"Fato ou ficção? Não sei até que ponto nossa cidade vai chegar. Não poder mais nem assistir um filme no shopping é um absurdo! Não gostaria de vincular este tipo de notícia em meu blog, porém é a terceira vez nas últimas duas semanas que recebo emails com relatos das vítimas deste tipo de ataque. E como acho que já está indo longe demais, acho que é válido divulgar isto para que as pessoas fiquem espertas sobre o que anda acontecendo. Este é o relato da última vítima: INDIGNAÇÃO!!! Na tarde de sábado passado, estava passeando, no Shopping Iguatemi, com a minha namorada, quando decidimos pegar um cineminha. Quando entramos na sala, percebemos que havia muitas crianças com seus pais e um grupo de 7 ou 8 rapazes, aparentando uns 18 anos, de bonés e óculos escuros, encostados em uma parede do corredor lateral. Fomos sentar em uma fileira de poltronas, no meio da sala; pouco depois, começaram a exibir os trailers. Minutos após começar o filme, um dos rapazes que estava em pé, sentou-se ao lado da minha namorada, sacou um revólver e disse que era para ela ficar quieta, senão ele iria atirar. Muito assustada, ela começou a chorar. Quando eu percebi o que estava acontecendo, já estava se sentando, na poltrona ao meu lado, um outro rapaz do grupo, anunciando que era um assalto e que ele estava armado. Eles me levaram para fora do cinema, enquanto outros dois elementos da gangue ficaram com a minha namorada, dentro da sala de projeção. Fui obrigado a sacar todo o dinheiro que foi possível, nos caixas 24hs do shopping, e tive que comprar 6 pares de tênis de quase $500,00, cada um, numa loja de artigos esportivos, usando meu cartão de crédito, até acabar meu limite. Uns 40 minutos depois, voltamos para o cinema e foi a vez de fazerem a mesma coisa com a minha namorada. Pouco antes de acabar o filme, os que estavam comigo me mandaram sair do cinema. Quando saí, me levaram até o estacionamento, onde já estava a minha namorada com os outros da gangue. Fizeram com que eu os levasse até o meu carro, nos colocaram dentro dele e terminaram de roubar as coisas que faltavam, como celulares, relógios, etc. Mandaram que eu dirigisse para fora do shopping, com três bandidos dentro do carro, e seguisse um outro carro, onde estava o restante da gangue. Ficamos dando voltas de carro, até escurecer; depois nos libertaram, em um matagal. Tivemos que andar descalços, em uma estrada de terra, durante muito tempo; acho que por mais de 2 horas, até acharmos um sítio, de onde pude ligar para meu pai e pedir para que ele nos apanhasse. No dia seguinte, acharam meu carro todo batido, sem os equipamentos de som, CD e outros acessórios. Quando estava na delegacia, prestando queixa, o delegado falou que já ocorreram mais de cinco assaltos como este, no mês passado. O pior é que as câmeras do circuito interno de TV do shopping não estavam funcionando, para tentarmos obter algumas imagens dos assaltantes. De qualquer forma, quando for ao cinema, atenção com as pessoas que sentam ao seu lado, especialmente se o cinema não estiver lotado ou se existirem muitas poltronas vazias por perto; se virem grupos parados,pelos cantos, tomem muito cuidado. Vale a pena levantar e avisar aos funcionários do cinema que há um grupo suspeito, em pé, esperando as luzes se apagarem, para, talvez, assaltarem os espectadores. Os funcionários têm recursos para avisar a vigilância do Shopping e a Polícia. Abraços ","date":"2008-10-20","objectID":"/posts/assalto-no-cinema-do-iguatemifortaleza/:0:0","tags":["Impressões"],"title":"Assalto No Cinema Do Iguatemi/fortaleza","uri":"/posts/assalto-no-cinema-do-iguatemifortaleza/"},{"categories":["Impressões"],"content":"Hoje, 19/10, foi lançado no repositório Extra do Archlinux o flashplugin 10. Este flash veio com a promessa de resolver o problema de transparência que nós, usuários Linux, tínhamos com muitos sites que utilizavam-se de flash. Quem aqui nunca teve dor de cabeça ao tentar navegar em sites como o da OI por exemplo? o.O Era impossível.","date":"2008-10-19","objectID":"/posts/nossos-problemas-com-flash-acabaram/","tags":["Arch Linux","Impressões","Linux","Software Livre"],"title":"Nossos Problemas Com Flash Acabaram - Flash 10 No Extra","uri":"/posts/nossos-problemas-com-flash-acabaram/"},{"categories":["Impressões"],"content":"Hoje, 19/10, foi lançado no repositório Extra do Archlinux o flashplugin 10. Este flash veio com a promessa de resolver o problema de transparência que nós, usuários Linux, tínhamos com muitos sites que utilizavam-se de flash. Quem aqui nunca teve dor de cabeça ao tentar navegar em sites como o da OI por exemplo? o.O Era impossível. Hoje pela manhã, ao mandar um pacman -Syu para atualizar meu sistema, tive a felicidade de ver que havia a atualização do flash. Já fui logo atualizando. Em seguida corri para o site da OI. Para minha surpresa, FUNCIONOU PERFEITAMENTE! Uma benção! Parece que os nossos problemas com flash acabaram! Fica o aviso para todos os usuários de Archlinux: Esta atualização já se encontra no nosso repositório Extra. Atualizem o quanto antes. Grande abraço ","date":"2008-10-19","objectID":"/posts/nossos-problemas-com-flash-acabaram/:0:0","tags":["Arch Linux","Impressões","Linux","Software Livre"],"title":"Nossos Problemas Com Flash Acabaram - Flash 10 No Extra","uri":"/posts/nossos-problemas-com-flash-acabaram/"},{"categories":["Aleatórios"],"content":"Finalmente tenho o prazer de anunciar que a Operadora Vivo chegou a Fortaleza. Finalmente uma operadora decente em nossa cidade. Ontem, 16 de Outubro, começaram as vendas resultando em mais de 25.000 chips vendidos em um dia. Não perdi a oportunidade e comprei o meu ontem mesmo. O que foi engraçado ver a confiança que os vendedores tinham em afirmar: “Aqui não é negócio apenas de ‘Olá’! A vivo chegou para derrubar tudo!” Apesar de ter achado um pouco audacioso demais, não duvido que ela conquiste rapidamente boa parte do mercado local, já que a vivo é portadora de uma estrutura bem melhor que a das concorrentes. Além das vantagens estruturais, a vivo trouxe um outro grande atrativo em seu lançamento no Ceará com a promoção dos 1000. Com recargas mensais a partir de 6 reais, o cliente ganha: 1000 reais para falar com outros vivos. (ligações locais) 100 minutos para falar com outros vivos. (DDD) 25 sms/15 dias … Dentre outras vantagens. Outra coisa que me surpreendeu foi o site deles bem como os recursos ofertados ao se fazer login com os dados de seu número. Vale a pena conferir. ","date":"2008-10-16","objectID":"/posts/vivo-chega-em-fortaleza-finalmente/:0:0","tags":["Impressões"],"title":"Vivo Chega Em Fortaleza, Finalmente","uri":"/posts/vivo-chega-em-fortaleza-finalmente/"},{"categories":["Impressões"],"content":"Conforme apresentei no post passado, o BR-Linux estava fazendo uma pesquisa para saber quais distribuições deveria indicar. Antes mesmo de ver as respostas, tinha plena certeza de que o Ubuntu estaria com uma grande quantidade de votos, afinal de contas foi e é uma das distribuições que mais divulgou o nome do Linux nos últimos anos por ser mais amigável para desktops de usuários que terão o primeiro contato com linux.","date":"2008-10-10","objectID":"/posts/resultado-quais-distribuicoes-o-br/","tags":["Arch Linux","Impressões","Linux","Software Livre"],"title":"Resultado: Quais Distribuicões O Br-Linux Deve Indicar","uri":"/posts/resultado-quais-distribuicoes-o-br/"},{"categories":["Impressões"],"content":"Conforme apresentei no post passado, o BR-Linux estava fazendo uma pesquisa para saber quais distribuições deveria indicar. Antes mesmo de ver as respostas, tinha plena certeza de que o Ubuntu estaria com uma grande quantidade de votos, afinal de contas foi e é uma das distribuições que mais divulgou o nome do Linux nos últimos anos por ser mais “amigável” para desktops de usuários que terão o primeiro contato com linux. Bom, isto de fato se mostrou verdade na pesquisa, porém o que mais me chamou a atenção foi o fato de que o Arch Linux, superando minhas expectativas, se saiu muito bem na pesquisa, deixando grandes distribuições para trás. Este resultado apenas demonstra o que muitos de nós já estávamos percebendo: O Arch vem ganhando maior força em nosso país. Este resultado não é apenas fruto de publicidade, mas também da qualidade da distribuição em si bem como o trabalho que a comunidade Archlinux-br vem desenvolvendo no quesito de suporte, documentações, traduções dentre outras formas de auxiliar os novos usuários. Abaixo segue um resultado aproximado da pesquisa feita no BR-Linux, até o dia de hoje: Ubuntu - 36 votos Mandriva - 31 votos Arch Linux - 15 votos Big Linux - 10 votos Fedora - 8 votos Debian - 6 votos Kurumin NG - 6 votos Opensuse - 3 votos Kubuntu - 3 votos Slackware - 2 votos Goblinx - 2 votos Linux From Scratch - 2 votos Resulinux - 1 votos Zenwalk - 1 votos Gnomux - 1 votos PCLinuxOS - 1 votos Sabayon - 1 votos Ultimate Edition - 1 votos Linux Mint - 1 votos Abraços ","date":"2008-10-10","objectID":"/posts/resultado-quais-distribuicoes-o-br/:0:0","tags":["Arch Linux","Impressões","Linux","Software Livre"],"title":"Resultado: Quais Distribuicões O Br-Linux Deve Indicar","uri":"/posts/resultado-quais-distribuicoes-o-br/"},{"categories":["Eventos"],"content":"Para aqueles que não conhecem, a Tux-CE é uma Comunidade Cearense de Software Livre que fundei com alguns amigos no ano de 2006. Desde então, a Tux-CE se mostra atuante na participação de eventos locais de Software Livre, bem como organização de alguns deles.","date":"2008-09-29","objectID":"/posts/fotos-do-v-campeonato-intergalatico/","tags":["Software Livre","Tux-ce"],"title":"Fotos Do V Campeonato Intergalático De Boliche Da Tux-Ce","uri":"/posts/fotos-do-v-campeonato-intergalatico/"},{"categories":["Eventos"],"content":"Para aqueles que não conhecem, a Tux-CE é uma Comunidade Cearense de Software Livre que fundei com alguns amigos no ano de 2006. Desde então, a Tux-CE se mostra atuante na participação de eventos locais de Software Livre, bem como organização de alguns deles. Além dos eventos e assuntos relacionados a tecnologia, a Tux-CE ainda conta com momentos de descontração, como por exemplo o nosso já tradicional campeonato de boliche. Tivemos recentemente nosso V Campeonato. Foi bastante divertido e proveitoso. Pudemos desfrutar de um ambiente amigável com a interação entre os presentes bem como um bate papo que foi além da tecnologia em si. Infelizmente muitos membros não puderam se fazer presente, porém teremos outras oportunidades pela frente. ;] Segue link para álbum de fotos: https://www.tux-ce.org/portal/image/tid/12 Abraços ","date":"2008-09-29","objectID":"/posts/fotos-do-v-campeonato-intergalatico/:0:0","tags":["Software Livre","Tux-ce"],"title":"Fotos Do V Campeonato Intergalático De Boliche Da Tux-Ce","uri":"/posts/fotos-do-v-campeonato-intergalatico/"},{"categories":["Tutoriais"],"content":"Sabe aqueles horários em que você não tem o que fazer e acaba, literalmente, procurando qualquer coisa pra mexer? Foi em um horário de almoço como este que fiz logoff em meu KDE4 e observei minha tela do KDM. Reparei em como os designers resposnsáveis fizeram um bom trabalho no KDE4. Foi aí que pensei: Porque não ter um pouquinho do gosto Arch Linux já na hora de me logar ao KDE4?","date":"2008-09-26","objectID":"/posts/deixando-seu-kde4-um-pouco/","tags":["Arch Linux","Impressões","KDE","Linux","Software Livre"],"title":"Deixando Seu Kde4 Um Pouco Mais Arch - Kdm","uri":"/posts/deixando-seu-kde4-um-pouco/"},{"categories":["Tutoriais"],"content":"Sabe aqueles horários em que você não tem o que fazer e acaba, literalmente, procurando qualquer coisa pra mexer? Foi em um horário de almoço como este que fiz logoff em meu KDE4 e observei minha tela do KDM. Reparei em como os designers resposnsáveis fizeram um bom trabalho no KDE4. Foi aí que pensei: Porque não ter um pouquinho do gosto Arch Linux já na hora de me logar ao KDE4? Alterei então o tema para ter como resultado final um tema de kdm para o meu Arch Linux. Ficou com a elegância que já trazia por padrão do KDE4, porém com uma pequena pitada de Arch Linux nele, de forma a tornar o ambiente mais customizado. Mãos à obra… Editei a imagem original com o Inkscape, portanto este pequeno trabalho lhes será poupado. Tudo o que vocês precisam é inserir esta imagem no tema original do KDM. Vamos às formas disponíveis: Primeiro, faça o download da imagem através do seguinte link: download 1- Você pode simplesmente substituir a imagem original por esta com o comando: mv ~/background.svg /usr/share/apps/kdm/themes/nome-do-tema/ ps: Isto, levando em consideração que a imagem alterada se encontra dentro do seu home. 2- Manter as duas imagens: Original e Alterada Para isso você precisa antes de mais nada renomear a imagem original no tema para um segundo nome: mv /usr/share/apps/kdm/themes/nome-do-tema/background.svg /usr/share/apps/kdm/themes/nome-do-tema/background2.svg Em seguida, jogar a imagem alterada lá dentro: mv ~/background.svg /usr/share/apps/kdm/themes/nome-do-tema/ ps: Isto, levando em consideração que a imagem alterada se encontra dentro do seu home. É isso pessoal, em breve maiores customizações para nosso KDE4 + Arch Linux. ;] Abraços! ","date":"2008-09-26","objectID":"/posts/deixando-seu-kde4-um-pouco/:0:0","tags":["Arch Linux","Impressões","KDE","Linux","Software Livre"],"title":"Deixando Seu Kde4 Um Pouco Mais Arch - Kdm","uri":"/posts/deixando-seu-kde4-um-pouco/"},{"categories":["Impressões"],"content":"Há algumas semanas atrás vimos a confusão causada por instalações de escutas telefônicas feitas pela ABIN. Houve uma grande onda de críticas em cima disto, até que resultou na proibição de comercialização de qualquer equipamento de espionagem em nosso lindo país como forma de penalizar qualquer um que efetue este tipo de atividade que agora é terminantemente proibida. Sim, nossa Agência de inteligência nacional não pode mais ficar sabendo das roubalheiras que nossos representantes andam fazendo. Sim, agora é crime descobrir que nossos políticos estão fazendo roubalheiras.","date":"2008-09-22","objectID":"/posts/o-que-vem-agora-proibicao/","tags":["Impressões","Segurança"],"title":"O Que Vem Agora? Proibição Do Uso De Criptografia?","uri":"/posts/o-que-vem-agora-proibicao/"},{"categories":["Impressões"],"content":"Há algumas semanas atrás vimos a confusão causada por instalações de escutas telefônicas feitas pela ABIN. Houve uma grande onda de críticas em cima disto, até que resultou na proibição de comercialização de qualquer equipamento de espionagem em nosso “lindo” país como forma de penalizar qualquer um que efetue este tipo de atividade que agora é terminantemente proibida. Sim, nossa Agência de inteligência nacional não pode mais ficar sabendo das roubalheiras que nossos “representantes” andam fazendo. Sim, agora é crime descobrir que nossos políticos estão fazendo roubalheiras. Hoje, li uma matéria publicada no site da Folha Online que abordava algo incrível: PF não consegue decifrar criptografia dos arquivos de Daniel Dantas! A fonte diz: “Dois meses e meio depois de apreender cinco discos rígidos no apartamento do banqueiro Daniel Dantas, durante a Operação Satiagraha, a Polícia Federal ainda não conseguiu decifrar a criptografia que protege os dados.” O mais interessante foi ver o anúncio deles de que nunca viram uma tecnologia tão avançada de criptografia aqui no Brasil. o.O Quanta ignorância. Para fechar com chave de ouro, eles informam que estão estudando a possibilidade de entrar judicialmente contra a empresa norte-americana desenvolvedora do mecanismo de criptografia adotado, como forma de obrigar a mesma a entregar a chave de acesso. Quanta palhaçada… Será que como peritos em segurança eles não sabem que estas chaves são geradas de forma assimétrica e que a forma mais simples seria fazer o próprio Dantas entregá-la? Algo como redução de pena em troca da informação seria mais útil do que tentar obrigar a empresa norte-americana, que nada tem a ver com isso, a entregar esta chave. Me pergunto se nosso dicionária descreve a palavra maturidade da forma correta.. Pois pelo visto, nosso país não entendeu muito bem o que significa isso. :/ ","date":"2008-09-22","objectID":"/posts/o-que-vem-agora-proibicao/:0:0","tags":["Impressões","Segurança"],"title":"O Que Vem Agora? Proibição Do Uso De Criptografia?","uri":"/posts/o-que-vem-agora-proibicao/"},{"categories":["Aleatórios"],"content":"Sei que o tópico não tem ligação alguma com Software Livre e Tecnologia, mas de certa forma tem ligação com nossa Liberdade. Não poderia deixar de comentar, afinal de contas é chegada a hora! É chegada a hora de votar pessoal. Votemos em nossos falsos reis.","date":"2008-09-17","objectID":"/posts/hora-de-votar-em-nossos/","tags":["Impressões"],"title":"Hora De Votar Em Nossos Falsos Reis","uri":"/posts/hora-de-votar-em-nossos/"},{"categories":["Aleatórios"],"content":"Sei que o tópico não tem ligação alguma com Software Livre e Tecnologia, mas de certa forma tem ligação com nossa Liberdade. Não poderia deixar de comentar, afinal de contas é chegada a hora! É chegada a hora de votar pessoal. Votemos em nossos falsos reis. Sim, é hora de escolher aqueles que nos representarão durante algum tempo. Aqueles que decidirão o rumo de uma boa parte de nosso dinheiro, sim vamos votar. Não estou aqui pedindo ou tentando encorajar as pessoas a votarem, mas sim lembrando de uma obrigação que temos perante nosso país. :/ Sim, eles não são obrigados a nos representar bem, mas somos obrigados e votar e participar desta cena. Observando filmes ou contos de tempos antigos, podemos ter uma real visão sobre o que era um verdadeiro Rei. Hoje não temos muita noção do que seja um Rei ou um reinado, pois vivemos em um mundo de fragmentações onde nossos representantes não ligam tanto ou se preocupam com o povo a ponto de buscar o benefício do mesmo. Naquele tempo, o Rei era o Povo! O Rei era o povo no sentido de que o povo era uma parte do Rei, onde este se dedicava tanto que poderia fazer tudo pelo seu povo. O Rei não era apenas um político, mas também um guerreiro, um general nas linhas de frente que morreria pelo seu povo. Ele era um cantor, um escritor, um poeta… Todas estas diferentes coisas..Enfim, uma pessoa real, em carne e osso. Paro por aqui pois não me permito perder mais tempo e palavras para falar sobre nossos “representantes”. Talvez não valha o esforço. “Ordem, Progresso e Perdão! Na terra onde quem rouba muito não tem punição!” ","date":"2008-09-17","objectID":"/posts/hora-de-votar-em-nossos/:0:0","tags":["Impressões"],"title":"Hora De Votar Em Nossos Falsos Reis","uri":"/posts/hora-de-votar-em-nossos/"},{"categories":["Eventos"],"content":"Para quem é membro antigo da casa(Tux-CE), teve a chance de presenciar a última competição que contou com a presença de lendas vivas na Tux-CE como o moonnight e o Mestre NGD. Figuras estas que ainda são desconhecidas para muitos dos novos membros da Tux-CE. Estamos agora marcando nossa V Competição de Boliche que servirá como momento de descontração entre os membros da Tux-CE. Data: Domingo 14/09 Horário: 16:00 Local: Boliche do North Shopping Espero sua presença lá. Não tenha medo…apesar das nossas caras, ninguém aqui morde… :p Se você desejar, pode conferir as fotos da última competição de boliche da Tux-CE no seguinte link: https://www.tux-ce.org/portal/image/tid/9 Abraços ","date":"2008-09-12","objectID":"/posts/v-competicao-de-boliche-da/:0:0","tags":["Software Livre","Tux-ce"],"title":"V Competição De Boliche Da Tux-Ce","uri":"/posts/v-competicao-de-boliche-da/"},{"categories":["Impressões"],"content":"Pois é pessoal. Quem ainda tem coragem de dizer que o Google não vai dominar o mundo? Brincadeiras a parte, o que parecia apenas boato de internet, se confirmou nesta segunda-feira como sendo um fato real. O Google acaba de lançar seu mais novo produto. Chrome é o nome da mais nova cria da gigante Google. Este que é um navegador web open source utilizando-se da toolkit do navegador Konqueror, já conhecido pelos usuários Linux que também foi utilizado pelo navegador Safari. Dentre as novidades que parecem se destacar estão a melhoria de performance do interpretador JavaScript e a separação de abas como processos distintos, aproveitando melhor a CPU de sua máquina, principalmente se você possui máquinas *core. ;] Até hoje pela manhã não havia nenhuma confirmação com relação a este lançamento, apenas boatos que acabaram por se confirmar nesta noite quando achei o aviso oficial no blog do próprio Google. A gigante também preparou uma história em quadrinhos bem bacana para ilustrar a chegada de sua nova ferramenta. Segue link oficial da fonte: https://googleblog.blogspot.com/2008/09/fresh-take-on-browser.html Link para a história em quadrinhos: http://books.google.com/books?id=8UsqHohwwVYC\u0026printsec=frontcover#PPA16,M1 ","date":"2008-09-02","objectID":"/posts/chrome-o-navegador-web-do/:0:0","tags":["Impressões"],"title":"Chrome - O Navegador Web Do Google","uri":"/posts/chrome-o-navegador-web-do/"},{"categories":["Impressões"],"content":"Em minha primeira participação no Almanarch publiquei este artigo no qual gostaria de abordar um tema que acaba por assustar muitas pessoas que cogitam a idéia de utilizar Linux em suas máquinas.","date":"2008-08-31","objectID":"/posts/jogos-porque-nem-tudo-e/","tags":["Arch Linux","Impressões","Jogos","Linux","Software Livre"],"title":"Jogos, Porque Nem Tudo É Tela Preta","uri":"/posts/jogos-porque-nem-tudo-e/"},{"categories":["Impressões"],"content":"Em minha primeira participação no Almanarch publiquei este artigo no qual gostaria de abordar um tema que acaba por assustar muitas pessoas que cogitam a idéia de utilizar Linux em suas máquinas. Muitos conseguem facilmente entender as vantagens do software livre em termos de segurança, qualidade, estabilidade, preço dentre outras, porém acabam por temer uma ou outra coisa. Neste artigo focarei aqueles que temem usar o Linux como sistema operacional padrão por achar que não vai mais poder se divertir com jogos. No Arch Linux não é difícil resolver este problema, já que os repositórios estão repletos de jogos prontos para animar o seu dia ou momento de ociosidade. Jogos estes que vão desde os mais simples e clássicos como roms de super nintendo, até mesmo simuladores de vôos repletos de ambientes e gráficos em 3D. ","date":"2008-08-31","objectID":"/posts/jogos-porque-nem-tudo-e/:0:0","tags":["Arch Linux","Impressões","Jogos","Linux","Software Livre"],"title":"Jogos, Porque Nem Tudo É Tela Preta","uri":"/posts/jogos-porque-nem-tudo-e/"},{"categories":["Impressões"],"content":"Emuladores e Roms Com uma simples busca em seus repositórios através do pacman pela palavra “emulator” (# pacman -Ss emulator) poderemos achar emuladores disponíveis para várias plataformas como Gameboy, Mega Drive, Atari, Super Nintendo, Nintendo 64, entre outros. Os emuladores são uma grande chance para quem gostaria de relembrar seus tempos de infância com games fantásticos como o da ilustração acima. O chamado Chrono Trigger foi e é um excelente jogo de RPG para Super Nintendo que fascinou muitas gerações por sua história onde passamos por várias eras diferentes do mundo entre passado, presente e futuro. Além deste, podemos relembrar outros clássicos desta época como Rock’n Roll Racing e outros vários, já que existem centenas de sites na internet com o único intuito de fornecer roms dos mais variados consoles possíveis. Além destes antigos clássicos, podemos ainda nos divertir com jogos não tão antigos como por exemplo o Super Mário 64, do Nintendo 64, conforme ilustração ao lado e muitos outros. Vale lembrar que neste artigo meu foco não é incentivar o uso exclusivo destes roms, já que estes são disponibilizados apenas para testes, onde caso você não tenha o game original, deverá manter o rom em seu computador por apenas 24hs por medidas legais. ","date":"2008-08-31","objectID":"/posts/jogos-porque-nem-tudo-e/:1:0","tags":["Arch Linux","Impressões","Jogos","Linux","Software Livre"],"title":"Jogos, Porque Nem Tudo É Tela Preta","uri":"/posts/jogos-porque-nem-tudo-e/"},{"categories":["Impressões"],"content":"Jogos no Arch Partindo agora aos jogos que rodam nativamente e livre no Linux, vamos apresentar alguns para divertir, ainda mais, os seus dias no Arch Linux. Como existem vários jogos e de várias categorias, irei abordar apenas 2 de algumas categorias. ","date":"2008-08-31","objectID":"/posts/jogos-porque-nem-tudo-e/:2:0","tags":["Arch Linux","Impressões","Jogos","Linux","Software Livre"],"title":"Jogos, Porque Nem Tudo É Tela Preta","uri":"/posts/jogos-porque-nem-tudo-e/"},{"categories":["Impressões"],"content":"RPG Na variante RPG temos alguns bons jogos como o The Mana World que agradaria os fans de Ragnarok por ser bastante parecido com o mesmo. Com gráficos simples em 2D, o que permite àqueles que não possuem uma placa 3D jogar, o game lhe permite participar de aventuras em um ambiente online com vários outros jogadores no mundo. Outro game que se destaca na categoria RPG é o Eternal Lands. Este com gráficos mais robustos necessita que você tenha uma placa com suporte a aceleração 3D. Neste incrível jogo online uma civilização é levada a destruir sua própria existência. Durante este jogo você passará pelos mais variados cenários, todos com ótimos detalhes gráficos. Outros games que merecem ser averiguados nesta categoria: Adonthell, Dofus, KQ e Vendetta. ","date":"2008-08-31","objectID":"/posts/jogos-porque-nem-tudo-e/:2:1","tags":["Arch Linux","Impressões","Jogos","Linux","Software Livre"],"title":"Jogos, Porque Nem Tudo É Tela Preta","uri":"/posts/jogos-porque-nem-tudo-e/"},{"categories":["Impressões"],"content":"Estratégia Na categoria Estratégia eu deixo o destaque para o Battle of Wesnoth no qual você tem o objetivo de recrutar membros para sua tropa e conquistar territórios e vilas destruindo o líder de outras tropas nesta luta por conquistas. Com interface simples, este game também não precisa de uma placa com aceleração 3D. Segue ilustração ao lado: Meu segundo destaque vai para Warzone 2100, no qual você pousa sua nave de trasporte em um mundo onde você deverá estabelecer seu território com a construção de bases, equipamentos, coleta de recursos, naves, tanques e etc. Você deverá crescer no jogo construindo novos veículos e planos de combate para o domínio do mundo, defendendo-se dos ataques inimigos. Este também requer uma placa de vídeo 3D com suporte a OpenGL. Segue imagem abaixo: Outros games que merecem ser averiguados nesta categoria: Pingus e UFO: Alien Invasion ","date":"2008-08-31","objectID":"/posts/jogos-porque-nem-tudo-e/:2:2","tags":["Arch Linux","Impressões","Jogos","Linux","Software Livre"],"title":"Jogos, Porque Nem Tudo É Tela Preta","uri":"/posts/jogos-porque-nem-tudo-e/"},{"categories":["Impressões"],"content":"Ação Na categoria Ação, esta que é a favorita de muitos fans de games, gostaria de dar o grande destaque para o Urban Terror. Este que é um jogo baseado na engine do Quake, lhe trará vários cenários nos quais você faz parte de uma equipe, ou não, que deverá defender seu território, atacar os adversários, invadir territórios, sendo isto tudo com pessoas pela internet ou amigos em uma rede LAN. O jogo necessita uma placa com aceleração 3D e compatível com OpenGL. A vantagem desde jogo é que é facilmente instalado, precisando apenas descompactar e executar, já trazendo os executáveis para Linux, Mac e Windows, o que facilita na hora de reunir amigos que possuem diferentes plataformas em suas máquinas, onde o mesmo arquivo compactado em seu pendrive servirá para qualquer um deles. Em segundo lugar, mas não inferior, deixo o Open Arena. Este, também em cima da engine do Quake, se trata de um jogo simples e direto ao ponto. Um jogo no qual você jogará sozinho contra o computador, ou jogares que estejam na rede ou internet. Neste também precisamos de aceleração 3D e suporte a OpenGL na placa. Outros games que merecem ser averiguados nesta categoria: America’s Army, Enemy Territory e Tremulous. ","date":"2008-08-31","objectID":"/posts/jogos-porque-nem-tudo-e/:2:3","tags":["Arch Linux","Impressões","Jogos","Linux","Software Livre"],"title":"Jogos, Porque Nem Tudo É Tela Preta","uri":"/posts/jogos-porque-nem-tudo-e/"},{"categories":["Impressões"],"content":"Simuladores Em primeiro lugar gostaria de apontar o FlightGear. Este é o resultado de um projeto que visava um simulador de vôo extremamente realista com cenários e gráficos muito bons de forma que pudesse ser utilizado inclusive em treinamento de pilotos. Requer também uma placa com aceleração 3D e OpenGL. Em segundo lugar vou deixar o Lin City NG. Este animará os fans da série Sim City, já que o mesmo lembra muito as antigas versões do mesmo. Apesar dos gráficos não serem muito ricos, este divertido jogo será bastante útil para preencher suas horas sem ter o que fazer, no qual seu objetivo é construir cidades e gerenciá-las de forma a agradar sua população. Segue imagem do mesmo: Outros games que merecem ser averiguados nesta categoria: Racer, BillarGL e Trigger. ","date":"2008-08-31","objectID":"/posts/jogos-porque-nem-tudo-e/:2:4","tags":["Arch Linux","Impressões","Jogos","Linux","Software Livre"],"title":"Jogos, Porque Nem Tudo É Tela Preta","uri":"/posts/jogos-porque-nem-tudo-e/"},{"categories":["Impressões"],"content":"Conclusão Bom, como podem ver, nem só de tela preta vivem os usuários de Linux. No Arch Linux não seria diferente. O grande lance desse artigo é que todos estes jogos você poderá instalar facilmente no Arch Linux. Todos os jogos que descrevi, com exceção do Eternal Lands e Open Arena, podem ser instalados diretamente pelo gerenciador de pacotes pacman. Ps: Um guia de utilização do pacman foi amplamente abordado na primeira edição do nosso Almanarch, escrito pelo Hugo Doria. Com relação aos dois acima citados, você poderá encontrá-los no AUR. Espero que tenham gostado… ","date":"2008-08-31","objectID":"/posts/jogos-porque-nem-tudo-e/:3:0","tags":["Arch Linux","Impressões","Jogos","Linux","Software Livre"],"title":"Jogos, Porque Nem Tudo É Tela Preta","uri":"/posts/jogos-porque-nem-tudo-e/"},{"categories":["Impressões"],"content":"Não sei se algum de vocês ficou sabendo..Mas na última semana foi notificado um problema na infra-estrutura do Fedora, e havia sido recomendado que nenhuma instalação ou atualizaçãp fosse feita, caso você use Fedora.","date":"2008-08-22","objectID":"/posts/problemas-de-infra-do-fedora/","tags":["Cultura Hacker","Fedora","Linux","Segurança","Software Livre"],"title":"Problemas De Infra Do Fedora - Servidores Hackeados","uri":"/posts/problemas-de-infra-do-fedora/"},{"categories":["Impressões"],"content":"Não sei se algum de vocês ficou sabendo..Mas na última semana foi notificado um problema na infra-estrutura do Fedora, e havia sido “recomendado” que nenhuma instalação ou atualizaçãp fosse feita, caso você use Fedora. Até ontem eu não tinha visto nenhuma explicação para o caso, mas discutindo com colegas de trabalho já suspeitávamos de uma invasão nos servidores do fedora que pudessem ocasionar este tipo de problema…Bom, hoje achei esta nota no site da red hat, que confirma nossas suspeitas. Os servidores foram sim invadidos. O caso é gravíssimo, pois pode, ou não, ter interferido na árvore de pacotes…pois existe o risco de eles terem pego as chaves dos pacotes fedora.. :/ Eu não sou usuário Fedora, mas para quem é…fica o Alarme piscando!! É bom se manter informado e até lá não sair usando o yum para instalar ou atualizar pacotes. Apesar de na nota eles informarem que os problemas podem não ser graves, eu não arriscaria isso em um ambiente de produção na empresa em que trabalho. Só Deus sabe o que de fato aconteceu. Segue link com informações mais detalhadas: https://www.redhat.com/archives/fedora-announce-list/2008-August/msg00012.html Abraços ","date":"2008-08-22","objectID":"/posts/problemas-de-infra-do-fedora/:0:0","tags":["Cultura Hacker","Fedora","Linux","Segurança","Software Livre"],"title":"Problemas De Infra Do Fedora - Servidores Hackeados","uri":"/posts/problemas-de-infra-do-fedora/"},{"categories":["Impressões"],"content":"Isso não é mentira. O Software Livre realmente precisa de você.","date":"2008-08-11","objectID":"/posts/o-software-livre-precisa-de/","tags":["Impressões","Linux","Software Livre"],"title":"O Software Livre Precisa De Você","uri":"/posts/o-software-livre-precisa-de/"},{"categories":["Impressões"],"content":"Isso não é mentira. O Software Livre realmente precisa de você. Como todos sabemos, o Software Livre vem ganhando a cada dia mais nome no mercado e aceitação como solução tecnológica. É comum abrirmos nosso navegador ou leitor de notícias RSS e nos depararmos com notícias que nos mostram claramente essa evolução como a recente “IBM empenhada em oferecer desktops Microsoft-Free”, anunciada no site da Linux Magazine, na qual é abordada a nova parceria da IBM com alguns dos principais distribuidores Linux numa tentativa de oferecer melhores e mais viáveis condições de venda de computadores caseiros trazendo o Software Livre como essência da máquina. É importante vermos que ele passa a ganhar seu espaço não apenas pelo custo se comparado à Softwares Proprietários, mas também pelo funcionamento eficaz do mesmo que está cada vez mais claro. Mas como um software ou sistema operacional como o Linux, que foi criado por uma pessoa inicialmente na Finlândia, poderia vir hoje a ter tamanha repercussão no mundo? Como ele poderia ganhar tanta voz, respeito e aceitação, diante do fato de que hoje é fácil chegar no colégio / faculdade / trabalho e conhecer alguém que fale do tal pinguim que roda gratuitamente em sua máquina? Como esse sistema ganhou importância tal a ponto de se manter diariamente atualizado e recebendo correções de bugs ou falhas de segurança? A resposta para essas e outras perguntas é o senso de COMUNIDADE que se formou em volta do mesmo. Como muitos já sabem, o Linux nasceu devagar na cabeça de um desenvolvedor chamado Linus Torvalds, que resolveu jogar sua idéia ao mundo expondo o que ele pensava em fazer e o “como” ele estava fazendo até então. Neste “como” está incluído o código inicialmente criado por ele, bem como a forma na qual ele estava trabalhando em cima do projeto. Juntamente com essas informações, ele deixou o convite para todos os que desejassem ajudar na elaboração daquela que ele, provavelmente, não imaginasse que seria tão popular depois de alguns anos. Em menos de 24 horas Linus já havia recebido várias respostas a este convite com pessoas se oferecendo para lhe ajudar na tarefa que daria origem ao Sistema Operacional que hoje conhecemos como Linux. Da mesma forma que o Linux precisou de voluntários e pessoas do mundo inteiro para ajudar naquele projeto inicial, o Software Livre como um todo continua precisando, cada vez mais, de pessoas dispostas a ajudar nesta disseminação de uma solução que se mostra a cada dia: Socialmente Justa, Economicamente Viável e Tecnologicamente Sustentável. Que tal você ajudar também? Muitos até pensam em ajudar, mas muitas vezes acabam inibindo esta vontade por não saber exatamente como ajudar ou achar que só pode ajudar quem tem bons conhecimentos de programação. A verdade é que além de desenvolvimento, existem outras várias formas de ajudar o Software Livre e em alguma(s) delas seu perfil poderá se encaixar melhor. Divulgação - O bom e velho boca-a-boca pode ajudar mais do que você imagina. Se você fala das vantagens do Software Livre para 5 pessoas e conseguir convencer 1 pessoa a pelo menos experimentar o Software Livre, já temos um grande lucro. Pois esta ação é multiplicadora e este 1 que experimentou por indicação sua poderá gostar e repassar a idéia para mais pessoas e assim por diante neste ciclo. Participação em listas ou fóruns na internet - Aqui você ajuda no sentido de tirar dúvidas e dar apoio a quem possa estar começando com o Software Livre. Estas pessoas as vezes acabam desistindo do Software Livre por encontrar dificuldades e não ter ninguém para lhes ajudar ou tirar dúvidas. Documentação - Escrever artigos, tutoriais, dicas e manuais sobre Software Livre, seja filosófico ou técnico, é sempre bom para ajudar aqueles que buscam informações sobre o mesmo na internet, já que todos sabemos que até para dúvidas como por exemplo “como dar nó em gravatas”, o Google é o primeiro a ser chamado como forma de pesquisa. Escrever documentações e jogar pela web, seja em ","date":"2008-08-11","objectID":"/posts/o-software-livre-precisa-de/:0:0","tags":["Impressões","Linux","Software Livre"],"title":"O Software Livre Precisa De Você","uri":"/posts/o-software-livre-precisa-de/"},{"categories":["Tutoriais"],"content":"Creio que todos os usuários de Arch Linux conhecem ou já ouviram falar do Hugo Doria. O Hugo é um dos maiores representantes do Arch Linux no Brasil e um dos atuais desenvolvedores do mesmo.","date":"2008-08-03","objectID":"/posts/instalacao-do-kdemod-41-no/","tags":["Arch Linux","KDE","Linux","Software Livre"],"title":"Instalação Do Kdemod 4.1 No Arch Linux","uri":"/posts/instalacao-do-kdemod-41-no/"},{"categories":["Tutoriais"],"content":"Creio que todos os usuários de Arch Linux conhecem ou já ouviram falar do Hugo Doria. O Hugo é um dos maiores representantes do Arch Linux no Brasil e um dos atuais desenvolvedores do mesmo. Este artigo sobre instalação do KDEmod 4.1 foi escrito por ele e resolvi postar aqui para que possamos atingir mais público ainda. Quanto mais a informação correr, melhor. ;] ","date":"2008-08-03","objectID":"/posts/instalacao-do-kdemod-41-no/:0:0","tags":["Arch Linux","KDE","Linux","Software Livre"],"title":"Instalação Do Kdemod 4.1 No Arch Linux","uri":"/posts/instalacao-do-kdemod-41-no/"},{"categories":["Tutoriais"],"content":"Introdução No Arch Linux o KDE é empacotado de um jeito que eu não curto. Nele, diversas aplicações são “englobadas” em um só pacote (isso é o padrão na maioria das distribuições). Ao instalar o pacote kdegraphics, por exemplo, você acaba instalando diversas aplicações para manipulação gráfica. Mesmo que você queira apenas a “aplicação x” daquele pacote será obrigado a instalar o kdegraphics todo. Isso torna o KDE enorme e com diversas aplicações que você nunca usa. A solução para isto é usar o KDEMod, um projeto que visa fornecer uma instalação modular do KDE e otimizada para o Arch Linux. NOTA: Não há planos para portar o KDEMod para outras distribuições. ","date":"2008-08-03","objectID":"/posts/instalacao-do-kdemod-41-no/:1:0","tags":["Arch Linux","KDE","Linux","Software Livre"],"title":"Instalação Do Kdemod 4.1 No Arch Linux","uri":"/posts/instalacao-do-kdemod-41-no/"},{"categories":["Tutoriais"],"content":"Instalação O primeiro passo a ser feito é remover toda e qualquer instalação do KDEMod anterior. Faça isso com: # pacman -Rscn kdemod-complete Se você já está usando as versões betas do kdemod4, também faça: # pacman -Rscn kdemod4-complete Verifique se tudo relacionado ao kde foi removido com: # pacman -Q | grep kde Se aparecer algo, pode remover. Uma maneira mais direta de fazer isto é executando: # pacman -Q | grep -i \"kde|qt\" | cut -d \" \" -f1 | xargs pacman -Rd É preciso, também, remover os arquivos de configuração do kdemod 3 e 4 anteriores, já que eles são incompatíveis com a nova versão: $ rm -rf ~/.kde* ~/.kdemod* NOTA: Ao invés de removê-los eu sugiro que você faça um backup. Pronto, seu sistema está limpo e agora podemos instalar a nova versão sem problemas. Abra o arquivo /etc/pacman.conf com seu editor preferido e adicione: [kdemod-core] Server = [https://kdemod.ath.cx/repo/core/i686](https://kdemod.ath.cx/repo/core/i686) NOTA: Remove qualquer entrada referente ao [kdemod] ou ao [kdemod-unstable] Para instalar o KDEMod faça: # pacman -Sy kdemod Se quiser o kdemod completo faça: # pacman -Sy kdemod-complete Seu KDEMod está pronto para uso. :) Para usá-lo basta editar seu ~/.xinitrc ou iniciar o kdm (gerenciador de login do KDE) com: # /etc/rc.d/kdm restart O primeiro boot do KDE 4 demora um pouco, mas depois melhora. Portanto, não se preocupe. Caso você queira seu ambiente em português instale o pacote abaixo: # pacman -Sy kdemod-kde-l10n-pt_br E selecione seu idioma nas configurações do KDE. ","date":"2008-08-03","objectID":"/posts/instalacao-do-kdemod-41-no/:2:0","tags":["Arch Linux","KDE","Linux","Software Livre"],"title":"Instalação Do Kdemod 4.1 No Arch Linux","uri":"/posts/instalacao-do-kdemod-41-no/"},{"categories":["Tutoriais"],"content":"Pacotes Adicionais Agora existe um repositório com alguns pacotes adicionais para o KDE (aplicativos, plasmoids etc). Para usá-lo adicione as seguintes linhas ao /etc/pacman.conf: [kdemod-extragear] Server = https://kdemod.ath.cx/repo/extragear/i686 E sincronize a base de dados dos pacotes: # pacman -Sy Para visualizar o que existe neste repositório faça: # pacman -Sl kdemod-extragear Por enquanto ainda existem poucos pacotes neste repositório, mas vários outros estão sendo adicionados. Bem, é isso. Agora é só você aproveitar seu KDEMod 4. No momento que estou escrevendo este artigo ele se encontra na versão 4.1 e já está ficando fantástico. Maiores informações: https://www.kdemod.ath.cx/ Deixo aqui os agradecimentos ao Hugo em nome de todos pela contribuição. ","date":"2008-08-03","objectID":"/posts/instalacao-do-kdemod-41-no/:3:0","tags":["Arch Linux","KDE","Linux","Software Livre"],"title":"Instalação Do Kdemod 4.1 No Arch Linux","uri":"/posts/instalacao-do-kdemod-41-no/"},{"categories":["Tutoriais"],"content":"Os usuários de Arch Linux que utilizam o kdemod como ambiente gráfico e que tentaram fazer uma atualização do sistema (pacman -Syu) nos últimos dias devem ter notado que havia um problema. Como o KDE 4.1 entrou para os repositórios do Arch, passou a haver uma incompatibilidade entre alguns pacotes.","date":"2008-07-30","objectID":"/posts/corrigindo-incompatibilidade-do-kdemod-apos/","tags":["Arch Linux","KDE","Linux","Software Livre"],"title":"Corrigindo Incompatibilidade Do Kdemod Após O Nascimento Do Kde4.1 No Arch","uri":"/posts/corrigindo-incompatibilidade-do-kdemod-apos/"},{"categories":["Tutoriais"],"content":"Os usuários de Arch Linux que utilizam o kdemod como ambiente gráfico e que tentaram fazer uma atualização do sistema (pacman -Syu) nos últimos dias devem ter notado que havia um problema. Como o KDE 4.1 entrou para os repositórios do Arch, passou a haver uma incompatibilidade entre alguns pacotes. E a atualização do sistema pedia que você substituisse alguns pacotes do kdemod pelos do kde. Logo que percebi este problema busquei ajuda em fórums mas ninguém tinha a solução, portanto decidi reportar este bug para os desenvolvedores do kdemod. A minha surpresa foi chegar no site de bugreport do kdemod e ver que este bug já havia sido identificado. Achei ótimo ver que o bug já havia sido notificado e que já estavam trabalhando em cima do mesmo, como o próprio desenvolvedor “funkyou” me informou. Hoje, 30/07, o problema já se encontra solucionado e o bug foi fechado no bugreport deles. É preciso seguir um procedimento para normalizar a situação, já que os pacotes do antigo kdemod foram re-construídos e re-empacotados como kdemod3 para fazê-los funcionar no novo upgrade do Arch. Mudanças que foram feitas: Todos os pacotes foram renomeados para kdemod3-$PACKAGE KDEmod 3.5.9 agora conflita com KDE 4.1, então não é possível ter ambos instalados simultaneamente Não é uma atualização muito comum, você precisará remover todos os pacotes do kdemod primeiramente para depois reinstalar Note que muitas coisas do [community] por exemplo precisam ser adaptados ao novo KDE3 renomeando no Arch Não force nada, o melhor é reportar os problemas no link a seguir: https://www.kdemod.ath.cx/bbs/viewtopic.php?pid=5303#p5303 Este repositório deixará de ser suportado até que alguém passe a lhe dar mais amor como nós acasionalmente fazemos INSTALAÇÃO**:** **1. **Remover todos os pacotes do KDE4: pacman -Rcs kde **2. **Remover todos os pacotes do KDEmod4: pacman -Rcs kdemod4-complete **3. **Remover todos os pacotes do KDEmod3: pacman -Rcs kdemod-complete **4. **Remover qualquer pacote do KDE que ainda exista em seu sistema **5. **Checar novamente se tudo foi removido: pacman -Q | grep kde **6. **Remover o antigo repositório [kdemod] do seu pacman.conf **7. **Adicionar o novo repositório [kdemod-legacy] ao seu pacman.conf Para i686 [kdemod-legacy] Server = https://kdemod.ath.cx/repo/legacy/ Para x86_64 [kdemod-legacy] Server = https://kdemod.ath.cx/repo/legacy/x86_64 ****Em seguida atualize com: pacman -Suy ****Instale com: pacman -S kdemod3 (sistema funcional básico) ou pacman -S kdemod3-complete (instalação completa do KDEmod) ou pacman -S kdemod3-vanilla (instalação completa do KDEmod, sabor vanilla (baunilha)) ou pacman -S kdemod3-base (instalação básica do KDE (base)) ****Instale sua língua(cheque os disponíveis com pacman -Ss kdemod3-kde-i18n) Feito. ;] ","date":"2008-07-30","objectID":"/posts/corrigindo-incompatibilidade-do-kdemod-apos/:0:0","tags":["Arch Linux","KDE","Linux","Software Livre"],"title":"Corrigindo Incompatibilidade Do Kdemod Após O Nascimento Do Kde4.1 No Arch","uri":"/posts/corrigindo-incompatibilidade-do-kdemod-apos/"},{"categories":["Impressões"],"content":"Semana passada completei um mês de utilização do Arch Linux, mas como não tive tempo para publicar nada, segue agora um resumo do que tenho obtido com o Arch Linux nesse 1 mês de uso intensivo do mesmo como distribuição oficial. ","date":"2008-07-24","objectID":"/posts/1-mes-de-arch-linux/:0:0","tags":["Arch Linux","Impressões","Linux","Software Livre"],"title":"1 Mês De Arch Linux: Meu Resultado Obtido","uri":"/posts/1-mes-de-arch-linux/"},{"categories":["Impressões"],"content":"Performance Performance: No quesito performance o Arch me surpreendou. Ganhou em meus olhos o lugar, com mérito, da distribuição mais rápida que já testei até hoje. Para os que acompanham meus posts, sabem que essa lista não é pequena. O Arch, por vir à luz de forma simples e “pelado”, bem como nós viemos a Terra, nos proporciona um maior controle do que queremos ter instalado e rodando. E como fazemos isto manualmente, podemos adquirir uma performance maior. O boot do mesmo é também o mais rápido que já tive em minha máquina. A utilização de recursos é muito bem clara quando se deixa um top rodando. Pude ver que o consumo de memória e processador baixaram muito se comparado a outras distribuições que utilizei durante muito tempo. ","date":"2008-07-24","objectID":"/posts/1-mes-de-arch-linux/:1:0","tags":["Arch Linux","Impressões","Linux","Software Livre"],"title":"1 Mês De Arch Linux: Meu Resultado Obtido","uri":"/posts/1-mes-de-arch-linux/"},{"categories":["Impressões"],"content":"Pacotes Pacotes i686: A maioria dos computadores hoje em dia possuem processadores i686, porém nenhuma distribuição até hoje possuia versões para i686. No máximo possuiam uma versão de sua iso de instalação para i686, mas os pacotes continuavam sendo para i386, desperdiçando o potencial de seu hardware. No Arch Linux, por padrão todos os pacotes já são feitos para arquiteturas i686, possuindo também a versão x64 para aqueles que possuem este tipo de processador. ;] ","date":"2008-07-24","objectID":"/posts/1-mes-de-arch-linux/:2:0","tags":["Arch Linux","Impressões","Linux","Software Livre"],"title":"1 Mês De Arch Linux: Meu Resultado Obtido","uri":"/posts/1-mes-de-arch-linux/"},{"categories":["Impressões"],"content":"Gerenciamento de Pacotes Gerenciamento de pacotes: Este também foi um pequeno choque no começo para mim. Depois de testar várias distros me apeguei bastante ao Debian e ao Kubuntu pelo fato de eles trazerem consigo a maravilhosa ferramenta Aptitude. Não tiro aqui os méritos da mesma. Ela me manteve entre as espirais Debian por cerca de 2 anos. ;] Utilizar algo diferente, depois de tanto tempo foi mesmo um choque, mas a verdade é que logo na primeira semana o pacman, gerenciador de pacotes do Arch Linux, roubou em meu coração o lugar no qual se encontrava o Aptitude. Ainda gosto do aptitude, e continuo optando por ele como segunda escolha, mas devo ser justo em meus comentários. Acreditem, se depois de 2 anos como um fanático pelo aptitude, e meus posts anteriores não me deixam mentir, eu passei agora a adotar uma nova ferramenta, o pacman, é porque alguma coisa realmente me convenceu de que valeria a pena. Além de muito estável, a forma como o pacman funciona é simples e eficaz. Trazendo respostas rápidas à simples comandos com poucos parâmetros, posso resolver tudo o que preciso relacionado a meus pacotes sem a preocupação de tratar dependências ou quebrar pacotes, já que além de instalar as dependências juntamente com um pacote, ele também as removerá desde que as mesmas estejam orfãns, ou não necessárias para outros pacotes. ","date":"2008-07-24","objectID":"/posts/1-mes-de-arch-linux/:3:0","tags":["Arch Linux","Impressões","Linux","Software Livre"],"title":"1 Mês De Arch Linux: Meu Resultado Obtido","uri":"/posts/1-mes-de-arch-linux/"},{"categories":["Impressões"],"content":"Bleeding Edge Pacotes Atualizados: Uma das coisas que mais me surpreendeu no Arch, é a velocidade com que as coisas acontecem. Desde que adotei o Arch como minha distribuição, adotei a prática de fazer um upgrade completo em meu sistema diariamente através do pacman. Fico muito contente em ver que diariamente, uso os pacotes em suas versões mais recentes. Dois que me chamaram a atenção foram por exemplo o amsn e firefox, já que são de uso diário. Bastou sair publicado no site oficial do amsn uma nova versão com correções de bugs, e no upgrade do dia seguinte, lá estava ele nos meus repositórios e logo em seguida rodando em minha máquina. O mesmo com o Firefox, após o nascimento do tão esperado Firefox 3.0, surgiram também descobertas sobre vulnerabilidades do mesmo. Assim que foi lançada a versão 3.0.1 do mesmo, no meu upgrade do dia seguinte, lá estava em minha máquina a raposa de fogo em sua versão 3.0.1 funcionando perfeitamente. O mesmo acontece com os outros vários pacotes que utilizo. ","date":"2008-07-24","objectID":"/posts/1-mes-de-arch-linux/:4:0","tags":["Arch Linux","Impressões","Linux","Software Livre"],"title":"1 Mês De Arch Linux: Meu Resultado Obtido","uri":"/posts/1-mes-de-arch-linux/"},{"categories":["Impressões"],"content":"AUR - Repositório Comunitário AUR: Como se já não bastasse o magnífico pacman pra gerenciar meus pacotes, também contamos com o AUR, onde podemos achar aquele pacote em específico que por alguma razão ainda não se encontra nos repositórios oficiais. A organização do AUR é excelente onde podemos criar pacotes e submetê-los para que depois de uma votação adequada, possam finalmente assumir postos mais reconhecidos, até quem sabe um dia entrar para os repositórios. A quantidade de pacotes disponíveis no AUR é surpreendente, o que apenas demonstra a força da comunidade atuante no Arch. ","date":"2008-07-24","objectID":"/posts/1-mes-de-arch-linux/:5:0","tags":["Arch Linux","Impressões","Linux","Software Livre"],"title":"1 Mês De Arch Linux: Meu Resultado Obtido","uri":"/posts/1-mes-de-arch-linux/"},{"categories":["Impressões"],"content":"Rolling Release Rolling Release: Eis um outro fator primordial no Arch Linux. É uma distribuição Rolling Release. O que isso significa? Você não tem que se dar ao trabalho de baixar uma iso e reinstalar cada vez que surge uma versão nova do Arch Linux. O próprio pacman se responsabiliza de fazer este upgrade sem quebrar seu sistema. Você não precisa mais se manter com versões antigas de sua distribuição por não querer perder tanto tempo fazendo seus backups ou reinstalando tudo do zero. Tive a sorte de poder testar este recurso durante este 1 mês de testes com o Arch, já que no mês de Junho tivemos o lançamento da nova versão do Arch Linux, 2008.6 Overlord, e pude pessoalmente atestar a validade desta qualidade do Arch. Resultado? A minha distro foi totalmente atualizada para a nova versão do Arch, sem nenhum trauma. Tudo funcinou perfeitamente. Mais um ponto pro Arch em meu coração. ","date":"2008-07-24","objectID":"/posts/1-mes-de-arch-linux/:6:0","tags":["Arch Linux","Impressões","Linux","Software Livre"],"title":"1 Mês De Arch Linux: Meu Resultado Obtido","uri":"/posts/1-mes-de-arch-linux/"},{"categories":["Impressões"],"content":"Segurança Segurança: O Linux trás uma característica em comum, independente de distribuição, que é a segurança. Porém quanto menos serviços desnecessários rodando, menores serão as brechas e vulnerabilidades, portanto o Arch tem vantagem nisso. E por trazer algumas características do BSD, procura também uma estabilidade neste sentido. O próprio ports do BSD é utilizado no Arch Linux. ;] ","date":"2008-07-24","objectID":"/posts/1-mes-de-arch-linux/:7:0","tags":["Arch Linux","Impressões","Linux","Software Livre"],"title":"1 Mês De Arch Linux: Meu Resultado Obtido","uri":"/posts/1-mes-de-arch-linux/"},{"categories":["Impressões"],"content":"Comunidade Comunidade: A comunidade do Arch Linux, em especial a comunidade archlinux-br, tem me recebido de braços abertos desde que passei a frequentar e tentar ajudar a mesma, seja na divulgação, resposta de dúvidas ou mesmo na tradução de documentações do Arch. Essa oportunidade de ajudar e ser bem recebido ajudou muito em minha decisão por adotar esta distribuição. Outro ponto a favor, é o fato de termos dois brasileiros atualmente engajados no time de desenvolvedores do Arch Linux, o que significa que nossa voz é mais facilmente ouvida. Deixo aqui os parabéns a ambos que tem feito um ótimo trabalho: Hugo Doria e Douglas Soares. (Perdão, não achei o link para o mesmo) É isso pessoal, espero que assim como eu, possam experimentar e conhecer esta magnífica distribuição. ","date":"2008-07-24","objectID":"/posts/1-mes-de-arch-linux/:8:0","tags":["Arch Linux","Impressões","Linux","Software Livre"],"title":"1 Mês De Arch Linux: Meu Resultado Obtido","uri":"/posts/1-mes-de-arch-linux/"},{"categories":["Tutoriais"],"content":"Muitos me pediram por aqui ou mesmo por email para explicar como seria a implementação desta técnica de forma automatizada.","date":"2008-07-14","objectID":"/posts/parte-ii-limpando-memoria-cache/","tags":["Linux","Redes","Software Livre"],"title":"Parte II Limpando Memória Cache De Forma Automatizada","uri":"/posts/parte-ii-limpando-memoria-cache/"},{"categories":["Tutoriais"],"content":"Muitos me pediram por aqui ou mesmo por email para explicar como seria a implementação desta técnica de forma automatizada. Bom, utilizo isto para o servidor que citei no artigo anterior, utilizado pelos nossos amigos desenvolvedores Java. ;] Nada pessoal eim?! Aqui precisaremos apenas de um mínimo de intimidade com shell script e um pouco de conhecimento sobre o agendamento de tarefas no linux através do cron. Mãos a obra… A missão: Uma vez que nossos amigos não conseguem trabalhar de forma harmônica com a alocação e desalocação de memória em nossos servidores, iremos agendar a limpeza de cache para todos os dias no começo do expediente (8:00) e após o almoço. Lembrando que este é apenas um exemplo, mas você pode adaptar os horários de acordo com sua real necessidade. Soldados Disponíveis: Shell Script e Cron Plano: Um pequeno e simples script em shell será executado nos dias e horários informados anteriormente de forma a fazer uma limpeza no cache. Execução: Primeiro criaremos o script que fará a ação de limpeza do cache. Para isso abra o editor de textos de sua preferência. Particularmente prefiro o vim, mas este pode ser substituido por qualquer outro. No seu corpo insira o seguinte conteúdo: #!/bin/bash #limpando cache #o seguinte comando é o responsável pela limpeza echo 3 \u003e /proc/sys/vm/drop_caches Feito isto, salve o arquivo com o nome de limpacache.sh Sim, isto é tudo o que o seu script precisa. Com o script criado, você deverá agora lhe dar condições de execução. Utilize o seguinte comando: chmod a+x limpacache.sh Agora que ele está pronto e com permissão de execução, iremos agendar a execução do mesmo. No terminal digite: crontab -e Isto irá abrir um arquivo no qual você deverá fazer o agendamento de sua tarefa. No mesmo insira o seguinte conteúdo: # mm HH DD MM DS tarefa 00 08 * * * /usr/bin/scripts/limpacache.sh 00 14 * * * /usr/bin/scripts/limpacache.sh Ps: O caminho /etc/scripts/ precisa ser configurado de acordo com o caminho utilizado por você. ;] Pronto. Pode salvar e encerrar este aquivo. Traduzindo o comando as linhas do cron que utilizamos: mm: minutos HH: horas DD: dia MM: mês DS: dia da semana /usr/bin/scripts/limpacache.sh: tarefa a ser realizada Feito isto, o plano está concretizado. Seu script será executado todos os dias nestes dois horários. Sinta-se livre agora para customizar os dias e horários da maneira que for mais conveniente para você. Abraços ","date":"2008-07-14","objectID":"/posts/parte-ii-limpando-memoria-cache/:0:0","tags":["Linux","Redes","Software Livre"],"title":"Parte II Limpando Memória Cache De Forma Automatizada","uri":"/posts/parte-ii-limpando-memoria-cache/"},{"categories":["Tutoriais"],"content":"Aqueles que são administradores de redes e servidores já devem ter passado por problemas parecidos com este. Nesta dica irei apresentar um comando simples para limpar sua memória em cache.","date":"2008-07-09","objectID":"/posts/limpando-o-cache-de-forma/","tags":["Linux","Redes","Software Livre"],"title":"Limpando O Cache De Forma Rápida","uri":"/posts/limpando-o-cache-de-forma/"},{"categories":["Tutoriais"],"content":"Aqueles que são administradores de redes e servidores já devem ter passado por problemas parecidos com este. Nesta dica irei apresentar um comando simples para limpar sua memória em cache. Resolvi escrever sobre isto por ter visto duas vezes na mesma semana problemas relacionados a isso. Um foi aqui mesmo onde trabalho, onde estávamos percebendo que o consumo de memória em um dos servidores estava muito alto, porém com pouca atividade no mesmo, no qual percebi que nada mais era do que muita memória alocada em cache sem necessidade no momento. Desenvolvedores java…vai entender.. hauhauha (brincadeira.. :p). Outro caso foi uma dúvida que surgiu, bem parecida, em um fórum do qual faço parte, onde um rapaz estava passando pelo mesmo problema no servidor dele… Com consumo exagerado de memória. Ele até colou o resultado do top no qual podíamos ver claramente que não haviam processos consumindo tudo aquilo de memória, e mais uma vez pudemos ver que o grande vilão era o cache, o que lhe passava essa impressão de memória totalmente consumida. O comando para se limpar este chache é o seguinte: # echo 3 \u003e /proc/sys/vm/drop_caches Exemplo: Aqui vai uma saída do meu top antes de rodar o comando. ( Reparem no consumo de memória armazenada em Cache na última linha!) top - 09:40:03 up 1:42, 1 user, load average: 0.06, 0.20, 0.20 Tasks: 83 total, 2 running, 80 sleeping, 0 stopped, 1 zombie Cpu(s): 4.3%us, 0.5%sy, 0.2%ni, 95.0%id, 0.0%wa, 0.0%hi, 0.0%si, 0.0%st Mem: 1944240k total, 898916k used, 245324k free, 51176k buffers Swap: 996020k total, 0k used, 996020k free, 969000k cached Repare agora o resultado obtido pelo top depois de executar o comando para limpar o cache: top - 09:45:03 up 1:47, 1 user, load average: 0.32, 0.16, 0.17 Tasks: 85 total, 3 running, 81 sleeping, 0 stopped, 1 zombie Cpu(s): 11.2%us, 1.5%sy, 0.0%ni, 63.4%id, 23.9%wa, 0.0%hi, 0.0%si, 0.0%st Mem: 1944240k total, 329412k used, 1614828k free, 768k buffers Swap: 996020k total, 0k used, 996020k free, 69088k cached A memória armazenada em cache caiu de ~969mb para ~69mb. ;] Bingo! ","date":"2008-07-09","objectID":"/posts/limpando-o-cache-de-forma/:0:0","tags":["Linux","Redes","Software Livre"],"title":"Limpando O Cache De Forma Rápida","uri":"/posts/limpando-o-cache-de-forma/"},{"categories":["Impressões"],"content":"Para quem não conhece, o OpenOffice.org é um software livre que possui uma suíte completa de aplicativos de escritório como editor de textos, planilhas, fórmulas matemáticas, apresentação de slides, etc... Mas o objetivo não é apenas lembrar o OpenOffice.org, mas sim todos os softwares que utilizo diariamente e que possuem uma característica em comum: Software Livre. Então não custa nada lembrar deles, os programadores, que dedicaram tanto tempo na construção de uma ferramenta e hoje nos disponibilizam.","date":"2008-06-28","objectID":"/posts/porque-lembrar-nao-custa-nada/","tags":["Cultura Hacker","Impressões","Linux","Software Livre"],"title":"Porque Lembrar Não Custa Nada","uri":"/posts/porque-lembrar-nao-custa-nada/"},{"categories":["Impressões"],"content":"Saudações pessoas… Estava eu hoje começando a escrever um artigo para a segunda edição do Almanarch, quando bateu uma sede e levantei para beber água. Ao voltar para minha cadeira, lembrei de algo assim que bati os olhos em minha tela com o OpenOffice.org aberto. Porquê não lembrar deles? Para quem não conhece, o OpenOffice.org é um software livre que possui uma suíte completa de aplicativos de escritório como editor de textos, planilhas, fórmulas matemáticas, apresentação de slides, etc… Mas o objetivo não é apenas lembrar o OpenOffice.org, mas sim todos os softwares que utilizo diariamente e que possuem uma característica em comum: Software Livre. Então não custa nada lembrar deles, os programadores, que dedicaram tanto tempo na construção de uma ferramenta e hoje nos disponibilizam. Abaixo segue a descrição de Software Livre pela GNU Foundation. ","date":"2008-06-28","objectID":"/posts/porque-lembrar-nao-custa-nada/:0:0","tags":["Cultura Hacker","Impressões","Linux","Software Livre"],"title":"Porque Lembrar Não Custa Nada","uri":"/posts/porque-lembrar-nao-custa-nada/"},{"categories":["Impressões"],"content":"O que é o Software Livre? Nós mantemos esta definição do Software Livre para mostrar claramente o que deve ser verdadeiro à respeito de um dado programa de software para que ele seja considerado software livre. “Software Livre” é uma questão de liberdade, não de preço. Para entender o conceito, você deve pensar em “liberdade de expressão”, não em “cerveja grátis”. “Software livre” se refere à liberdade dos usuários executarem, copiarem, distribuírem, estudarem, modificarem e aperfeiçoarem o software. Mais precisamente, ele se refere a quatro tipos de liberdade, para os usuários do software: A liberdade de executar o programa, para qualquer propósito (liberdade no. 0) A liberdade de estudar como o programa funciona, e adaptá-lo para as suas necessidades (liberdade no. 1). Acesso ao código-fonte é um pré-requisito para esta liberdade. A liberdade de redistribuir cópias de modo que você possa ajudar ao seu próximo (liberdade no. 2). A liberdade de aperfeiçoar o programa, e liberar os seus aperfeiçoamentos, de modo que toda a comunidade se beneficie (liberdade no. 3). Acesso ao código-fonte é um pré-requisito para esta liberdade. Um programa é software livre se os usuários tem todas essas liberdades. Portanto, você deve ser livre para redistribuir cópias, seja com ou sem modificações, seja de graça ou cobrando uma taxa pela distribuição, para qualquer um em qualquer lugar. Ser livre para fazer essas coisas significa (entre outras coisas) que você não tem que pedir ou pagar pela permissão. Você deve também ter a liberdade de fazer modifcações e usá-las privativamente no seu trabalho ou lazer, sem nem mesmo mencionar que elas existem. Se você publicar as modificações, você não deve ser obrigado a avisar a ninguém em particular, ou de nenhum modo em especial. A liberdade de utilizar um programa significa a liberdade para qualquer tipo de pessoa física ou jurídica utilizar o software em qualquer tipo de sistema computacional, para qualquer tipo de trabalho ou atividade, sem que seja necessário comunicar ao desenvolvedor ou a qualquer outra entidade em especial. A liberdade de redistribuir cópias deve incluir formas binárias ou executáveis do programa, assim como o código-fonte, tanto para as versões originais quanto para as modificadas. Está ok se não for possível produzir uma forma binária ou executável (pois algumas linguagens de programação não suportam este recurso), mas deve ser concedida a liberdade de redistribuir essas formas caso seja desenvolvido um meio de cria-las. De modo que a liberdade de fazer modificações, e de publicar versões aperfeiçoadas, tenha algum significado, deve-se ter acesso ao código-fonte do programa. Portanto, acesso ao código-fonte é uma condição necessária ao software livre. Para que essas liberdades sejam reais, elas tem que ser irrevogáveis desde que você não faça nada errado; caso o desenvolvedor do software tenha o poder de revogar a licença, mesmo que você não tenha dado motivo, o software não é livre. Entretanto, certos tipos de regras sobre a maneira de distribuir software livre são aceitáveis, quando elas não entram em conflito com as liberdades principais. Por exemplo, copyleft (apresentado de forma bem simples) é a regra de que, quando redistribuindo um programa, você não pode adicionar restrições para negar para outras pessoas as liberdades principais. Esta regra não entra em conflito com as liberdades; na verdade, ela as protege. Portanto, você pode ter pago para receber cópias do software GNU, ou você pode ter obtido cópias sem nenhum custo. Mas independente de como você obteve a sua cópia, você sempre tem a liberdade de copiar e modificar o software, ou mesmo de vender cópias. “Software Livre” Não significa “não-comercial”. Um programa livre deve estar disponível para uso comercial, desenvolvimento comercial, e distribuição comercial. O desenvolvimento comercial de software livre não é incomum; tais softwares livres comerciais são muito importantes. Regras sobre como empacotar uma versão ","date":"2008-06-28","objectID":"/posts/porque-lembrar-nao-custa-nada/:1:0","tags":["Cultura Hacker","Impressões","Linux","Software Livre"],"title":"Porque Lembrar Não Custa Nada","uri":"/posts/porque-lembrar-nao-custa-nada/"},{"categories":["Aleatórios"],"content":"Ajude a sustentar a Wikipédia e outros projetos, sem colocar a mão no bolso, e concorra a um Eee PC!","date":"2008-06-24","objectID":"/posts/ajude-a-sustentar-a-wikipedia/","tags":["Impressões","Software Livre"],"title":"Ajude a Sustentar a Wikipedia E Concorra a Um Eee Pc","uri":"/posts/ajude-a-sustentar-a-wikipedia/"},{"categories":["Aleatórios"],"content":"Ajude a sustentar a Wikipédia e outros projetos, sem colocar a mão no bolso, e concorra a um Eee PC! …e também a pen drives, card drives, camisetas geeks, livros e mais! O BR-Linux e o Efetividade lançaram uma campanha para ajudar a Wikimedia Foundation e outros mantenedores de projetos que usamos no dia-a-dia on-line. Se você puder doar diretamente, ou contribuir de outra forma, são sempre melhores opções. Mas se não puder, veja as regras da promoção e participe - quanto mais divulgação, maior será a doação do BR-Linux e do Efetividade, e você ainda concorre a diversos brindes! Toda ajuda é bem vinda quando se trata de projetos livres que na maioria das vezes não possui uma renda fixa para investimento e gastos necessários para manter o mesmo, ficando na maioria das vezes este peso no bolso dos próprios mantenedores do mesmo. Esta Promoção do BR-Linux vem justamente incentivando esta ajuda e apoio, portanto não fique aí parado e divulgue você também. ;] ","date":"2008-06-24","objectID":"/posts/ajude-a-sustentar-a-wikipedia/:0:0","tags":["Impressões","Software Livre"],"title":"Ajude a Sustentar a Wikipedia E Concorra a Um Eee Pc","uri":"/posts/ajude-a-sustentar-a-wikipedia/"},{"categories":["Impressões"],"content":"Quem me conhece sabe que sou um aventureiro quando se trata de distribuições Linux. Sempre utilizei várias distros dos mais variados tipos passando pelo Conectiva, Slackware, Suse, Kurumin, Ubuntu, Kalango, Kubuntu, Debian, Fluxbuntu, Goblinx, Fedora, Big, dentre outros. Agora é a vez do Arch.","date":"2008-06-03","objectID":"/posts/minhas-primeiras-impressoes-com-o/","tags":["Arch Linux","Impressões","Linux"],"title":"Minhas Primeiras Impressões Com O Arch Linux","uri":"/posts/minhas-primeiras-impressoes-com-o/"},{"categories":["Impressões"],"content":"Quem me conhece sabe que sou um aventureiro quando se trata de distribuições Linux. Sempre utilizei várias distros dos mais variados tipos passando pelo Conectiva, Slackware, Suse, Kurumin, Ubuntu, Kalango, Kubuntu, Debian, Fluxbuntu, Goblinx, Fedora, Big, dentre outros. Agora é a vez do Arch. A simplicidade do Slackware sempre me fascinou, porém seu gerenciamento de pacotes me desanimou bastante há alguns anos atrás quando vi outras distribuições evoluindo tanto neste ponto como o Debian por exemplo. Foi quando fui fascinado pelo poder do apt-get/aptitude. Por outro lado, sempre gostei de ter os aplicativos mais atualizados e funcionando em minha máquina, e como esse não é o forte do Debian resolvi partir para distros baseadas nele, onde o Kubuntu se destacou ficando por mais tempo. Independente de minha máquina, também utilizo diariamente o Fedora, distribuição que utilizo no trabalho em minha estação. Diante de tantas mudanças, porque não tentar o Arch Linux agora? Há algum tempo ouço amigos falando sobre suas vantagens mas queria confirmar se era tudo verdade, ou apenas mais uma visão de usuário fanático por sua distro. E foi aí que tudo começou… Primeiramente parti para a filosofia e história do mesmo. Para quem não sabe, o Arch Linux foi criado em 2001 por Judd Vinet e, desde, então vem crescendo bastante. É uma distribuição rápida, leve, elegante e bastante flexível. No Brasil ainda é uma distro pouco conhecida e usada. Por ser otimizado para processadores i686, o Arch roda mais rápido que a maioria das distribuições que, por sua vez, utilizam pacotes para i386, porém por outro lado só roda em máquinas com processadores superiores ao pentium II. O Arch possui uma filosofia que se assemelha a do Slackware no estilo KISS, Keep It Simple Stupid, mantendo o sistema simples e bastante customizável de modo que pode-se configurar tudo possuindo um pouco de intimidade com o shell do Linux. Porém encontrei nele uma grande evolução com relação ao Slackware que resolveu se manter mais tradicional, enquanto que o Arch trouxe um gerenciador de pacotes chamado pacman. O pacman, de certa forma, lembra o apt-get/aptitude, com o qual é possível facilmente atualizar seu sistema, buscar, instalar ou remover pacotes de forma rápida e segura sem precisar se preocupar com problemas de dependências que o mesmo resolve por você corretamente. Sempre adorei ler, mas não ia ser uma simples leitura que me convenceria sobre o fato de o Arch ser uma boa distribuição Linux, mesmo porque em cinco minutos eu sou capaz de “criar” uma distribuição Kalib e escrever uma bela história sobre como ela funciona e torná-la assim a melhor distribuição Unix Like ou mesmo BSD, concorda? Sendo assim, parti para os primeiros testes reais. Como não queria particionar meu disco, pelo mesmo já ter muitas fatias, resolvi criar uma máquina virtual com o Arch Linux, utilizando para isto um aplicativo chamado Virtual Box. A instalação foi bem simples, sem maiores dificuldades, apesar de ser toda em modo texto sem as facilidades da interface gráfica, o que acaba por assustar um pouco os usuários iniciantes no mundo Linux. Sem maiores traumas passei pelo poucos passos de particionamento do disco, escolha dos pacotes e instalação dos mesmos. Após a instalação pude, ou melhor, TIVE que testar as habilidades do pacman no gerenciamento de pacotes. Porque TIVE? Bom, digamos que o Arch não traga muitos pacotes instalados por default. Tive de instalar as fontes, o xorg, interface gráfica (kdemod), driver de minha placa de áudio, driver de vídeo, etc… Mas nada que o pacman não tenha resolvido com bastante eficiência. ;] Fiquei surpreso com sua eficiência nesse momento. Após instalado, resolvi checar a eficiência de seus repositórios. Mandei o pacman instalar o amsn, apenas a nível de curiosidade para saber qual versão ele traria, e para minha surpresa ele me instalou a versão 0.97 que é a mais recente de todas, e que no kubuntu havia conseguido instalar apenas via svn. Realmente me ","date":"2008-06-03","objectID":"/posts/minhas-primeiras-impressoes-com-o/:0:0","tags":["Arch Linux","Impressões","Linux"],"title":"Minhas Primeiras Impressões Com O Arch Linux","uri":"/posts/minhas-primeiras-impressoes-com-o/"},{"categories":["Aleatórios"],"content":"Queremos estabelecer um Recorde Mundial no Guinness para o software mais baixado em 24 horas e com a sua ajuda temos certeza de que conseguiremos!","date":"2008-05-31","objectID":"/posts/ajude-o-firefox-a-estabelecer/","tags":["Firefox","Impressões","Software Livre"],"title":"Ajude O Firefox a Estabelecer Um Recorde Mundial","uri":"/posts/ajude-o-firefox-a-estabelecer/"},{"categories":["Aleatórios"],"content":"“Queremos estabelecer um Recorde Mundial no Guinness para o software mais baixado em 24 horas e com a sua ajuda temos certeza de que conseguiremos!” A Fundação Mozilla pretende bater este recorde e entrar para o Guinness Book e para isso está contando com o apoio dos usuários e fans da raposa de fogo no Download Day 2008. Mas o que isso tudo significa? A fundação Mozilla lançou um site para este projeto no qual podemos nos cadastrar e participar desta corrente. No dia do download a Mozilla encaminhará uma chamada para todos os cadastrados para que possam fazer seus respectivos downloads. O site ainda nos mostra em tempo real a quantidade de pessoas já cadastradas bem como um mapa do mundo com detalhes sobre quantas pessoas já se cadastraram em cada país de nosso globo. A iniciativa é excelente para divulgar um excelente Software Livre que já ganhou muitos adeptos, mesmo aqueles que nem conheciam o significado da palavra Software Livre. Lembrando também que todo e qualquer incentivo ao uso de Software Livre é bastante bem vindo em um país em desenvolvimento como o nosso, portanto vamos ajudar nessa campanha pessoal. ;] Para participar é muito simples, bastando apenas clicar no link a seguir, na raposa do início do post ou mesmo no baner que disponibilizei no topo do site. Link do projeto: Spread Firefox []’s ","date":"2008-05-31","objectID":"/posts/ajude-o-firefox-a-estabelecer/:0:0","tags":["Firefox","Impressões","Software Livre"],"title":"Ajude O Firefox a Estabelecer Um Recorde Mundial","uri":"/posts/ajude-o-firefox-a-estabelecer/"},{"categories":["Impressões"],"content":"Imaginemos o seguinte padrão: Softwares são programados através de uma linguagem. O que é Linguagem? É um conjunto de códigos que funciona como Meio de Comunicação, seja ele entre Humano / Humano ou Humano / Máquina por exemplo.","date":"2008-05-29","objectID":"/posts/por-que-usar-a-plataforma/","tags":["Cultura Hacker","Impressões","Linux","Software Livre"],"title":"Por Que Usar a Plataforma Livre","uri":"/posts/por-que-usar-a-plataforma/"},{"categories":["Impressões"],"content":"Imaginemos o seguinte padrão: Softwares são programados através de uma linguagem. O que é Linguagem? É um conjunto de códigos que funciona como Meio de Comunicação, seja ele entre Humano / Humano ou Humano / Máquina por exemplo. ","date":"2008-05-29","objectID":"/posts/por-que-usar-a-plataforma/:0:0","tags":["Cultura Hacker","Impressões","Linux","Software Livre"],"title":"Por Que Usar a Plataforma Livre","uri":"/posts/por-que-usar-a-plataforma/"},{"categories":["Impressões"],"content":"Introdução Então imaginemos que a língua portuguesa é como um Software, e precisamos dela para nos comunicar com outras pessoas, correto? Agora imagine você se os códigos da língua portuguesa fossem patenteados por alguém ou mesmo fechados. Além de você não ter livre acesso aos vários códigos que formam a língua portuguesa você ainda teria de pagar para quem a patenteou. Sim, você teria que pagar para falar! O que isto tudo importa para a informática? Bom, infelizmente a maioria dos softwares ou programas de computador vem enfrentando esta mesma situação no Brasil, pois é através do software que eu consigo me comunicar com meu computador, e a maioria das pessoas ainda tem de pagar para falar com seu computador. O mais absurdo é que o pagamento recolhido sequer fica no Brasil, pois é entregue para uma empresa no exterior que monopoliza o mercado. O Brasil paga cerca de R$ 1.000.000.000,00 (1 bilhão) por ano em troca desses softwares. Num sistema fechado, também não conseguimos desenvolver nossa própria autonomia tecnológica, pois não temos como estudar o seu código e não temos segurança de acesso e envio de informações em nossas próprias máquinas. Quem garante que naquele software fechado instalado em minha máquina não há junto um programa espião vasculhando minhas contas e arquivos pessoais? ","date":"2008-05-29","objectID":"/posts/por-que-usar-a-plataforma/:1:0","tags":["Cultura Hacker","Impressões","Linux","Software Livre"],"title":"Por Que Usar a Plataforma Livre","uri":"/posts/por-que-usar-a-plataforma/"},{"categories":["Impressões"],"content":"Software Livre No software livre você não tem obrigatoriedade de pagar nada a ninguém, desenvolvido por milhares de programadores ao redor do mundo, voluntários ou não, que compartilham seus códigos com o mundo, no software livre você usa produtos testados por milhares de pessoas que entendem do assunto e que procuraram de todas as formas possíveis, brechas, falhas, bugs e você mesmo pode ajudar nisso, você como usuário é parte importante da comunidade do software livre, sugerindo, reportando alguma falha, opinando, discutindo, ensinando e aprendendo, ou seja, o software livre vai além do uso da ferramenta, ele vai à democratização do conhecimento. Principais vantagens da utilização de Software Livre: Segurança (praticamente isento de vírus, você sabe o que está instalando em sua máquina, pois seu código é aberto) Economia (você pode baixar ele sem custo da internet, tanto o software quanto a sua documentação de uso) Alternativa à pirataria (você não corre riscos ao ser surpreendido por fiscais cobrando por licenças) Engajamento (você estará utilizando uma solução mais viável para um país em desenvolvimento como o Brasil) Autonomia (você tem liberdade para fazer o que quiser com este software desde que siga as 4 liberdades básicas a ele atribuídas) As 4 liberdades foram citadas no último post: “De onde vem o conceito de Software Livre”. SOFTWARE LIVRE! Socialmente Justo…Economicamente Viável…Tecnologicamente Sustentável. ","date":"2008-05-29","objectID":"/posts/por-que-usar-a-plataforma/:2:0","tags":["Cultura Hacker","Impressões","Linux","Software Livre"],"title":"Por Que Usar a Plataforma Livre","uri":"/posts/por-que-usar-a-plataforma/"},{"categories":["Impressões"],"content":"Diante de nossa atual situação tecnológica seria impossível falarmos de GNU Linux sem antes entendermos o que é Software Livre ou de onde surgiu essa filosofia.","date":"2008-05-23","objectID":"/posts/de-onde-vem-o-conceito/","tags":["Cultura Hacker","Impressões","Linux","Software Livre"],"title":"De Onde Vêm O Conceito De Software Livre","uri":"/posts/de-onde-vem-o-conceito/"},{"categories":["Impressões"],"content":"Diante de nossa atual situação tecnológica seria impossível falarmos de GNU Linux sem antes entendermos o que é Software Livre ou de onde surgiu essa filosofia. ","date":"2008-05-23","objectID":"/posts/de-onde-vem-o-conceito/:0:0","tags":["Cultura Hacker","Impressões","Linux","Software Livre"],"title":"De Onde Vêm O Conceito De Software Livre","uri":"/posts/de-onde-vem-o-conceito/"},{"categories":["Impressões"],"content":"Introdução Durante muito tempo a tecnologia vem se desenvolvendo e tornando-se cada vez mais necessária para os dias atuais. Para tal evolução, pessoas do mundo inteiro, chamadas programadores, contribuíram de forma significativa criando programas ou softwares para customizar o funcionamento dos computadores. Em boa parte desta evolução, ao precisar de algo que outro já criou, o programador receberia prontamente deste outro para assim poder fazer suas devidas mudanças ou mesmo aperfeiçoamentos poupando-lhe esforço e tempo. O autor original como agradecimento recebia seu programa melhorado. Porque refazer o que já foi feito antes? Desta forma se dava a troca de informações e conhecimento entre a comunidade como um todo até que uma outra idéia surgiu: Fechar o código fonte e ganhar dinheiro em cima disso. ","date":"2008-05-23","objectID":"/posts/de-onde-vem-o-conceito/:1:0","tags":["Cultura Hacker","Impressões","Linux","Software Livre"],"title":"De Onde Vêm O Conceito De Software Livre","uri":"/posts/de-onde-vem-o-conceito/"},{"categories":["Impressões"],"content":"Dinheiro falou alto Foi nesta época que o conhecimento passou a deixar de ser livre passando a ter um dono e uma patente em cima do mesmo. Sendo vendido em caixas com a permissão para instalação em apenas uma máquina limitando-se ao uso técnico sem poder estudar aquela tecnologia a fundo ou repassar para outros interessados. Aí mostrava-se o limite da tecnologia como uma linha que não se podia ultrapassar, já que você não mais poderia aperfeiçoar um software adaptando-o às suas necessidades por não mais ter acesso ao código fonte do mesmo. O conhecimento passou a ser então manipulado e controlado criando uma enorme dependência tecnológica. ","date":"2008-05-23","objectID":"/posts/de-onde-vem-o-conceito/:2:0","tags":["Cultura Hacker","Impressões","Linux","Software Livre"],"title":"De Onde Vêm O Conceito De Software Livre","uri":"/posts/de-onde-vem-o-conceito/"},{"categories":["Impressões"],"content":"Richard Stallman inicia um movimento Em meados de 1983-1984 o programador americano Richard Stallman percebeu que o senso de união e integração estava perdendo espaço para um senso de egoísmo e monopólio passando assim a iniciar um movimento ativista criando assim o Projeto GNU em 1985 defendendo a idéia do Software Livre. Por que refazer todo um programa quando você tinha programas parecidos com o que você queria desenvolver? Por que não ajudar em um programa que você achava que estava rodando lento e que possivelmente saberia como deixa-lo mais rápido contribuindo assim para o seu código fonte? Essas perguntas não faziam sentido para o Richard, e por essas e outras ele começou este projeto, que de tão óbvio que era, rapidamente caiu na simpatia de toda a comunidade. A partir daí milhares de pessoas espalhadas pelo mundo inteiro uniram-se a ele nessa luta de forma a mostrar ao mundo que o compartilhamento da informação é fundamental para o desenvolvimento assim como a união e a solidariedade. Para tal filosofia foram criadas algumas regras que na verdade são liberdades. Não poderia ser diferente tratando-se de Software LIVRE. São as 4 liberdades do Software Livre listadas abaixo: Liberdade de executar o programa, da forma como quiser. * Liberdade de estudar o funcionamento do programa podendo inclusive modificá-lo de acordo com sua necessidade. * Liberdade de redistribuir cópias do programa livremente. * Liberdade de melhorar o programa e tornar estas melhorias públicas de forma a beneficiar o próximo. O projeto GNU não é somente desenvolvimento e distribuição de alguns softwares livres úteis. O coração do projeto GNU é uma idéia: que software deve ser livre__, e que a liberdade do usuário vale a pena ser defendida. Se as pessoas têm liberdade mas não a apreciam conscientemente, não irão mantê-la por muito tempo. Se queremos que a liberdade dure, precisamos chamar a atenção das pessoas para a liberdade que elas têm em programas livres. Com o passar dos anos, e baseado nessa filosofia do Software Livre, surgiu então o sistema operacional que hoje chamamos de GNU / Linux. ","date":"2008-05-23","objectID":"/posts/de-onde-vem-o-conceito/:3:0","tags":["Cultura Hacker","Impressões","Linux","Software Livre"],"title":"De Onde Vêm O Conceito De Software Livre","uri":"/posts/de-onde-vem-o-conceito/"},{"categories":["Tutoriais"],"content":"Aqui segue uma rápida dica que poderá ajudar aqueles que, assim como eu, instalaram o *buntu 8.04 e perceberam que o mesmo possui o Firefox 3.0 em seus repositórios como o navegador padrão.","date":"2008-05-07","objectID":"/posts/jre-buntu804/","tags":["Firefox","Java","Kubuntu","Linux","Software Livre"],"title":"Configurando a Jre Para Funcionar No *Buntu 8.04 Com Firefox 3","uri":"/posts/jre-buntu804/"},{"categories":["Tutoriais"],"content":"Aqui segue uma rápida dica que poderá ajudar aqueles que, assim como eu, instalaram o *buntu 8.04 e perceberam que o mesmo possui o Firefox 3.0 em seus repositórios como o navegador padrão. ","date":"2008-05-07","objectID":"/posts/jre-buntu804/:0:0","tags":["Firefox","Java","Kubuntu","Linux","Software Livre"],"title":"Configurando a Jre Para Funcionar No *Buntu 8.04 Com Firefox 3","uri":"/posts/jre-buntu804/"},{"categories":["Tutoriais"],"content":"O problema Bom, ao tentar instalar, desde ontem, o plugin do java para poder acessar minha página do banco, encontrei uma solução bem simples depois de várias tentativas frustradas. Após tentar tudo que sempre utilizei como por exemplo baixar o pacote jre diretamente do site da sun, descompactar no diretório /usr/java (como sempre fiz por questão de organização), instalar e criar um link simbólico para o mesmo no diretório de plugins do Firefox, e mesmo assim não ter nenhum resultado concreto, pesquisei um pouco e achei uma solução bem mais simples e rápida. ","date":"2008-05-07","objectID":"/posts/jre-buntu804/:1:0","tags":["Firefox","Java","Kubuntu","Linux","Software Livre"],"title":"Configurando a Jre Para Funcionar No *Buntu 8.04 Com Firefox 3","uri":"/posts/jre-buntu804/"},{"categories":["Tutoriais"],"content":"A solução Basta descomentar as linhas referentes aos mirrors multiverse nos seus repositórios (/etc/apt/sources.list), dar um update (# aptitude update) e em seguida instalar os pacotes com o seguinte comando: # aptitude install sun-java6-jre sun-java6-plugin sun-java6-fonts Feito isto reinicie o firefox e digite em sua barra de endereços: about:plugins Deverá agora constar em sua lista de plugins os referentes ao java. ;] Outro teste é digitar no seu console: $ java -version Você deverá ter um retorno similar a este: java version \"1.6.0_06\" Java(TM) SE Runtime Environment (build 1.6.0_06-b02) Java HotSpot(TM) Client VM (build 10.0-b22, mixed mode, sharing) Ou mesmo acessando alguma página que se utilize de java como o teclado virtual do Banco do Brasil por exemplo. Bom, espero ter ajudado com esta simples, porém eficiente dica. Abraços ","date":"2008-05-07","objectID":"/posts/jre-buntu804/:2:0","tags":["Firefox","Java","Kubuntu","Linux","Software Livre"],"title":"Configurando a Jre Para Funcionar No *Buntu 8.04 Com Firefox 3","uri":"/posts/jre-buntu804/"},{"categories":["Tutoriais"],"content":"Novamente estou aqui para lhes passar uma pequena dica que para muitos pode nem ser novidade, porém para alguns a dúvida pode existir.","date":"2008-05-03","objectID":"/posts/vantagem-aptitude/","tags":["Aptitude","Debian","Linux","Software Livre"],"title":"Vantagem Do Aptitude Sobre O Apt Get","uri":"/posts/vantagem-aptitude/"},{"categories":["Tutoriais"],"content":"Novamente estou aqui para lhes passar uma pequena dica que para muitos pode nem ser novidade, porém para alguns a dúvida pode existir. ","date":"2008-05-03","objectID":"/posts/vantagem-aptitude/:0:0","tags":["Aptitude","Debian","Linux","Software Livre"],"title":"Vantagem Do Aptitude Sobre O Apt Get","uri":"/posts/vantagem-aptitude/"},{"categories":["Tutoriais"],"content":"Introdução Bom, para aqueles que ainda não sabem, o apt é uma ferramenta da Debian para gerenciamento de pacotes de forma simples, amigável e rápida contando inclusive com a instalação automática de dependências necessárias para a finalização do processo. O que muitas pessoas ainda não sabem é que utilizando-se do comando “apt-get install NOME_PACOTE” serão instalados pacotes que o mesmo não removerá automaticamente posteriormente, fazendo assim um acúmulo de “lixo” em nosso sistema. Como assim? Suponhamos que eu queira instalar um aplicativo de instant messenger como por exemplo o amsn. Esta ferramenta possui dependências necessárias para seu funcionamento, sendo elas o TCL e o TK. O seguinte comando fará a instalação do amsn juntamente com suas dependências, sem que eu precise me preocupar em buscar por elas desesperadamente na internet: #apt-get install amsn Ótimo! Agora tenho o meu messenger devidamente instalado, sem nenhuma dificuldade e funcionando perfeitamente. Porém, um certo dia resolvi remover essa ferramenta que com o tempo parei de usar, então para isso utilizo o seguinte comando: #apt-get remove amsn Perfeito! Meu amsn está desinstalado sem dificuldade alguma. ;] Agora, e o que acontece com os dois pacotes que foram instalados juntamente com ele anteriormente? TCL e TK? Bom, eles continuam instalados, fazendo um certo acúmulo de “lixo” em seu sistema. O mesmo ocorre com todos os pacotes que forem instalados em seu sistema e futuramente removidos com o apt-get. Onde entra o Aptitude nessa história? ","date":"2008-05-03","objectID":"/posts/vantagem-aptitude/:1:0","tags":["Aptitude","Debian","Linux","Software Livre"],"title":"Vantagem Do Aptitude Sobre O Apt Get","uri":"/posts/vantagem-aptitude/"},{"categories":["Tutoriais"],"content":"Aptitude Bom, o aptitude tem um funcionamento bem semelhante para a instalação de pacotes. Passaremos a adotar o mesmo cenário aqui, instalando portanto o amsn: #aptitude install amsn Assim como o apt-get, o aptitude irá instalar automaticamente as dependências do amsn, TCL e TK. Passado algum tempo, resolvo remover o amsn usando o seguinte comando: #aptitude remove amsn Aparentemente ele terá o mesmo efeito do apt-get, com o grande diferencial de excluir juntamente com o amsn, as suas dependências que outrora foram instaladas, TCL e TK. Imagine a quantidade de pacotes desnecessários que deve existir em sua máquina…provavelmente vários. O aptitude é uma solução para que isto não ocorra mais. Para os fans de distribuições como o Fedora que utilizam-se da ferramenta Yum para instalar seus pacotes, caso tenha surgido a curiosidade, fica a informação de que, infelizmente, o yum ainda não possui este mecanismo. A mesma curiosidade surgiu em mim e resolvi testar, porém o yum, assim como o apt-get, apenas me removeu o amsn, deixando para trás as dependências que foram instaladas. Essa foi uma simples dica para aqueles que desconheciam este fato diferencial dentre os dois. Espero ter ajudado com esta pequena contribuição para com a comunidade. abraços e até a próxima. ","date":"2008-05-03","objectID":"/posts/vantagem-aptitude/:2:0","tags":["Aptitude","Debian","Linux","Software Livre"],"title":"Vantagem Do Aptitude Sobre O Apt Get","uri":"/posts/vantagem-aptitude/"},{"categories":["Impressões"],"content":"Assim que saiu o Kubuntu 8.04 oficialmente, corri para baixar a iso antes mesmo de ser divulgado no site oficial como forma de evitar pegar uma banda completamente congestionada por centenas de pessoas baixando o mesmo arquivo na mesma fonte. Sim, existem algumas vantagens em se fazer parte das listas de discussão, desenvolvimento e debugs.","date":"2008-04-29","objectID":"/posts/kubuntu-804/","tags":["Impressões","Kubuntu","Software Livre"],"title":"Kubuntu 8.04 - Minhas Primeiras Impressões","uri":"/posts/kubuntu-804/"},{"categories":["Impressões"],"content":"Assim que saiu o Kubuntu 8.04 oficialmente, corri para baixar a iso antes mesmo de ser divulgado no site oficial como forma de evitar pegar uma banda completamente congestionada por centenas de pessoas baixando o mesmo arquivo na mesma fonte. Sim, existem algumas vantagens em se fazer parte das listas de discussão, desenvolvimento e debugs. :p ","date":"2008-04-29","objectID":"/posts/kubuntu-804/:0:0","tags":["Impressões","Kubuntu","Software Livre"],"title":"Kubuntu 8.04 - Minhas Primeiras Impressões","uri":"/posts/kubuntu-804/"},{"categories":["Impressões"],"content":"Introdução Bom, apenas consegui tempo para instalar de fato, na madrugada de domingo/segunda pois o fim de semana foi muito corrido e tornou-se impossível realizar esta tarefa que há tanto tempo eu esperava. Porque tamanha espera? Digamos que as versões anteriores do Kubuntu não me deixaram satisfeito por questões de incompatibilidades com minha placa de áudio e como consequência tive de me manter na versão 6.06 até antes de ontem. Deixando de blablabla vamos ao que interessa. ","date":"2008-04-29","objectID":"/posts/kubuntu-804/:1:0","tags":["Impressões","Kubuntu","Software Livre"],"title":"Kubuntu 8.04 - Minhas Primeiras Impressões","uri":"/posts/kubuntu-804/"},{"categories":["Impressões"],"content":"Compatibilidade com Hardware Logo ao dar boot no live cd do kubuntu 8.04, desde sua primeira beta test, pude constatar que haviam melhorias com relação ao reconhecimento de meu hardware. Tudo havia sido reconhecido automaticamente, desde minha placa de áudio ATI até meu dispositivo wireless da Atheros. Desde então estive numa espera pela release final, porém sempre baixando as versões beta bem como alpha para testes e ajudar com alguns bugs que por ventura eu viesse a encontrar. ","date":"2008-04-29","objectID":"/posts/kubuntu-804/:2:0","tags":["Impressões","Kubuntu","Software Livre"],"title":"Kubuntu 8.04 - Minhas Primeiras Impressões","uri":"/posts/kubuntu-804/"},{"categories":["Impressões"],"content":"Softwares Logo que instalei a versão final nesta madrugada, parti para a instalação de alguns pacotes básicos de sobrevivência como o firefox por exemplo. Minha surpresa aqui foi em ver que nos repositórios havia a raposa em sua versão beta 3.0 como padrão. o.O Apesar do susto que levei em ver o kubuntu trazendo por default uma versão beta, fiquei animado em poder testá-la já que ainda não havia encontrado tempo para isso. Instalei e pude ver claras melhorias em relação às demais versões de nossa raposa de fogo. Sem grandes dificuldades consegui instalar os plugins de java e flash, já que esta versão do firefox ainda não consegue instalar automaticamente. Fui adiconando alguns outros aplicativos que uso no meu dia-a-dia como o amsn, em sua versão 0.98, thunderbird, xchat, yakuake, kooldock, eclipse, dia, gimp, jsms, etc… Tudo funcionando redondinho e com uma performance bastante estável. A única coisa que pesou um pouco a nível de memória foi ao instalar o compiz e adicionar alguns efeitos, porém admito que nunca curti essas “frescuras” e instalei apenas a nível de teste, já que até a versão 7.10, o kubuntu não conseguia reconhecer minha placa de vídeo por default. Fiquei surpreso como até nisso ele se saiu bem. Reconheceu minha placa, instalou automaticamente o driver e o compiz juntamente. Em poucos segundos eu estava com os efeitos do compiz habilitados. Porém minha máquina é modesta e isso pesou um pouco para mim no quesito memória. Mas como disse antes, nunca fui fã dessas “frescuras” e logo desabilitei o compiz deixando novamente meu notebook respirar. Vou seguindo com meu segundo dia de testes no kubuntu 8.04 e veremos no que essa parceria kalib/kubuntu vai dar. ","date":"2008-04-29","objectID":"/posts/kubuntu-804/:3:0","tags":["Impressões","Kubuntu","Software Livre"],"title":"Kubuntu 8.04 - Minhas Primeiras Impressões","uri":"/posts/kubuntu-804/"},{"categories":["Eventos"],"content":"Mais um ano chega e novamente estamos envolvidos com as vibrações que o Flisol sempre nos proporciona.","date":"2008-04-22","objectID":"/posts/flisol-fortaleza-2008/","tags":["Flisol","Linux","Software Livre"],"title":"Flisol Fortaleza 2008","uri":"/posts/flisol-fortaleza-2008/"},{"categories":["Eventos"],"content":"Mais um ano chega e novamente estamos envolvidos com as vibrações que o Flisol sempre nos proporciona. Para aqueles que não conhecem ainda, o Flisol, Festival Latino Americano de Instalação de Software Livre, acontece anualmente em mais de 15 países da América-Latina simultaneamente. Logo em sua primeira edição, em 2005, Fortaleza saiu consagrada como tendo sido a cidade com o maior Flisol dentre as mais de 100 cidades latinoamericanas envolvidas no evento. O evento se resume em fazer instalações de software livre em máquinas de visitantes ou curiosos em conhecer um pouco da filosofia bem como funcionalidade desta vasta gama de possibilidades que é o Mundo do Software Livre. Apesar disto, desde sua primeira edição, aqui em Fortaleza procuramos sempre fazer uma grade recheada de palestras, workshops, atividades ou mini-cursos de forma a trazer uma maior vivência e compreensão aos visitantes que buscam ali muitas vezes mais do que um simples conhecimento introdutório. Focando o público iniciante, o evento deste ano está repleto de boas palestras para este tipo de público como forma de garantir que todos saiam de lá conhecendo a filosofia do software livre bem como a sua importância. O evento deste ano será no dia 26 de Abril (Sábado) das 9:00 às 17:00 na Faculdade Evolução: Rua Pedro I, 1276 - Centro. (Clique na foto para ampliar) A entrada é gratuita, porém incentivamos fortemente que sejam trazidos 2 kilos de alimentos não perecíveis, já que todo ano o Flisol Fortaleza ajuda alguma instituição com esta arrecadação. Além das palestras, teremos o tradicional install fest onde os visitantes poderão trazer suas máquinas para ter instalados nela softwares livres dos mais diversos tipos gratuitamente com o acompanhamento de pessoas da comunidade com bastante experiência no assunto, bem como tirar suas dúvidas sobre o assunto. Nos stands das comunidades também estarão sendo distribuídos cds com distribuições Linux bem como Softwares Livres diversos dentre outros brindes. Quem quizer ver fotos de versões passadas do Flisol em Fortaleza, abaixo disponibilizo links: Flisol 2006 Flisol 2007 Abaixo segue a grade de palestras do evento deste ano. 09:00 – ABERTURA DO EVENTO 10:00 Sala 1 - Esperanto, Língua Livre - Humberto Xis Sala 2 – Slackware 12 e suas novidades – Luiz Antonio Oliveira Sala 3 – Apresentação da ferramenta eGroupWare – Fernando Chucre Sala 4 - OpenSocial: Construa a sua rede social - Christiano Milfont 11:00 Sala 1- Inclusão Sócio-digital para a cidadania: O uso do Software Livre na Educação pública nos LIES municipais – Sinara Duarte Sala 2 - Firefox: Domine a raposa de fogo – Rafael Siqueira Telles Vieira Sala 3 - Programação Orientada a Objetos com Java – Alessandro Moreira Sala 4 – Mais que um Linux, um Big Linux – Lucas Filho 12:00 – INTERVALO 14:00 Sala 1 - Movimentos de software e cultura livre no estado – Uirá Porã Sala 2 - Gimp - Tratamento de imagens – Lucas Filho Sala 3 - P\u0026D e Software Livre – Alex Torquato Souza Carneiro Sala 4 – I Encontro de Desenvolvedores de Jogos do Ceará – David Ferreira 15:00 Sala 1 – Economia Solidária – Kelma Nunes Sala 2 - K3B: Gravação e Ripagem no Linux - Rafael Siqueira Telles Vieira Sala 3 – Mini-Curso Shell Script – Osvaldo Filho 16:00 Sala 1 - Sistema de HelpDek/ServiceDesk OpenSource Ocomon – Rafael Barreira Maia Sala 2 - BrOffice.org do básico ao avançado – Lucas Filho Sala 3 - Introdução a Desenvolvimento e Linguagens de Programação – Rafael de Carvalho Farias Local: Rua Pedro I, 1276 - Centro Horário: 09:00 - 17:00 Inscrições: https://flisol-ce.890m.com ","date":"2008-04-22","objectID":"/posts/flisol-fortaleza-2008/:0:0","tags":["Flisol","Linux","Software Livre"],"title":"Flisol Fortaleza 2008","uri":"/posts/flisol-fortaleza-2008/"},{"categories":["Impressões"],"content":"Pode parecer estranho mas de fato este título já deve ter passado pela cabeça de muitos administradores de redes/infra-estruturas empresariais.","date":"2008-04-16","objectID":"/posts/seguranca-particular/","tags":["Impressões","Segurança"],"title":"Procura-se Segurança Particular","uri":"/posts/seguranca-particular/"},{"categories":["Impressões"],"content":"Pode parecer estranho mas de fato este título já deve ter passado pela cabeça de muitos administradores de redes/infra-estruturas empresariais. Por incrível que pareça, ainda nos dias de hoje, o administrador de redes é muitas vezes visto pelos demais funcionários da empresa com um certo desprezo. Porquê? Bom, basicamente é pelo fato de ele fazer o que é pago para fazer. Como um carcará voando sob a presa, o administrador gera medo e raiva nos demais funcionários pelo fato de ter que policiar e capturar atos que vão contra as políticas do local de trabalho. Vida ingrata e ao mesmo tempo honrosa a de quem precisa fazer valer a regra existente. Este é o principal motivo pelo qual Precisa-se de segurança particular. Por incrível que pareça, já ouvi história de administradores de redes que encontraram seus pneus furados sem “motivo algum” pessoalmente falando. Diariamente somos torturados por pessoas reclamando que serviço X está lento ou que acesso Y está impossível de se realizar. Porém ao fazer uma breve análise das possíveis causas, constantemente percebemos que os causadores são os mesmos que estão reclamando. E como eles causam isso? Acessando sites de jogos online, pornografia, downloads dentre outros tipos de acessos indevidos que consomem banda de internet ou mesmo recursos do servidor onde muitas vezes seus colegas de trabalho acabam se prejudicando. Até aí não haveria problema, concordam? Bastaria matar os processos deste indivíduo ou mesmo sua sessão. Porém, o que eles não sabem é que, há uma enorme cobrança da diretoria da empresa para com o lado responsável pela administração de redes e infra estrutura. Os diretores nos cobram cada vez mais uma estabilidade no ambiente de produção e quando acontece um problema desse tipo, eles querem uma respota concreta, que envolve uma causa bem como uma solução do problema apresentado. Para isto temos que acabar por literalmente mostrar o que(quem) está atrapalhando o andamento dos processos da empresa e como o faz. Sim. Geralmente somos mal vistos na empresa. Deuses, assim alguns nos chamam, como nos tempos da Grécia Antiga. Onipotentes e onipresentes são estes seres aos quais os mortais apenas podem orar tementes aos castigos que lhes podem ser lançados. Abraços pessoal ","date":"2008-04-16","objectID":"/posts/seguranca-particular/:0:0","tags":["Impressões","Segurança"],"title":"Procura-se Segurança Particular","uri":"/posts/seguranca-particular/"},{"categories":["Impressões"],"content":"Com a evolução da informática e a solidificação dos sistemas de informação na comunidade um personagem passa a ter maior visibilidade em nossa comunidade ocupando um espaço no palco principal.","date":"2008-04-15","objectID":"/posts/cultura-hacker/","tags":["Cultura Hacker","Segurança","Software Livre"],"title":"Cultura Hacker - Tenha Ética E Ganharás Respeito","uri":"/posts/cultura-hacker/"},{"categories":["Impressões"],"content":"Com a evolução da informática e a solidificação dos sistemas de informação na comunidade um personagem passa a ter maior visibilidade em nossa comunidade ocupando um espaço no palco principal. Nota Como a Cultura Hacker carece de uma definição universal, compartilho aqui minha perspectiva pessoal, fundamentada em experiências e reflexões - não como verdade absoluta, mas como um ponto de partida para o diálogo. ","date":"2008-04-15","objectID":"/posts/cultura-hacker/:0:0","tags":["Cultura Hacker","Segurança","Software Livre"],"title":"Cultura Hacker - Tenha Ética E Ganharás Respeito","uri":"/posts/cultura-hacker/"},{"categories":["Impressões"],"content":"Introdução Com a evolução da informática e a solidificação dos sistemas de informação na comunidade um personagem passa a ter maior visibilidade em nossa comunidade ocupando um espaço no palco principal. Os hackers, ou erroneamente conhecidos como Piratas da Rede, vem tendo sua imagem atrelada à cibercriminosos com conhecimentos avançados sobre as tecnologias de redes e computação, aproveitando-se justamente das redes de comunicação para a pratica de delitos das mais diversas formas causando danos à terceiros de todos os níveis com o objetivo de simplesmente destruir dados e informações ou mesmo enriquecer com práticas classificadas como estelionato. É comum deparar-se na mídia com este termo sendo usado num sentido bastante pejorativo, conotando indissociável relação com o crime e a ilegalidade. Seja nos filmes de Hollywood ou no jornal cotidiano, jovens com grande conhecimento aplicado à fins benignos são apontados como hackers, quando na verdade o termo que ali melhor se encaixaria seria cracker. Surge um novo personagem, este sim usando o conhecimento livre para fins não legais. Mas se assim o é, então o que é um hacker? ","date":"2008-04-15","objectID":"/posts/cultura-hacker/:1:0","tags":["Cultura Hacker","Segurança","Software Livre"],"title":"Cultura Hacker - Tenha Ética E Ganharás Respeito","uri":"/posts/cultura-hacker/"},{"categories":["Impressões"],"content":"A Ética Hacker O finlandês Pekka Himanen, doutorado aos 20 anos em Filosofia na Universidade de Helsínquia, lançou um livro chamado A Ética Hacker e o Espírito da Era da Informação. Segundo ele, hacker é uma pessoa que tem uma paixão por tecnologia e desenvolve ou programa prazerosamente acreditando na filosofia do Software Livre, ou seja que compartilhar informação é um poderoso bem concreto e que seja um dever moral compartilhar a sua perícia facilitando o acesso à informação e a recursos computacionais onde for possível. Explica também que tal termo na verdade é um referente para o Hacker utilizado no início dos anos 60 que nasceu com programadores do MIT - Instituto Tecnológico de Massachusetts, onde a designação é um título nobre para os aficcionados pelo mundo da computação que passavam horas diante da máquina por puro prazer e curiosidade. Segundo Pekka, a origem deste equívoco remontaria a meados dos anos 80, quando surgiram os primeiros crimes computacionais, e a mídia, não sabendo como designar tais criminosos, aplicou o termo de forma um tanto infeliz. Podemos tirar como exemplos de grandes hackers Richard Stallman e Linus Torvalds que foram alguns dos grandes responsáveis pelos fundamentos da Sociedade da Informação, principalmente no quesito de Software Livre, nos últimos 30 anos. Ou seja, a ética hacker está diretamente ligada à Inclusão Digital, pois hackers são os apaixonados que não medem esforços em empregar tempo e esforço para desenvolver formas de tornar, no caso, a Sociedade da Informação mais abrangente em fundamentos e ao mesmo tempo disponibilizar acesso aos mais variados tipos de usuários. Seguindo esta linha de pensamento, os hackers já não são mais os vilões da história, mas sim os mocinhos pois ao analisar-mos alguns dos símbolos mais conhecidos dos tempos atuais como a internet, o computador pessoal e softwares como o sistema operacional Linux, veremos que foram criados por entusiastas trabalhando sileciosamente ou com ajuda de uma comunidade de forma a tentar quebrar padrões trazendo esta gama de evolução que temos hoje trabalhando em um ritmo livre. Sem eles o mundo da informática não seria como o temos hoje por exemplo. Na visão de um hacker, o sentido da vida esta baseado em uma paixão. Esta paixão sendo uma coisa prazerosa, significativa ou inspiradora para o indivíduo, sendo isto chamado de trabalho ou puramente diversão. Mas quando afirmo que o hacker vive de uma paixão, não significa que sua vida seja apenas alegria e felicidade, pois muitas vezes empreende trabalho duro e tédio, porém o mesmo se compromete a fazê-lo tendo em vista o conjunto em si e o resultado que ele conseguirá propiciar a partir daquilo podendo beneficiar toda uma comunidade ou até mesmo a sociedade em geral, ou seja, ele investe esse tempo e esforço visando um bem maior. Mais prazeroso é a perda de tempo com um tédio que envolve uma paixão do que um tédio que envolve uma obrigação ou um trabalho desagradável permanente não é mesmo?! ","date":"2008-04-15","objectID":"/posts/cultura-hacker/:2:0","tags":["Cultura Hacker","Segurança","Software Livre"],"title":"Cultura Hacker - Tenha Ética E Ganharás Respeito","uri":"/posts/cultura-hacker/"},{"categories":["Impressões"],"content":"Dinheiro Mesmo vivendo num mundo atual onde o capitalismo se estabilizou de forma selvagem, para um hacker o dinheiro não é um bem primordial, sendo um quesito secundário para sua sobrevivência. O dinheiro nunca foi e nunca será objetivo de vida ou meta de trabalho de um hacker, tendo que o mesmo se beneficia ou parece satisfazer-se mais em ver que pôde de alguma forma contribuir para um outro indivíduo ou até mesmo uma comunidade. Não importando raça, credo ou nacionalidade, os hackers, em geral, são unidos em um objetivo em comum, provavelmente por meio da internet, que é fazer coisas que acham interessantes e construtivas, nos lembrando então um pouco do movimento hippie dos anos 60. Ainda nos dias de hoje existem cada vez mais pessoas, curiosas, que investem boa parte de sua vida fuçando códigos e sistemas, muitas vezes sem permissões, à nível de estudo e análise prévia, caindo no famoso lema: “Nosso crime é a curiosidade”. Porém, esta onda de curiosidade, ligada à esta má interpretação que tem sido feita durante décadas acerca do termo hacker, fez com que alguns deles debatessem a respeito e então percebendo que não se pode ter muito controle sobre a evolução da língua, o termo que alguns passaram a adotar foi o “geek”, perdendo então boa parte do significado que a palavra hacker realmente trazia consigo, porém por outro lado também não traz a contaminação que vinha sofrendo estas décadas. Alguns aceitam este novo termo, outros, onde eu me encaixo, preferem bater de frente e insistir na fortificação da ideologia hacker, mostrando o verdadeiro sentido do termo e tornando-o claro e conhecido por todos, para que algum dia quem sabe, os hackers sejam tratados com o devido respeito que merecem. ","date":"2008-04-15","objectID":"/posts/cultura-hacker/:3:0","tags":["Cultura Hacker","Segurança","Software Livre"],"title":"Cultura Hacker - Tenha Ética E Ganharás Respeito","uri":"/posts/cultura-hacker/"},{"categories":["Tutoriais"],"content":"Para quem não conhece, brute-force é um ataque bastante utilizado em serviços web tais como smtp, pop, ssh, ftp, iax dentre outros. Se você possui um serviço web ele já sofreu tentativa de ataques brute-force.","date":"0001-01-01","objectID":"/posts/brute-force-o-dirb-lhe/","tags":["Cultura Hacker","Impressões","Linux","Redes","Segurança","Software Livre"],"title":"Brute Force: O Dirb Lhe Ajuda a Identificar Vulnerabilidades Em Seu Site","uri":"/posts/brute-force-o-dirb-lhe/"},{"categories":["Tutoriais"],"content":"Para quem não conhece, brute-force é um ataque bastante utilizado em serviços web tais como smtp, pop, ssh, ftp, iax dentre outros. Se você possui um serviço web ele já sofreu tentativa de ataques brute-force. ","date":"0001-01-01","objectID":"/posts/brute-force-o-dirb-lhe/:0:0","tags":["Cultura Hacker","Impressões","Linux","Redes","Segurança","Software Livre"],"title":"Brute Force: O Dirb Lhe Ajuda a Identificar Vulnerabilidades Em Seu Site","uri":"/posts/brute-force-o-dirb-lhe/"},{"categories":["Tutoriais"],"content":"Brute-Force Para quem não conhece, brute-force é um ataque bastante utilizado em serviços web tais como smtp, pop, ssh, ftp, iax dentre outros. O ataque consiste em basicamente forçar o login em um determinado serviço que esteja disponível online sem que seja necessário um ataque mais sofisticado ou mesmo grandes conhecimentos sobre a tecnologia em questão. Por ser demasiado simples de se utilizar, visto que existem milhares de ferramentas disponíveis na web para este fim, ele acaba se tornando um dos pesadelos mais constantes dos administradores de redes, SysAdmins, etc.. Pois é um fato! Se você possui um serviço web ele já sofreu tentativa de ataques brute-force. Não sofreu? Não se preocupe, sofrerá. ;] Basicamente existem duas formas de brute-force, porém eu prefiro acrescentar uma terceira forma…rude e grosseira, mas infelizmente já vi casos de pessoas que se utilizam dela, então vamos lá. 1- Brute-force puro ou força bruta, como prefiram chamar. É a metodologia mais lenta por testar uma quantidade absurdamente grande de combinações de caracteres de forma aleatória a ponto de tentar descobrir uma senha. Utilizam-se classes como “alfanuméricos”, “numéricos”, “caracteres especiais”, etc. Por exemplo. Supondo que nosso alfabeto fosse composto apenas das letras A, B e C. E alguém possui uma senha para um determinado serviço web. Com uma tentativa de brute-force, eu utilizaria uma ferramenta que geraria todas as combinações possíveis a partir destas 3 letras, o que, ocasionalmente, me daria acesso ao serviço uma vez que, com certeza, eu descobriria a senha, uma hora ou outra. A ferramenta começaria a tentar logar com senhas da seguite forma: A AA AB AC B C BA BB BC C CA CB CC AAB AAC … ACABCAACB … Enfim.. Faria todas as combinações possíveis com estas 3 letras e cedo ou tarde teria sucesso no login, mas… Nosso alfabeto não é tão pequeno assim. E os números? E os caracteres especiais como %, $, #, @, !, “, \u0026, *, (, ), _, -, +, =, etc… Já imaginaram quantas tentativas seriam necessárias para se descobrir uma senha, por exemplo, de 8 caracteres contendo letras, números e caracteres especiais? o.O Quanto mais demorado for o ataque, mais fácil será de detectar o mesmo. Por estas questões ele acaba não sendo a primeira opção para estes ataques. O que nos leva para a outra forma que é a mais utilizada hoje em dia e que tem se provado a mais eficaz, graças a triste realidade global de que as pessoas não possuem uma política eficiente para escolha de suas senhas, acabando por utilizar senhas com palavras reais como: deus, amor, sexo, felicidade, vida, segredo, secreto, etc. 2- Dicionários. Lembra daquela sua senha que faz sentido e você gosta porque é fácil de lembrar? Aquela “deus”, “amor”, “sexo”, “cerveja”, etc. Bom, ela corre grandes riscos se passar por um ataque que se utiliza de dicionários. Ataques com dicionários se resumem ao mesmo ataque de tentativa e erro com o intuito de logar em algum serviço web porém de forma mais coerente e orientada. O dicionário consiste em classes ou arquivos texto com uma sequência de palavras pré-formatadas pelo atacante que serão utilizadas como banco de possíveis senhas, ao invés de simplesmente sair tentando todas as combinações possíveis. Supondo que sua senha seja “cachorro”. Eu lanço o ataque de brute-force utilizando-me de um dicionário de strings, ou palavras, que possui as seguintes: amor deus ceu inferno gato sexo divino futebol cachorro galinha absurdo segredo naodigo … … Como percebem, é uma simples lista de palavras. Porém, notaram que cachorro está na lista? Bom, o meu ataque faria de forma automática tentativas de login com todas estas possíveis senhas até chegar na vez do “cachorro”, que me resultaria em acesso à sua conta, serviço, site, aplicação ou o que quer que estivesse “protegido” com a senha “cachorro”. Imagine a mesma senha cachorro. Já imaginou quantas tentativas seriam necessárias com a outra técnica? A de combinações? Imaginem quantas milhares de combinações seriam nece","date":"0001-01-01","objectID":"/posts/brute-force-o-dirb-lhe/:1:0","tags":["Cultura Hacker","Impressões","Linux","Redes","Segurança","Software Livre"],"title":"Brute Force: O Dirb Lhe Ajuda a Identificar Vulnerabilidades Em Seu Site","uri":"/posts/brute-force-o-dirb-lhe/"},{"categories":["Tutoriais"],"content":"Dirb Dirb é um URL Bruteforcer. Um WCS (Web Content Scanner) que tem a função de buscar por objetos Web Ocultos. Basicamente funciona com o lançamento um ataque baseado em dicionários contra o servidor Web analizando as respostas do mesmo. O principal propósito do Dirb é auditoria em aplicações web. Dentre as funcionalidades avançadas do Dirb destacam-se: _* setar diferentes cookies; adicionar qualquer tipo de HTTP header desejado; utilizar proxys para mascarar a conexão; utilizar catalogos ou arquivos utilizando dicionários definidos ou templates fazendo uma varredura direcionada._ Mas, chega de falatório.. vamos ao teclado… A ferramenta pode ser baixada através do site do projeto: [Dirb](https://sourceforge.net/projects/dirb/. A compilação é simples e sem grandes mistérios. Descompacte o arquivo e compile seguindo os seguintes comandos: tar -xvzf dirb203.tar.gz cd dirb/ ./configure make Pronto. O Dirb está pronto para funcionar. Se você apenas executar o dirb sem nenhum parâmetros lhe serão apresentados os parâmetros deisponíveis para utilização bem como uma descrição dos mesmos: ./dirb ----------------- DIRB v2.03 By The Dark Raver ----------------- ./dirb \u003curl_base\u003e [\u003cwordlist_file(s)\u003e] [options] ./dirb -----------------DIRB v2.03 By The Dark Raver----------------- ./dirb \u003curl_base\u003e [\u003cwordlist_file(s)\u003e] [options] .... .... .... Mas vamos ao uso mais básico. A forma mais simples é utilizando apenas a URL que deseja testar, por exemplo https://www.meulaboratorio.com.br ./dirb https://www.meulaboratorio.com.br ----------------- DIRB v2.03 By The Dark Raver ----------------- START_TIME: Mon Jan 31 10:05:16 2011 URL_BASE: https://www.meulaboratorio.com.br WORDLIST_FILES: wordlists/common.txt ----------------- GENERATED WORDS: 1942 ---- Scanning URL: https://www.meulaboratorio.com.br/ ---- + https://www.meulaboratorio.com.br/A (FOUND: 301 [Moved Permanently] - Size: 241) + https://www.meulaboratorio.com.br/a (FOUND: 200 [Ok] - Size: 419) + https://www.meulaboratorio.com.br/about (FOUND: 301 [Moved Permanently] - Size: 237) + https://www.meulaboratorio.com.br/accessibility/ ==\u003e DIRECTORY + https://www.meulaboratorio.com.br/account (FOUND: 302 [Moved Temporarily] - Size: 227) + https://www.meulaboratorio.com.br/accounts (FOUND: 302 [Moved Temporarily] - Size: 192) + https://www.meulaboratorio.com.br/ad (FOUND: 301 [Moved Permanently] - Size: 223) + https://www.meulaboratorio.com.br/ads/ ==\u003e DIRECTORY ... ... ... Cortei pois o resultado seria muito grande. Mas, como podem ver, ele escaneia a URL por diretórios, arquivos, etc., que podem ser alvos de tentativas de brute-force. No nosso simples caso, vi que foi identificado um diretório chamado accounts. Este diretório já é um alvo que merece ser inspecionado com mais atenção pois as chances de ele conter algo que interesse ao invasor são grandes. Como eu havia dito, o Dirb funciona com dicionários. Como devem ter reparado, eu não setei nenhum dicionário, portanto ele utilizou o dicionário padrão “common”. Mas você pode especificar manualmente qual dicionário deseja utilizar. No diretório dirb, você encontrará um diretório chamado wordlists que conterá os dicionários disponíveis. cd wordlists/ ls big.txt catala.txt common.txt euskera.txt extensions_common.txt indexes.txt mutations_common.txt others small.txt spanish.txt stress vulns Bom, e sobre parâmetros? Vou apresentar apenas algumas possibilidades. Para utilização de um dicionário em específico, basta adicionar o nome do dicionário desejado ao final do comando: ./dirb https://www.meulaboratorio.com.br euskera.txt Para utilização de SSL, apenas inclua o HTTPS na url desejada: ./dirb https://www.meulaboratorio.com.br euskera.tx -i Você também pode utilizar múltiplos dicionários separando-os com vírgulas: ./dirb https://www.meulaboratorio.com.br euskera.txt,common.txt,spanish.txt,big.txt Além disto você pode filtrar sua busca por uma extensão em específico através do parâmetro -X: ./dirb https://www.meulaboratorio.com.br euskera.txt","date":"0001-01-01","objectID":"/posts/brute-force-o-dirb-lhe/:2:0","tags":["Cultura Hacker","Impressões","Linux","Redes","Segurança","Software Livre"],"title":"Brute Force: O Dirb Lhe Ajuda a Identificar Vulnerabilidades Em Seu Site","uri":"/posts/brute-force-o-dirb-lhe/"}]